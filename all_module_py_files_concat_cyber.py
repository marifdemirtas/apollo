#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import subprocess

import sphinx_rtd_theme


on_rtd = os.environ.get('READTHEDOCS', None) == 'True'

if on_rtd:
    subprocess.call('cd ..; doxygen', shell=True)


html_theme = "sphinx_rtd_theme"

html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]


def setup(app):
    app.add_stylesheet("main_stylesheet.css")


extensions = ['breathe', 'recommonmark']
breathe_projects = {'Cyber RT Documents': '../xml'}
templates_path = ['_templates']
html_static_path = ['_static']
source_suffix = {
    '.rst': 'restructuredtext',
    '.md': 'markdown',
}
master_doc = 'index'
project = 'Cyber RT Documents'
copyright = '2019, Apollo'
author = 'Apollo Baidu'

#html_logo = 'quantstack-white.svg'

exclude_patterns = []
highlight_language = 'c++'
pygments_style = 'sphinx'
todo_include_todos = False
htmlhelp_basename = 'CyberRTdoc'
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************

import sys


if sys.version_info[0] < 3:
    sys.stderr.write('''
        You are running Python2 while importing Python3 Cyber wrapper!
        Please change to "import cyber_py.xyz" accordingly.\n''')
    sys.exit(1)
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for init environment."""

import ctypes
import importlib
import os
import sys
import threading
import time

from google.protobuf.descriptor_pb2 import FileDescriptorProto


PY_CALLBACK_TYPE = ctypes.CFUNCTYPE(ctypes.c_int, ctypes.c_char_p)
PY_CALLBACK_TYPE_T = ctypes.CFUNCTYPE(ctypes.c_int, ctypes.c_char_p)

# init vars
wrapper_lib_path = os.path.abspath(os.path.join(os.path.dirname(__file__),
                                                '../internal'))
sys.path.append(wrapper_lib_path)

_CYBER = importlib.import_module('_cyber_wrapper')


##
# @brief init cyber environment.
# @param module_name Used as the log file name.
#
# @return Success is True, otherwise False.
def init(module_name="cyber_py"):
    """
    init cyber environment.
    """
    return _CYBER.py_init(module_name)


def ok():
    """
    is cyber envi ok.
    """
    return _CYBER.py_ok()


def shutdown():
    """
    shutdown cyber envi.
    """
    return _CYBER.py_shutdown()


def is_shutdown():
    """
    is cyber shutdown.
    """
    return _CYBER.py_is_shutdown()


def waitforshutdown():
    """
    wait until the cyber is shutdown.
    """
    return _CYBER.py_waitforshutdown()

# //////////////////////////////class//////////////////////////////


class Writer(object):

    """
    Class for cyber writer wrapper.
    """

    def __init__(self, name, writer, data_type):
        self.name = name
        self.writer = writer
        self.data_type = data_type

    ##
    # @brief write message.
    #
    # @param data is a message type.
    #
    # @return Success is 0, otherwise False.
    def write(self, data):
        """
        writer message string
        """
        return _CYBER.PyWriter_write(self.writer, data.SerializeToString())


class Reader(object):

    """
    Class for cyber reader wrapper.
    """

    def __init__(self, name, reader, data_type):
        self.name = name
        self.reader = reader
        self.data_type = data_type


class Client(object):

    """
    Class for cyber service client wrapper.
    """

    def __init__(self, client, data_type):
        self.client = client
        self.data_type = data_type

    ##
    # @brief send request message to service.
    #
    # @param data is a message type.
    #
    # @return None or response from service.
    def send_request(self, data):
        """
        send request to service
        """
        response_str = _CYBER.PyClient_send_request(
            self.client, data.SerializeToString())
        if len(response_str) == 0:
            return None

        response = self.data_type()
        response.ParseFromString(response_str)
        return response


class Node(object):

    """
    Class for cyber Node wrapper.
    """

    def __init__(self, name):
        self.node = _CYBER.new_PyNode(name)
        self.list_writer = []
        self.list_reader = []
        self.subs = {}
        self.pubs = {}
        self.list_client = []
        self.list_service = []
        self.mutex = threading.Lock()
        self.callbacks = {}
        self.services = {}

    def __del__(self):
        # print("+++ node __del___")
        for writer in self.list_writer:
            _CYBER.delete_PyWriter(writer)
        for reader in self.list_reader:
            _CYBER.delete_PyReader(reader)
        for c in self.list_client:
            _CYBER.delete_PyClient(c)
        for s in self.list_service:
            _CYBER.delete_PyService(s)
        _CYBER.delete_PyNode(self.node)

    ##
    # @brief register proto message by proto descriptor file.
    #
    # @param file_desc object about datatype.DESCRIPTOR.file .
    def register_message(self, file_desc):
        """
        register proto message desc file.
        """
        for dep in file_desc.dependencies:
            self.register_message(dep)
        proto = FileDescriptorProto()
        file_desc.CopyToProto(proto)
        proto.name = file_desc.name
        desc_str = proto.SerializeToString()
        _CYBER.PyNode_register_message(self.node, desc_str)

    ##
    # @brief create a channel writer for send message to another channel.
    #
    # @param name is the channel name.
    # @param data_type is message class for serialization
    # @param qos_depth is a queue size, which defines the size of the cache.
    #
    # @return return the writer object.
    def create_writer(self, name, data_type, qos_depth=1):
        """
        create a channel writer for send message to another channel.
        """
        self.register_message(data_type.DESCRIPTOR.file)
        datatype = data_type.DESCRIPTOR.full_name
        writer = _CYBER.PyNode_create_writer(self.node, name,
                                             datatype, qos_depth)
        self.list_writer.append(writer)
        return Writer(name, writer, datatype)

    def reader_callback(self, name):
        sub = self.subs[name.decode('utf8')]
        msg_str = _CYBER.PyReader_read(sub[0], False)
        if len(msg_str) > 0:
            if sub[3] != "RawData":
                proto = sub[3]()
                proto.ParseFromString(msg_str)
            else:
                # print "read rawdata-> ",sub[3]
                proto = msg_str

            if sub[2] is None:
                sub[1](proto)
            else:
                sub[1](proto, sub[2])
        return 0

    ##
    # @brief create a channel reader for receive message from another channel.
    #
    # @param name the channel name to read.
    # @param data_type  message class for serialization
    # @param callback function to call (fn(data)) when data is received. If
    # args is set, the function must accept the args as a second argument,
    # i.e. fn(data, args)
    # @param args additional arguments to pass to the callback
    #
    # @return return the writer object.
    def create_reader(self, name, data_type, callback, args=None):
        """
        create a channel reader for receive message from another channel.
        """
        self.mutex.acquire()
        if name in self.subs.keys():
            self.mutex.release()
            return None
        self.mutex.release()

        # datatype = data_type.DESCRIPTOR.full_name
        reader = _CYBER.PyNode_create_reader(
            self.node, name, str(data_type))
        if reader is None:
            return None
        self.list_reader.append(reader)
        sub = (reader, callback, args, data_type, False)

        self.mutex.acquire()
        self.subs[name] = sub
        self.mutex.release()
        fun_reader_cb = PY_CALLBACK_TYPE(self.reader_callback)
        self.callbacks[name] = fun_reader_cb
        f_ptr = ctypes.cast(self.callbacks[name], ctypes.c_void_p).value
        _CYBER.PyReader_register_func(reader, f_ptr)

        return Reader(name, reader, data_type)

    def create_rawdata_reader(self, name, callback, args=None):
        """
        Create RawData reader:listener RawMessage
        """
        return self.create_reader(name, "RawData", callback, args)

    ##
    # @brief create client for the c/s.
    #
    # @param name the service name.
    # @param request_data_type the request message type.
    # @param response_data_type the response message type.
    #
    # @return the client object.
    def create_client(self, name, request_data_type, response_data_type):
        datatype = request_data_type.DESCRIPTOR.full_name
        c = _CYBER.PyNode_create_client(self.node, name,
                                        str(datatype))
        self.list_client.append(c)
        return Client(c, response_data_type)

    def service_callback(self, name):
        # Temporary workaround for cyber_py3 examples: service & client
        v = self.services[name.decode("utf-8")]

        msg_str = _CYBER.PyService_read(v[0])
        if (len(msg_str) > 0):
            proto = v[3]()
            proto.ParseFromString(msg_str)
            response = None
            if v[2] is None:
                response = v[1](proto)
            else:
                response = v[1](proto, v[2])
            _CYBER.PyService_write(v[0], response.SerializeToString())
        return 0

    ##
    # @brief create client for the c/s.
    #
    # @param name the service name.
    # @param req_data_type the request message type.
    # @param res_data_type the response message type.
    # @param callback function to call (fn(data)) when data is received. If
    # args is set, the function must accept the args as a second argument,
    # i.e. fn(data, args)
    # @param args additional arguments to pass to the callback.
    #
    # @return return the service object.
    def create_service(self, name, req_data_type, res_data_type, callback,
                       args=None):
        self.mutex.acquire()
        if name in self.services.keys():
            self.mutex.release()
            return None
        self.mutex.release()
        datatype = req_data_type.DESCRIPTOR.full_name
        s = _CYBER.PyNode_create_service(self.node, name, str(datatype))
        self.list_service.append(s)
        v = (s, callback, args, req_data_type, False)
        self.mutex.acquire()
        self.services[name] = v
        self.mutex.release()
        f = PY_CALLBACK_TYPE(self.service_callback)
        self.callbacks[name] = f
        f_ptr = ctypes.cast(f, ctypes.c_void_p).value
        _CYBER.PyService_register_func(s, f_ptr)
        return s

    def spin(self):
        """
        spin for every 0.002s.
        """
        while not _CYBER.py_is_shutdown():
            time.sleep(0.002)


class ChannelUtils(object):

    @staticmethod
    ##
    # @brief Parse rawmsg from rawmsg data by message type.
    #
    # @param msg_type message type.
    # @param rawmsgdata rawmsg data.
    #
    # @return a human readable form of this message. For debugging and
    # other purposes.
    def get_debugstring_rawmsgdata(msg_type, rawmsgdata):
        return _CYBER.PyChannelUtils_get_debugstring_by_msgtype_rawmsgdata(msg_type, rawmsgdata)

    @staticmethod
    ##
    # @brief Parse rawmsg from channel name.
    #
    # @param channel_name channel name.
    # @param sleep_s wait time for topo discovery.
    #
    # @return return the messsage type of this channel.
    def get_msgtype(channel_name, sleep_s=2):
        return _CYBER.PyChannelUtils_get_msg_type(channel_name, sleep_s)

    @staticmethod
    ##
    # @brief Get all active channel names
    #
    # @param sleep_s wait time for topo discovery.
    #
    # @return all active channel names.
    def get_channels(sleep_s=2):
        return _CYBER.PyChannelUtils_get_active_channels(sleep_s)

    @staticmethod
    ##
    # @brief Get the active channel info.
    #
    # @param sleep_s wait time for topo discovery.
    #
    # @return all active channels info. {'channel1':[], 'channel2':[]} .
    def get_channels_info(sleep_s=2):
        return _CYBER.PyChannelUtils_get_channels_info(sleep_s)


class NodeUtils(object):

    @staticmethod
    ##
    # @brief Get all active node names.
    #
    # @param sleep_s wait time for topo discovery.
    #
    # @return all active node names.
    def get_nodes(sleep_s=2):
        return _CYBER.PyNodeUtils_get_active_nodes(sleep_s)

    @staticmethod
    ##
    # @brief Get node attribute by the node name.
    #
    # @param node_name node name.
    # @param sleep_s wait time for topo discovery.
    #
    # @return the node's attribute.
    def get_node_attr(node_name, sleep_s=2):
        return _CYBER.PyNodeUtils_get_node_attr(node_name, sleep_s)

    @staticmethod
    ##
    # @brief Get node's reader channel names
    #
    # @param node_name the node name.
    # @param sleep_s wait time for topo discovery.
    #
    # @return node's reader channel names.
    def get_readersofnode(node_name, sleep_s=2):
        return _CYBER.PyNodeUtils_get_readersofnode(node_name, sleep_s)

    @staticmethod
    ##
    # @brief Get node's writer channel names.
    #
    # @param node_name the node name.
    # @param sleep_s wait time for topo discovery.
    #
    # @return node's writer channel names.
    def get_writersofnode(node_name, sleep_s=2):
        return _CYBER.PyNodeUtils_get_writersofnode(node_name, sleep_s)


class ServiceUtils(object):

    @staticmethod
    ##
    # @brief Get all active service names.
    #
    # @param sleep_s wait time for topo discovery.
    #
    # @return all active service names.
    def get_services(sleep_s=2):
        return _CYBER.PyServiceUtils_get_active_services(sleep_s)

    @staticmethod
    ##
    # @brief Get service attribute by the service name.
    #
    # @param service_name service name.
    # @param sleep_s wait time for topo discovery.
    #
    # @return the service's attribute.
    def get_service_attr(service_name, sleep_s=2):
        return _CYBER.PyServiceUtils_get_service_attr(service_name, sleep_s)
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for init environment."""

import importlib
import os
import sys


# init vars
wrapper_lib_path = os.path.abspath(os.path.join(os.path.dirname(__file__),
                                                '../internal'))
sys.path.append(wrapper_lib_path)

_CYBER = importlib.import_module('_cyber_wrapper')
_CYBER_TIME = importlib.import_module('_cyber_time_wrapper')


class Duration(object):

    """
    Class for cyber Duration wrapper.
    """

    def __init__(self, other):
        if isinstance(other, int):
            self.nanoseconds_ = other
        elif isinstance(other, float):
            self.nanoseconds_ = other * 1000000000
        elif isinstance(other, Duration):
            self.nanoseconds_ = other.nanoseconds_
        self.duration_ = _CYBER_TIME.new_PyDuration(int(self.nanoseconds_))

    def __del__(self):
        _CYBER_TIME.delete_PyDuration(self.duration_)

    def sleep(self):
        """
        sleep for the amount of time specified by the duration.
        """
        _CYBER_TIME.PyDuration_sleep(self.duration_)

    def __str__(self):
        return str(self.nanoseconds_)

    def to_sec(self):
        """
        convert to second.
        """
        return float(self.nanoseconds_) / 1000000000

    def to_nsec(self):
        """
        convert to nanosecond.
        """
        return self.nanoseconds_

    def iszero(self):
        return self.nanoseconds_ == 0

    def __add__(self, other):
        return Duration(self.nanoseconds_ + other.nanoseconds_)

    def __radd__(self, other):
        return Duration(self.nanoseconds_ + other.nanoseconds_)

    def __sub__(self, other):
        return Duration(self.nanoseconds_ - other.nanoseconds_)

    def __lt__(self, other):
        return self.nanoseconds_ < other.nanoseconds_

    def __gt__(self, other):
        return self.nanoseconds_ > other.nanoseconds_

    def __le__(self, other):
        return self.nanoseconds_ <= other.nanoseconds_

    def __ge__(self, other):
        return self.nanoseconds_ >= other.nanoseconds_

    def __eq__(self, other):
        return self.nanoseconds_ == other.nanoseconds_

    def __ne__(self, other):
        return self.nanoseconds_ != other.nanoseconds_


class Time(object):

    """
    Class for cyber time wrapper.
    """

    ##
    # @brief Constructor, creates a Time.
    #
    # @param other float means seconds unit.
    # int means nanoseconds.
    def __init__(self, other):
        nanoseconds = 0
        if isinstance(other, int):
            nanoseconds = other
        elif isinstance(other, float):
            nanoseconds = other * 1000000000
        elif isinstance(other, Time):
            nanoseconds = other.to_nsec()

        self.time = _CYBER_TIME.new_PyTime(int(nanoseconds))

    def __del__(self):
        _CYBER_TIME.delete_PyTime(self.time)

    def __str__(self):
        return str(self.to_nsec())

    def iszero(self):
        return self.to_nsec() == 0

    @staticmethod
    def now():
        """
        return current time.
        """
        # print _CYBER_TIME.PyTime_now()
        # print type(_CYBER_TIME.PyTime_now())
        time_now = Time(_CYBER_TIME.PyTime_now())
        return time_now

    @staticmethod
    def mono_time():
        mono_time = Time(_CYBER_TIME.PyTime_mono_time())
        return mono_time

    def to_sec(self):
        """
        convert to second.
        """
        return _CYBER_TIME.PyTime_to_sec(self.time)

    def to_nsec(self):
        """
        convert to nanosecond.
        """
        return _CYBER_TIME.PyTime_to_nsec(self.time)

    def sleep_until(self, cyber_time):
        """
        sleep until time.
        """
        if isinstance(time, Time):
            return _CYBER_TIME.PyTime_sleep_until(self.time,
                                                  cyber_time.to_nsec())
        return NotImplemented

    def __sub__(self, other):
        if isinstance(other, Time):
            return Duration(self.to_nsec() - other.to_nsec())
        else:
            isinstance(other, Duration)
            return Time(self.to_nsec() - other.to_nsec())

    def __add__(self, other):
        return Time(self.to_nsec() + other.to_nsec())

    def __radd__(self, other):
        return Time(self.to_nsec() + other.to_nsec())

    def __lt__(self, other):
        return self.to_nsec() < other.to_nsec()

    def __gt__(self, other):
        return self.to_nsec() > other.to_nsec()

    def __le__(self, other):
        return self.to_nsec() <= other.to_nsec()

    def __ge__(self, other):
        return self.to_nsec() >= other.to_nsec()

    def __eq__(self, other):
        return self.to_nsec() == other.to_nsec()

    def __ne__(self, other):
        return self.to_nsec() != other.to_nsec()


class Rate(object):

    """
    Class for cyber Rate wrapper. Help run loops at a desired frequency.
    """

    ##
    # @brief Constructor, creates a Rate.
    #
    # @param other float means frequency the desired rate to run at in Hz.
    # int means the expected_cycle_time.
    def __init__(self, other):
        if isinstance(other, int):
            self.rate_ = _CYBER_TIME.new_PyRate(other)
        elif isinstance(other, float):
            self.rate_ = _CYBER_TIME.new_PyRate(int(1.0 / other))
        elif isinstance(other, Duration):
            self.rate_ = _CYBER_TIME.new_PyRate(other.to_nsec())

    def __del__(self):
        _CYBER_TIME.delete_PyRate(self.rate_)

    def __str__(self):
        return "cycle_time = %s, exp_cycle_time = %s" % (str(self.get_cycle_time()), str(self.get_expected_cycle_time()))

    def sleep(self):
        """
        Sleeps for any leftover time in a cycle.
        """
        _CYBER_TIME.PyRate_sleep(self.rate_)

    def reset(self):
        """
        Sets the start time for the rate to now.
        """
        _CYBER_TIME.PyRate_PyRate_reset(self.rate_)

    def get_cycle_time(self):
        """
        Get the actual run time of a cycle from start to sleep.
        """
        return Duration(_CYBER_TIME.PyRate_get_cycle_time(self.rate_))

    def get_expected_cycle_time(self):
        """
        Get the expected cycle time.
        """
        return Duration(_CYBER_TIME.PyRate_get_expected_cycle_time(self.rate_))
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for init environment."""

import ctypes
import importlib
import os
import sys


PY_TIMER_CB_TYPE = ctypes.CFUNCTYPE(ctypes.c_void_p)

# init vars
wrapper_lib_path = os.path.abspath(os.path.join(os.path.dirname(__file__),
                                                '../internal'))
sys.path.append(wrapper_lib_path)

_CYBER_TIMER = importlib.import_module('_cyber_timer_wrapper')


class Timer(object):

    """
    Class for cyber timer wrapper.
    """

    ##
    # @brief Used to perform oneshot or periodic timing tasks
    #
    # @param period The period of the timer, unit is ms.
    # @param callback The tasks that the timer needs to perform.
    # @param oneshot 1:perform the callback only after the first timing cycle
    # 0:perform the callback every timed period
    def __init__(self, period=None, callback=None, oneshot=None):
        if period is None and callback is None and oneshot is None:
            self.timer = _CYBER_TIMER.new_PyTimer_noparam()
        else:
            self.timer_cb = PY_TIMER_CB_TYPE(callback)
            self.f_ptr_cb = ctypes.cast(self.timer_cb, ctypes.c_void_p).value
            self.timer = _CYBER_TIMER.new_PyTimer(
                period, self.f_ptr_cb, oneshot)

    def __del__(self):
        _CYBER_TIMER.delete_PyTimer(self.timer)

    ##
    # @brief set the option of timer.
    #
    # @param period The period of the timer, unit is ms.
    # @param callback The tasks that the timer needs to perform.
    # @param oneshot 1:perform the callback only after the first timing cycle
    # 0:perform the callback every timed period
    def set_option(self, period, callback, oneshot=0):
        self.timer_cb = PY_TIMER_CB_TYPE(callback)
        self.f_ptr_cb = ctypes.cast(self.timer_cb, ctypes.c_void_p).value
        _CYBER_TIMER.PyTimer_set_option(
            self.timer, period, self.f_ptr_cb, oneshot)

    ##
    # @brief start the timer
    def start(self):
        _CYBER_TIMER.PyTimer_start(self.timer)

    ##
    # @brief stop the timer
    def stop(self):
        _CYBER_TIMER.PyTimer_stop(self.timer)
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for example of listener."""

import time

from cyber.python.cyber_py3 import cyber
from cyber.proto.unit_test_pb2 import ChatterBenchmark


def test_client_class():
    """
    Client send request
    """
    node = cyber.Node("client_node")
    client = node.create_client("server_01", ChatterBenchmark, ChatterBenchmark)
    req = ChatterBenchmark()
    req.content = "clt:Hello service!"
    req.seq = 0
    count = 0
    while not cyber.is_shutdown():
        time.sleep(1)
        count += 1
        req.seq = count
        print("-" * 80)
        response = client.send_request(req)
        print("get Response [ ", response, " ]")


if __name__ == '__main__':
    cyber.init()
    test_client_class()
    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for example of listener."""

from cyber.python.cyber_py3 import cyber
from cyber.proto.unit_test_pb2 import ChatterBenchmark


def callback(data):
    """
    Reader message callback.
    """
    print("=" * 80)
    print("py:reader callback msg->:")
    print(data)
    print("=" * 80)


def test_listener_class():
    """
    Reader message.
    """
    print("=" * 120)
    test_node = cyber.Node("listener")
    test_node.create_reader("channel/chatter", ChatterBenchmark, callback)
    test_node.spin()


if __name__ == '__main__':
    cyber.init()
    test_listener_class()
    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for example of parameter."""

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import parameter


PARAM_SERVICE_NAME = "global_parameter_service"


def print_param_srv():
    param1 = parameter.Parameter("author_name", "WanderingEarth")
    param2 = parameter.Parameter("author_age", 5000)
    param3 = parameter.Parameter("author_score", 888.88)

    test_node = cyber.Node(PARAM_SERVICE_NAME)
    srv = parameter.ParameterServer(test_node)

    node_handle = cyber.Node("service_client_node")
    clt = parameter.ParameterClient(test_node, PARAM_SERVICE_NAME)
    clt.set_parameter(param1)
    clt.set_parameter(param2)
    clt.set_parameter(param3)

    param_list = clt.get_paramslist()
    print("clt param lst len is ", len(param_list))
    for param in param_list:
        print(param.debug_string())

    print("")
    param_list = srv.get_paramslist()
    print("srv param lst len is ", len(param_list))
    for param in param_list:
        print(param.debug_string())


if __name__ == '__main__':
    cyber.init()
    print_param_srv()
    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""
Module for example of record.

Run with:
    bazel run //cyber/python/cyber_py3/examples:record
"""

import time

from google.protobuf.descriptor_pb2 import FileDescriptorProto

from cyber.proto.unit_test_pb2 import Chatter
from cyber.python.cyber_py3 import record
from modules.common.util.testdata.simple_pb2 import SimpleMessage


MSG_TYPE = "apollo.common.util.test.SimpleMessage"
MSG_TYPE_CHATTER = "apollo.cyber.proto.Chatter"


def test_record_writer(writer_path):
    """
    Record writer.
    """
    fwriter = record.RecordWriter()
    fwriter.set_size_fileseg(0)
    fwriter.set_intervaltime_fileseg(0)

    if not fwriter.open(writer_path):
        print('Failed to open record writer!')
        return
    print('+++ Begin to writer +++')

    # Writer 2 SimpleMessage
    msg = SimpleMessage()
    msg.text = "AAAAAA"

    file_desc = msg.DESCRIPTOR.file
    proto = FileDescriptorProto()
    file_desc.CopyToProto(proto)
    proto.name = file_desc.name
    desc_str = proto.SerializeToString()
    print(msg.DESCRIPTOR.full_name)
    fwriter.write_channel(
        'simplemsg_channel', msg.DESCRIPTOR.full_name, desc_str)
    fwriter.write_message('simplemsg_channel', msg, 990, False)
    fwriter.write_message('simplemsg_channel', msg.SerializeToString(), 991)

    # Writer 2 Chatter
    msg = Chatter()
    msg.timestamp = 99999
    msg.lidar_timestamp = 100
    msg.seq = 1

    file_desc = msg.DESCRIPTOR.file
    proto = FileDescriptorProto()
    file_desc.CopyToProto(proto)
    proto.name = file_desc.name
    desc_str = proto.SerializeToString()
    print(msg.DESCRIPTOR.full_name)
    fwriter.write_channel('chatter_a', msg.DESCRIPTOR.full_name, desc_str)
    fwriter.write_message('chatter_a', msg, 992, False)
    msg.seq = 2
    fwriter.write_message("chatter_a", msg.SerializeToString(), 993)

    fwriter.close()


def test_record_reader(reader_path):
    """
    Record reader.
    """
    freader = record.RecordReader(reader_path)
    time.sleep(1)
    print('+' * 80)
    print('+++ Begin to read +++')
    count = 0
    for channel_name, msg, datatype, timestamp in freader.read_messages():
        count += 1
        print('=' * 80)
        print('read [%d] messages' % count)
        print('channel_name -> %s' % channel_name)
        print('msgtime -> %d' % timestamp)
        print('msgnum -> %d' % freader.get_messagenumber(channel_name))
        print('msgtype -> %s' % datatype)
        print('message is -> %s' % msg)
        print('***After parse(if needed),the message is ->')
        if datatype == MSG_TYPE:
            msg_new = SimpleMessage()
            msg_new.ParseFromString(msg)
            print(msg_new)
        elif datatype == MSG_TYPE_CHATTER:
            msg_new = Chatter()
            msg_new.ParseFromString(msg)
            print(msg_new)


if __name__ == '__main__':
    test_record_file = "/tmp/test_writer.record"

    print('Begin to write record file: {}'.format(test_record_file))
    test_record_writer(test_record_file)

    print('Begin to read record file: {}'.format(test_record_file))
    test_record_reader(test_record_file)
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for example of record."""

import sys

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record
from cyber.proto import record_pb2


def print_channel_info(file_path):
    freader = record.RecordReader(file_path)
    channels = freader.get_channellist()

    header_msg = freader.get_headerstring()
    header = record_pb2.Header()
    header.ParseFromString(header_msg)

    print('\n++++++++++++Begin Channel Info Statistics++++++++++++++')
    print('-' * 40)
    print(
        'record version: [%d:%d]' %
        (header.major_version, header.minor_version))
    print('record message_number: %s' % str(header.message_number))
    print('record file size(Byte): %s' % str(header.size))
    print('chunk_number: %d' % header.chunk_number)
    print('channel count: %d' % len(channels))
    print('-' * 40)
    count = 0
    for channel in channels:
        desc = freader.get_protodesc(channel)
        count += 1
        print(
            'Channel: %s, count: %d, desc size: %d' %
            (channel, count, len(desc)))
        # print(desc)
    print("++++++++++++Finish Channel Info Statistics++++++++++++++\n")


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print('Usage: %s record_file' % sys.argv[0])
        sys.exit(0)

    cyber.init()
    print_channel_info(sys.argv[1])
    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for example of record trans."""

import sys

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record


TEST_RECORD_FILE = "trans_ret.record"


def test_record_trans(reader_path):
    """
    Record trans.
    """
    fwriter = record.RecordWriter()
    if not fwriter.open(TEST_RECORD_FILE):
        print('Failed to open record writer!')
        return
    print('+++ Begin to trans +++')

    fread = record.RecordReader(reader_path)
    count = 0
    for channelname, msg, datatype, timestamp in fread.read_messages():
        # print channelname, timestamp, fread.get_messagenumber(channelname)
        desc = fread.get_protodesc(channelname)
        fwriter.write_channel(channelname, datatype, desc)
        fwriter.write_message(channelname, msg, timestamp)
        count += 1
    print('-' * 80)
    print('Message count: %d' % count)
    print('Channel info: ')
    channel_list = fread.get_channellist()
    print('Channel count: %d' % len(channel_list))
    print(channel_list)


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print('Usage: %s record_file' % sys.argv[0])
        sys.exit(0)

    cyber.init()
    test_record_trans(sys.argv[1])
    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for example of listener."""

from cyber.python.cyber_py3 import cyber
from cyber.proto.unit_test_pb2 import ChatterBenchmark


def callback(data):
    print("-" * 80)
    print("get Request [ ", data, " ]")
    return ChatterBenchmark(content="svr: Hello client!", seq=data.seq + 2)


def test_service_class():
    """
    Reader message.
    """
    print("=" * 120)
    node = cyber.Node("service_node")
    r = node.create_service(
        "server_01", ChatterBenchmark, ChatterBenchmark, callback)
    node.spin()


if __name__ == '__main__':
    cyber.init()
    test_service_class()
    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for example of talker."""

import time

from cyber.python.cyber_py3 import cyber
from cyber.proto.unit_test_pb2 import ChatterBenchmark


def test_talker_class():
    """
    Test talker.
    """
    msg = ChatterBenchmark()
    msg.content = "py:talker:send Alex!"
    msg.stamp = 9999
    msg.seq = 0
    print(msg)
    test_node = cyber.Node("node_name1")
    g_count = 1

    writer = test_node.create_writer("channel/chatter", ChatterBenchmark, 6)
    while not cyber.is_shutdown():
        time.sleep(1)
        g_count = g_count + 1
        msg.seq = g_count
        msg.content = "I am python talker."
        print("=" * 80)
        print("write msg -> %s" % msg)
        writer.write(msg)


if __name__ == '__main__':
    cyber.init("talker_sample")
    test_talker_class()
    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for example of cyber time."""

import time

from cyber.python.cyber_py3 import cyber_time


def test_time():
    ct = cyber_time.Time(123)
    print(ct.to_nsec())
    ftime = ct.now().to_sec()
    print(ftime)
    time.sleep(1)
    ftime = cyber_time.Time.now().to_sec()
    print(ftime)
    ftime = cyber_time.Time.mono_time().to_sec()
    print(ftime)

    td1 = cyber_time.Duration(111)
    tm1 = ct - td1
    print("ct sub du is ", tm1)
    tm1 = ct - td1
    print(tm1)

    tm5 = cyber_time.Time(1.8)
    tm7 = cyber_time.Time(tm5)
    print(tm7)


def test_duration():
    td1 = cyber_time.Duration(111)
    td2 = cyber_time.Duration(601000000000)
    td3 = td2 - td1
    print(td1, td1.to_nsec())
    print(td2, td2.to_nsec())
    print(td3, td3.to_nsec())
    print(td2.to_sec())
    print(td2.iszero())
    print(str(td2))
    td5 = cyber_time.Duration(1.8)
    td6 = td5
    print(type(td6))
    td7 = cyber_time.Duration(td6)
    print(td7)
    # td7 = cyber_time.Duration("zzz")
    # print(td7)
    # print(type(td2))


def test_rate():
    rt1 = cyber_time.Rate(111)
    rt2 = cyber_time.Rate(0.2)
    rt3 = cyber_time.Rate(cyber_time.Duration(666))
    print(rt1)
    print(rt2)
    print(rt3)


if __name__ == '__main__':
    print("test time", "-" * 50)
    test_time()
    print("test duration", "-" * 50)
    test_duration()
    print("test rate", "-" * 50)
    test_rate()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************

"""Module for example of timer."""

import time

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_timer


count = 0


def fun():
    global count
    print("cb fun is called:", count)
    count += 1


def test_timer():
    cyber.init()
    ct = cyber_timer.Timer(10, fun, 0)  # 10ms
    ct.start()
    time.sleep(1)  # 1s
    ct.stop()

    print("+" * 80, "test set_option")
    ct2 = cyber_timer.Timer()  # 10ms
    ct2.set_option(10, fun, 0)
    ct2.start()
    time.sleep(1)  # 1s
    ct2.stop()

    cyber.shutdown()


if __name__ == '__main__':
    test_timer()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for init environment."""

import importlib
import os
import sys


# init vars
CYBER_PATH = os.environ.get('CYBER_PATH', '/apollo/cyber')
CYBER_DIR = os.path.split(CYBER_PATH)[0]
wrapper_lib_path = os.path.abspath(os.path.join(os.path.dirname(__file__),
                                                '../internal'))
sys.path.append(wrapper_lib_path)

_CYBER_PARAM = importlib.import_module('_cyber_parameter_wrapper')


class Parameter(object):

    """
    Class for Parameter wrapper.
    """

    def __init__(self, name, value=None):
        if (name is not None and value is None):
            self.param = name
        elif (name is None and value is None):
            self.param = _CYBER_PARAM.new_PyParameter_noparam()
        elif isinstance(value, int):
            self.param = _CYBER_PARAM.new_PyParameter_int(name, value)
        elif isinstance(value, float):
            self.param = _CYBER_PARAM.new_PyParameter_double(name, value)
        elif isinstance(value, str):
            self.param = _CYBER_PARAM.new_PyParameter_string(name, value)
        else:
            print("type is not supported: ", type(value))

    def __del__(self):
        _CYBER_PARAM.delete_PyParameter(self.param)

    def type_name(self):
        """
        return Parameter typename
        """
        return _CYBER_PARAM.PyParameter_type_name(self.param)

    def descriptor(self):
        """
        return Parameter descriptor
        """
        return _CYBER_PARAM.PyParameter_descriptor(self.param)

    def name(self):
        """
        return Parameter name
        """
        return _CYBER_PARAM.PyParameter_name(self.param)

    def debug_string(self):
        """
        return Parameter debug string
        """
        return _CYBER_PARAM.PyParameter_debug_string(self.param)

    def as_string(self):
        """
        return native value
        """
        return _CYBER_PARAM.PyParameter_as_string(self.param)

    def as_double(self):
        """
        return native value
        """
        return _CYBER_PARAM.PyParameter_as_double(self.param)

    def as_int64(self):
        """
        return native value
        """
        return _CYBER_PARAM.PyParameter_as_int64(self.param)


class ParameterClient(object):

    """
    Class for ParameterClient wrapper.
    """

    ##
    # @brief constructor the ParameterClient by a node and the parameter server node name.
    #
    # @param node a node to create client.
    # @param server_node_name the parameter server's node name.
    def __init__(self, node, server_node_name):
        self.param_clt = _CYBER_PARAM.new_PyParameterClient(
            node.node, server_node_name)

    def __del__(self):
        _CYBER_PARAM.delete_PyParameterClient(self.param_clt)

    def set_parameter(self, param):
        """
        set parameter, param is Parameter.
        """
        return _CYBER_PARAM.PyParameter_clt_set_parameter(self.param_clt, param.param)

    def get_parameter(self, param_name):
        """
        get Parameter by param name param_name.
        """
        return Parameter(_CYBER_PARAM.PyParameter_clt_get_parameter(self.param_clt, param_name))

    def get_paramslist(self):
        """
        get all params of the server_node_name parameterserver.
        """
        pycapsulelist = _CYBER_PARAM.PyParameter_clt_get_parameter_list(
            self.param_clt)
        param_list = []
        for capsuleobj in pycapsulelist:
            param_list.append(Parameter(capsuleobj))
        return param_list


class ParameterServer(object):

    """
    Class for ParameterServer wrapper.
    """

    ##
    # @brief constructor the ParameterServer by the node object.
    #
    # @param node the node to support the parameter server.
    def __init__(self, node):
        self.param_srv = _CYBER_PARAM.new_PyParameterServer(node.node)

    def __del__(self):
        _CYBER_PARAM.delete_PyParameterServer(self.param_srv)

    def set_parameter(self, param):
        """
        set parameter, param is Parameter.
        """
        return _CYBER_PARAM.PyParameter_srv_set_parameter(self.param_srv, param.param)

    def get_parameter(self, param_name):
        """
        get Parameter by param name param_name.
        """
        return Parameter(_CYBER_PARAM.PyParameter_srv_get_parameter(self.param_srv, param_name))

    def get_paramslist(self):
        """
        get all params of this parameterserver.
        """
        pycapsulelist = _CYBER_PARAM.PyParameter_srv_get_parameter_list(
            self.param_srv)
        param_list = []
        for capsuleobj in pycapsulelist:
            param_list.append(Parameter(capsuleobj))
        return param_list
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for wrapper cyber record."""

import collections
import importlib
import os
import sys

from google.protobuf.descriptor_pb2 import FileDescriptorProto

# Refer to the _cyber_record_wrapper.so with relative path so that it can be
# always addressed as a part of the runfiles.
wrapper_lib_path = os.path.abspath(os.path.join(os.path.dirname(__file__),
                                                '../internal'))
sys.path.append(wrapper_lib_path)

_CYBER_RECORD = importlib.import_module('_cyber_record_wrapper')
PyBagMessage = collections.namedtuple('PyBagMessage',
                                      'topic message data_type timestamp')


class RecordReader(object):

    """
    Class for cyber RecordReader wrapper.
    """

    ##
    # @brief the constructor function.
    #
    # @param file_name the record file name.
    def __init__(self, file_name):
        self.record_reader = _CYBER_RECORD.new_PyRecordReader(file_name)

    def __del__(self):
        _CYBER_RECORD.delete_PyRecordReader(self.record_reader)

    ##
    # @brief Read message from bag file.
    #
    # @param start_time the start time to read.
    # @param end_time the end time to read.
    #
    # @return return (channnel, data, data_type, timestamp)
    def read_messages(self, start_time=0, end_time=18446744073709551615):
        while True:
            message = _CYBER_RECORD.PyRecordReader_ReadMessage(
                self.record_reader, start_time, end_time)

            if not message["end"]:
                yield PyBagMessage(message["channel_name"], message["data"],
                                   message["data_type"], message["timestamp"])
            else:
                # print "No message more."
                break

    ##
    # @brief Return message count of the channel in current record file.
    #
    # @param channel_name the channel name.
    #
    # @return return the message count.
    def get_messagenumber(self, channel_name):
        return _CYBER_RECORD.PyRecordReader_GetMessageNumber(
            self.record_reader, channel_name)

    ##
    # @brief Get the corresponding message type of channel.
    #
    # @param channel_name channel name.
    #
    # @return return the name of ther string type.
    def get_messagetype(self, channel_name):
        return _CYBER_RECORD.PyRecordReader_GetMessageType(
            self.record_reader, channel_name).decode('utf-8')

    def get_protodesc(self, channel_name):
        """
        Return message protodesc.
        """
        return _CYBER_RECORD.PyRecordReader_GetProtoDesc(
            self.record_reader, channel_name)

    def get_headerstring(self):
        """
        Return message header string.
        """
        return _CYBER_RECORD.PyRecordReader_GetHeaderString(self.record_reader)

    def reset(self):
        """
        Return reset.
        """
        return _CYBER_RECORD.PyRecordReader_Reset(self.record_reader)

    def get_channellist(self):
        """
        Return current channel names list.
        """
        return _CYBER_RECORD.PyRecordReader_GetChannelList(self.record_reader)


class RecordWriter(object):

    """
    Class for cyber RecordWriter wrapper.
    """

    ##
    # @brief the constructor function.
    #
    # @param file_segmentation_size_kb size to segment the file, 0 is no segmentation.
    # @param file_segmentation_interval_sec size to segment the file, 0 is no segmentation.
    def __init__(self, file_segmentation_size_kb=0,
                 file_segmentation_interval_sec=0):
        self.record_writer = _CYBER_RECORD.new_PyRecordWriter()
        _CYBER_RECORD.PyRecordWriter_SetSizeOfFileSegmentation(
            self.record_writer, file_segmentation_size_kb)
        _CYBER_RECORD.PyRecordWriter_SetIntervalOfFileSegmentation(
            self.record_writer, file_segmentation_interval_sec)

    def __del__(self):
        _CYBER_RECORD.delete_PyRecordWriter(self.record_writer)

    ##
    # @brief Open record file for write.
    #
    # @param path the file path.
    #
    # @return Success is True, other False.
    def open(self, path):
        return _CYBER_RECORD.PyRecordWriter_Open(self.record_writer, path)

    ##
    # @brief Close record file.
    def close(self):
        """
        Close record file.
        """
        _CYBER_RECORD.PyRecordWriter_Close(self.record_writer)

    ##
    # @brief Writer channel by channelname, typename, protodesc.
    #
    # @param channel_name the channel name to write
    # @param type_name a string of message type name.
    # @param proto_desc the message descriptor.
    #
    # @return Success is True, other False.
    def write_channel(self, channel_name, type_name, proto_desc):
        """
        Writer channel by channelname,typename,protodesc
        """
        return _CYBER_RECORD.PyRecordWriter_WriteChannel(
            self.record_writer, channel_name, type_name, proto_desc)

    ##
    # @brief Writer msg: channelname, data, writer time.
    #
    # @param channel_name channel name to write.
    # @param data when raw is True, data processed as a rawdata, other it needs to SerializeToString
    # @param time message time.
    # @param raw the flag implies data whether or not a rawdata.
    #
    # @return Success is True, other False.
    def write_message(self, channel_name, data, time, raw=True):
        """
        Writer msg:channelname,rawmsg,writer time
        """
        if raw:
            return _CYBER_RECORD.PyRecordWriter_WriteMessage(
                self.record_writer, channel_name, data, time, "")

        file_desc = data.DESCRIPTOR.file
        proto = FileDescriptorProto()
        file_desc.CopyToProto(proto)
        proto.name = file_desc.name
        desc_str = proto.SerializeToString()
        return _CYBER_RECORD.PyRecordWriter_WriteMessage(
            self.record_writer,
            channel_name, data.SerializeToString(), time, desc_str)

    def set_size_fileseg(self, size_kilobytes):
        """
        Return filesegment size.
        """
        return _CYBER_RECORD.PyRecordWriter_SetSizeOfFileSegmentation(
            self.record_writer, size_kilobytes)

    def set_intervaltime_fileseg(self, time_sec):
        """
        Return file interval time.
        """
        return _CYBER_RECORD.PyRecordWriter_SetIntervalOfFileSegmentation(
            self.record_writer, time_sec)

    def get_messagenumber(self, channel_name):
        """
        Return message count.
        """
        return _CYBER_RECORD.PyRecordWriter_GetMessageNumber(
            self.record_writer, channel_name)

    def get_messagetype(self, channel_name):
        """
        Return message type.
        """
        return _CYBER_RECORD.PyRecordWriter_GetMessageType(
            self.record_writer, channel_name).decode('utf-8')

    def get_protodesc(self, channel_name):
        """
        Return message protodesc.
        """
        return _CYBER_RECORD.PyRecordWriter_GetProtoDesc(
            self.record_writer, channel_name)
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for test cyber."""

import time
import unittest

from cyber.python.cyber_py3 import cyber
from modules.common.util.testdata.simple_pb2 import SimpleMessage


class TestCyber(unittest.TestCase):
    """
    Class for node unit test.
    """
    @staticmethod
    def callback(data):
        """
        Reader callback.
        """
        print("=" * 80)
        print("py:reader callback msg->:")
        print(data)
        print("=" * 80)

    def test_read_write(self):
        """
        Unit test of reader.
        """
        self.assertTrue(cyber.ok())
        # Read.
        reader_node = cyber.Node("listener")
        reader = reader_node.create_reader("channel/chatter",
                                           SimpleMessage, self.callback)
        self.assertEqual(reader.name, "channel/chatter")
        self.assertEqual(reader.data_type, SimpleMessage)
        self.assertEqual(SimpleMessage.DESCRIPTOR.full_name,
                         "apollo.common.util.test.SimpleMessage")

        # Write.
        msg = SimpleMessage()
        msg.text = "talker:send Alex!"
        msg.integer = 0

        self.assertTrue(cyber.ok())
        writer_node = cyber.Node("writer")
        writer = writer_node.create_writer("channel/chatter", SimpleMessage, 7)
        self.assertEqual(writer.name, "channel/chatter")
        self.assertEqual(
            writer.data_type, "apollo.common.util.test.SimpleMessage")
        self.assertTrue(writer.write(msg))

        # Wait for data to be processed by callback function.
        time.sleep(0.1)


if __name__ == '__main__':
    cyber.init()
    unittest.main()
    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for test cyber_time."""

import time
import unittest

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time


class TestTime(unittest.TestCase):

    """
    Class for node unit test.
    """
    @classmethod
    def setUpClass(cls):
        cyber.init()

    @classmethod
    def tearDownClass(cls):
        cyber.shutdown()

    def test_time(self):
        ct = cyber_time.Time(123)
        self.assertEqual(123, ct.to_nsec())
        ftime = ct.now().to_sec()
        print(ftime)
        time.sleep(1)
        ftime = cyber_time.Time.now().to_sec()
        print(ftime)
        ftime = cyber_time.Time.mono_time().to_sec()
        print(ftime)

        td1 = cyber_time.Duration(111)
        tm1 = ct - td1
        self.assertEqual(12, tm1.to_nsec())

        tm5 = cyber_time.Time(1.8)
        self.assertFalse(tm5.iszero())
        self.assertEqual(1800000000, tm5.to_nsec())
        tm7 = cyber_time.Time(tm5)
        self.assertEqual(1800000000, tm7.to_nsec())

    def test_duration(self):
        td1 = cyber_time.Duration(111)
        td2 = cyber_time.Duration(601000000000)
        td3 = td2 - td1
        self.assertEqual(111, td1.to_nsec())
        self.assertEqual(601000000000, td2.to_nsec())
        self.assertEqual(601000000000 - 111, td3.to_nsec())

        print(td2.to_sec())
        self.assertEqual(601.0, td2.to_sec())
        self.assertFalse(td2.iszero())
        print(str(td2))
        td5 = cyber_time.Duration(1.8)
        td6 = td5
        print(type(td6))
        self.assertTrue(isinstance(td6, cyber_time.Duration))

    def test_rate(self):
        rt1 = cyber_time.Rate(111)
        self.assertEqual(0, rt1.get_cycle_time().to_nsec())
        self.assertEqual(111, rt1.get_expected_cycle_time().to_nsec())
        rt2 = cyber_time.Rate(0.2)
        self.assertEqual(0, rt2.get_cycle_time().to_nsec())
        self.assertEqual(5, rt2.get_expected_cycle_time().to_nsec())
        rt3 = cyber_time.Rate(cyber_time.Duration(666))
        self.assertEqual(0, rt3.get_cycle_time().to_nsec())
        self.assertEqual(666, rt3.get_expected_cycle_time().to_nsec())


if __name__ == '__main__':
    unittest.main()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************

"""Module for test cyber timer."""

import time
import unittest

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_timer


class TestCyberTimer(unittest.TestCase):
    """
    Class for cyber timer unit test.
    """

    count = 0

    @classmethod
    def setUpClass(cls):
        cyber.init()

    @classmethod
    def tearDownClass(cls):
        cyber.shutdown()

    def func(cls):
        print('Callback function is called [%d] times.' % cls.count)
        cls.count += 1

    def test_timer(self):
        ct = cyber_timer.Timer(100, self.func, 0)  # 100ms
        ct.start()
        time.sleep(1)  # 1s
        ct.stop()

        print('+' * 40 + 'test set_option' + '+' * 40)
        ct2 = cyber_timer.Timer()  # 10ms
        ct2.set_option(100, self.func, 0)
        ct2.start()
        time.sleep(1)  # 1s
        ct2.stop()


if __name__ == '__main__':
    unittest.main()
    # TODO(xiaoxq): It crashes here.
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for test init."""

import unittest

from cyber.python.cyber_py3 import cyber

class TestInit(unittest.TestCase):

    """
    Class for init unit test.
    """

    def test_init(self):
        """
        Test cyber.
        """
        self.assertTrue(cyber.init())
        self.assertTrue(cyber.ok())
        cyber.shutdown()
        self.assertTrue(cyber.is_shutdown())


if __name__ == '__main__':
    unittest.main()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for test node."""

import time
import unittest

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import parameter


PARAM_SERVICE_NAME = "global_parameter_service"


class TestParams(unittest.TestCase):

    """
    Class for node unit test.
    """
    @classmethod
    def setUpClass(cls):
        cyber.init()

    @classmethod
    def tearDownClass(cls):
        cyber.shutdown()

    def test_params(self):
        param1 = parameter.Parameter("author_name", "WanderingEarth")
        param2 = parameter.Parameter("author_age", 5000)
        param3 = parameter.Parameter("author_score", 888.88)

        test_node = cyber.Node(PARAM_SERVICE_NAME)
        srv = parameter.ParameterServer(test_node)

        node_handle = cyber.Node("service_client_node")
        clt = parameter.ParameterClient(test_node, PARAM_SERVICE_NAME)
        clt.set_parameter(param1)
        clt.set_parameter(param2)
        clt.set_parameter(param3)

        param_list = clt.get_paramslist()
        self.assertEqual(3, len(param_list))
        param_list = srv.get_paramslist()
        self.assertEqual(3, len(param_list))


if __name__ == '__main__':
    unittest.main()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
"""Module for test record."""

import unittest

from cyber.proto import record_pb2
from cyber.python.cyber_py3 import record
from modules.common.util.testdata.simple_pb2 import SimpleMessage


TEST_RECORD_FILE = "/tmp/test02.record"
CHAN_1 = "channel/chatter"
MSG_TYPE = "apollo.common.util.test.SimpleMessage"
PROTO_DESC = b"1234567890"
MSG_DATA = b"0123456789"
TIME = 999


class TestRecord(unittest.TestCase):

    """
    Class for record unit test.
    """

    def test_record_writer_read(self):
        """
        unit test of record.
        """
        # writer
        fwriter = record.RecordWriter()
        fwriter.set_size_fileseg(0)
        fwriter.set_intervaltime_fileseg(0)

        self.assertTrue(fwriter.open(TEST_RECORD_FILE))
        fwriter.write_channel(CHAN_1, MSG_TYPE, PROTO_DESC)
        fwriter.write_message(CHAN_1, MSG_DATA, TIME)

        self.assertEqual(1, fwriter.get_messagenumber(CHAN_1))
        self.assertEqual(MSG_TYPE, fwriter.get_messagetype(CHAN_1))
        self.assertEqual(PROTO_DESC, fwriter.get_protodesc(CHAN_1))
        fwriter.close()

        # reader
        fread = record.RecordReader(TEST_RECORD_FILE)
        channel_list = fread.get_channellist()
        self.assertEqual(1, len(channel_list))
        self.assertEqual(CHAN_1, channel_list[0])

        header = record_pb2.Header()
        header.ParseFromString(fread.get_headerstring())
        self.assertEqual(1, header.major_version)
        self.assertEqual(0, header.minor_version)
        self.assertEqual(1, header.chunk_number)
        self.assertEqual(1, header.channel_number)
        self.assertTrue(header.is_complete)

        for channelname, msg, datatype, timestamp in fread.read_messages():
            self.assertEqual(CHAN_1, channelname)
            self.assertEqual(MSG_DATA, msg)
            self.assertEqual(TIME, timestamp)
            self.assertEqual(1, fread.get_messagenumber(channelname))
            self.assertEqual(MSG_TYPE, datatype)
            self.assertEqual(MSG_TYPE, fread.get_messagetype(channelname))


if __name__ == '__main__':
    unittest.main()
#!/usr/bin/env python3
# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************

import math
import os
import sys
import time

from cyber.python.cyber_py3 import cyber_time
from cyber.python.cyber_py3 import cyber

def print_channel_type(channel_name):
    msgtype = cyber.ChannelUtils.get_msgtype(channel_name)
    print(channel_name, " type is [", msgtype, "]")


def _channel_cmd_type(argv):
    """
    Command-line parsing for 'cyber_channel type channelname' command.
    """
    args = argv[2:]
    from optparse import OptionParser
    parser = OptionParser(
        usage="usage: cyber_channel type channelname")
    (options, args) = parser.parse_args(args)
    if len(args) > 1:
        parser.error("you may only specify one input channel")
    elif len(args) == 0:
        parser.error("channelname must be specified")
    print_channel_type(args[0])


class CyberChannelBw(object):

    def __init__(self, window_size=100):
        import threading
        self.lock = threading.Lock()
        self.sizes = []
        self.times = []
        self.window_size = window_size
        if window_size <= 0 or window_size > 50000:
            self.window_size = 100
        print("bw window_size: ", self.window_size)

    def callback_bw(self, rawdata):
        with self.lock:
            t = time.time()
            self.times.append(t)
            self.sizes.append(len(rawdata))
            assert(len(self.times) == len(self.sizes))

            if len(self.times) > self.window_size:
                self.times.pop(0)
                self.sizes.pop(0)

    def print_bw(self):
        if len(self.times) < 2:
            return
        with self.lock:
            n = len(self.times)
            tn = time.time()
            t0 = self.times[0]

            total = sum(self.sizes)
            bytes_per_s = total / (tn - t0)
            mean = total / n

            max_s = max(self.sizes)
            min_s = min(self.sizes)

        if bytes_per_s < 1000:
            bw, mean, min_s, max_s = [
                "%.2fB" % v for v in [bytes_per_s, mean, min_s, max_s]]
        elif bytes_per_s < 1000000:
            bw, mean, min_s, max_s = ["%.2fKB" % (v / 1000)
                                      for v in [bytes_per_s, mean, min_s, max_s]]
        else:
            bw, mean, min_s, max_s = ["%.2fMB" % (v / 1000000)
                                      for v in [bytes_per_s, mean, min_s, max_s]]

        print("average: %s/s\n\tmean: %s min: %s max: %s window: %s" %
              (bw, mean, min_s, max_s, n))


def channel_bw(channel_name, window_size):
    rt = CyberChannelBw(window_size)
    node_bw = cyber.Node("listener_node_bw")
    node_bw.create_rawdata_reader(channel_name, rt.callback_bw)
    print("reader to [%s]" % channel_name)
    while not cyber.is_shutdown():
        time.sleep(1.0)
        rt.print_bw()


def _channel_cmd_bw(argv):
    """
    Command-line parsing for 'cyber_channel bw' command.
    """
    args = argv[2:]
    from optparse import OptionParser
    parser = OptionParser(
        usage="usage: cyber_channel bw channelname")
    parser.add_option("-w", "--window",
                      dest="window_size", default=-1,
                      help="window size for calculating rate, max size is 50000")

    channel_name = ""
    (options, args) = parser.parse_args(args)
    if len(args) == 0:
        parser.error("channelname must be specified")
    if len(args) == 1:
        channel_name = args[0]
    if len(args) > 1:
        parser.error("param is too much")

    try:
        if options.window_size != -1:
            import string
            window_size = string.atoi(options.window_size)
        else:
            window_size = options.window_size
    except:
        parser.error("window size must be an integer")

    channel_bw(channel_name, window_size)


class CyberChannelHz(object):

    """
    CyberChannelHz receives messages for a topic and computes frequency stats
    """

    def __init__(self, window_size):
        import threading
        self.lock = threading.Lock()
        self.last_printed_tn = 0
        self.msg_t0 = -1.
        self.msg_tn = 0
        self.times = []

        if window_size <= 0 or window_size > 50000:
            window_size = 50000
        self.window_size = window_size
        print("hz window_size: ", window_size)

    def callback_hz(self, m):
        with self.lock:
            curr_time = cyber_time.Time.now().to_sec()

            if curr_time == 0:
                if len(self.times) > 0:
                    print("reset times.")
                    self.times = []
                return

            if self.msg_t0 < 0 or self.msg_t0 > curr_time:
                self.msg_t0 = curr_time
                self.msg_tn = curr_time
                self.times = []
            else:
                self.times.append(curr_time - self.msg_tn)
                self.msg_tn = curr_time

            if len(self.times) > self.window_size - 1:
                self.times.pop(0)

    def print_hz(self):
        """
        print the average publishing rate to screen
        """
        if not self.times:
            return
        elif self.msg_tn == self.last_printed_tn:
            print("no new messages")
            return
        with self.lock:
            n = len(self.times)
            mean = sum(self.times) / n
            rate = 1. / mean if mean > 0. else 0

            std_dev = math.sqrt(sum((x - mean) ** 2 for x in self.times) / n)

            max_delta = max(self.times)
            min_delta = min(self.times)

            self.last_printed_tn = self.msg_tn
        print("average rate: %.3f\n\tmin: %.3fs max: %.3fs std dev: %.5fs window: %s" %
              (rate, min_delta, max_delta, std_dev, n + 1))


def channel_hz(channel_name, window_size):
    rt = CyberChannelHz(window_size)
    node_hz = cyber.Node("listener_node_hz")
    node_hz.create_rawdata_reader(channel_name, rt.callback_hz)
    print("reader to [%s]" % channel_name)
    while not cyber.is_shutdown():
        time.sleep(1.0)
        rt.print_hz()


def _channel_cmd_hz(argv):
    """
    Command-line parsing for 'cyber_channel hz' command.
    """
    args = argv[2:]
    from optparse import OptionParser
    parser = OptionParser(
        usage="usage: cyber_channel hz channelname")
    parser.add_option("-w", "--window",
                      dest="window_size", default=-1,
                      help="window size for calculating rate, max size is 50000")

    channel_name = ""
    (options, args) = parser.parse_args(args)
    if len(args) == 0:
        parser.error("channelname must be specified")
    if len(args) == 1:
        channel_name = args[0]
    if len(args) > 1:
        parser.error("param is too much")

    # check string
    try:
        if options.window_size != -1:
            import string
            window_size = string.atoi(options.window_size)
        else:
            window_size = options.window_size
    except:
        parser.error("window size must be an integer")

    channel_hz(channel_name, window_size)


def print_role(rolsattr_rawdata):
    from google.protobuf.message import DecodeError
    from cyber.proto.role_attributes_pb2 import RoleAttributes
    try:
        msg = RoleAttributes()
        msg.ParseFromString(rolsattr_rawdata)
    except DecodeError:
        print("RoleAttributes ParseFromString failed. size is ", len(rolsattr_rawdata))
        return
    print("\troleid\t\t", msg.id)
    print("\thostname\t", msg.host_name)
    print("\tprocessid\t", msg.process_id)
    print("\tnodename\t", msg.node_name)
    print("\tmsgtype\t\t", msg.message_type)


def channel_info(channel_name):
    channlesinfo_dict = cyber.ChannelUtils.get_channels_info()
    time.sleep(1)
    if len(channlesinfo_dict) == 0:
        print("channelsinfo dict is null")
        return

    # for key in channlesinfo_dict.keys():
    #     print key
    if channel_name != "":
        print(channel_name)
        for role_data in channlesinfo_dict[channel_name]:
            print_role(role_data)
    else:
        channels = sorted(channlesinfo_dict.keys())
        print("The number of channels is: ", len(channels))
        for channel in channels:
            print(channel)
            for role_data in channlesinfo_dict[channel]:
                print_role(role_data)


def _channel_cmd_info(argv):
    """
    Command-line parsing for 'cyber_channel info' command.
    """
    args = argv[2:]
    from optparse import OptionParser
    parser = OptionParser(
        usage="usage: cyber_channel info channelname ")
    parser.add_option("-a", "--all",
                      dest="all_channels", default=False,
                      action="store_true",
                      help="display all channels info")

    (options, args) = parser.parse_args(args)
    if len(args) == 0 and not options.all_channels:
        parser.error("channelname must be specified")
    elif len(args) > 1:
        parser.error("you may only specify one topic name")
    elif len(args) == 1:
        channel_info(args[0])
    elif len(args) == 0 and options.all_channels:
        channel_info("")


def print_channel_list():
    channels = sorted(cyber.ChannelUtils.get_channels())
    print("The number of channels is: ", len(channels))
    for channel in channels:
        print(channel)


def _channel_cmd_list(argv):
    """
    Command-line parsing for 'cyber_channel list' command.
    """
    args = argv[2:]
    from optparse import OptionParser
    parser = OptionParser(
        usage="usage: cyber_channel list")
    (options, args) = parser.parse_args(args)
    if len(args) > 0:
        parser.error("param is too much")
    print_channel_list()


class CyberChannelecho(object):

    def __init__(self, channel_name):
        self.channel_name = channel_name

    def callback(self, raw_data):
        """
        Channel echo callback.
        """
        # pass
        # print "py:reader callback raw_data->:"
        # print type(raw_data) # str
        # print raw_data # str

        msgtype = cyber.ChannelUtils.get_msgtype(self.channel_name, 0).decode('utf-8')
        print(cyber.ChannelUtils.get_debugstring_rawmsgdata(msgtype, raw_data).decode('utf-8'))


def channel_echo(channel_name):
    """
    Reader message.
    """
    node_echo = cyber.Node("listener_node_echo")
    echo_cb = CyberChannelecho(channel_name)
    node_echo.create_rawdata_reader(channel_name, echo_cb.callback)
    while not cyber.is_shutdown():
        pass


def _channel_cmd_echo(argv):
    """
    Command-line parsing for 'cyber_channel echo' command.
    """
    args = argv[2:]
    from optparse import OptionParser
    parser = OptionParser(
        usage="usage: cyber_channel echo channelname")
    (options, args) = parser.parse_args(args)
    if len(args) > 1:
        parser.error("you may only specify one input channel")
    elif len(args) == 0:
        parser.error("channelname must be specified")
    channel_echo(args[0])


def _printallusage():
    print("""cyber_channel is a command-line tool for printing information about CyberRT Channels.

Commands:
\tcyber_channel list\tlist active channels
\tcyber_channel info\tprint information about active channel
\tcyber_channel echo\tprint messages to screen
\tcyber_channel hz\tdisplay publishing rate of channel
\tcyber_channel bw\tdisplay bandwidth used by channel
\tcyber_channel type\tprint channel type

Type cyber_channel <command> -h for more detailed usage, e.g. 'cyber_channel echo -h'
""")
    sys.exit(getattr(os, 'EX_USAGE', 1))


if __name__ == '__main__':
    if len(sys.argv) == 1:
        _printallusage()

    cyber.init()

    argv = sys.argv[0:]
    command = argv[1]
    if command == 'list':
        _channel_cmd_list(argv)
    elif command == 'info':
        _channel_cmd_info(argv)
    elif command == 'echo':
        _channel_cmd_echo(argv)
    elif command == 'hz':
        _channel_cmd_hz(argv)
    elif command == 'bw':
        _channel_cmd_bw(argv)
    elif command == 'type':
        _channel_cmd_type(argv)
    else:
        _printallusage()

    cyber.shutdown()
#!/usr/bin/env python3
# ****************************************************************************
# Copyright 2018 The Apollo Authors. All Rights Reserved.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************

import argparse
import atexit
import logging
import os
import os.path
import signal
import subprocess
import sys
import time
import threading
import traceback

import xml.etree.ElementTree as ET


g_binary_name = 'mainboard'
g_pwd = os.getcwd()
g_script_name = os.path.basename(sys.argv[0]).split(".")[0]
g_process_pid = os.getpid()
g_process_name = g_script_name + "_" + str(g_process_pid)

cyber_path = os.getenv('CYBER_PATH')

"""
colorful logging
"""
BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE = list(range(8))
RESET_SEQ = "\033[0m"
COLOR_SEQ = "\033[1;%dm"
BOLD_SEQ = "\033[1m"

COLORS = {
    'INFO':     GREEN,
    'WARNING':  YELLOW,
    'DEBUG':    BLUE,
    'ERROR':    RED,
    'CRITICAL': YELLOW
}

class ColoredFormatter(logging.Formatter):

    def __init__(self, msg):
        logging.Formatter.__init__(self, msg)

    def format(self, record):
        levelname = record.levelname
        if levelname in COLORS:
            if levelname == 'DEBUG':
                record.levelname = COLOR_SEQ % (30 + COLORS[levelname]) + \
                    record.msg.split('#')[0] + RESET_SEQ
                record.msg = COLOR_SEQ % (30 + COLORS[levelname]) + \
                    record.msg.split('#')[-1] + RESET_SEQ
            else:
                record.levelname = COLOR_SEQ % (30 + COLORS[levelname]) + \
                    g_process_name + RESET_SEQ
                record.msg = COLOR_SEQ % (30 + COLORS[levelname]) + levelname + \
                    " " + record.msg.split('#')[-1] + RESET_SEQ
        return logging.Formatter.format(self, record)


color_formatter = ColoredFormatter("[%(levelname)-18s] %(message)s")
console = logging.StreamHandler()
console.setFormatter(color_formatter)
logger = logging.Logger(__name__)
logger.addHandler(console)


def exit_handler():
    stop()
    os.chdir(g_pwd)
    logger.info('cyber_launch exit.')


atexit.register(exit_handler)


def singleton(cls):
    instances = {}

    def getinstance(*args, **kwargs):
        if cls not in instances:
            instances[cls] = cls(*args, **kwargs)
        return instances[cls]
    return getinstance


def module_monitor(mod):
    while True:
        line = mod.popen.stdout.readline()
        if line:
            logger.debug('%s# %s' % (mod.name, line.decode('utf8').strip('\n')))
            continue
        time.sleep(0.01)


class ProcessWrapper(object):

    def __init__(self, binary_path, dag_num, dag_list, process_name,
                 process_type, sched_name, exception_handler=''):
        self.time_of_death = None
        self.started = False
        self.binary_path = binary_path
        self.dag_num = dag_num
        self.dag_list = dag_list
        self.name = process_name
        self.sched_name = sched_name
        self.process_type = process_type
        self.popen = None
        self.exit_code = None
        self.args = []
        self.pid = -1
        self.exception_handler = exception_handler

    def wait(self):
        if self.started:
            self.popen.wait()

    def start(self):
        """
        Start a manager in process name
        """
        if self.process_type == 'binary':
            args_list = self.name.split()
        else:
            args_list = [self.binary_path, '-d'] + self.dag_list
            if len(self.name) != 0:
                args_list.append('-p')
                args_list.append(self.name)
            if len(self.sched_name) != 0:
                args_list.append('-s')
                args_list.append(self.sched_name)

        self.args = args_list

        try:
            self.popen = subprocess.Popen(args_list, stdout=subprocess.PIPE,
                                          stderr=subprocess.STDOUT)
        except Exception as err:
            logger.error('Subprocess Popen exception: ' + str(err))
            return 2
        else:
            if self.popen.pid == 0 or self.popen.returncode is not None:
                logger.error('Start process [%s] failed.' % self.name)
                return 2

        th = threading.Thread(target=module_monitor, args=(self, ))
        th.setDaemon(True)
        th.start()
        self.started = True
        self.pid = self.popen.pid
        logger.info('Start process [%s] successfully. pid: %d' %
                    (self.name, self.popen.pid))
        logger.info('-' * 120)
        return 0

    def is_alive(self):
        """
        Check the process if is still running
        @return: True if process is still running
        @rtype: bool
        """
        if not self.started:
            return False

        if self.popen is None:
            if self.time_of_death is None:
                self.time_of_death = time.time()
            return False

        self.exit_code = self.popen.poll()
        if self.exit_code is not None:
            if self.time_of_death is None:
                self.time_of_death = time.time()
            return False
        return True

    def get_exit_state(self):
        """
        @return: description of exit state
        @rtype: str
        """
        if self.popen.returncode is None:
            pass
        elif self.popen.returncode != 0:
            output = 'Process [%s] has died [pid %s, exit code %s, cmd %s].' % \
                     (self.name, self.pid, self.exit_code, ' '.join(self.args))
            logger.error(output)
        else:
            output = 'Process [%s] has finished. [pid %s, cmd %s].' % \
                     (self.name, self.pid, ' '.join(self.args))
            logger.error(output)


@singleton
class ProcessMonitor(object):

    def __init__(self):
        self.procs = []
        self.dead_cnt = 0
        self.done = False
        self.is_shutdown = False

    def register(self, p):
        """
        Register process with L{ProcessMonitor}
        @param p: Process
        @type  p: L{Process}
        """
        if self.has_process(p.name):
            logger.error(
                'Cannot add process due to duplicate name "%s".' % p.name)
        elif self.is_shutdown:
            logger.error(
                'Cannot add process [%s] due to monitor has been stopped.' % p.name)
        else:
            self.procs.append(p)

    def has_process(self, name):
        """
        @return: True if process is still be monitored. If False, process
        has died or was never registered with process
        @rtype: bool
        """
        return len([p for p in self.procs if p.name == name]) > 0

    def check_cleanup(self):
        """
        Check processes are alived, cleanup processes
        """
        dead_cnt = 0
        for pw in self.procs:
            if self.is_shutdown:
                break
            if pw.process_type == 'binary':
                continue
            try:
                if not pw.is_alive():
                    if pw.exception_handler == "respawn":
                        logger.warning(
                            'child process [%s][%d] exit, respawn!' % (pw.name, pw.pid))
                        result = pw.start()
                        if result != 0:
                            logger.error(
                                'respawn process [%s] failed, stop all!' % (pw.name))
                            stop()
                    elif pw.exception_handler == "exit":
                        logger.warning(
                            'child process [%s][%d] exit, stop all' % (pw.name, pw.pid))
                        stop()
                    dead_cnt += 1
            except Exception:
                dead_cnt += 1
                traceback.print_exc()
        if dead_cnt > 0:
            self.dead_cnt = dead_cnt
            if self.dead_cnt == len(self.procs):
                self.is_shutdown = True

    def run(self):
        """
        Run processes monitor, until all processes are died.
        """
        while not self.is_shutdown:
            self.check_cleanup()
            time.sleep(0.2)
        for p in self.procs:
            p.get_exit_state()
        if self.dead_cnt == len(self.procs):
            logger.info("All processes has died.")
            return True
        return False

    def stop(self, signal):
        """
        Stop all processes in monitor
        """
        for p in self.procs:
            if p.is_alive():
                p.popen.send_signal(signal)

        for p in self.procs:
            if p.is_alive():
                logger.warning('Waiting for [%s][%s] exit.' % (p.name, p.pid))
                p.wait()
                logger.info(
                    'Process [%s] has been stopped. dag_file: %s' % (p.name, p.dag_list))
        # Reset members
        self.procs = []
        self.dead_cnt = 0


def start(launch_file=''):
    """
    Start all modules in xml config
    """
    pmon = ProcessMonitor()
    # Find launch file
    if launch_file[0] == '/':
        launch_file = launch_file
    elif launch_file == os.path.basename(launch_file):
        launch_file = os.path.join(cyber_path, 'launch', launch_file)
    else:
        if os.path.exists(os.path.join(g_pwd, launch_file)):
            launch_file = os.path.join(g_pwd, launch_file)
        else:
            logger.error('Cannot find launch file: %s ' % launch_file)
            sys.exit(1)
    logger.info('Launch file [%s]' % launch_file)
    logger.info('=' * 120)

    if not os.path.isfile(launch_file):
        logger.error('Launch xml file %s does not exist' % launch_file)
        sys.exit(1)

    try:
        tree = ET.parse(launch_file)
    except Exception:
        logger.error('Parse xml failed. illegal xml!')
        sys.exit(1)
    total_dag_num = 0
    dictionary = {}
    dag_dict = {}
    root1 = tree.getroot()
    for module in root1.findall('module'):
        dag_conf = module.find('dag_conf').text
        process_name = module.find('process_name').text
        process_type = module.find('type')
        if process_type is None:
            process_type = 'library'
        else:
            process_type = process_type.text
            if process_type is None:
                process_type = 'library'
            process_type = process_type.strip()
        if process_type != 'binary':
            if dag_conf is None or not dag_conf.strip():
                logger.error('Library dag conf is null')
                continue
            if process_name is None:
                process_name = 'mainboard_default_' + str(os.getpid())
            process_name = process_name.strip()
            if str(process_name) in dictionary:
                dictionary[str(process_name)] += 1
            else:
                dictionary[str(process_name)] = 1
            if str(process_name) not in dag_dict:
                dag_dict[str(process_name)] = [str(dag_conf)]
            else:
                dag_dict[str(process_name)].append(str(dag_conf))
            if dag_conf is not None:
                total_dag_num += 1

    process_list = []
    root = tree.getroot()
    for env in root.findall('environment'):
        for var in env.getchildren():
            os.environ[var.tag] = str(var.text)
    for module in root.findall('module'):
        module_name = module.find('name').text
        dag_conf = module.find('dag_conf').text
        process_name = module.find('process_name').text
        sched_name = module.find('sched_name')
        process_type = module.find('type')
        exception_handler = module.find('exception_handler')
        if process_type is None:
            process_type = 'library'
        else:
            process_type = process_type.text
            if process_type is None:
                process_type = 'library'
            process_type = process_type.strip()

        if sched_name is None:
            sched_name = "CYBER_DEFAULT"
        else:
            sched_name = sched_name.text

        if process_name is None:
            process_name = 'mainboard_default_' + str(os.getpid())
        if dag_conf is None:
            dag_conf = ''
        if module_name is None:
            module_name = ''
        if exception_handler is None:
            exception_handler = ''
        else:
            exception_handler = exception_handler.text
        module_name = module_name.strip()
        dag_conf = dag_conf.strip()
        process_name = process_name.strip()
        sched_name = sched_name.strip()
        exception_handler = exception_handler.strip()

        logger.info('Load module [%s] %s: [%s] [%s] conf: [%s] exception_handler: [%s]' %
                    (module_name, process_type, process_name, sched_name, dag_conf,
                     exception_handler))

        if process_name not in process_list:
            if process_type == 'binary':
                if len(process_name) == 0:
                    logger.error(
                        'Start binary failed. Binary process_name is null.')
                    continue
                pw = ProcessWrapper(
                    process_name.split()[0], 0, [
                        ""], process_name, process_type,
                    exception_handler)
            # Default is library
            else:
                pw = ProcessWrapper(
                    g_binary_name, 0, dag_dict[
                        str(process_name)], process_name,
                    process_type, sched_name, exception_handler)
            result = pw.start()
            if result != 0:
                logger.error(
                    'Start manager [%s] failed. Stop all!' % process_name)
                stop()
            pmon.register(pw)
            process_list.append(process_name)

    # No module in xml
    if not process_list:
        logger.error("No module was found in xml config.")
        return
    all_died = pmon.run()
    if not all_died:
        logger.info("Stop all processes...")
        stop()
    logger.info("Cyber exit.")


def stop(sig=signal.SIGINT):
    """
    stop all modules
    """
    pmon = ProcessMonitor()
    if len(pmon.procs) == 0:
        return
    pmon.stop(sig)

    logger.info('All processes have been stopped.')
    sys.exit(0)


def stop_launch(launch_file):
    """
    Stop the launch file
    """
    if not launch_file:
        cmd = 'pkill -INT cyber_launch'
    else:
        cmd = 'pkill -INT -f ' + launch_file

    os.system(cmd)
    time.sleep(3)
    logger.info('Stop cyber launch finished.')
    sys.exit(0)


def signal_handler(sig, frame):
    logger.info('Keyboard interrupt received. Stop all processes.')
    stop(sig)


def main():
    """
    Main function
    """
    if cyber_path is None:
        logger.error(
            'Error: environment variable CYBER_PATH not found, set environment first.')
        sys.exit(1)
    os.chdir(cyber_path)
    parser = argparse.ArgumentParser(description='cyber launcher')
    subparsers = parser.add_subparsers(help='sub-command help')

    start_parser = subparsers.add_parser(
        'start', help='launch/benchmark.launch')
    start_parser.add_argument('file', nargs='?', action='store',
                              help='launch file, default is cyber.launch')

    stop_parser = subparsers.add_parser(
        'stop', help='stop all the module in launch file')
    stop_parser.add_argument('file', nargs='?', action='store',
                             help='launch file, default stop all the launcher')

    # restart_parser = subparsers.add_parser('restart', help='restart the module')
    # restart_parser.add_argument('file', nargs='?', action='store', help='launch file,
    #                            default is cyber.launch')

    params = parser.parse_args(sys.argv[1:])

    command = sys.argv[1]
    if command == 'start':
        start(params.file)
    elif command == 'stop':
        stop_launch(params.file)
    # elif command == 'restart':
    #    restart(params.file)
    else:
        logger.error('Invalid command %s' % command)
        sys.exit(1)


if __name__ == '__main__':
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    main()
#!/usr/bin/env python3
# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************

import os
import sys

from optparse import OptionParser

from cyber.python.cyber_py3 import cyber
from cyber.proto.role_attributes_pb2 import RoleAttributes


def print_node_info(node_name, sleep_s=2):
    raw_data = cyber.NodeUtils.get_node_attr(node_name, sleep_s)
    try:
        msg = RoleAttributes()
        msg.ParseFromString(raw_data)
        assert(node_name == msg.node_name)
    except:
        print("RoleAttributes ParseFromString failed. size is ",
              len(raw_data))
        return
    print("Node:    \t%s" % msg.node_name)
    print("ProcessId: \t%d" % msg.process_id)
    print("Hostname:\t%s" % msg.host_name)

    print("[Reading Channels]:")
    reading_channels = sorted(cyber.NodeUtils.get_readersofnode(node_name, 0))
    for channel in reading_channels:
        print(channel)
    print("")

    print("[Writing Channels]:")
    writing_channels = sorted(cyber.NodeUtils.get_writersofnode(node_name, 0))
    for channel in writing_channels:
        print(channel)
    print("")


def _node_cmd_info(argv):
    """
    Command-line parsing for 'cyber_node info' command.
    """
    args = argv[2:]
    parser = OptionParser(
        usage="usage: cyber_node info [OPTION...] [NODE...]")
    parser.add_option("-a", "--all",
                      dest="all_nodes", default=False,
                      action="store_true",
                      help="display all nodes' info")
    (options, args) = parser.parse_args(args)
    if options.all_nodes:
        if len(args) != 0:
            parser.error(
                """"-a/--all" option is expected to run w/o node name(s)""")
        else:
            nodes = cyber.NodeUtils.get_nodes()
            for nodename in nodes:
                print_node_info(nodename, 0)
    elif len(args) == 0:
        parser.error("No node name provided.")
    else:
        for arg in args:
            print_node_info(arg)


def print_node_list():
    nodes = cyber.NodeUtils.get_nodes()
    print("Number of active nodes: {}".format(len(nodes)))
    for node_name in sorted(nodes):
        print(node_name)


def _node_cmd_list(argv):
    """
    Command-line parsing for 'cyber_node list'
    """
    args = argv[2:]
    parser = OptionParser(usage="usage: cyber_node list")
    (options, args) = parser.parse_args(args)
    if len(args) > 0:
        parser.error("too many arguments")
    print_node_list()


def _usage():
    print("""cyber_node is a command-line tool to show information about CyberRT Nodes.

Commands:
\tcyber_node list \tList active nodes.
\tcyber_node info \tPrint node info.

Type cyber_node <command> -h for more detailed usage, e.g. 'cyber_node info -h'
""")
    sys.exit(getattr(os, "EX_USAGE", 1))


if __name__ == '__main__':
    if len(sys.argv) == 1:
        _usage()
    cyber.init()

    argv = sys.argv[0:]
    command = argv[1]
    if command == "list":
        _node_cmd_list(argv)
    elif command == "info":
        _node_cmd_info(argv)
    else:
        _usage()

    cyber.shutdown()
#!/usr/bin/env python3
# ****************************************************************************
# Copyright 2019 The Apollo Authors. All Rights Reserved.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************

import os
import sys

from cyber.python.cyber_py3 import cyber

def print_service_info(service_name, sleep_s=2):
    roleattr_rawdata = cyber.ServiceUtils.get_service_attr(service_name, sleep_s)
    from cyber.proto.role_attributes_pb2 import RoleAttributes
    try:
        msg = RoleAttributes()
        msg.ParseFromString(roleattr_rawdata)
        assert(service_name == msg.service_name)
    except:
        print("RoleAttributes ParseFromString failed. size is ", len(roleattr_rawdata),
              ", service name: ", service_name)
        return
    print(msg.service_name)
    print("\tprocessid\t", msg.process_id)
    print("\tnodename\t", msg.node_name)
    print("\thostname\t", msg.host_name)
    print("")


def _service_cmd_info(argv):
    """
    Command-line parsing for 'cyber_service info' command.
    """
    args = argv[2:]
    from optparse import OptionParser
    parser = OptionParser(
        usage="usage: cyber_service info servicename ")
    parser.add_option("-a", "--all",
                      dest="all_services", default=False,
                      action="store_true",
                      help="display all services info")

    (options, args) = parser.parse_args(args)
    if len(args) == 0 and not options.all_services:
        parser.error("servicename must be specified")
    elif len(args) > 1:
        parser.error("you may only specify one service name")
    elif len(args) == 1:
        print_service_info(args[0])
    elif len(args) == 0 and options.all_services:
        services = cyber.ServiceUtils.get_services()
        for servicename in services:
            print_service_info(servicename, 0)


def print_service_list():
    services = sorted(cyber.ServiceUtils.get_services())
    print("The number of services is: ", len(services))
    for service_name in services:
        print(service_name)


def _service_cmd_list(argv):
    """
    Command-line parsing for 'cyber_service list' command.
    """
    args = argv[2:]
    from optparse import OptionParser
    parser = OptionParser(
        usage="usage: cyber_service list")
    (options, args) = parser.parse_args(args)
    if len(args) > 0:
        parser.error("param is too much")
    print_service_list()


def _printallusage():
    print("""cyber_service is a command-line tool for printing information about CyberRT Services.

Commands:
\tcyber_service list\tlist active services
\tcyber_service info\tprint information about active service

Type cyber_service <command> -h for more detailed usage, e.g. 'cyber_service info -h'
""")
    sys.exit(getattr(os, 'EX_USAGE', 1))

if __name__ == '__main__':
    if len(sys.argv) == 1:
        _printallusage()

    cyber.init()

    argv = sys.argv[0:]
    command = argv[1]
    if command == 'list':
        _service_cmd_list(argv)
    elif command == 'info':
        _service_cmd_info(argv)
    else:
        _printallusage()

    cyber.shutdown()
#!/usr/bin/env python3

# ****************************************************************************
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ****************************************************************************
# -*- coding: utf-8 -*-
import atexit
import os
import wave
from cyber.python.cyber_py3 import cyber
from modules.drivers.microphone.proto.audio_pb2 import AudioData

RESPEAKER_CHANNEL = "/apollo/sensor/microphone"
WAV_SAVING_PATH = "/tmp"
frames = [b"" for _ in range(6)]
sample_width = 0
sample_rate = 0


def save_to_wave(frames, filepath, sample_width, sample_rate, n_channels=1):
    """Save frame to file.wave"""
    with wave.open(filepath, 'wb') as wf:
        wf.setnchannels(n_channels)
        wf.setsampwidth(sample_width)
        wf.setframerate(sample_rate)
        wf.writeframes(frames)


def before_exit():
    for idx, data in enumerate(frames):
        file_path = os.path.join(WAV_SAVING_PATH, "channel_{}.wav".format(idx))
        save_to_wave(data, file_path, sample_width, sample_rate, 1)
    print("Done...")


def callback(audio):
    global frames, sample_width, sample_rate
    sample_width = audio.microphone_config.sample_width
    sample_rate = audio.microphone_config.sample_rate
    print("=" * 40)
    print(audio.header)
    for idx, channel_data in enumerate(audio.channel_data):
        frames[idx] += channel_data.data


def run():
    print("=" * 120)
    test_node = cyber.Node("audiosaver")
    test_node.create_reader(RESPEAKER_CHANNEL, AudioData, callback)
    test_node.spin()


if __name__ == '__main__':
    atexit.register(before_exit)
    cyber.init()
    run()
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
Broadcaster static transform
"""

from subprocess import call
import sys

import yaml


def main():
    """Main function.

    Reading transform info from a yaml file and publish to tf2
    """
    if len(sys.argv) < 2:
        print('Usage: %s extrinsic_example.yaml' % sys.argv[0])
        return

    with open(sys.argv[1]) as fp:
        transform_stamped = yaml.safe_load(file_path)
        command = 'rosrun tf2_ros static_transform_publisher ' \
                  '%f %f %f %f %f %f %f %s %s' % \
                  (transform_stamped['transform']['translation']['x'],
                   transform_stamped['transform']['translation']['y'],
                   transform_stamped['transform']['translation']['z'],
                   transform_stamped['transform']['rotation']['x'],
                   transform_stamped['transform']['rotation']['y'],
                   transform_stamped['transform']['rotation']['z'],
                   transform_stamped['transform']['rotation']['w'],
                   transform_stamped['header']['frame_id'],
                   transform_stamped['child_frame_id'])

    print(command)

    try:
        return call(command, shell=True)
    except OSError as e:
        print(e)


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# Software License Agreement (BSD License)
#
# Copyright (C) 2012, Austin Robot Technology
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above
#    copyright notice, this list of conditions and the following
#    disclaimer in the documentation and/or other materials provided
#    with the distribution.
#  * Neither the name of Austin Robot Technology, Inc. nor the names
#    of its contributors may be used to endorse or promote products
#    derived from this software without specific prior written
#    permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
# COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#
# Revision $Id$

"""
Generate YAML calibration file from Velodyne db.xml.

The input data provided by the manufacturer are in degrees and
centimeters. The YAML file uses radians and meters, following ROS
standards [REP-0103].

"""

from xml.etree import ElementTree
import math
import optparse
import os
import six
import sys

import yaml


# parse the command line
usage = """usage: %prog infile.xml [outfile.yaml]

       Default output file is input file with .yaml suffix."""
parser = optparse.OptionParser(usage=usage)
options, args = parser.parse_args()

if len(args) < 1:
    parser.error('XML file name missing')
    sys.exit(9)

xmlFile = args[0]
if len(args) >= 2:
    yamlFile = args[1]
else:
    yamlFile, ext = os.path.splitext(xmlFile)
    yamlFile += '.yaml'

print('converting "' + xmlFile + '" to "' + yamlFile + '"')

calibrationGood = True


def xmlError(msg):
    'handle XML calibration error'
    global calibrationGood
    calibrationGood = False
    print('gen_calibration.py: ' + msg)


db = None
try:
    db = ElementTree.parse(xmlFile)
except IOError:
    xmlError('unable to read ' + xmlFile)
except ElementTree.ParseError:
    xmlError('XML parse failed for ' + xmlFile)

if not calibrationGood:
    sys.exit(2)

# create a dictionary to hold all relevant calibration values
calibration = {'num_lasers': 0, 'lasers': []}
cm2meters = 0.01                       # convert centimeters to meters


def addLaserCalibration(laser_num, key, val):
    """Define key and corresponding value for laser_num"""

    global calibration
    if laser_num < len(calibration['lasers']):
        calibration['lasers'][laser_num][key] = val
    else:
        calibration['lasers'].append({key: val})


# add enabled flags
num_enabled = 0
enabled_lasers = []
enabled = db.find('DB/enabled_')
if enabled is None:
    print('no enabled tags found: assuming all 64 enabled')
    num_enabled = 64
    enabled_lasers = [True for i in range(num_enabled)]
else:
    index = 0
    for el in enabled:
        if el.tag == 'item':
            this_enabled = int(el.text) != 0
            enabled_lasers.append(this_enabled)
            index += 1
            if this_enabled:
                num_enabled += 1

calibration['num_lasers'] = num_enabled
print(str(num_enabled) + ' lasers')

# add minimum laser intensities
minIntensities = db.find('DB/minIntensity_')
if minIntensities is not None:
    index = 0
    for el in minIntensities:
        if el.tag == 'item':
            if enabled_lasers[index]:
                value = int(el.text)
                if value != 256:
                    addLaserCalibration(index, 'min_intensity', value)
            index += 1

# add maximum laser intensities
maxIntensities = db.find('DB/maxIntensity_')
if maxIntensities is not None:
    index = 0
    for el in maxIntensities:
        if el.tag == 'item':
            if enabled_lasers[index]:
                value = int(el.text)
                if value != 256:
                    addLaserCalibration(index, 'max_intensity', value)
                index += 1

# add calibration information for each laser
for el in db.find('DB/points_'):
    if el.tag == 'item':
        for px in el:
            for field in px:
                if field.tag == 'id_':
                    index = int(field.text)
                    if not enabled_lasers[index]:
                        break   # skip this laser, it is not enabled
                    addLaserCalibration(index, 'laser_id', index)

                if field.tag == 'rotCorrection_':
                    addLaserCalibration(index, 'rot_correction',
                                        math.radians(float(field.text)))
                elif field.tag == 'vertCorrection_':
                    addLaserCalibration(index, 'vert_correction',
                                        math.radians(float(field.text)))
                elif field.tag == 'distCorrection_':
                    addLaserCalibration(index, 'dist_correction',
                                        float(field.text) * cm2meters)
                elif field.tag == 'distCorrectionX_':
                    addLaserCalibration(index, 'dist_correction_x',
                                        float(field.text) * cm2meters)
                elif field.tag == 'distCorrectionY_':
                    addLaserCalibration(index, 'dist_correction_y',
                                        float(field.text) * cm2meters)
                elif field.tag == 'vertOffsetCorrection_':
                    addLaserCalibration(index, 'vert_offset_correction',
                                        float(field.text) * cm2meters)
                elif field.tag == 'horizOffsetCorrection_':
                    addLaserCalibration(index, 'horiz_offset_correction',
                                        float(field.text) * cm2meters)
                elif field.tag == 'focalDistance_':
                    addLaserCalibration(index, 'focal_distance',
                                        float(field.text) * cm2meters)
                elif field.tag == 'focalSlope_':
                    addLaserCalibration(index, 'focal_slope', float(field.text))

# validate input data
if calibration['num_lasers'] <= 0:
    xmlError('no lasers defined')
elif calibration['num_lasers'] != num_enabled:
    xmlError('inconsistent number of lasers defined')

# TODO: make sure all required fields are present.
# (Which ones are required?)

if calibrationGood:
    # write calibration data to YAML file
    with open(yamlFile, 'w') as f:
        yaml.dump(calibration, f)
#!/usr/bin/env python3

"""
velodyne check
"""

import time

from cyber.python.cyber_py3 import cyber_time
from sensor_msgs.msg import PointCloud2


prev_stamp = 0
count = 0
LOG_FILE = None
EXCEPT_LOG_FILE = None


def create_log_file():
    data_time = time.strftime(
        '%Y-%m-%d-%H-%M-%S', time.localtime(cyber_time.Time.now().to_sec()))
    file_name = '/apollo/data/log/velodyne_hz.' + data_time + '.log'
    except_file_name = '/apollo/data/log/velodyne_hz.' + data_time + '.log.err'
    global LOG_FILE
    global EXCEPT_LOG_FILE
    LOG_FILE = open(file_name, 'a+')
    EXCEPT_LOG_FILE = open(except_file_name, 'a+')


def log_latency(log_file, frequence):
    pass


def callback(pointcloud):
    global count
    global prev_stamp
    count += 1
    stamp = pointcloud.header.stamp.to_time()
    if prev_stamp == 0:
        prev_stamp = stamp
        return
    interval = stamp - prev_stamp
    frequence = 1.0 / interval
    log_info = "%f: %.2fms\t%.2fHz\n" % (stamp, interval * 1000, frequence)
    LOG_FILE.write(log_info)
    if frequence < 9:
        EXCEPT_LOG_FILE.write(log_info)
    prev_stamp = stamp


def listener():
    node_name = 'velodyne_check'
    topic = '/apollo/sensor/velodyne64/compensator/PointCloud2'
    rospy.init_node(node_name)
    rospy.Subscriber(topic, PointCloud2, callback)
    rospy.spin()


if __name__ == "__main__":
    create_log_file()
    listener()
#!/usr/bin/env python3

"""
plot pr curve provided precision-recall samples
and plot sr curve provided similarity-recall samples
"""

import sys

import matplotlib.pyplot as plt
import numpy


def plot_curve(in_path, out_path, x_label, y_label, title):
    """ plot curve
    """
    data = numpy.loadtxt(in_path)
    plt.gcf().clear()

    num = int(data.shape[0] / 5)
    names = ['OTH', 'PED', 'CYC', 'VEH', 'ALL']
    for i in range(0, 5):
        plt.plot(data[i * num: (i + 1) * num, 1],
                 data[i * num: (i + 1) * num, 0],
                 label=names[i], linestyle='-')

    plt.grid()
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.title(title)
    plt.ylim(0, 1.1)
    #plt.legend(bbox_to_anchor=(0.98, 0.99), ncol=len(names), labels=names, prop={'size': 10})
    plt.legend(ncol=len(names), labels=names, prop={'size': 10})

    plt.savefig(out_path, dpi=150)


if __name__ == '__main__':
    if len(sys.argv) < 2:
        parent = '.'
    else:
        parent = sys.argv[1]
    prc_in = parent + '/prc_sample'
    prc_out = parent + '/pr_curve.png'
    print("prc in is %s" % prc_in)
    plot_curve(prc_in, prc_out, 'Recall', 'Precision', 'PR Curve')
    src_in = parent + '/src_sample'
    src_out = parent + '/sr_curve.png'
    plot_curve(src_in, src_out, 'Recall', 'Similarity', 'SR Curve')
#!/usr/bin/env python3

###############################################################################
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""File utils."""
import os


def list_files(dir_path):
    """List all sub-files in given dir_path."""
    return [
        os.path.join(root, f) for root, _, files in os.walk(dir_path)
        for f in files
    ]


def getInputDirDataSize(path):
    sumsize = 0
    filelist = list_files(path)
    for file in filelist:
        size = os.path.getsize(file)
        sumsize += size
    return int(sumsize)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This module provides the logging function.
"""

import logging
import logging.handlers
import os
import sys


class Logger(object):
    """The logger factory class. It is a template to help quickly create a log utility.
    Attributes:
    set_conf(log_file, use_stdout, log_level): this is a static method that returns a configured logger.
    get_logger(tag): this is a static method that returns a configured logger.
    """
    __loggers = {}

    __use_stdout = True
    __log_file = ""
    __log_level = logging.DEBUG

    @staticmethod
    def config(log_file, use_stdout, log_level):
        """set the config, where config is a ConfigParser object
        """
        Logger.__use_stdout = use_stdout
        Logger.__log_level = log_level
        dirname = os.path.dirname(log_file)
        if (not os.path.isfile(log_file)) and (not os.path.isdir(dirname)):
            try:
                os.makedirs(dirname)
            except OSError as e:
                print("create path '%s' for logging failed: %s" % (dirname, e))
                sys.exit()
        Logger.__log_file = log_file

    @staticmethod
    def get_logger(tag):
        """return the configured logger object
        """
        if tag not in Logger.__loggers:
            Logger.__loggers[tag] = logging.getLogger(tag)
            Logger.__loggers[tag].setLevel(Logger.__log_level)
            formatter = logging.Formatter(
                "[%(name)s][%(levelname)s] %(asctime)s "
                "%(filename)s:%(lineno)s %(message)s")
            file_handler = logging.handlers.TimedRotatingFileHandler(
                Logger.__log_file, when='H', interval=1, backupCount=0)
            file_handler.setLevel(Logger.__log_level)
            file_handler.setFormatter(formatter)
            file_handler.suffix = "%Y%m%d%H%M.log"
            Logger.__loggers[tag].addHandler(file_handler)
            if Logger.__use_stdout:
                stream_headler = logging.StreamHandler()
                stream_headler.setLevel(Logger.__log_level)
                stream_headler.setFormatter(formatter)
                Logger.__loggers[tag].addHandler(stream_headler)
        return Logger.__loggers[tag]
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from modules.audio.proto import audio_event_pb2
from modules.localization.proto import localization_pb2
from modules.perception.proto import perception_obstacle_pb2
from modules.perception.proto import traffic_light_detection_pb2
from modules.planning.proto import planning_internal_pb2
from modules.planning.proto import planning_pb2
from modules.prediction.proto import prediction_obstacle_pb2
from modules.routing.proto import routing_pb2
from modules.control.proto import control_cmd_pb2
from modules.canbus.proto import chassis_pb2
from modules.common.proto import drive_event_pb2
from modules.map.relative_map.proto import navigation_pb2
from modules.guardian.proto import guardian_pb2
from modules.tools.common import proto_utils



class MessageType:
    def __init__(self, name, topic, msg_type):
        self.name = name
        self.topic = topic
        self.msg_type = msg_type

    def instance(self):
        return self.__msg_type()

    def parse_file(self, filename):
        value = self.instance()
        if not proto_utils.get_pb_from_file(filename, value):
            print("Failed to parse file %s" % filename)
            return None
        else:
            return value


topic_pb_list = [
    MessageType("audio_event", "/apollo/audio_event",
                    audio_event_pb2.AudioEvent),
    MessageType("planning", "/apollo/planning", planning_pb2.ADCTrajectory),
    MessageType("control", "/apollo/control", control_cmd_pb2.ControlCommand),
    MessageType("chassis", "/apollo/canbus/chassis", chassis_pb2.Chassis),
    MessageType("prediction", "/apollo/prediction",
                prediction_obstacle_pb2.PredictionObstacles),
    MessageType("perception", "/apollo/perception/obstacles",
                perception_obstacle_pb2.PerceptionObstacles),
    MessageType("routing_response", "/apollo/routing_response",
                routing_pb2.RoutingResponse),
    MessageType("routing_request", "/apollo/routing_request",
                routing_pb2.RoutingRequest),
    MessageType("localization", "/apollo/localization/pose",
                localization_pb2.LocalizationEstimate),
    MessageType("traffic_light", "/apollo/perception/traffic_light",
                traffic_light_detection_pb2.TrafficLightDetection),
    MessageType("drive_event", "/apollo/drive_event",
                drive_event_pb2.DriveEvent),
    MessageType("relative_map", "/apollo/relative_map", navigation_pb2.MapMsg),
    MessageType("navigation", "/apollo/navigation",
                navigation_pb2.NavigationInfo),
    MessageType("guardian", "/apollo/guardian", guardian_pb2.GuardianCommand),
]


class PbMessageManager:
    def __init__(self):
        self.__topic_dict = {}
        self.__name_dict = {}

        for msg in topic_pb_list:
            self.__topic_dict[msg.topic] = msg
            self.__name_dict[msg.name] = msg

    def topic_dict(self):
        return self.__topic_dict

    def get_msg_meta_by_topic(self, topic):
        if topic in self.__topic_dict:
            return self.__topic_dict[topic]
        else:
            return None

    def get_msg_meta_by_name(self, name):
        if name in self.__name_dict:
            return self.__name_dict[name]
        else:
            return None

    def name_dict(self):
        return self.__name_dict

    def parse_topic_file(self, topic, filename):
        if topic not in self.__topic_dict:
            print("topic %s is not registered in topic_pb_list" % topic)
            return None
        meta_msg = self.__topic_dict[topic]
        return meta_msg.parse_file(filename)

    def parse_file(self, filename):
        """parse a file by guessing topic type"""
        for topic, meta_msg in self.__topic_dict.items():
            try:
                message = meta_msg.parse_file(filename)
                if message:
                    print("identified topic %s" % topic)
                    return (meta_msg, message)
            except text_format.ParseError as e:
                print("Tried %s, failed" % (topic))
                continue
        return (None, None)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""Protobuf utils."""
import google.protobuf.text_format as text_format


def write_pb_to_text_file(topic_pb, file_path):
    """write pb message to file"""
    with open(file_path, 'w') as f:
        f.write(str(topic_pb))


def get_pb_from_text_file(filename, pb_value):
    """Get a proto from given text file."""
    with open(filename, 'r') as file_in:
        return text_format.Merge(file_in.read(), pb_value)


def get_pb_from_bin_file(filename, pb_value):
    """Get a proto from given binary file."""
    with open(filename, 'rb') as file_in:
        pb_value.ParseFromString(file_in.read())
    return pb_value


def get_pb_from_file(filename, pb_value):
    """Get a proto from given file by trying binary mode and text mode."""
    try:
        return get_pb_from_bin_file(filename, pb_value)
    except:
        try:
            return get_pb_from_text_file(filename, pb_value)
        except:
            print('Error: Cannot parse %s as binary or text proto' % filename)
    return None


def flatten(pb_value, selectors):
    """
    Get a flattened tuple from pb_value. Selectors is a list of sub-fields.

    Usage:
    For a pb_value of:
        total_pb = {
            me: { name: 'myself' }
            children: [{ name: 'child0' }, { name: 'child1' }]
        }
    my_name, child0_name = flatten(total_pb, ['me.name', 'children[0].name'])
    # You get (my_name='myself', child0_name='child0')

    children_names = flatten(total_pb, 'children.name')
    # You get (children_names=['child0', 'child1'])
    """

    def __select_field(val, field):
        if hasattr(val, '__len__'):
            # Flatten repeated field.
            return [__select_field(elem, field) for elem in val]
        if not field.endswith(']'):
            # Simple field.
            return val.__getattribute__(field)
        # field contains index: "field[index]".
        field, index = field.split('[')
        val = val.__getattribute__(field)
        index = int(index[:-1])
        return val[index] if index < len(val) else None

    def __select(val, selector):
        for field in selector.split('.'):
            val = __select_field(val, field)
            if val is None:
                return None
        return val

    # Return the single result for single selector.
    if isinstance(selectors, str):
        return __select(pb_value, selectors)
    # Return tuple result for multiple selectors.
    return tuple((__select(pb_value, selector) for selector in selectors))
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Control Planning Analyzer
"""
import argparse
import math
import sys
import threading
import time

import matplotlib
import matplotlib.pyplot as plt
import numpy
import tkinter.filedialog
from matplotlib import patches
from matplotlib import lines

from cyber.python.cyber_py3 import cyber
from modules.localization.proto import localization_pb2
from modules.canbus.proto import chassis_pb2
from modules.planning.proto import planning_pb2
from modules.control.proto import control_cmd_pb2


class ControlInfo(object):
    """
    ControlInfo Class
    """

    def __init__(self, axarr):
        self.throttlecmd = []
        self.throttlefbk = []
        self.brakecmd = []
        self.brakefbk = []
        self.steercmd = []
        self.steerfbk = []
        self.speed = []
        self.curvature = []
        self.imuright = []
        self.imuforward = []
        self.imuup = []
        self.controltime = []
        self.planningtime = []
        self.localizationtime = []
        self.canbustime = []

        self.acceleration_lookup = []
        self.speed_lookup = []
        self.acc_open = []
        self.acc_close = []
        self.station_error = []
        self.speed_error = []

        self.heading_error = []
        self.lateral_error = []
        self.heading_error_rate = []
        self.lateral_error_rate = []

        self.target_speed = []
        self.target_curvature = []
        self.target_acceleration = []
        self.target_heading = []
        self.target_time = []

        self.driving_mode = 0
        self.mode_time = []

        self.ax = axarr

        self.planningavailable = False

        self.lock = threading.Lock()

    def callback_planning(self, entity):
        """
        New Planning Trajectory
        """
        basetime = entity.header.timestamp_sec
        numpoints = len(entity.trajectory_point)
        with self.lock:
            self.pointx = numpy.zeros(numpoints)
            self.pointy = numpy.zeros(numpoints)
            self.pointspeed = numpy.zeros(numpoints)
            self.pointtime = numpy.zeros(numpoints)
            self.pointtheta = numpy.zeros(numpoints)
            self.pointcurvature = numpy.zeros(numpoints)
            self.pointacceleration = numpy.zeros(numpoints)

            for idx in range(numpoints):
                self.pointx[idx] = entity.trajectory_point[idx].path_point.x
                self.pointy[idx] = entity.trajectory_point[idx].path_point.y
                self.pointspeed[idx] = entity.trajectory_point[idx].v
                self.pointtheta[idx] = entity.trajectory_point[
                    idx].path_point.theta
                self.pointcurvature[idx] = entity.trajectory_point[
                    idx].path_point.kappa
                self.pointacceleration[idx] = entity.trajectory_point[
                    idx].a
                self.pointtime[
                    idx] = entity.trajectory_point[idx].relative_time + basetime

        if numpoints == 0:
            self.planningavailable = False
        else:
            self.planningavailable = True

    def callback_canbus(self, entity):
        """
        New Canbus
        """
        self.throttlefbk.append(entity.throttle_percentage)
        self.brakefbk.append(entity.brake_percentage)
        self.steerfbk.append(entity.steering_percentage)
        self.speed.append(entity.speed_mps)
        self.canbustime.append(entity.header.timestamp_sec)

        if entity.driving_mode == chassis_pb2.Chassis.COMPLETE_AUTO_DRIVE:
            if self.driving_mode == 0:
                self.mode_time.append(entity.header.timestamp_sec)
                self.driving_mode = 1
        elif self.driving_mode == 1:
            self.mode_time.append(entity.header.timestamp_sec)
            self.driving_mode = 0

    def callback_localization(self, entity):
        """
        New Localization
        """
        self.imuright.append(entity.pose.linear_acceleration_vrf.x)
        self.imuforward.append(entity.pose.linear_acceleration_vrf.y)
        self.imuup.append(entity.pose.linear_acceleration_vrf.z)
        self.localizationtime.append(entity.header.timestamp_sec)

    def callback_control(self, entity):
        """
        New Control Command
        """
        self.throttlecmd.append(entity.throttle)
        self.brakecmd.append(entity.brake)
        self.steercmd.append(entity.steering_target)
        self.controltime.append(entity.header.timestamp_sec)

        self.acceleration_lookup.append(
            entity.debug.simple_lon_debug.acceleration_lookup)
        self.speed_lookup.append(entity.debug.simple_lon_debug.speed_lookup)
        self.acc_open.append(
            entity.debug.simple_lon_debug.preview_acceleration_reference)
        self.acc_close.append(
            entity.debug.simple_lon_debug.acceleration_cmd_closeloop)
        self.station_error.append(entity.debug.simple_lon_debug.station_error)
        self.speed_error.append(entity.debug.simple_lon_debug.speed_error)

        self.curvature.append(entity.debug.simple_lat_debug.curvature)
        self.heading_error.append(entity.debug.simple_lat_debug.heading_error)
        self.lateral_error.append(entity.debug.simple_lat_debug.lateral_error)
        self.heading_error_rate.append(
            entity.debug.simple_lat_debug.heading_error_rate)
        self.lateral_error_rate.append(
            entity.debug.simple_lat_debug.lateral_error_rate)

        with self.lock:
            if self.planningavailable:
                self.target_speed.append(
                    numpy.interp(entity.header.timestamp_sec, self.pointtime,
                                 self.pointspeed))
                self.target_curvature.append(
                    numpy.interp(entity.header.timestamp_sec, self.pointtime,
                                 self.pointcurvature))
                self.target_acceleration.append(
                    numpy.interp(entity.header.timestamp_sec, self.pointtime,
                                 self.pointacceleration))
                self.target_heading.append(
                    numpy.interp(entity.header.timestamp_sec, self.pointtime,
                                 self.pointtheta))
                self.target_time.append(entity.header.timestamp_sec)

    def longitudinal(self):
        """
        Showing Longitudinal
        """
        for loc, ax in numpy.ndenumerate(self.ax):
            ax.clear()
        self.ax[0, 0].plot(
            self.canbustime, self.throttlefbk, label='Throttle Feedback')
        self.ax[0, 0].plot(
            self.controltime, self.throttlecmd, label='Throttle Command')
        self.ax[0, 0].plot(
            self.canbustime, self.brakefbk, label='Brake Feedback')
        self.ax[0, 0].plot(
            self.controltime, self.brakecmd, label='Brake Command')
        self.ax[0, 0].legend(fontsize='medium')
        self.ax[0, 0].grid(True)
        self.ax[0, 0].set_title('Throttle Brake Info')
        self.ax[0, 0].set_xlabel('Time')

        self.ax[0, 1].plot(
            self.speed_lookup, self.acceleration_lookup, label='Table Lookup')
        self.ax[0, 1].plot(
            self.target_speed, self.target_acceleration, label='Target')
        self.ax[0, 1].legend(fontsize='medium')
        self.ax[0, 1].grid(True)
        self.ax[0, 1].set_title('Calibration Lookup')
        self.ax[0, 1].set_xlabel('Speed')
        self.ax[0, 1].set_ylabel('Acceleration')

        self.ax[1, 0].plot(self.canbustime, self.speed, label='Vehicle Speed')
        self.ax[1, 0].plot(
            self.target_time, self.target_speed, label='Target Speed')
        self.ax[1, 0].plot(
            self.target_time, self.target_acceleration, label='Target Acc')
        self.ax[1, 0].plot(
            self.localizationtime, self.imuforward, label='IMU Forward')
        self.ax[1, 0].legend(fontsize='medium')
        self.ax[1, 0].grid(True)
        self.ax[1, 0].set_title('Speed Info')
        self.ax[1, 0].set_xlabel('Time')

        self.ax[1, 1].plot(
            self.controltime, self.acceleration_lookup, label='Lookup Acc')
        self.ax[1, 1].plot(self.controltime, self.acc_open, label='Acc Open')
        self.ax[1, 1].plot(self.controltime, self.acc_close, label='Acc Close')
        self.ax[1, 1].plot(
            self.controltime, self.station_error, label='station_error')
        self.ax[1, 1].plot(
            self.controltime, self.speed_error, label='speed_error')
        self.ax[1, 1].legend(fontsize='medium')
        self.ax[1, 1].grid(True)
        self.ax[1, 1].set_title('IMU Info')
        self.ax[1, 1].set_xlabel('Time')

        if len(self.mode_time) % 2 == 1:
            self.mode_time.append(self.controltime[-1])
        for i in range(0, len(self.mode_time), 2):
            self.ax[0, 0].axvspan(
                self.mode_time[i], self.mode_time[i + 1], fc='0.1', alpha=0.1)
            self.ax[1, 0].axvspan(
                self.mode_time[i], self.mode_time[i + 1], fc='0.1', alpha=0.1)
            self.ax[1, 1].axvspan(
                self.mode_time[i], self.mode_time[i + 1], fc='0.1', alpha=0.1)
        plt.draw()

    def lateral(self):
        """
        Plot everything in time domain
        """
        print("Showing Lateral")
        for loc, ax in numpy.ndenumerate(self.ax):
            ax.clear()
        self.ax[0, 0].plot(
            self.canbustime, self.steerfbk, label='Steering Feedback')
        self.ax[0, 0].plot(
            self.controltime, self.steercmd, label='Steering Command')
        self.ax[0, 0].plot(self.controltime, self.curvature, label='Curvature')
        self.ax[0, 0].legend(fontsize='medium')
        self.ax[0, 0].grid(True)
        self.ax[0, 0].set_title('Steering Info')
        self.ax[0, 0].set_xlabel('Time')
        """
        self.ax[0, 1].legend(fontsize = 'medium')
        self.ax[0, 1].grid(True)
        self.ax[0, 1].set_title('Calibration Lookup')
        self.ax[0, 1].set_xlabel('Speed')
        self.ax[0, 1].set_ylabel('Acceleration')
        """

        self.ax[1, 0].plot(
            self.controltime, self.heading_error, label='heading_error')
        self.ax[1, 0].plot(
            self.controltime, self.lateral_error, label='lateral_error')
        self.ax[1, 0].legend(fontsize='medium')
        self.ax[1, 0].grid(True)
        self.ax[1, 0].set_title('Error Info')
        self.ax[1, 0].set_xlabel('Time')

        self.ax[1, 1].plot(
            self.controltime,
            self.heading_error_rate,
            label='heading_error_rate')
        self.ax[1, 1].plot(
            self.controltime,
            self.lateral_error_rate,
            label='lateral_error_rate')
        self.ax[1, 1].legend(fontsize='medium')
        self.ax[1, 1].grid(True)
        self.ax[1, 1].set_title('IMU Info')
        self.ax[1, 1].set_xlabel('Time')

        if len(self.mode_time) % 2 == 1:
            self.mode_time.append(self.controltime[-1])
        for i in range(0, len(self.mode_time), 2):
            self.ax[0, 0].axvspan(
                self.mode_time[i], self.mode_time[i + 1], fc='0.1', alpha=0.1)
            self.ax[1, 0].axvspan(
                self.mode_time[i], self.mode_time[i + 1], fc='0.1', alpha=0.1)
            self.ax[1, 1].axvspan(
                self.mode_time[i], self.mode_time[i + 1], fc='0.1', alpha=0.1)
        plt.draw()

    def press(self, event):
        """
        Keyboard events during plotting
        """
        if event.key == 'q' or event.key == 'Q':
            plt.close('all')
        if event.key == 'a' or event.key == 'A':
            self.longitudinal()
        if event.key == 'z' or event.key == 'Z':
            self.lateral()


if __name__ == "__main__":
    from cyber.python.cyber_py3.record import RecordReader

    parser = argparse.ArgumentParser(
        description='Process and analyze control and planning data')
    parser.add_argument('--bag', type=str, help='use Rosbag')
    args = parser.parse_args()

    fig, axarr = plt.subplots(2, 2)
    plt.tight_layout()
    axarr[0, 0].get_shared_x_axes().join(axarr[0, 0], axarr[1, 0])
    axarr[1, 1].get_shared_x_axes().join(axarr[0, 0], axarr[1, 1])

    controlinfo = ControlInfo(axarr)

    if args.bag:
        file_path = args.bag
        # bag = rosbag.Bag(file_path)
        reader = RecordReader(file_path)
        for msg in reader.read_messages():
            print(msg.timestamp, msg.topic)
            if msg.topic == "/apollo/localization/pose":
                localization = localization_pb2.LocalizationEstimate()
                localization.ParseFromString(msg.message)
                controlinfo.callback_localization(localization)
            elif msg.topic == "/apollo/planning":
                adc_trajectory = planning_pb2.ADCTrajectory()
                adc_trajectory.ParseFromString(msg.message)
                controlinfo.callback_planning(adc_trajectory)
            elif msg.topic == "/apollo/control":
                control_cmd = control_cmd_pb2.ControlCommand()
                control_cmd.ParseFromString(msg.message)
                controlinfo.callback_control(control_cmd)
            elif msg.topic == "/apollo/canbus/chassis":
                chassis = chassis_pb2.Chassis()
                chassis.ParseFromString(msg.message)
                controlinfo.callback_canbus(chassis)
        print("Done reading the file")

    else:
        cyber.init()
        # rospy.init_node('control_info', anonymous=True)
        node = cyber.Node("rtk_recorder")
        planningsub = node.create_reader('/apollo/planning',
                                         planning_pb2.ADCTrajectory,
                                         controlinfo.callback_planning)
        localizationsub = node.create_reader(
            '/apollo/localization/pose', localization_pb2.LocalizationEstimate,
            controlinfo.callback_localization)
        controlsub = node.create_reader('/apollo/control',
                                        control_cmd_pb2.ControlCommand,
                                        controlinfo.callback_control)
        canbussub = node.create_reader('/apollo/canbus/chassis',
                                       chassis_pb2.Chassis,
                                       controlinfo.callback_canbus)
        input("Press Enter To Stop")

    mng = plt.get_current_fig_manager()
    controlinfo.longitudinal()
    fig.canvas.mpl_connect('key_press_event', controlinfo.press)
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Convert a base map from txt to bin format
"""

import argparse
from modules.map.proto.map_pb2 import Map
from google.protobuf import text_format


def main():
    parser = argparse.ArgumentParser(
        description='Convert a base map from txt to bin format')
    parser.add_argument(
        '-i',
        '--input_file',
        help='Input base map in txt format',
        type=str,
        default='modules/map/data/gen/base_map.txt')
    parser.add_argument(
        '-o',
        '--output_file',
        help='Output base map in bin format',
        type=str,
        default='modules/map/data/gen/base_map.bin')
    args = vars(parser.parse_args())

    input_file_name = args['input_file']
    output_file_name = args['output_file']

    with open(input_file_name, 'r') as f:
        mp = Map()
        text_format.Merge(f.read(), mp)

    # Output map
    with open(output_file_name, "wb") as f:
        f.write(mp.SerializeToString())


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Extract messages of gps topic from data record file,
and save them into specified binary file

Usage:
    dump_gpsbin.py --input_file=a.record --output_dir=dir

See the gflags for more optional args.
"""

import os
import sys
import time

import gflags
import glog

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record
from modules.drivers.gnss.proto.gnss_pb2 import RawData


# Requried flags.
gflags.DEFINE_string('input_file', None, 'Input record file path.')

# Optional flags.
gflags.DEFINE_string('output_dir', './', 'Output directory path.')

# Stable flags which rarely change.
gflags.DEFINE_string('gps_raw_data_channel',
                     '/apollo/sensor/gnss/raw_data',
                     'gps raw data channel.')


def process_record_file(args):
    """Read record file and extract the message with specified channels"""
    freader = record.RecordReader(args.input_file)
    glog.info('#processing record file {}'.format(args.input_file))
    time.sleep(1)
    output_file = os.path.join(args.output_dir, 'gpsimu.bin')
    with open(output_file, 'wb') as outfile:
        for channel, message, _type, _timestamp in freader.read_messages():
            if channel == args.gps_raw_data_channel:
                raw_data = RawData()
                raw_data.ParseFromString(message)
                outfile.write(raw_data.data)


def main():
    """Entry point."""
    gflags.FLAGS(sys.argv)
    process_record_file(gflags.FLAGS)
    return


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import re
import shlex
import sys

import yaml


MAX_CAN_ID = 4096000000  # 2048


def extract_var_info(items):
    """
       Desp: extract var info from line split items.
    """
    car_var = {}
    car_var["name"] = items[1]
    car_var["bit"] = int(items[3].split('|')[0])
    car_var["len"] = int(items[3].split('|')[1].split('@')[0])
    order_sign = items[3].split('|')[1].split('@')[1]
    if order_sign == "0+":
        car_var["order"] = "motorola"
        car_var["is_signed_var"] = False
    elif order_sign == "0-":
        car_var["order"] = "motorola"
        car_var["is_signed_var"] = True
    elif order_sign == "1+":
        car_var["order"] = "intel"
        car_var["is_signed_var"] = False
    elif order_sign == "1-":
        car_var["order"] = "intel"
        car_var["is_signed_var"] = True
    car_var["offset"] = float(items[4].split(',')[1].split(')')[0])
    car_var["precision"] = float(items[4].split(',')[0].split('(')[1])
    car_var["physical_range"] = items[5]
    car_var["physical_unit"] = items[6].replace('_', ' ')
    if car_var["len"] == 1:
        car_var["type"] = "bool"
    elif car_var["physical_range"].find(
            ".") != -1 or car_var["precision"] != 1.0:
        car_var["type"] = "double"
    else:
        car_var["type"] = "int"

    return car_var


def extract_dbc_meta(dbc_file, out_file, car_type, black_list, sender_list,
                     sender):
    """
        the main gen_config func, use dbc file to gen a yaml file
        parse every line, if the line is:
        eg:BO_ 1104 BMS_0x450: 8 VCU
        5 segments, and segments[0] is "BO_", then begin parse every signal in the following line

    """
    sender_list = map(str, sender_list)
    with open(dbc_file) as fp:
        in_protocol = False
        protocols = {}
        protocol = {}
        p_name = ""
        line_num = 0
        for line in fp:
            items = shlex.split(line)
            line_num = line_num + 1
            if len(items) == 5 and items[0] == "BO_":
                p_name = items[2][:-1].lower()
                protocol = {}
                if int(items[1]) > MAX_CAN_ID:
                    continue
                protocol["id"] = "%x" % int(items[1])
                protocol["name"] = "%s_%s" % (p_name, protocol["id"])
                protocol["sender"] = items[4]
                if protocol["id"] in black_list:
                    continue
                protocol["protocol_type"] = "report"
                if protocol["id"] in sender_list or protocol["sender"] == sender:
                    protocol["protocol_type"] = "control"
                protocol["vars"] = []
                in_protocol = True
            elif in_protocol:
                if len(items) > 3 and items[0] == "SG_":
                    if items[2] == ":":
                        var_info = extract_var_info(items)
                        # current we can't process than 4 byte value
                        if var_info["len"] <= 32:
                            protocol["vars"].append(var_info)
                else:
                    in_protocol = False
                    if len(protocol) != 0 and len(protocol["vars"]) != 0 and len(
                            protocol["vars"]) < 65:
                        protocols[protocol["id"]] = protocol
                        # print protocol
                        protocol = {}

            if len(items) == 5 and items[0] == "CM_" and items[1] == "SG_":
                protocol_id = "%x" % int(items[2])
                if int(items[2]) > MAX_CAN_ID:
                    continue
                for var in protocols[protocol_id]["vars"]:
                    if var["name"] == items[3]:
                        var["description"] = items[4][:-1]

            if len(items) > 2 and items[0] == "VAL_":
                protocol_id = "%x" % int(items[1])
                if int(items[1]) > MAX_CAN_ID:
                    continue
                for var in protocols[protocol_id]["vars"]:
                    if var["name"] == items[2]:
                        var["type"] = "enum"
                        var["enum"] = {}
                        for idx in range(3, len(items) - 1, 2):
                            enumtype = re.sub('\W+', ' ', items[idx + 1])
                            enumtype = enumtype.strip().replace(" ",
                                                                "_").upper()
                            enumtype = items[2].upper() + "_" + enumtype
                            var["enum"][int(items[idx])] = enumtype

        cpp_reserved_key_words = ['minor', 'major', 'long', 'int']
        for key in protocols:
            for var in protocols[key]["vars"]:
                if var["name"].lower() in cpp_reserved_key_words:
                    var["name"] = "MY_" + var["name"]

        # print protocols
        config = {}
        config["car_type"] = car_type
        config["protocols"] = protocols
        with open(out_file, 'w') as fp_write:
            fp_write.write(yaml.dump(config))

        control_protocol_num =\
            len([key for key in protocols.keys()
                 if protocols[key]["protocol_type"] == "control"])
        report_protocol_num =\
            len([key for key in protocols.keys()
                 if protocols[key]["protocol_type"] == "report"])
        print("Extract car_type:%s's protocol meta info to file: %s" % (
            car_type.upper(), out_file))
        print("Total parsed protocols: %d" % len(protocols))
        print("Control protocols: %d" % control_protocol_num)
        print("Report protocols: %d" % report_protocol_num)
        return True


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage:\npython %s your_car_parse_config_file.yml" % sys.argv[0])
        sys.exit(0)
    with open(sys.argv[1], 'r') as fp:
        conf = yaml.safe_load(fp)
    dbc_file = conf["dbc_file"]
    protocol_conf_file = conf["protocol_conf"]
    car_type = conf["car_type"]
    black_list = conf["black_list"]
    sender_list = conf["sender_list"]
    sender = conf["sender"]
    extract_dbc_meta(dbc_file, protocol_conf_file, car_type, black_list,
                     sender_list, sender)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# -*- coding:utf-8 -*-

import datetime
import os
import shutil
import sys

import yaml

from modules.tools.gen_vehicle_protocol.gen_proto_file import gen_proto_file
from modules.tools.gen_vehicle_protocol.gen_protocols import gen_protocols
from modules.tools.gen_vehicle_protocol.gen_vehicle_controller_and_manager import gen_vehicle_controller_and_manager
from modules.tools.gen_vehicle_protocol.extract_dbc_meta import extract_dbc_meta


def gen(conf):
    """
        doc string:
    """
    dbc_file = conf["dbc_file"]
    protocol_conf_file = conf["protocol_conf"]
    car_type = conf["car_type"]
    black_list = conf["black_list"]
    sender_list = conf["sender_list"]
    sender = conf["sender"]
    output_dir = conf["output_dir"]

    # extract dbc file meta to an internal config file
    if not extract_dbc_meta(dbc_file, protocol_conf_file, car_type, black_list,
                            sender_list, sender):
        return

    # gen proto
    proto_dir = output_dir + "proto/"
    gen_proto_file(protocol_conf_file, proto_dir)

    # gen protocol
    protocol_dir = output_dir + "vehicle/" + car_type.lower() + "/protocol/"
    gen_protocols(protocol_conf_file, protocol_dir)

    # gen vehicle controller and protocol_manager
    vehicle_dir = output_dir + "vehicle/" + car_type.lower() + "/"
    gen_vehicle_controller_and_manager(protocol_conf_file, vehicle_dir)


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("usage:\npython %s some_config.yml" % sys.argv[0])
        sys.exit(0)
    with open(sys.argv[1], 'r') as fp:
        conf = yaml.safe_load(fp)
    gen(conf)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import datetime
import os
import re
import shutil
import sys

import yaml


def write_single_protocol_vars(pb_fp, p):
    pb_fp.write("\nmessage %s {\n" % p["name"].capitalize())
    if p["protocol_type"] == "control":
        pb_fp.write("// Control Message\n")
    elif p["protocol_type"] == "report":
        pb_fp.write("// Report Message\n")

    for var in p["vars"]:
        fmt = "    %s = %d;\n"
        if var["type"] == "enum":
            pb_fp.write("  enum %s {\n" % (var["name"].capitalize() + "Type"))
            for key in sorted(var["enum"]):
                pb_fp.write(fmt % (var["enum"][key], int(key)))
            pb_fp.write("  }\n")

    var_seq = 1
    for var in p["vars"]:
        fmt = "  optional %s %s = %d;\n"
        t = var["type"]
        if t == "int":
            t = "int32"

        pb_fp.write("  // ")
        if "description" in var:
            pb_fp.write("%s " % var["description"])
        pb_fp.write("[%s] %s\n" %
                    (var["physical_unit"], var["physical_range"]))
        if t == "enum":
            pb_fp.write(fmt % (var["name"].capitalize() + "Type",
                               var["name"].lower(), var_seq))
        else:
            pb_fp.write(fmt % (t, var["name"].lower(), var_seq))
        var_seq = var_seq + 1
    pb_fp.write("}\n")


def update_detail_pb(car_type):
    with open("../../canbus/proto/chassis_detail.proto", 'r+') as pb_fp:
        importline = "import \"modules/canbus/proto/" + car_type.lower(
        ) + ".proto\";\n"
        vehicleline = "    " + car_type.capitalize() + " " + car_type.lower()
        lines = pb_fp.readlines()
        importfound = False
        vehiclefound = False

        oneof = "oneof vehicle"
        index = 0
        startidx = 0
        for l in lines:
            if importline in l:
                importfound = True
            if vehicleline in l:
                vehiclefound = True
            if oneof in l:
                startidx = index
            index = index + 1

        startidx = startidx + 1
        count = 0
        while not "}" in lines[startidx]:
            count = int(lines[startidx].split()[-1][:-1])
            startidx = startidx + 1
        count = count + 1

        if not vehiclefound:
            lines.insert(startidx, vehicleline + " = " + str(count) + ";\n")

        if not importfound:
            lines.insert(4, importline)

        pb_fp.seek(0)
        for l in lines:
            pb_fp.write(l)


def gen_proto_file(config_file, work_dir):
    """
        config_file: the config file is generated with dbc
        work_dir: the protobuf file will be output
    """
    print("Generating proto file")
    if not os.path.exists(work_dir):
        os.makedirs(work_dir)
    with open(config_file, 'r') as fp:
        content = yaml.safe_load(fp)
        protocols = content["protocols"]
        car_type = content["car_type"]
        with open("%s/%s.proto" % (work_dir, car_type.lower()), 'w') as pb_fp:
            pb_fp.write("syntax = \"proto2\";\n\npackage apollo.canbus;\n")
            for pid in protocols:
                p = protocols[pid]
                write_single_protocol_vars(pb_fp, p)
            pb_fp.write("\nmessage %s {\n" % car_type.capitalize())

            pb_var_seq = 1
            for p_name in protocols:
                p = protocols[p_name]
                pb_fp.write("  optional %s %s = %d;" %
                            (p["name"].capitalize(), p["name"], pb_var_seq))
                if protocols[p_name]["protocol_type"] == "control":
                    pb_fp.write(" // control message")
                if protocols[p_name]["protocol_type"] == "report":
                    pb_fp.write(" // report message")
                pb_fp.write("\n")
                pb_var_seq = pb_var_seq + 1
            pb_fp.write("}\n")

            # update_detail_pb(car_type)


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("usage:\npython %s some_config.yml" % sys.argv[0])
        sys.exit(0)
    with open(sys.argv[1], 'r') as fp:
        conf = yaml.safe_load(fp)
    protocol_conf = conf["protocol_conf"]

    work_dir = conf["output_dir"] + "proto/"
    gen_proto_file(protocol_conf, work_dir)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# -*- coding:utf-8 -*-

import datetime
import os
import shutil
import sys

import yaml


def gen_report_header(car_type, protocol, output_dir):
    """
        doc string:
    """
    report_header_tpl_file = "template/report_protocol.h.tpl"
    FMT = get_tpl_fmt(report_header_tpl_file)
    report_header_file = output_dir + "%s.h" % protocol["name"]
    with open(report_header_file, 'w') as h_fp:
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type.lower()
        fmt_val["car_type_upper"] = car_type.upper()
        fmt_val["protocol_name_upper"] = protocol["name"].upper()
        fmt_val["classname"] = protocol["name"].replace('_', '').capitalize()
        func_declare_list = []
        for var in protocol["vars"]:
            fmt = """
  // config detail: %s
  %s %s(const std::uint8_t* bytes, const int32_t length) const;"""
            returntype = var["type"]
            if var["type"] == "enum":
                returntype = protocol["name"].capitalize(
                ) + "::" + var["name"].capitalize() + "Type"
            declare = fmt % (str(var), returntype, var["name"].lower())
            func_declare_list.append(declare)
        fmt_val["func_declare_list"] = "\n".join(func_declare_list)
        h_fp.write(FMT % fmt_val)


def gen_report_cpp(car_type, protocol, output_dir):
    """
        doc string:
    """
    report_cpp_tpl_file = "template/report_protocol.cc.tpl"
    FMT = get_tpl_fmt(report_cpp_tpl_file)
    report_cpp_file = output_dir + "%s.cc" % protocol["name"]
    with open(report_cpp_file, 'w') as fp:
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type
        fmt_val["protocol_name_lower"] = protocol["name"]
        classname = protocol["name"].replace('_', '').capitalize()
        fmt_val["classname"] = classname
        protocol_id = int(protocol["id"].upper(), 16)
        if protocol_id > 2048:
            fmt_val["id_upper"] = gen_esd_can_extended(protocol["id"].upper())
        else:
            fmt_val["id_upper"] = protocol["id"].upper()
        set_var_to_protocol_list = []
        func_impl_list = []
        for var in protocol["vars"]:
            var["name"] = var["name"].lower()

            returntype = var["type"]
            if var["type"] == "enum":
                returntype = protocol["name"].capitalize(
                ) + "::" + var["name"].capitalize() + "Type"
            # gen func top
            fmt = """
// config detail: %s
%s %s::%s(const std::uint8_t* bytes, int32_t length) const {"""
            impl = fmt % (str(var), returntype, classname, var["name"])

            byte_info = get_byte_info(var)
            impl = impl + gen_parse_value_impl(var, byte_info)

            impl = impl + gen_report_value_offset_precision(var, protocol)
            impl = impl + "}"

            func_impl_list.append(impl)
            proto_set_fmt = "  chassis->mutable_%s()->mutable_%s()->set_%s(%s(bytes, length));"
            func_name = var["name"]
            proto_set = proto_set_fmt % (car_type, protocol["name"], var["name"],
                                         func_name)
            set_var_to_protocol_list.append(proto_set)
        fmt_val["set_var_to_protocol_list"] = "\n".join(
            set_var_to_protocol_list)
        fmt_val["func_impl_list"] = "\n".join(func_impl_list)
        fp.write(FMT % fmt_val)


def gen_report_value_offset_precision(var, protocol):
    """
        doc string:
    """
    impl = ""
    if var["is_signed_var"]:
        fmt = "\n  x <<= %d;\n  x >>= %d;\n"
        # x is an int32_t var
        shift_bit = 32 - var["len"]
        impl = impl + fmt % (shift_bit, shift_bit)

    returntype = var["type"]
    if var["type"] == "enum":
        returntype = protocol["name"].capitalize() + "::" + var["name"].capitalize(
        ) + "Type"
    impl = impl + "\n  " + returntype + " ret = "

    if var["type"] == "enum":
        impl = impl + " static_cast<" + returntype + ">(x);\n"
    else:
        impl = impl + "x"
        if var["precision"] != 1.0:
            impl = impl + " * %f" % var["precision"]
        if var["offset"] != 0.0:
            impl = impl + " + %f" % (var["offset"])
        impl = impl + ";\n"
    return impl + "  return ret;\n"


def gen_parse_value_impl(var, byte_info):
    """
        doc string:
    """
    impl = ""
    fmt = "\n  Byte t%d(bytes + %d);\n"
    shift_bit = 0
    for i in range(0, len(byte_info)):
        info = byte_info[i]
        impl = impl + fmt % (i, info["byte"])
        if i == 0:
            impl = impl + "  int32_t x = t%d.get_byte(%d, %d);\n" %\
                (i, info["start_bit"], info["len"])
        elif i == 1:
            impl = impl + "  int32_t t = t%d.get_byte(%d, %d);\n  x <<= %d;\n  x |= t;\n" %\
                (i, info["start_bit"], info["len"], info["len"])
        else:
            impl = impl + "  t = t%d.get_byte(%d, %d);\n  x <<= %d;\n  x |= t;\n" %\
                (i, info["start_bit"], info["len"], info["len"])
        shift_bit = shift_bit + info["len"]
    return impl


def gen_control_header(car_type, protocol, output_dir):
    """
        doc string:
    """
    control_header_tpl_file = "template/control_protocol.h.tpl"
    FMT = get_tpl_fmt(control_header_tpl_file)
    control_header_file = output_dir + "%s.h" % protocol["name"]
    with open(control_header_file, 'w') as h_fp:
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type
        fmt_val["car_type_upper"] = car_type.upper()
        fmt_val["protocol_name_upper"] = protocol["name"].upper()
        classname = protocol["name"].replace('_', '').capitalize()
        fmt_val["classname"] = classname
        declare_public_func_list = []
        declare_private_func_list = []
        declare_private_var_list = []

        fmtpub = "\n  // config detail: %s\n  %s* set_%s(%s %s);"
        fmtpri = "\n  // config detail: %s\n  void set_p_%s(uint8_t* data, %s %s);"
        for var in protocol["vars"]:
            returntype = var["type"]
            if var["type"] == "enum":
                returntype = protocol["name"].capitalize(
                ) + "::" + var["name"].capitalize() + "Type"
            private_var = ""
            public_func_declare = fmtpub % (str(var), classname,
                                            var["name"].lower(), returntype,
                                            var["name"].lower())
            private_func_declare = fmtpri % (str(var), var["name"].lower(),
                                             returntype, var["name"].lower())

            private_var = "  %s %s_;" % (returntype, var["name"].lower())

            declare_private_var_list.append(private_var)
            declare_public_func_list.append(public_func_declare)
            declare_private_func_list.append(private_func_declare)

        fmt_val["declare_public_func_list"] = "\n".join(
            declare_public_func_list)
        fmt_val["declare_private_func_list"] = "\n".join(
            declare_private_func_list)
        fmt_val["declare_private_var_list"] = "\n".join(
            declare_private_var_list)
        h_fp.write(FMT % fmt_val)


def get_byte_info(var):
    """
        doc string: https://wenku.baidu.com/view/3fe9a7a4dd3383c4bb4cd293.html
        u can reference this link to known the difference between motorola and intel encoding
        return : the byte info of a variable in the protocol how many bytes are, and every byte use
                 how many bits, and bit start position
                 for the purpose of easily parsing value from CAN frame, the byte_info is arranged
                 from msb byte to lsb byte order
    """
    bit = var["bit"]
    byte_info = []
    left_len = var["len"]
    byte_idx = bit // 8
    bit_start = bit % 8
    if var["order"] == "motorola":
        while left_len > 0:
            info = {}
            info["byte"] = byte_idx
            info["len"] = min(bit_start + 1, left_len)
            # start_bit is always the lowest bit
            info["start_bit"] = bit_start - info["len"] + 1
            byte_info.append(info)
            left_len = left_len - info["len"]
            byte_idx = byte_idx + 1
            bit_start = 7
    else:
        while left_len > 0:
            info = {}
            info["byte"] = byte_idx
            info["len"] = min(8 - bit_start, left_len)
            info["start_bit"] = bit_start
            byte_info.append(info)
            left_len = left_len - info["len"]
            byte_idx = byte_idx + 1
            bit_start = 0
        # byte_info is always construct with msb(most significant bit) byte to lsb byte
        byte_info.reverse()
    return byte_info


def gen_control_decode_offset_precision(var):
    """
        doc string:
    """
    impl = "\n"
    range_info = get_range_info(var)
    if var["type"] == "double":
        if range_info["low"].find(".") == -1:
            range_info["low"] = "%s.0" % range_info["low"]
        if range_info["high"].find(".") == -1:
            range_info["high"] = "%s.0" % range_info["high"]

    if var["type"] != "enum" and var["type"] != "bool":
        impl = impl + "  %s = ProtocolData::BoundedValue(%s, %s, %s);\n" %\
            (var["name"].lower(), range_info["low"],
             range_info["high"], var["name"].lower())
    impl = impl + "  int x ="
    if var["offset"] != 0.0:
        impl = impl + " (%s - %f)" % (var["name"].lower(), var["offset"])
    else:
        impl = impl + " %s" % var["name"].lower()

    if var["precision"] != 1.0:
        impl = impl + " / %f" % var["precision"]
    return impl + ";\n"


def gen_control_encode_one_byte_value_impl(var, byte_info):
    """
        only has int and double, int can hold all the value whatever it is signed or unsigned
    """
    fmt = """
  Byte to_set(data + %d);
  to_set.set_value(x, %d, %d);
"""
    return fmt % (byte_info["byte"], byte_info["start_bit"], byte_info["len"])


def get_range_info(var):
    """
        doc string:
    """
    info = {}
    if "physical_range" not in var.keys():
        return info
    items = var["physical_range"].split('|')
    info["low"] = items[0].split('[')[1]
    info["high"] = items[1].split(']')[0]
    return info


def gen_control_encode_value_impl(var, byte_info):
    """
        doc string:
    """
    impl = "  uint8_t t = 0;\n"
    fmt = """
  t = x & %s;
  Byte to_set%d(data + %d);
  to_set%d.set_value(t, %d, %d);
"""
    shift_bit = 0
    for i in range(0, len(byte_info)):
        info = byte_info[i]
        if i != 0:
            impl = impl + "  x >>= %d;\n" % shift_bit
        mask_bit = "0x%X" % ((1 << info["len"]) - 1)
        impl = impl + fmt % (mask_bit, i, info["byte"], i, info["start_bit"],
                             info["len"])
        shift_bit = info["len"]
    return impl


def gen_control_value_func_impl(classname, var, protocol):
    """
        doc string:
    """
    impl = ""
    if var["len"] > 32:
        print("This generator not support big than four bytes var." +
              "protocol classname: %s, var_name:%s " % (
                  class_name, var["name"]))
        return impl

    fmt = """
%(classname)s* %(classname)s::set_%(var_name)s(
    %(var_type)s %(var_name)s) {
  %(var_name)s_ = %(var_name)s;
  return this;
 }

// config detail: %(config)s
void %(classname)s::set_p_%(var_name)s(uint8_t* data,
    %(var_type)s %(var_name)s) {"""
    fmt_val = {}
    fmt_val["classname"] = classname
    fmt_val["var_name"] = var["name"].lower()
    returntype = var["type"]
    if var["type"] == "enum":
        returntype = protocol["name"].capitalize() + "::" + var["name"].capitalize(
        ) + "Type"
    fmt_val["var_type"] = returntype
    fmt_val["config"] = str(var)
    impl = impl + fmt % fmt_val
    impl = impl + gen_control_decode_offset_precision(var)

    # get lsb to msb order
    byte_info = get_byte_info(var)
    byte_info.reverse()
    if len(byte_info) == 1:
        impl = impl + gen_control_encode_one_byte_value_impl(var, byte_info[0])
    else:
        impl = impl + gen_control_encode_value_impl(var, byte_info)

    return impl + "}\n"


def gen_control_cpp(car_type, protocol, output_dir):
    """
        doc string:
    """
    control_cpp_tpl_file = "template/control_protocol.cc.tpl"
    FMT = get_tpl_fmt(control_cpp_tpl_file)
    control_cpp_file = output_dir + "%s.cc" % protocol["name"]
    with open(control_cpp_file, 'w') as fp:
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type
        fmt_val["protocol_name_lower"] = protocol["name"]
        protocol_id = int(protocol["id"].upper(), 16)
        if protocol_id > 2048:
            fmt_val["id_upper"] = gen_esd_can_extended(protocol["id"].upper())
        else:
            fmt_val["id_upper"] = protocol["id"].upper()
        classname = protocol["name"].replace('_', '').capitalize()
        fmt_val["classname"] = classname

        set_private_var_list = []
        set_private_var_init_list = []
        set_func_impl_list = []
        for var in protocol["vars"]:
            func_impl = gen_control_value_func_impl(classname, var, protocol)
            set_func_impl_list.append(func_impl)
            set_private_var = "  set_p_%s(data, %s_);" % (var["name"].lower(),
                                                          var["name"].lower())
            set_private_var_list.append(set_private_var)
            init_val = "0"
            if var["type"] == "double":
                init_val = "0.0"
            elif var["type"] == "bool":
                init_val = "false"
            elif var["type"] == "enum":
                if 0 in var["enum"]:
                    init_val = protocol["name"].capitalize(
                    ) + "::" + var["enum"][0].upper()
                else:
                    init_val = protocol["name"].capitalize(
                    ) + "::" + list(var["enum"].values())[0].upper()

            set_private_var_init_list.append("  %s_ = %s;" %
                                             (var["name"].lower(), init_val))
        fmt_val["set_private_var_list"] = "\n".join(set_private_var_list)
        fmt_val["set_private_var_init_list"] = "\n".join(
            set_private_var_init_list)
        fmt_val["set_func_impl_list"] = "\n".join(set_func_impl_list)
        fp.write(FMT % fmt_val)


def get_tpl_fmt(tpl_file):
    """
        get fmt from tpl_file
    """
    with open(tpl_file, 'r') as tpl:
        fmt = tpl.readlines()
    fmt = "".join(fmt)
    return fmt


def gen_build_file(car_type, work_dir):
    """
        doc string:
    """
    build_tpl_file = "template/protocol_BUILD.tpl"
    fmt = get_tpl_fmt(build_tpl_file)
    with open(work_dir + "BUILD", "w") as build_fp:
        fmt_var = {}
        fmt_var["car_type"] = car_type.lower()
        build_fp.write(fmt % fmt_var)


def gen_protocols(protocol_conf_file, protocol_dir):
    """
        doc string:
    """
    print("Generating protocols")
    if not os.path.exists(protocol_dir):
        os.makedirs(protocol_dir)
    with open(protocol_conf_file, 'r') as fp:
        content = yaml.safe_load(fp)
        protocols = content["protocols"]
        car_type = content["car_type"]
        for p_name in protocols:
            protocol = protocols[p_name]

            if protocol["protocol_type"] == "report":
                gen_report_header(car_type, protocol, protocol_dir)
                gen_report_cpp(car_type, protocol, protocol_dir)
            elif protocol["protocol_type"] == "control":
                gen_control_header(car_type, protocol, protocol_dir)
                gen_control_cpp(car_type, protocol, protocol_dir)

            else:
                print("Unknown protocol_type:%s" % protocol["protocol_type"])
        gen_build_file(car_type, protocol_dir)


def gen_esd_can_extended(str):
    """
        id string:
    """
    int_id = int(str, 16)
    int_id &= 0x1FFFFFFF
    int_id |= 0x20000000
    str = hex(int_id).replace('0x', '')
    return str


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage:\npython %s some_config.yml" % sys.argv[0])
        sys.exit(0)
    with open(sys.argv[1], 'r') as fp:
        conf = yaml.safe_load(fp)
    protocol_conf = conf["protocol_conf"]

    protocol_dir = conf["output_dir"] + "vehicle/" + conf["car_type"].lower(
    ) + "/protocol/"
    shutil.rmtree(output_dir, True)
    os.makedirs(output_dir)
    gen_protocols(protocol_conf, protocol_dir)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# -*- coding:utf-8 -*-

import datetime
import os
import shutil
import sys

import yaml


def gen_vehicle_controller_header(content, output_dir):
    controller_header_tpl_file = "template/controller.h.tpl"
    car_type = content["car_type"]
    with open(controller_header_tpl_file, 'r') as tpl:
        fmt = tpl.readlines()
    controller_header_file = output_dir + (
        "%s_controller.h" % content["car_type"].lower())
    with open(controller_header_file, 'w') as header:
        FMT = "".join(fmt)
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type
        fmt_val["car_type_upper"] = car_type.upper()
        fmt_val["car_type_cap"] = car_type.capitalize()

        control_protocol_include_list = []
        control_protocol_include_fmt = "#include \"modules/canbus/vehicle/%s/protocol/%s.h\""

        control_protocol_ptr_list = []
        control_protocol_ptr_fmt = "  %s* %s_ = nullptr;"

        protocols = content["protocols"]
        for pid in protocols:
            p = protocols[pid]
            if p["protocol_type"] == "control":
                name = p["name"]
                include = control_protocol_include_fmt % (car_type.lower(),
                                                          name.lower())
                control_protocol_include_list.append(include)

                var_classname = name.replace('_', '').capitalize()
                var_ptr = control_protocol_ptr_fmt % (var_classname, name)
                control_protocol_ptr_list.append(var_ptr)
        control_protocol_include_list.sort()
        control_protocol_ptr_list.sort()
        fmt_val["control_protocol_include_list"] = "\n".join(
            control_protocol_include_list)
        fmt_val["control_protocol_ptr_list"] = "\n".join(
            control_protocol_ptr_list)
        header.write(FMT % fmt_val)


def gen_vehicle_controller_cpp(content, output_dir):
    controller_cpp_tpl_file = "template/controller.cc.tpl"
    with open(controller_cpp_tpl_file, 'r') as tpl:
        fmt = tpl.readlines()
    car_type = content["car_type"]
    controller_cpp_file = output_dir + ("%s_controller.cc" % car_type.lower())
    with open(controller_cpp_file, 'w') as cpp:
        FMT = "".join(fmt)
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type.lower()
        fmt_val["car_type_cap"] = car_type.capitalize()

        protocol_ptr_get_list = []
        protocol_ptr_get_fmt = """  %(var_name)s_ = dynamic_cast<%(class_name)s*>
          (message_manager_->GetMutableProtocolDataById(%(class_name)s::ID));
  if (%(var_name)s_ == nullptr) {
     AERROR << "%(class_name)s does not exist in the %(car_type)sMessageManager!";
     return ErrorCode::CANBUS_ERROR;
  }
"""
        protocol_add_list = []
        protocol_add_fmt = "  can_sender_->AddMessage(%s::ID, %s_, false);"
        protocols = content["protocols"]
        for pid in protocols:
            p = protocols[pid]
            if p["protocol_type"] == "control":
                var_name = p["name"].lower()
                class_name = p["name"].replace('_', '').capitalize()
                ptr_get_fmt_val = {}
                ptr_get_fmt_val["var_name"] = var_name
                ptr_get_fmt_val["class_name"] = class_name
                ptr_get_fmt_val["car_type"] = car_type.capitalize()
                ptr_get = protocol_ptr_get_fmt % ptr_get_fmt_val
                protocol_ptr_get_list.append(ptr_get)

                protocol_add = protocol_add_fmt % (class_name, var_name)
                protocol_add_list.append(protocol_add)
        protocol_ptr_get_list.sort()
        protocol_add_list.sort()
        fmt_val["protocol_ptr_get_list"] = "\n".join(protocol_ptr_get_list)
        fmt_val["protocol_add_list"] = "\n".join(protocol_add_list)
        cpp.write(FMT % fmt_val)


def gen_message_manager_header(content, output_dir):
    message_manager_header_tpl_file = "template/message_manager.h.tpl"
    with open(message_manager_header_tpl_file, 'r') as tpl:
        fmt = tpl.readlines()
    car_type = content["car_type"]
    message_manager_header_file = output_dir + (
        "%s_message_manager.h" % car_type.lower())
    with open(message_manager_header_file, 'w') as header:
        FMT = "".join(fmt)
        fmt_val = {}
        fmt_val["car_type_namespace"] = car_type.lower()
        fmt_val["car_type_cap"] = car_type.capitalize()
        fmt_val["car_type_up"] = car_type.upper()
        header.write(FMT % fmt_val)


def gen_message_manager_cpp(content, output_dir):
    message_manager_cpp_tpl_file = "template/message_manager.cc.tpl"
    with open(message_manager_cpp_tpl_file, 'r') as tpl:
        fmt = tpl.readlines()
    car_type = content["car_type"]
    message_manager_cpp_file = output_dir + (
        "%s_message_manager.cc" % car_type.lower())
    with open(message_manager_cpp_file, 'w') as cpp:
        FMT = "".join(fmt)
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type.lower()
        fmt_val["car_type_cap"] = car_type.capitalize()
        protocols = content["protocols"]

        control_header_list = []
        report_header_list = []
        header_fmt = "#include \"modules/canbus/vehicle/%s/protocol/%s.h\""

        control_add_list = []
        report_add_list = []
        add_fmt = "  Add%sProtocolData<%s, true>();"
        for p_name in protocols:
            p = protocols[p_name]
            var_name = "%s" % p["name"].lower()
            class_name = p["name"].replace('_', '').capitalize()
            header = header_fmt % (car_type.lower(), var_name)
            if p["protocol_type"] == "control":
                control_header_list.append(header)
                item = add_fmt % ("Send", class_name)
                control_add_list.append(item)
            elif p["protocol_type"] == "report":
                report_header_list.append(header)
                item = add_fmt % ("Recv", class_name)
                report_add_list.append(item)
        control_header_list.sort()
        report_header_list.sort()
        control_add_list.sort()
        report_add_list.sort()
        fmt_val["control_header_list"] = "\n".join(control_header_list)
        fmt_val["report_header_list"] = "\n".join(report_header_list)
        fmt_val["control_add_list"] = "\n".join(control_add_list)
        fmt_val["report_add_list"] = "\n".join(report_add_list)
        cpp.write(FMT % fmt_val)


def gen_vehicle_factory_header(content, output_dir):
    vehicle_factory_header_tpl_file = "template/vehicle_factory.h.tpl"
    with open(vehicle_factory_header_tpl_file, 'r') as tpl:
        fmt = tpl.readlines()
    car_type = content["car_type"]
    vehicle_factory_header_file = output_dir + (
        "%s_vehicle_factory.h" % car_type.lower())
    with open(vehicle_factory_header_file, 'w') as header:
        FMT = "".join(fmt)
        fmt_val = {}
        fmt_val["car_type_cap"] = car_type.capitalize()
        fmt_val["car_type_upper"] = car_type.upper()
        fmt_val["car_type_lower"] = car_type.lower()
        header.write(FMT % fmt_val)


def gen_vehicle_factory_cpp(content, output_dir):
    vehicle_factory_cpp_tpl_file = "template/vehicle_factory.cc.tpl"
    with open(vehicle_factory_cpp_tpl_file, 'r') as tpl:
        fmt = tpl.readlines()
    car_type = content["car_type"]
    vehicle_factory_cpp_file = output_dir + (
        "%s_vehicle_factory.cc" % car_type.lower())
    with open(vehicle_factory_cpp_file, 'w') as cpp:
        FMT = "".join(fmt)
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type.lower()
        fmt_val["car_type_cap"] = car_type.capitalize()
        fmt_val["car_type_upper"] = car_type.upper()
        cpp.write(FMT % fmt_val)


def gen_build_file(content, output_dir):
    build_tpl_file = "template/controller_manager_BUILD.tpl"
    with open(build_tpl_file, 'r') as tpl:
        fmt = tpl.readlines()
    car_type = content["car_type"]
    build_file = output_dir + "BUILD"
    with open(build_file, 'w') as fp:
        FMT = "".join(fmt)
        fmt_val = {}
        fmt_val["car_type_lower"] = car_type.lower()
        fp.write(FMT % fmt_val)


def gen_vehicle_controller_and_manager(config_file, output_dir):
    print("Generating controller and manager")
    with open(config_file, 'r') as fp:
        content = yaml.safe_load(fp)
        gen_vehicle_controller_header(content, output_dir)
        gen_vehicle_controller_cpp(content, output_dir)
        gen_message_manager_header(content, output_dir)
        gen_message_manager_cpp(content, output_dir)
        gen_vehicle_factory_header(content, output_dir)
        gen_vehicle_factory_cpp(content, output_dir)
        gen_build_file(content, output_dir)


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print('Usage: python %s some_config.yml' % sys.argv[0])
        sys.exit(0)

    with open(sys.argv[1], 'r') as fp:
        conf = yaml.safe_load(fp)
    protocol_conf = conf["protocol_conf"]

    output_dir = conf["output_dir"] + "vehicle/" + conf["car_type"].lower() + \
        "/"
    shutil.rmtree(output_dir, True)
    os.makedirs(output_dir)
    gen_vehicle_controller_and_manager(protocol_conf, output_dir)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
import os
import sys

import numpy


def get_stat2_from_data(data):
    """Find the max number of continuous frames when position error is lager
       than 30cm, 20cm and 10cm

    Arguments:
        data: error array
    Returns:
        stat: array of max number of continuous frames
    """
    max_con_frame_num_10 = 0
    max_con_frame_num_20 = 0
    max_con_frame_num_30 = 0

    tem_con_frame_num_10 = 0
    tem_con_frame_num_20 = 0
    tem_con_frame_num_30 = 0

    for d in data:
        if d > 0.1:
            tem_con_frame_num_10 += 1
            if d > 0.2:
                tem_con_frame_num_20 += 1
                if d > 0.3:
                    tem_con_frame_num_30 += 1
                else:
                    if tem_con_frame_num_30 > max_con_frame_num_30:
                        max_con_frame_num_30 = tem_con_frame_num_30
                        tem_con_frame_num_30 = 0
            else:
                if tem_con_frame_num_20 > max_con_frame_num_20:
                    max_con_frame_num_20 = tem_con_frame_num_20
                    tem_con_frame_num_20 = 0
        else:
            if tem_con_frame_num_10 > max_con_frame_num_10:
                max_con_frame_num_10 = tem_con_frame_num_10
                tem_con_frame_num_10 = 0

    stat = [max_con_frame_num_10, max_con_frame_num_20, max_con_frame_num_30]
    return stat


def get_angle_stat2_from_data(data):
    """Find the max number of continuous frames when yaw error is lager
       than 1.0d, 0.6d and 0.3d

    Arguments:
        data: error array
    Returns:
        stat: array of max number of continuous frames
    """
    max_con_frame_num_1_0 = 0
    max_con_frame_num_0_6 = 0
    max_con_frame_num_0_3 = 0

    tem_con_frame_num_1_0 = 0
    tem_con_frame_num_0_6 = 0
    tem_con_frame_num_0_3 = 0

    for d in data:
        if(d > 0.3):
            tem_con_frame_num_0_3 += 1
            if(d > 0.6):
                tem_con_frame_num_0_6 += 1
                if(d > 1.0):
                    tem_con_frame_num_1_0 += 1
                else:
                    if tem_con_frame_num_1_0 > max_con_frame_num_1_0:
                        max_con_frame_num_1_0 = tem_con_frame_num_1_0
                        tem_con_frame_num_1_0 = 0
            else:
                if tem_con_frame_num_0_6 > max_con_frame_num_0_6:
                    max_con_frame_num_0_6 = tem_con_frame_num_0_6
                    tem_con_frame_num_0_6 = 0
        else:
            if tem_con_frame_num_0_3 > max_con_frame_num_0_3:
                max_con_frame_num_0_3 = tem_con_frame_num_0_3
                tem_con_frame_num_0_3 = 0

    stat = [max_con_frame_num_1_0, max_con_frame_num_0_6, max_con_frame_num_0_3]
    return stat


def get_stat_from_data(data):
    if len(data) == 0:
        print("No statistics data!")
        return []
    num_data = numpy.array(data)
    sum1 = num_data.sum()
    sum2 = (num_data * num_data).sum()
    mean = sum1 / len(data)
    std = math.sqrt(sum2 / len(data) - mean * mean)
    mx = num_data.max()
    count_less_than_30 = 0.0
    count_less_than_20 = 0.0
    count_less_than_10 = 0.0
    for d in data:
        if d < 0.3:
            count_less_than_30 += 1.0
            if d < 0.2:
                count_less_than_20 += 1.0
                if d < 0.1:
                    count_less_than_10 += 1.0
    count_less_than_30 /= float(len(data))
    count_less_than_20 /= float(len(data))
    count_less_than_10 /= float(len(data))
    stat = [mean, std, mx, count_less_than_30,
            count_less_than_20, count_less_than_10]
    return stat


def get_angle_stat_from_data(data):
    if len(data) == 0:
        print("No statistics data!")
        return []
    num_data = numpy.array(data)
    sum1 = num_data.sum()
    sum2 = (num_data * num_data).sum()
    mean = sum1 / len(data)
    std = math.sqrt(sum2 / len(data) - mean * mean)
    mx = num_data.max()
    count_less_than_1 = 0.0
    count_less_than_06 = 0.0
    count_less_than_03 = 0.0
    for d in data:
        if d < 1.0:
            count_less_than_1 += 1.0
            if d < 0.6:
                count_less_than_06 += 1.0
                if d < 0.3:
                    count_less_than_03 += 1.0
    count_less_than_1 /= float(len(data))
    count_less_than_06 /= float(len(data))
    count_less_than_03 /= float(len(data))
    stat = [mean, std, mx, count_less_than_1,
            count_less_than_06, count_less_than_03]
    return stat


def parse_file(filename, type):
    with open(filename, 'r') as fp:
        lines = fp.readlines()
    print('%d frames' % len(lines))
    error = []
    error_lon = []
    error_lat = []
    error_alt = []
    error_roll = []
    error_pitch = []
    error_yaw = []
    for line in lines:
        s = line.split()
        if (len(s) > 7):
            # error.append(float(s[6]))
            error_lon.append(float(s[2]))
            error_lat.append(float(s[3]))
            error_alt.append(float(s[4]))
            error_roll.append(float(s[5]))
            error_pitch.append(float(s[6]))
            error_yaw.append(float(s[7]))

            x = float(s[2])
            y = float(s[3])
            error.append(math.sqrt(x * x + y * y))
            # print "%f %f %f" % (error[-1], error_lon[-1], error_lat[-1])
    if type == "all":
        print_distance_error(error, error_lon, error_lat, error_alt)
        print_angle_error(error_roll, error_pitch, error_yaw)
    elif type == "distance_only":
        print_distance_error(error, error_lon, error_lat, error_alt)
    elif type == "angle_only":
        print_angle_error(error_roll, error_pitch, error_yaw)
    else:
        print_distance_error(error, error_lon, error_lat, error_alt)
        print_angle_error(error_roll, error_pitch, error_yaw)


def print_distance_error(error, error_lon, error_lat, error_alt):
    print('criteria : mean     std      max      < 30cm   < 20cm   < 10cm  con_frames(>30cm)')
    result = get_stat_from_data(error)
    if len(result) != 6:
        return
    res = get_stat2_from_data(error)
    print('error    : %06f %06f %06f %06f %06f %06f %06d' %
          (result[0], result[1], result[2],
           result[3], result[4], result[5], res[2]))
    result = get_stat_from_data(error_lon)
    res = get_stat2_from_data(error_lon)
    print('error lon: %06f %06f %06f %06f %06f %06f %06d' %
          (result[0], result[1], result[2],
           result[3], result[4], result[5], res[2]))
    result = get_stat_from_data(error_lat)
    res = get_stat2_from_data(error_lat)
    print('error lat: %06f %06f %06f %06f %06f %06f %06d' %
          (result[0], result[1], result[2],
           result[3], result[4], result[5], res[2]))
    result = get_stat_from_data(error_alt)
    res = get_stat2_from_data(error_alt)
    print('error alt: %06f %06f %06f %06f %06f %06f %06d' %
          (result[0], result[1], result[2],
           result[3], result[4], result[5], res[2]))


def print_angle_error(error_roll, error_pitch, error_yaw):
    print('criteria : mean     std      max      < 1.0d   < 0.6d   < 0.3d  con_frames(>1.0d)')
    result = get_angle_stat_from_data(error_roll)
    if len(result) != 6:
        return
    res = get_angle_stat2_from_data(error_roll)
    print("error rol: %06f %06f %06f %06f %06f %06f %06d" %
          (result[0], result[1], result[2],
           result[3], result[4], result[5], res[0]))
    result = get_angle_stat_from_data(error_pitch)
    res = get_angle_stat2_from_data(error_pitch)
    print("error pit: %06f %06f %06f %06f %06f %06f %06d" %
          (result[0], result[1], result[2],
           result[3], result[4], result[5], res[0]))
    result = get_angle_stat_from_data(error_yaw)
    res = get_angle_stat2_from_data(error_yaw)
    print("error yaw: %06f %06f %06f %06f %06f %06f %06d" %
          (result[0], result[1], result[2],
           result[3], result[4], result[5], res[0]))


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print('Usage: %s [evaluation file] [evaluation type]' % argv[0])
        sys.exit(0)
    elif not os.path.isfile(sys.argv[1]):
        print('File does not exist')
    elif len(sys.argv) < 3:
        parse_file(sys.argv[1], 'all')
    else:
        parse_file(sys.argv[1], sys.argv[2])
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
from modules.map.proto import map_pb2
from modules.map.proto import map_signal_pb2
from modules.map.proto import map_overlap_pb2
from google.protobuf import text_format
from shapely.geometry import LineString, Point

if len(sys.argv) < 3:
    print('Usage: %s [map_file] [signal_file]' % sys.argv[0])
    sys.exit(0)

map_file = sys.argv[1]
signal_file = sys.argv[2]

with open(map_file, 'r') as fmap:
    map_data = fmap.read()
    map = map_pb2.Map()
    text_format.Parse(map_data, map)

with open(signal_file, 'r') as fsignal:
    signal_data = fsignal.read()
    signal = map_signal_pb2.Signal()
    text_format.Parse(signal_data, signal)

lanes = {}
lanes_map = {}
for lane in map.lane:
    lane_points = []
    lanes_map[lane.id.id] = lane
    for segment in lane.central_curve.segment:
        for point in segment.line_segment.point:
            lane_points.append((point.x, point.y))
    lane_string = LineString(lane_points)
    lanes[lane.id.id] = lane_string

lines = {}
for stop_line in signal.stop_line:
    stop_line_points = []
    for segment in stop_line.segment:
        for point in segment.line_segment.point:
            stop_line_points.append((point.x, point.y))
    stop_line_string = LineString(stop_line_points)
    for lane_id, lane_string in lanes.items():
        p = stop_line_string.intersection(lane_string)
        if type(p) == Point:
            s = lane_string.project(p)
            overlap = map.overlap.add()
            overlap.id.id = str(lane_id) + "_" + str(signal.id.id)
            obj = overlap.object.add()
            obj.id.id = signal.id.id
            obj.signal_overlap_info.CopyFrom(
                map_overlap_pb2.SignalOverlapInfo())
            obj = overlap.object.add()
            obj.id.id = lane_id
            obj.lane_overlap_info.start_s = s
            obj.lane_overlap_info.end_s = s + 0.1
            obj.lane_overlap_info.is_merge = False

            signal.overlap_id.add().id = overlap.id.id
            lanes_map[lane_id].overlap_id.add().id = overlap.id.id
map.signal.add().CopyFrom(signal)

with open(map_file + "_" + fsignal_file, 'w') as fmap:
    fmap.write(str(map))
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
Extract localization message from data record file,
and save them into specified  file

Usage:
    extract_path.py save_fileName  bag1 bag2

See the gflags for more optional args.
"""

import sys
from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from modules.localization.proto import localization_pb2

if len(sys.argv) < 3:
    print("Usage: %s <filename> <fbags>" % sys.argv[0])
    sys.exit(0)

filename = sys.argv[1]
fbags = sys.argv[2:]

with open(filename, 'w') as f:
    for fbag in fbags:
        reader = RecordReader(fbag)
        for msg in reader.read_messages():
            if msg.topic == "/apollo/localization/pose":
                localization = localization_pb2.LocalizationEstimate()
                localization.ParseFromString(msg.message)
                x = localization.pose.position.x
                y = localization.pose.position.y
                f.write(str(x) + "," + str(y) + "\n")
print("File written to: %s" % filename)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys

from modules.map.proto import map_pb2
from modules.map.proto import map_lane_pb2
import math
from shapely.geometry import LineString, Point

LANE_WIDTH = 3.3


def convert(p, p2, distance):
    delta_y = p2.y - p.y
    delta_x = p2.x - p.x
    # print math.atan2(delta_y, delta_x)
    left_angle = math.atan2(delta_y, delta_x) + math.pi / 2.0
    right_angle = math.atan2(delta_y, delta_x) - math.pi / 2.0
    # print angle
    lp = []
    lp.append(p.x + (math.cos(left_angle) * distance))
    lp.append(p.y + (math.sin(left_angle) * distance))

    rp = []
    rp.append(p.x + (math.cos(right_angle) * distance))
    rp.append(p.y + (math.sin(right_angle) * distance))
    return lp, rp


def shift(p, p2, distance, isleft=True):
    delta_y = p2.y - p.y
    delta_x = p2.x - p.x
    # print math.atan2(delta_y, delta_x)
    angle = 0
    if isleft:
        angle = math.atan2(delta_y, delta_x) + math.pi / 2.0
    else:
        angle = math.atan2(delta_y, delta_x) - math.pi / 2.0
    # print angle
    p1n = []
    p1n.append(p.x + (math.cos(angle) * distance))
    p1n.append(p.y + (math.sin(angle) * distance))

    p2n = []
    p2n.append(p2.x + (math.cos(angle) * distance))
    p2n.append(p2.y + (math.sin(angle) * distance))
    return Point(p1n), Point(p2n)


def create_lane(map, id):
    lane = map.lane.add()
    lane.id.id = str(id)
    lane.type = map_lane_pb2.Lane.CITY_DRIVING
    lane.direction = map_lane_pb2.Lane.FORWARD
    lane.length = 100.0
    lane.speed_limit = 20.0
    lane.turn = map_lane_pb2.Lane.NO_TURN
    lane.predecessor_id.add().id = str(id - 1)
    lane.successor_id.add().id = str(id + 1)
    left_boundary = lane.left_boundary.curve.segment.add()
    right_boundary = lane.right_boundary.curve.segment.add()
    central = lane.central_curve.segment.add()
    central.length = 100.0

    type = lane.left_boundary.boundary_type.add()
    type.s = 0
    type.types.append(map_lane_pb2.LaneBoundaryType.DOTTED_YELLOW)
    lane.right_boundary.length = 100.0

    type = lane.right_boundary.boundary_type.add()
    type.s = 0
    type.types.append(map_lane_pb2.LaneBoundaryType.DOTTED_YELLOW)
    lane.left_boundary.length = 100.0

    return lane, central, left_boundary, right_boundary


fpath = sys.argv[1]
points = []
with open(fpath, 'r') as f:
    for line in f:
        line = line.replace("\n", '')
        data = line.split(',')
        x = float(data[0])
        y = float(data[1])
        points.append((x, y))

path = LineString(points)
length = int(path.length)

fmap = open("map_" + fpath.split("/")[-1] + ".txt", 'w')
id = 0
map = map_pb2.Map()
road = map.road.add()
road.id.id = "1"
section = road.section.add()
section.id.id = "2"
lane = None
for i in range(length - 1):
    if i % 100 == 0:
        id += 1
        lane, central, left_boundary, right_boundary = create_lane(map, id)
        lane_n1, central_n1, left_boundary_n1, right_boundary_n1 = create_lane(
            map, id + 1000)
        lane_n2, central_n2, left_boundary_n2, right_boundary_n2 = create_lane(
            map, id + 2000)
        section.lane_id.add().id = str(id)
        section.lane_id.add().id = str(id + 1000)
        section.lane_id.add().id = str(id + 2000)

        lane.left_neighbor_forward_lane_id.add().id = str(id + 1000)
        lane_n1.left_neighbor_forward_lane_id.add().id = str(id + 2000)
        lane_n2.right_neighbor_forward_lane_id.add().id = str(id + 1000)
        lane_n1.right_neighbor_forward_lane_id.add().id = str(id)

        if i > 0:
            left_bound_point = left_boundary.line_segment.point.add()
            right_bound_point = right_boundary.line_segment.point.add()
            central_point = central.line_segment.point.add()

            p = path.interpolate(i - 1)
            p2 = path.interpolate(i - 1 + 0.5)
            distance = LANE_WIDTH / 2.0
            lp, rp = convert(p, p2, distance)

            left_bound_point.y = lp[1]
            left_bound_point.x = lp[0]
            right_bound_point.y = rp[1]
            right_bound_point.x = rp[0]
            central_point.x = p.x
            central_point.y = p.y

            left_sample = lane.left_sample.add()
            left_sample.s = 0
            left_sample.width = LANE_WIDTH / 2.0

            right_sample = lane.right_sample.add()
            right_sample.s = 0
            right_sample.width = LANE_WIDTH / 2.0

            #####
            left_bound_point = left_boundary_n1.line_segment.point.add()
            right_bound_point = right_boundary_n1.line_segment.point.add()
            central_point = central_n1.line_segment.point.add()

            p = path.interpolate(i - 1)
            p2 = path.interpolate(i - 1 + 0.5)
            distance = LANE_WIDTH
            p, p2 = shift(p, p2, distance)
            distance = LANE_WIDTH / 2.0
            lp, rp = convert(p, p2, distance)

            left_bound_point.y = lp[1]
            left_bound_point.x = lp[0]
            right_bound_point.y = rp[1]
            right_bound_point.x = rp[0]
            central_point.x = p.x
            central_point.y = p.y

            left_sample = lane_n1.left_sample.add()
            left_sample.s = 0
            left_sample.width = LANE_WIDTH / 2.0

            right_sample = lane_n1.right_sample.add()
            right_sample.s = 0
            right_sample.width = LANE_WIDTH / 2.0

            #####
            left_bound_point = left_boundary_n2.line_segment.point.add()
            right_bound_point = right_boundary_n2.line_segment.point.add()
            central_point = central_n2.line_segment.point.add()

            p = path.interpolate(i - 1)
            p2 = path.interpolate(i - 1 + 0.5)
            distance = LANE_WIDTH * 2.0
            p, p2 = shift(p, p2, distance)
            distance = LANE_WIDTH / 2.0
            lp, rp = convert(p, p2, distance)

            left_bound_point.y = lp[1]
            left_bound_point.x = lp[0]
            right_bound_point.y = rp[1]
            right_bound_point.x = rp[0]
            central_point.x = p.x
            central_point.y = p.y

            left_sample = lane_n2.left_sample.add()
            left_sample.s = 0
            left_sample.width = LANE_WIDTH / 2.0

            right_sample = lane_n2.right_sample.add()
            right_sample.s = 0
            right_sample.width = LANE_WIDTH / 2.0

    left_bound_point = left_boundary.line_segment.point.add()
    right_bound_point = right_boundary.line_segment.point.add()
    central_point = central.line_segment.point.add()

    p = path.interpolate(i)
    p2 = path.interpolate(i + 0.5)
    distance = LANE_WIDTH / 2.0
    lp, rp = convert(p, p2, distance)

    central_point.x = p.x
    central_point.y = p.y
    left_bound_point.y = lp[1]
    left_bound_point.x = lp[0]
    right_bound_point.y = rp[1]
    right_bound_point.x = rp[0]

    left_sample = lane.left_sample.add()
    left_sample.s = i % 100 + 1
    left_sample.width = LANE_WIDTH / 2.0

    right_sample = lane.right_sample.add()
    right_sample.s = i % 100 + 1
    right_sample.width = LANE_WIDTH / 2.0

    ################
    left_bound_point = left_boundary_n1.line_segment.point.add()
    right_bound_point = right_boundary_n1.line_segment.point.add()
    central_point = central_n1.line_segment.point.add()

    p = path.interpolate(i)
    p2 = path.interpolate(i + 0.5)
    distance = LANE_WIDTH
    p, p2 = shift(p, p2, distance)
    distance = LANE_WIDTH / 2.0
    lp, rp = convert(p, p2, distance)

    central_point.x = p.x
    central_point.y = p.y
    left_bound_point.y = lp[1]
    left_bound_point.x = lp[0]
    right_bound_point.y = rp[1]
    right_bound_point.x = rp[0]

    left_sample = lane_n1.left_sample.add()
    left_sample.s = i % 100 + 1
    left_sample.width = LANE_WIDTH / 2.0

    right_sample = lane_n1.right_sample.add()
    right_sample.s = i % 100 + 1
    right_sample.width = LANE_WIDTH / 2.0

    ################
    left_bound_point = left_boundary_n2.line_segment.point.add()
    right_bound_point = right_boundary_n2.line_segment.point.add()
    central_point = central_n2.line_segment.point.add()

    p = path.interpolate(i)
    p2 = path.interpolate(i + 0.5)
    distance = 6.6
    p, p2 = shift(p, p2, distance)
    distance = LANE_WIDTH / 2.0
    lp, rp = convert(p, p2, distance)

    central_point.x = p.x
    central_point.y = p.y
    left_bound_point.y = lp[1]
    left_bound_point.x = lp[0]
    right_bound_point.y = rp[1]
    right_bound_point.x = rp[0]

    left_sample = lane_n2.left_sample.add()
    left_sample.s = i % 100 + 1
    left_sample.width = LANE_WIDTH / 2.0

    right_sample = lane_n2.right_sample.add()
    right_sample.s = i % 100 + 1
    right_sample.width = LANE_WIDTH / 2.0

fmap.write(str(map))
fmap.close()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys

from modules.map.proto import map_pb2
from modules.map.proto import map_lane_pb2
from modules.map.proto import map_road_pb2
import math
from shapely.geometry import LineString, Point

LANE_WIDTH = 3.3


def convert(p, p2, distance):
    delta_y = p2.y - p.y
    delta_x = p2.x - p.x
    # print math.atan2(delta_y, delta_x)
    left_angle = math.atan2(delta_y, delta_x) + math.pi / 2.0
    right_angle = math.atan2(delta_y, delta_x) - math.pi / 2.0
    # print angle
    lp = []
    lp.append(p.x + (math.cos(left_angle) * distance))
    lp.append(p.y + (math.sin(left_angle) * distance))

    rp = []
    rp.append(p.x + (math.cos(right_angle) * distance))
    rp.append(p.y + (math.sin(right_angle) * distance))
    return lp, rp


def shift(p, p2, distance, isleft=True):
    delta_y = p2.y - p.y
    delta_x = p2.x - p.x
    # print math.atan2(delta_y, delta_x)
    angle = 0
    if isleft:
        angle = math.atan2(delta_y, delta_x) + math.pi / 2.0
    else:
        angle = math.atan2(delta_y, delta_x) - math.pi / 2.0
    # print angle
    p1n = []
    p1n.append(p.x + (math.cos(angle) * distance))
    p1n.append(p.y + (math.sin(angle) * distance))

    p2n = []
    p2n.append(p2.x + (math.cos(angle) * distance))
    p2n.append(p2.y + (math.sin(angle) * distance))
    return Point(p1n), Point(p2n)


def create_lane(map, id):
    lane = map.lane.add()
    lane.id.id = str(id)
    lane.type = map_lane_pb2.Lane.CITY_DRIVING
    lane.direction = map_lane_pb2.Lane.FORWARD
    lane.length = 100.0
    lane.speed_limit = 20.0
    lane.turn = map_lane_pb2.Lane.NO_TURN
    #lane.predecessor_id.add().id = str(id - 1)
    #lane.successor_id.add().id = str(id + 1)
    left_boundary = lane.left_boundary.curve.segment.add()
    right_boundary = lane.right_boundary.curve.segment.add()
    central = lane.central_curve.segment.add()
    central.length = 100.0

    type = lane.left_boundary.boundary_type.add()
    type.s = 0
    type.types.append(map_lane_pb2.LaneBoundaryType.DOTTED_YELLOW)
    lane.right_boundary.length = 100.0

    type = lane.right_boundary.boundary_type.add()
    type.s = 0
    type.types.append(map_lane_pb2.LaneBoundaryType.DOTTED_YELLOW)
    lane.left_boundary.length = 100.0

    return lane, central, left_boundary, right_boundary


fpath = sys.argv[1]
f = open(fpath, 'r')
points = []
for line in f:
    line = line.replace("\n", '')
    data = line.split(',')
    x = float(data[0])
    y = float(data[1])
    points.append((x, y))

path = LineString(points)
length = int(path.length)

extra_roi_extension = float(sys.argv[3])

fmap = open(sys.argv[2], 'w')
id = 0
map = map_pb2.Map()
road = map.road.add()
road.id.id = "1"
section = road.section.add()
section.id.id = "2"
lane = None
for i in range(length - 1):
    if i % 100 == 0:
        id += 1
        if lane is not None:
            lane.successor_id.add().id = str(id)
        lane, central, left_boundary, right_boundary = create_lane(map, id)
        section.lane_id.add().id = str(id)

        left_edge = section.boundary.outer_polygon.edge.add()
        left_edge.type = map_road_pb2.BoundaryEdge.LEFT_BOUNDARY
        left_edge_segment = left_edge.curve.segment.add()

        right_edge = section.boundary.outer_polygon.edge.add()
        right_edge.type = map_road_pb2.BoundaryEdge.RIGHT_BOUNDARY
        right_edge_segment = right_edge.curve.segment.add()

        if i > 0:
            lane.predecessor_id.add().id = str(id - 1)

            left_bound_point = left_boundary.line_segment.point.add()
            right_bound_point = right_boundary.line_segment.point.add()
            central_point = central.line_segment.point.add()

            right_edge_point = right_edge_segment.line_segment.point.add()
            left_edge_point = left_edge_segment.line_segment.point.add()

            p = path.interpolate(i - 1)
            p2 = path.interpolate(i - 1 + 0.5)
            distance = LANE_WIDTH / 2.0

            lp, rp = convert(p, p2, distance)
            left_bound_point.y = lp[1]
            left_bound_point.x = lp[0]
            right_bound_point.y = rp[1]
            right_bound_point.x = rp[0]

            lp, rp = convert(p, p2, distance + extra_roi_extension)
            left_edge_point.y = lp[1]
            left_edge_point.x = lp[0]
            right_edge_point.y = rp[1]
            right_edge_point.x = rp[0]

            central_point.x = p.x
            central_point.y = p.y

            left_sample = lane.left_sample.add()
            left_sample.s = 0
            left_sample.width = LANE_WIDTH / 2.0

            right_sample = lane.right_sample.add()
            right_sample.s = 0
            right_sample.width = LANE_WIDTH / 2.0

    left_bound_point = left_boundary.line_segment.point.add()
    right_bound_point = right_boundary.line_segment.point.add()
    central_point = central.line_segment.point.add()

    right_edge_point = right_edge_segment.line_segment.point.add()
    left_edge_point = left_edge_segment.line_segment.point.add()

    p = path.interpolate(i)
    p2 = path.interpolate(i + 0.5)
    distance = LANE_WIDTH / 2.0
    lp, rp = convert(p, p2, distance)

    central_point.x = p.x
    central_point.y = p.y
    left_bound_point.y = lp[1]
    left_bound_point.x = lp[0]
    right_bound_point.y = rp[1]
    right_bound_point.x = rp[0]

    left_edge_point.y = lp[1]
    left_edge_point.x = lp[0]
    right_edge_point.y = rp[1]
    right_edge_point.x = rp[0]

    left_sample = lane.left_sample.add()
    left_sample.s = i % 100 + 1
    left_sample.width = LANE_WIDTH / 2.0

    right_sample = lane.right_sample.add()
    right_sample.s = i % 100 + 1
    right_sample.width = LANE_WIDTH / 2.0

fmap.write(str(map))
fmap.close()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys

from modules.map.proto import map_pb2
from modules.map.proto import map_lane_pb2
from modules.map.proto import map_road_pb2
import math
from shapely.geometry import LineString, Point

LANE_WIDTH = 3.3


def convert(p, p2, distance):
    delta_y = p2.y - p.y
    delta_x = p2.x - p.x
    # print math.atan2(delta_y, delta_x)
    left_angle = math.atan2(delta_y, delta_x) + math.pi / 2.0
    right_angle = math.atan2(delta_y, delta_x) - math.pi / 2.0
    # print angle
    lp = []
    lp.append(p.x + (math.cos(left_angle) * distance))
    lp.append(p.y + (math.sin(left_angle) * distance))

    rp = []
    rp.append(p.x + (math.cos(right_angle) * distance))
    rp.append(p.y + (math.sin(right_angle) * distance))
    return lp, rp


def shift(p, p2, distance, isleft=True):
    delta_y = p2.y - p.y
    delta_x = p2.x - p.x
    # print math.atan2(delta_y, delta_x)
    angle = 0
    if isleft:
        angle = math.atan2(delta_y, delta_x) + math.pi / 2.0
    else:
        angle = math.atan2(delta_y, delta_x) - math.pi / 2.0
    # print angle
    p1n = []
    p1n.append(p.x + (math.cos(angle) * distance))
    p1n.append(p.y + (math.sin(angle) * distance))

    p2n = []
    p2n.append(p2.x + (math.cos(angle) * distance))
    p2n.append(p2.y + (math.sin(angle) * distance))
    return Point(p1n), Point(p2n)


def create_lane(map, id):
    lane = map.lane.add()
    lane.id.id = str(id)
    lane.type = map_lane_pb2.Lane.CITY_DRIVING
    lane.direction = map_lane_pb2.Lane.FORWARD
    lane.length = 100.0
    lane.speed_limit = 20.0
    lane.turn = map_lane_pb2.Lane.NO_TURN
    #lane.predecessor_id.add().id = str(id - 1)
    #lane.successor_id.add().id = str(id + 1)
    left_boundary = lane.left_boundary.curve.segment.add()
    right_boundary = lane.right_boundary.curve.segment.add()
    central = lane.central_curve.segment.add()
    central.length = 100.0

    type = lane.left_boundary.boundary_type.add()
    type.s = 0
    type.types.append(map_lane_pb2.LaneBoundaryType.DOTTED_YELLOW)
    lane.right_boundary.length = 100.0

    type = lane.right_boundary.boundary_type.add()
    type.s = 0
    type.types.append(map_lane_pb2.LaneBoundaryType.DOTTED_YELLOW)
    lane.left_boundary.length = 100.0

    return lane, central, left_boundary, right_boundary


fpath = sys.argv[1]
f = open(fpath, 'r')
points = []
for line in f:
    line = line.replace("\n", '')
    data = line.split(',')
    x = float(data[0])
    y = float(data[1])
    points.append((x, y))

path = LineString(points)
length = int(path.length)

fmap = open(sys.argv[2], 'w')
id = 0
map = map_pb2.Map()
road = map.road.add()
road.id.id = "1"
section = road.section.add()
section.id.id = "2"
lane = None
lane_n1 = None
for i in range(length - 1):
    if i % 100 == 0:
        id += 1
        if lane is not None:
            lane.successor_id.add().id = str(id)
        if lane_n1 is not None:
            lane_n1.successor_id.add().id = str(id + 1000)

        lane, central, left_boundary, right_boundary = create_lane(map, id)
        lane_n1, central_n1, left_boundary_n1, right_boundary_n1 = create_lane(
            map, id + 1000)

        section.lane_id.add().id = str(id)
        section.lane_id.add().id = str(id + 1000)

        left_edge = section.boundary.outer_polygon.edge.add()
        left_edge.type = map_road_pb2.BoundaryEdge.LEFT_BOUNDARY
        left_edge_segment = left_edge.curve.segment.add()

        right_edge = section.boundary.outer_polygon.edge.add()
        right_edge.type = map_road_pb2.BoundaryEdge.RIGHT_BOUNDARY
        right_edge_segment = right_edge.curve.segment.add()

        lane.right_neighbor_forward_lane_id.add().id = str(id + 1000)
        lane_n1.left_neighbor_forward_lane_id.add().id = str(id)

        if i > 0:
            lane.predecessor_id.add().id = str(id - 1)
            lane_n1.predecessor_id.add().id = str(id - 1 + 1000)

            right_edge_point = right_edge_segment.line_segment.point.add()
            left_edge_point = left_edge_segment.line_segment.point.add()

            left_bound_point = left_boundary.line_segment.point.add()
            right_bound_point = right_boundary.line_segment.point.add()
            central_point = central.line_segment.point.add()

            p = path.interpolate(i - 1)
            p2 = path.interpolate(i - 1 + 0.5)
            distance = LANE_WIDTH / 2.0
            lp, rp = convert(p, p2, distance)

            left_bound_point.y = lp[1]
            left_bound_point.x = lp[0]
            right_bound_point.y = rp[1]
            right_bound_point.x = rp[0]
            central_point.x = p.x
            central_point.y = p.y

            left_edge_point.y = lp[1]
            left_edge_point.x = lp[0]

            left_sample = lane.left_sample.add()
            left_sample.s = 0
            left_sample.width = LANE_WIDTH / 2.0

            right_sample = lane.right_sample.add()
            right_sample.s = 0
            right_sample.width = LANE_WIDTH / 2.0

            #####
            left_bound_point = left_boundary_n1.line_segment.point.add()
            right_bound_point = right_boundary_n1.line_segment.point.add()
            central_point = central_n1.line_segment.point.add()

            p = path.interpolate(i - 1)
            p2 = path.interpolate(i - 1 + 0.5)
            distance = LANE_WIDTH
            p, p2 = shift(p, p2, distance, False)
            distance = LANE_WIDTH / 2.0
            lp, rp = convert(p, p2, distance)

            left_bound_point.y = lp[1]
            left_bound_point.x = lp[0]
            right_bound_point.y = rp[1]
            right_bound_point.x = rp[0]
            central_point.x = p.x
            central_point.y = p.y

            right_edge_point.y = rp[1]
            right_edge_point.x = rp[0]

            left_sample = lane_n1.left_sample.add()
            left_sample.s = 0
            left_sample.width = LANE_WIDTH / 2.0

            right_sample = lane_n1.right_sample.add()
            right_sample.s = 0
            right_sample.width = LANE_WIDTH / 2.0

    right_edge_point = right_edge_segment.line_segment.point.add()
    left_edge_point = left_edge_segment.line_segment.point.add()

    left_bound_point = left_boundary.line_segment.point.add()
    right_bound_point = right_boundary.line_segment.point.add()
    central_point = central.line_segment.point.add()

    p = path.interpolate(i)
    p2 = path.interpolate(i + 0.5)
    distance = LANE_WIDTH / 2.0
    lp, rp = convert(p, p2, distance)

    central_point.x = p.x
    central_point.y = p.y
    left_bound_point.y = lp[1]
    left_bound_point.x = lp[0]
    right_bound_point.y = rp[1]
    right_bound_point.x = rp[0]

    left_edge_point.y = lp[1]
    left_edge_point.x = lp[0]

    left_sample = lane.left_sample.add()
    left_sample.s = i % 100 + 1
    left_sample.width = LANE_WIDTH / 2.0

    right_sample = lane.right_sample.add()
    right_sample.s = i % 100 + 1
    right_sample.width = LANE_WIDTH / 2.0

    ################
    left_bound_point = left_boundary_n1.line_segment.point.add()
    right_bound_point = right_boundary_n1.line_segment.point.add()
    central_point = central_n1.line_segment.point.add()

    p = path.interpolate(i)
    p2 = path.interpolate(i + 0.5)
    distance = LANE_WIDTH
    p, p2 = shift(p, p2, distance, False)
    distance = LANE_WIDTH / 2.0
    lp, rp = convert(p, p2, distance)

    central_point.x = p.x
    central_point.y = p.y
    left_bound_point.y = lp[1]
    left_bound_point.x = lp[0]
    right_bound_point.y = rp[1]
    right_bound_point.x = rp[0]

    right_edge_point.y = rp[1]
    right_edge_point.x = rp[0]

    left_sample = lane_n1.left_sample.add()
    left_sample.s = i % 100 + 1
    left_sample.width = LANE_WIDTH / 2.0

    right_sample = lane_n1.right_sample.add()
    right_sample.s = i % 100 + 1
    right_sample.width = LANE_WIDTH / 2.0

fmap.write(str(map))
fmap.close()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import matplotlib.pyplot as plt

f = open(sys.argv[1], 'r')
xs = []
ys = []
for line in f:
    line = line.replace("\n", '')
    data = line.split(',')
    x = float(data[0])
    y = float(data[1])
    xs.append(x)
    ys.append(y)
f.close()

fig = plt.figure()
ax = plt.subplot2grid((1, 1), (0, 0))
ax.plot(xs, ys, "b-", lw=3, alpha=0.8)
ax.axis('equal')
plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
import threading

import modules.tools.common.proto_utils as proto_utils
from modules.localization.proto.localization_pb2 import LocalizationEstimate


class Localization:
    def __init__(self, localization_pb=None):
        self.localization_pb = localization_pb
        self.localization_data_lock = threading.Lock()

    def update_localization_pb(self, localization_pb):
        self.localization_data_lock.acquire()
        self.localization_pb = localization_pb
        self.localization_data_lock.release()

    def load(self, localization_file_name):
        self.localization_pb = proto_utils.get_pb_from_text_file(
            localization_file_name, LocalizationEstimate())

    def plot_vehicle(self, ax):
        self.plot_vehicle_position(ax)
        self.plot_vehicle_polygon(ax)
        self.show_annotation(ax)

    def replot_vehicle(self, position_line, polygon_line):
        self.localization_data_lock.acquire()
        if self.localization_pb is None:
            self.localization_data_lock.release()
            return
        position_line.set_visible(True)
        polygon_line.set_visible(True)
        self._replot_vehicle_position(position_line)
        self._replot_vehicle_polygon(polygon_line)
        self.localization_data_lock.release()

    def plot_vehicle_position(self, ax):
        loc_x = [self.localization_pb.pose.position.x]
        loc_y = [self.localization_pb.pose.position.y]
        ax.plot(loc_x, loc_y, "bo")

    def _replot_vehicle_position(self, line):
        loc_x = [self.localization_pb.pose.position.x]
        loc_y = [self.localization_pb.pose.position.y]
        line.set_xdata(loc_x)
        line.set_ydata(loc_y)

    def _replot_vehicle_polygon(self, line):
        position = []
        position.append(self.localization_pb.pose.position.x)
        position.append(self.localization_pb.pose.position.y)
        position.append(self.localization_pb.pose.position.z)

        polygon = self.get_vehicle_polygon(position,
                                           self.localization_pb.pose.heading)
        px = []
        py = []
        for point in polygon:
            px.append(point[0])
            py.append(point[1])
        line.set_xdata(px)
        line.set_ydata(py)

    def plot_vehicle_polygon(self, ax):
        position = []
        position.append(self.localization_pb.pose.position.x)
        position.append(self.localization_pb.pose.position.y)
        position.append(self.localization_pb.pose.position.z)

        polygon = self.get_vehicle_polygon(position,
                                           self.localization_pb.pose.heading)
        self.plot_polygon(polygon, ax)

    def show_annotation(self, ax):
        current_t = self.localization_pb.header.timestamp_sec
        content = "t = " + str(current_t) + "\n"
        content += "speed @y = " + str(
            self.localization_pb.pose.linear_velocity.y) + "\n"
        content += "acc @y = " + str(
            self.localization_pb.pose.linear_acceleration_vrf.y)
        lxy = [-80, 80]
        ax.annotate(
            content,
            xy=(self.localization_pb.pose.position.x,
                self.localization_pb.pose.position.y),
            xytext=lxy,
            textcoords='offset points',
            ha='left',
            va='top',
            bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.3),
            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'),
            alpha=0.8)

    def plot_polygon(self, polygon, ax):
        px = []
        py = []
        for point in polygon:
            px.append(point[0])
            py.append(point[1])
        ax.plot(px, py, "g-")

    def get_vehicle_polygon(self, position, heading):

        front_edge_to_center = 3.89
        back_edge_to_center = 1.043
        left_edge_to_center = 1.055
        right_edge_to_center = 1.055

        cos_h = math.cos(heading)
        sin_h = math.sin(heading)
        #  (p3)  -------- (p0)
        #        | o     |
        #   (p2) -------- (p1)
        p0_x, p0_y = front_edge_to_center, left_edge_to_center
        p1_x, p1_y = front_edge_to_center, -right_edge_to_center
        p2_x, p2_y = -back_edge_to_center, -left_edge_to_center
        p3_x, p3_y = -back_edge_to_center, right_edge_to_center

        p0_x, p0_y = p0_x * cos_h - p0_y * sin_h, p0_x * sin_h + p0_y * cos_h
        p1_x, p1_y = p1_x * cos_h - p1_y * sin_h, p1_x * sin_h + p1_y * cos_h
        p2_x, p2_y = p2_x * cos_h - p2_y * sin_h, p2_x * sin_h + p2_y * cos_h
        p3_x, p3_y = p3_x * cos_h - p3_y * sin_h, p3_x * sin_h + p3_y * cos_h

        [x, y, z] = position
        polygon = []
        polygon.append([p0_x + x, p0_y + y, 0])
        polygon.append([p1_x + x, p1_y + y, 0])
        polygon.append([p2_x + x, p2_y + y, 0])
        polygon.append([p3_x + x, p3_y + y, 0])
        polygon.append([p0_x + x, p0_y + y, 0])
        return polygon
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import random

from matplotlib import cm as cmx
from matplotlib import colors as mcolors
import matplotlib.pyplot as plt

from modules.map.proto import map_pb2
import modules.tools.common.proto_utils as proto_utils


class Map:
    def __init__(self):
        self.map_pb = map_pb2.Map()
        self.colors = []
        self.init_colors()

    def init_colors(self):
        color_num = 6
        self.colors = []
        values = list(range(color_num))
        jet = plt.get_cmap('brg')
        color_norm = mcolors.Normalize(vmin=0, vmax=values[-1])
        scalar_map = cmx.ScalarMappable(norm=color_norm, cmap=jet)
        for val in values:
            color_val = scalar_map.to_rgba(val)
            self.colors.append(color_val)

    def load(self, map_file_name):
        res = proto_utils.get_pb_from_file(map_file_name, self.map_pb)
        return res is not None

    def draw_roads(self, ax):
        cnt = 1
        for road in self.map_pb.road:
            color_val = self.colors[cnt % len(self.colors)]
            self.draw_road(ax, road, color_val)
            cnt += 1

    def draw_road(self, ax, road, color_val):
        for section in road.section:
            for edge in section.boundary.outer_polygon.edge:
                for segment in edge.curve.segment:
                    if segment.HasField('line_segment'):
                        px = []
                        py = []
                        for p in segment.line_segment.point:
                            px.append(float(p.x))
                            py.append(float(p.y))
                        ax.plot(px, py, ls='-', c=color_val, alpha=0.5)

    def draw_lanes(self, ax, is_show_lane_ids, laneids, is_show_lane_details):
        cnt = 1
        for lane in self.map_pb.lane:
            color_val = self.colors[cnt % len(self.colors)]
            if len(laneids) == 0:
                self._draw_lane_boundary(lane, ax, color_val)
                self._draw_lane_central(lane, ax, color_val)
            else:
                if lane.id.id in laneids:
                    self._draw_lane_boundary(lane, ax, color_val)
                    self._draw_lane_central(lane, ax, color_val)
            if is_show_lane_ids:
                self._draw_lane_id(lane, ax, color_val)
            elif is_show_lane_details:
                self._draw_lane_details(lane, ax, color_val)
            elif lane.id.id in laneids:
                print(str(lane))
                self._draw_lane_id(lane, ax, color_val)
            cnt += 1

    def _draw_lane_id(self, lane, ax, color_val):
        """draw lane id"""
        x, y = self._find_lane_central_point(lane)
        self._draw_label(lane.id.id, (x, y), ax, color_val)

    def _draw_lane_details(self, lane, ax, color_val):
        """draw lane id"""
        labelxys = []
        labelxys.append((40, -40))
        labelxys.append((-40, -40))
        labelxys.append((40, 40))
        labelxys.append((-40, 40))
        has = ['right', 'left', 'right', 'left']
        vas = ['bottom', 'bottom', 'top', 'top']

        idx = random.randint(0, 3)
        lxy = labelxys[idx]
        x, y = self._find_lane_central_point(lane)
        details = str(lane.id.id)
        for predecessor_id in lane.predecessor_id:
            details += '\npre:' + str(predecessor_id.id)

        for successor_id in lane.successor_id:
            details += '\nsuc:' + str(successor_id.id)

        for left_neighbor_forward_lane_id in lane.left_neighbor_forward_lane_id:
            details += '\nlnf:' + str(left_neighbor_forward_lane_id.id)

        for right_neighbor_forward_lane_id in lane.right_neighbor_forward_lane_id:
            details += '\nrnf:' + str(right_neighbor_forward_lane_id.id)

        for left_neighbor_reverse_lane_id in lane.left_neighbor_reverse_lane_id:
            details += '\nlnr:' + str(left_neighbor_reverse_lane_id.id)

        for right_neighbor_reverse_lane_id in lane.right_neighbor_reverse_lane_id:
            details += '\nrnr:' + str(right_neighbor_reverse_lane_id.id)

        plt.annotate(
            details,
            xy=(x, y), xytext=lxy,
            textcoords='offset points', ha=has[idx], va=vas[idx],
            bbox=dict(boxstyle='round,pad=0.5', fc=color_val, alpha=0.5),
            arrowprops=dict(arrowstyle='-|>', connectionstyle='arc3,rad=-0.2',
                            fc=color_val, ec=color_val, alpha=0.5))

    def draw_pnc_junctions(self, ax):
        cnt = 1
        for pnc_junction in self.map_pb.pnc_junction:
            color_val = self.colors[cnt % len(self.colors)]
            self._draw_polygon_boundary(pnc_junction.polygon, ax, color_val)
            self._draw_pnc_junction_id(pnc_junction, ax, color_val)
            cnt += 1

    def _draw_pnc_junction_id(self, pnc_junction, ax, color_val):
        x = pnc_junction.polygon.point[0].x
        y = pnc_junction.polygon.point[0].y
        self._draw_label(pnc_junction.id.id, (x, y), ax, color_val)

    def draw_crosswalks(self, ax):
        cnt = 1
        for crosswalk in self.map_pb.crosswalk:
            color_val = self.colors[cnt % len(self.colors)]
            self._draw_polygon_boundary(crosswalk.polygon, ax, color_val)
            self._draw_crosswalk_id(crosswalk, ax, color_val)
            cnt += 1

    def _draw_crosswalk_id(self, crosswalk, ax, color_val):
        x = crosswalk.polygon.point[0].x
        y = crosswalk.polygon.point[0].y
        self._draw_label(crosswalk.id.id, (x, y), ax, color_val)

    @staticmethod
    def _draw_label(label_id, point, ax, color_val):
        """draw label id"""
        labelxys = []
        labelxys.append((40, -40))
        labelxys.append((-40, -40))
        labelxys.append((40, 40))
        labelxys.append((-40, 40))
        has = ['right', 'left', 'right', 'left']
        vas = ['bottom', 'bottom', 'top', 'top']

        idx = random.randint(0, 3)
        lxy = labelxys[idx]
        plt.annotate(
            label_id,
            xy=(point[0], point[1]), xytext=lxy,
            textcoords='offset points', ha=has[idx], va=vas[idx],
            bbox=dict(boxstyle='round,pad=0.5', fc=color_val, alpha=0.5),
            arrowprops=dict(arrowstyle='-|>', connectionstyle='arc3,rad=-0.2',
                            fc=color_val, ec=color_val, alpha=0.5))

    @staticmethod
    def _find_lane_central_point(lane):
        segment_idx = len(lane.left_boundary.curve.segment) // 2
        median_segment = lane.left_boundary.curve.segment[segment_idx]
        left_point_idx = len(median_segment.line_segment.point) // 2
        left_median_point = median_segment.line_segment.point[left_point_idx]

        segment_idx = len(lane.right_boundary.curve.segment) // 2
        median_segment = lane.right_boundary.curve.segment[segment_idx]
        right_point_idx = len(median_segment.line_segment.point) // 2
        right_median_point = median_segment.line_segment.point[right_point_idx]

        x = (left_median_point.x + right_median_point.x) // 2
        y = (left_median_point.y + right_median_point.y) // 2

        return x, y

    @staticmethod
    def _get_median_point(points):
        """get_median_point"""
        if len(points) % 2 == 1:
            point = points[len(points) // 2]
            return point.x, point.y
        else:
            point1 = points[len(points) // 2 - 1]
            point2 = points[len(points) // 2]
            return (point1.x + point2.x) / 2.0, (point1.y + point2.y) / 2.0

    @staticmethod
    def _draw_lane_boundary(lane, ax, color_val):
        """draw boundary"""
        for curve in lane.left_boundary.curve.segment:
            if curve.HasField('line_segment'):
                px = []
                py = []
                for p in curve.line_segment.point:
                    px.append(float(p.x))
                    py.append(float(p.y))
                ax.plot(px, py, ls='-', c=color_val, alpha=0.5)
        for curve in lane.right_boundary.curve.segment:
            if curve.HasField('line_segment'):
                px = []
                py = []
                for p in curve.line_segment.point:
                    px.append(float(p.x))
                    py.append(float(p.y))
                ax.plot(px, py, ls='-', c=color_val, alpha=0.5)

    @staticmethod
    def _draw_lane_central(lane, ax, color_val):
        """draw boundary"""
        for curve in lane.central_curve.segment:
            if curve.HasField('line_segment'):
                px = []
                py = []
                for p in curve.line_segment.point:
                    px.append(float(p.x))
                    py.append(float(p.y))
                ax.plot(px, py, ls=':', c=color_val, alpha=0.5)

    @staticmethod
    def _draw_polygon_boundary(polygon, ax, color_val):
        """draw polygon boundary"""
        px = []
        py = []
        for point in polygon.point:
            px.append(point.x)
            py.append(point.y)
        ax.plot(px, py, ls='-', c=color_val, alpha=0.5)

    def draw_signal_lights(self, ax):
        """draw_signal_lights"""
        for signal in self.map_pb.signal:
            for stop_line in signal.stop_line:
                for curve in stop_line.segment:
                    self._draw_stop_line(curve.line_segment, signal.id.id, ax, "mistyrose")

    def draw_stop_signs(self, ax):
        """draw_stop_signs"""
        for stop_sign in self.map_pb.stop_sign:
            for stop_line in stop_sign.stop_line:
                for curve in stop_line.segment:
                    self._draw_stop_line(curve.line_segment, stop_sign.id.id, ax, "yellow")

    def draw_yield_signs(self, ax):
        """draw_yield_signs"""
        for yieldsign in getattr(self.map_pb, "yield"):
            for stop_line in yieldsign.stop_line:
                for curve in stop_line.segment:
                    self._draw_stop_line(curve.line_segment, yieldsign.id.id, ax, "powderblue")

    @staticmethod
    def _draw_stop_line(line_segment, label, ax, label_color_val):
        """draw a signal"""
        px = []
        py = []
        for p in line_segment.point:
            px.append(float(p.x))
            py.append(float(p.y))
        ax.plot(px, py, 'o-')
        lxy = [random.randint(20, 80) * random.sample([-1, 1], 1)[0],
               random.randint(20, 80) * random.sample([-1, 1], 1)[0]]
        xy = (sum(px) // len(px), sum(py) // len(py))
        plt.annotate(
            label,
            xy=xy, xytext=lxy,
            textcoords='offset points',
            bbox=dict(boxstyle='round,pad=0.5', fc=label_color_val, alpha=0.5),
            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class Path:
    def __init__(self, path_files):
        self.path_files = path_files

    def draw(self, ax):
        xs = []
        ys = []
        for path_file in self.path_files:
            with open(path_file, 'r') as f:
                lines = f.readlines()
                for line in lines:
                    items = line.split(',')
                    xs.append(float(items[1]))
                    ys.append(float(items[2]))
        ax.plot(xs, ys, ls='--', c='k', alpha=0.5)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import threading

import numpy as np

from modules.planning.proto import planning_internal_pb2


class Planning:
    def __init__(self, planning_pb=None):
        self.data_lock = threading.Lock()
        self.init_point_lock = threading.Lock()
        self.planning_pb = planning_pb
        self.path_data_lock = threading.Lock()
        self.path_data_x = {}
        self.path_data_y = {}
        self.speed_data_lock = threading.Lock()
        self.speed_data_time = {}
        self.speed_data_val = {}

        self.traj_data_lock = threading.Lock()
        self.traj_speed_history_len = 30
        self.traj_speed_t_history = []
        self.traj_speed_v_history = []
        self.traj_acc_history_len = 30
        self.traj_acc_t_history = []
        self.traj_acc_a_history = []
        self.traj_path_history_len = 30
        self.traj_path_x_history = []
        self.traj_path_y_history = []

        self.st_data_lock = threading.Lock()
        self.st_curve_s = {}
        self.st_curve_t = {}
        self.st_curve_v = {}
        self.st_data_boundary_s = {}
        self.st_data_boundary_t = {}
        self.st_data_boundary_type = {}
        self.st_speed_limit_s = {}
        self.st_speed_limit_v = {}

        self.st_speed_constraint_s = {}
        self.st_speed_constraint_lower = {}
        self.st_speed_constraint_upper = {}

        self.sl_data_lock = threading.Lock()
        self.sl_sampled_s = []
        self.sl_static_obstacle_lower_boundary = []
        self.sl_static_obstacle_upper_boundary = []
        self.sl_dynamic_obstacle_lower_boundary = []
        self.sl_dynamic_obstacle_upper_boundary = []
        self.sl_map_lower_boundary = []
        self.sl_map_upper_boundary = []
        self.sl_path_s = []
        self.sl_path_l = []
        self.sl_aggregated_boundary_low_l = []
        self.sl_aggregated_boundary_high_l = []
        self.sl_aggregated_boundary_s = []

        self.kernel_cruise_t = {}
        self.kernel_cruise_s = {}
        self.kernel_follow_t = {}
        self.kernel_follow_s = {}

        self.init_point_x = []
        self.init_point_y = []

    def update_planning_pb(self, planning_pb):
        self.planning_pb = planning_pb

    def compute_init_point(self):
        self.init_point_lock.acquire()
        init_point = self.planning_pb.debug.planning_data.init_point
        self.init_point_x = [init_point.path_point.x]
        self.init_point_y = [init_point.path_point.y]
        self.init_point_lock.release()

    def compute_sl_data(self):
        sl_sampled_s = []
        sl_map_lower_boundary = []
        sl_map_upper_boundary = []
        sl_static_obstacle_lower_boundary = []
        sl_static_obstacle_upper_boundary = []
        sl_dynamic_obstacle_lower_boundary = []
        sl_dynamic_obstacle_upper_boundary = []
        sl_path_s = []
        sl_path_l = []
        sl_aggregated_boundary_low_l = []
        sl_aggregated_boundary_high_l = []
        sl_aggregated_boundary_s = []

        for sl_frame in self.planning_pb.debug.planning_data.sl_frame:
            for s in sl_frame.sampled_s:
                sl_sampled_s.append(s)
            for l in sl_frame.map_lower_bound:
                if (l > 10 or l < -10):
                    sl_map_lower_boundary.append(100 * l // abs(l))
                else:
                    sl_map_lower_boundary.append(l)
            for l in sl_frame.map_upper_bound:
                if (l > 10 or l < -10):
                    sl_map_upper_boundary.append(100 * l // abs(l))
                else:
                    sl_map_upper_boundary.append(l)
            for l in sl_frame.static_obstacle_lower_bound:
                sl_static_obstacle_lower_boundary.append(l)
            for l in sl_frame.static_obstacle_upper_bound:
                sl_static_obstacle_upper_boundary.append(l)
            for l in sl_frame.dynamic_obstacle_lower_bound:
                sl_dynamic_obstacle_lower_boundary.append(l)
            for l in sl_frame.dynamic_obstacle_upper_bound:
                sl_dynamic_obstacle_upper_boundary.append(l)
            for slpoint in sl_frame.sl_path:
                sl_path_s.append(slpoint.s)
                sl_path_l.append(slpoint.l)
            for l in sl_frame.aggregated_boundary_low:
                sl_aggregated_boundary_low_l.append(l)
            for l in sl_frame.aggregated_boundary_high:
                sl_aggregated_boundary_high_l.append(l)
            for s in sl_frame.aggregated_boundary_s:
                sl_aggregated_boundary_s.append(s)

        self.sl_data_lock.acquire()
        self.sl_sampled_s = sl_sampled_s
        self.sl_map_upper_boundary = sl_map_upper_boundary
        self.sl_map_lower_boundary = sl_map_lower_boundary
        self.sl_static_obstacle_lower_boundary = sl_static_obstacle_lower_boundary
        self.sl_static_obstacle_upper_boundary = sl_static_obstacle_upper_boundary
        self.sl_dynamic_obstacle_lower_boundary = sl_dynamic_obstacle_lower_boundary
        self.sl_dynamic_obstacle_upper_boundary = sl_dynamic_obstacle_upper_boundary
        self.sl_path_s = sl_path_s
        self.sl_path_l = sl_path_l
        self.sl_aggregated_boundary_low_l = sl_aggregated_boundary_low_l
        self.sl_aggregated_boundary_high_l = sl_aggregated_boundary_high_l
        self.sl_aggregated_boundary_s = sl_aggregated_boundary_s
        self.sl_data_lock.release()

    def compute_st_data(self):
        st_data_boundary_s = {}
        st_data_boundary_t = {}
        st_curve_s = {}
        st_curve_t = {}
        st_curve_v = {}
        st_data_boundary_type = {}
        st_speed_limit_s = {}
        st_speed_limit_v = {}
        st_speed_constraint_s = {}
        st_speed_constraint_lower = {}
        st_speed_constraint_upper = {}
        kernel_cruise_t = {}
        kernel_cruise_s = {}
        kernel_follow_t = {}
        kernel_follow_s = {}

        for st_graph in self.planning_pb.debug.planning_data.st_graph:

            st_data_boundary_s[st_graph.name] = {}
            st_data_boundary_t[st_graph.name] = {}
            st_data_boundary_type[st_graph.name] = {}
            for boundary in st_graph.boundary:
                st_data_boundary_type[st_graph.name][boundary.name] \
                    = planning_internal_pb2.StGraphBoundaryDebug.StBoundaryType.Name(
                    boundary.type)
                st_data_boundary_s[st_graph.name][boundary.name] = []
                st_data_boundary_t[st_graph.name][boundary.name] = []
                for point in boundary.point:
                    st_data_boundary_s[st_graph.name][boundary.name] \
                        .append(point.s)
                    st_data_boundary_t[st_graph.name][boundary.name] \
                        .append(point.t)
                st_data_boundary_s[st_graph.name][boundary.name].append(
                    st_data_boundary_s[st_graph.name][boundary.name][0])
                st_data_boundary_t[st_graph.name][boundary.name].append(
                    st_data_boundary_t[st_graph.name][boundary.name][0])

            st_curve_s[st_graph.name] = []
            st_curve_t[st_graph.name] = []
            st_curve_v[st_graph.name] = []
            for point in st_graph.speed_profile:
                st_curve_s[st_graph.name].append(point.s)
                st_curve_t[st_graph.name].append(point.t)
                st_curve_v[st_graph.name].append(point.v)

            st_speed_limit_s[st_graph.name] = []
            st_speed_limit_v[st_graph.name] = []
            for point in st_graph.speed_limit:
                st_speed_limit_s[st_graph.name].append(point.s)
                st_speed_limit_v[st_graph.name].append(point.v)

            st_speed_constraint_s[st_graph.name] = []
            st_speed_constraint_lower[st_graph.name] = []
            st_speed_constraint_upper[st_graph.name] = []

            speed_constraint = st_graph.speed_constraint
            interp_s_set = []
            for t in speed_constraint.t:
                interp_s = np.interp(t, st_curve_t[st_graph.name],
                                     st_curve_s[st_graph.name])
                interp_s_set.append(interp_s)
            st_speed_constraint_s[st_graph.name].extend(interp_s_set)
            st_speed_constraint_lower[st_graph.name].extend(
                speed_constraint.lower_bound)
            st_speed_constraint_upper[st_graph.name].extend(
                speed_constraint.upper_bound)

            kernel_cruise_t[st_graph.name] = []
            kernel_cruise_s[st_graph.name] = []
            kernel_cruise = st_graph.kernel_cruise_ref
            kernel_cruise_t[st_graph.name].append(kernel_cruise.t)
            kernel_cruise_s[st_graph.name].append(kernel_cruise.cruise_line_s)

            kernel_follow_t[st_graph.name] = []
            kernel_follow_s[st_graph.name] = []
            kernel_follow = st_graph.kernel_follow_ref
            kernel_follow_t[st_graph.name].append(kernel_follow.t)
            kernel_follow_s[st_graph.name].append(kernel_follow.follow_line_s)

        self.st_data_lock.acquire()

        self.st_data_boundary_s = st_data_boundary_s
        self.st_data_boundary_t = st_data_boundary_t
        self.st_curve_s = st_curve_s
        self.st_curve_t = st_curve_t
        self.st_curve_v = st_curve_v
        self.st_speed_limit_v = st_speed_limit_v
        self.st_speed_limit_s = st_speed_limit_s
        self.st_data_boundary_type = st_data_boundary_type

        self.st_speed_constraint_s = st_speed_constraint_s
        self.st_speed_constraint_lower = st_speed_constraint_lower
        self.st_speed_constraint_upper = st_speed_constraint_upper

        self.kernel_cruise_t = kernel_cruise_t
        self.kernel_cruise_s = kernel_cruise_s
        self.kernel_follow_t = kernel_follow_t
        self.kernel_follow_s = kernel_follow_s

        self.st_data_lock.release()

    def compute_traj_data(self):
        traj_speed_t = []
        traj_speed_v = []
        traj_acc_t = []
        traj_acc_a = []
        traj_path_x = []
        traj_path_y = []
        base_time = self.planning_pb.header.timestamp_sec
        for trajectory_point in self.planning_pb.trajectory_point:
            traj_acc_t.append(base_time + trajectory_point.relative_time)
            traj_acc_a.append(trajectory_point.a)
            traj_speed_t.append(base_time + trajectory_point.relative_time)
            traj_speed_v.append(trajectory_point.v)
            traj_path_x.append(trajectory_point.path_point.x)
            traj_path_y.append(trajectory_point.path_point.y)

        self.traj_data_lock.acquire()

        self.traj_speed_t_history.append(traj_speed_t)
        self.traj_speed_v_history.append(traj_speed_v)
        if len(self.traj_speed_t_history) > self.traj_speed_history_len:
            self.traj_speed_t_history = \
                self.traj_speed_t_history[len(self.traj_speed_t_history)
                                          - self.traj_speed_history_len:]
            self.traj_speed_v_history = \
                self.traj_speed_v_history[len(self.traj_speed_v_history)
                                          - self.traj_speed_history_len:]

        self.traj_acc_t_history.append(traj_acc_t)
        self.traj_acc_a_history.append(traj_acc_a)
        if len(self.traj_acc_t_history) > self.traj_acc_history_len:
            self.traj_acc_t_history = \
                self.traj_acc_t_history[len(self.traj_acc_t_history)
                                        - self.traj_acc_history_len:]
            self.traj_acc_a_history = \
                self.traj_acc_a_history[len(self.traj_acc_a_history)
                                        - self.traj_acc_history_len:]

        self.traj_path_x_history.append(traj_path_x)
        self.traj_path_y_history.append(traj_path_y)
        if len(self.traj_path_x_history) > self.traj_path_history_len:
            self.traj_path_x_history = \
                self.traj_path_x_history[len(self.traj_path_x_history)
                                         - self.traj_path_history_len:]
            self.traj_path_y_history = \
                self.traj_path_y_history[len(self.traj_path_y_history)
                                         - self.traj_path_history_len:]

        self.traj_data_lock.release()

    def replot_sl_data(self,
                       sl_static_obstacle_lower_boundary,
                       sl_static_obstacle_upper_boundary,
                       sl_dynamic_obstacle_lower_boundary,
                       sl_dynamic_obstacle_upper_boundary,
                       sl_map_lower_boundary,
                       sl_map_upper_boundary, sl_path,
                       sl_aggregated_boundary_low_line,
                       sl_aggregated_boundary_high_line):
        self.sl_data_lock.acquire()
        sl_static_obstacle_lower_boundary.set_visible(True)
        sl_static_obstacle_upper_boundary.set_visible(True)
        sl_dynamic_obstacle_lower_boundary.set_visible(True)
        sl_dynamic_obstacle_upper_boundary.set_visible(True)
        sl_map_lower_boundary.set_visible(True)
        sl_map_upper_boundary.set_visible(True)
        sl_path.set_visible(True)
        sl_aggregated_boundary_low_line.set_visible(True)
        sl_aggregated_boundary_high_line.set_visible(True)

        new_sampled_s = []
        for s in self.sl_sampled_s:
            new_sampled_s.append(s)
            new_sampled_s.append(s)
        new_map_lower = []
        for l in self.sl_map_lower_boundary:
            new_map_lower.append(l)
            new_map_lower.append(-11)
        new_map_upper = []
        for l in self.sl_map_upper_boundary:
            new_map_upper.append(l)
            new_map_upper.append(11)
        sl_map_lower_boundary.set_xdata(new_sampled_s)
        sl_map_lower_boundary.set_ydata(new_map_lower)
        sl_map_upper_boundary.set_xdata(new_sampled_s)
        sl_map_upper_boundary.set_ydata(new_map_upper)

        sl_dynamic_obstacle_lower_boundary.set_xdata(self.sl_sampled_s)
        sl_dynamic_obstacle_lower_boundary.set_ydata(
            self.sl_dynamic_obstacle_lower_boundary)
        sl_dynamic_obstacle_upper_boundary.set_xdata(self.sl_sampled_s)
        sl_dynamic_obstacle_upper_boundary.set_ydata(
            self.sl_dynamic_obstacle_upper_boundary)

        new_static_lower = []
        for l in self.sl_static_obstacle_lower_boundary:
            new_static_lower.append(l)
            new_static_lower.append(-11)
        new_static_upper = []
        for l in self.sl_static_obstacle_upper_boundary:
            new_static_upper.append(l)
            new_static_upper.append(11)
        sl_static_obstacle_lower_boundary.set_xdata(new_sampled_s)
        sl_static_obstacle_lower_boundary.set_ydata(new_static_lower)
        sl_static_obstacle_upper_boundary.set_xdata(new_sampled_s)
        sl_static_obstacle_upper_boundary.set_ydata(new_static_upper)
        sl_path.set_xdata(self.sl_path_s)
        sl_path.set_ydata(self.sl_path_l)
        sl_aggregated_boundary_low_line.set_xdata(
            self.sl_aggregated_boundary_s)
        sl_aggregated_boundary_low_line.set_ydata(
            self.sl_aggregated_boundary_low_l)
        sl_aggregated_boundary_high_line.set_xdata(
            self.sl_aggregated_boundary_s)
        sl_aggregated_boundary_high_line.set_ydata(
            self.sl_aggregated_boundary_high_l)
        self.sl_data_lock.release()

    def replot_st_data(self, boundaries_pool, st_line,
                       obstacle_annotation_pool, st_graph_name):
        if st_graph_name not in self.st_data_boundary_s:
            return
        if st_graph_name not in self.st_curve_s:
            return

        cnt = 0
        self.st_data_lock.acquire()

        st_graph_boudnary_s = self.st_data_boundary_s[st_graph_name]
        st_graph_boudnary_t = self.st_data_boundary_t[st_graph_name]
        st_boundary_type = self.st_data_boundary_type[st_graph_name]
        for boundary_name in st_graph_boudnary_s.keys():
            if cnt >= len(boundaries_pool):
                print("WARNING: number of path lines is more than "
                      + len(boundaries_pool))
                continue
            boundary = boundaries_pool[cnt]
            boundary.set_visible(True)

            boundary.set_xdata(st_graph_boudnary_t[boundary_name])
            boundary.set_ydata(st_graph_boudnary_s[boundary_name])
            center_t = 0
            center_s = 0
            for i in range(len(st_graph_boudnary_t[boundary_name]) - 1):
                center_s += st_graph_boudnary_s[boundary_name][i]
                center_t += st_graph_boudnary_t[boundary_name][i]
            center_s /= float(len(st_graph_boudnary_s[boundary_name]) - 1)
            center_t /= float(len(st_graph_boudnary_t[boundary_name]) - 1)

            annotation = obstacle_annotation_pool[cnt]
            annotation.set_visible(True)
            annotation.set_text(boundary_name + "_"
                                + st_boundary_type[boundary_name]
                                .replace("ST_BOUNDARY_TYPE_", ""))
            annotation.set_x(center_t)
            annotation.set_y(center_s)

            cnt += 1

        st_line.set_visible(True)
        st_line.set_xdata(self.st_curve_t[st_graph_name])
        st_line.set_ydata(self.st_curve_s[st_graph_name])
        st_line.set_label(st_graph_name[0:5])

        self.st_data_lock.release()

    def compute_path_data(self):
        path_data_x = {}
        path_data_y = {}
        for path_debug in self.planning_pb.debug.planning_data.path:
            name = path_debug.name
            path_data_x[name] = []
            path_data_y[name] = []
            for path_point in path_debug.path_point:
                path_data_x[name].append(path_point.x)
                path_data_y[name].append(path_point.y)
        self.path_data_lock.acquire()
        self.path_data_x = path_data_x
        self.path_data_y = path_data_y
        self.path_data_lock.release()

    def replot_path_data(self, path_lines):
        cnt = 0
        self.path_data_lock.acquire()
        for name in self.path_data_x.keys():
            if cnt >= len(path_lines):
                print("WARNING: number of path lines is more than "
                      + len(path_lines))
                continue
            if len(self.path_data_x[name]) <= 1:
                continue
            line = path_lines[cnt]
            line.set_visible(True)
            line.set_xdata(self.path_data_x[name])
            line.set_ydata(self.path_data_y[name])
            line.set_label(name[0:5])
            cnt += 1
        self.path_data_lock.release()

    def compute_speed_data(self):
        speed_data_time = {}
        speed_data_val = {}

        for speed_plan in self.planning_pb.debug.planning_data.speed_plan:
            name = speed_plan.name
            speed_data_time[name] = []
            speed_data_val[name] = []
            for speed_point in speed_plan.speed_point:
                speed_data_time[name].append(speed_point.t)
                speed_data_val[name].append(speed_point.v)
        name = "final_speed_output"
        speed_data_time[name] = []
        speed_data_val[name] = []
        for traj_point in self.planning_pb.trajectory_point:
            speed_data_time[name].append(traj_point.relative_time)
            speed_data_val[name].append(traj_point.v)
        self.speed_data_lock.acquire()
        self.speed_data_time = speed_data_time
        self.speed_data_val = speed_data_val
        self.speed_data_lock.release()

    def replot_speed_data(self, speed_lines):
        cnt = 0
        self.speed_data_lock.acquire()
        for name in self.speed_data_time.keys():
            if cnt >= len(speed_lines):
                print("WARNING: number of speed lines is more than "
                      + len(speed_lines))
                continue
            if len(self.speed_data_time[name]) <= 1:
                continue
            line = speed_lines[cnt]
            line.set_visible(True)
            line.set_xdata(self.speed_data_time[name])
            line.set_ydata(self.speed_data_val[name])
            line.set_label(name[0:5])
            cnt += 1
        self.speed_data_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse

import matplotlib.animation as animation
import matplotlib.pyplot as plt

from cyber.python.cyber_py3 import cyber
from modules.planning.proto import planning_pb2
from modules.tools.mapshow.libs.localization import Localization
from modules.tools.mapshow.libs.planning import Planning
from modules.tools.mapshow.libs.subplot_path import PathSubplot
from modules.tools.mapshow.libs.subplot_sl_main import SlMainSubplot
from modules.tools.mapshow.libs.subplot_speed import SpeedSubplot
from modules.tools.mapshow.libs.subplot_st_main import StMainSubplot
from modules.tools.mapshow.libs.subplot_st_speed import StSpeedSubplot


planning = Planning()
localization = Localization()


def update(frame_number):
    # st_main_subplot.show(planning)
    # st_speed_subplot.show(planning)
    map_path_subplot.show(planning, localization)
    dp_st_main_subplot.show(planning)
    qp_st_main_subplot.show(planning)
    speed_subplot.show(planning)
    sl_main_subplot.show(planning)
    st_speed_subplot.show(planning)


def planning_callback(planning_pb):
    planning.update_planning_pb(planning_pb)
    localization.update_localization_pb(
        planning_pb.debug.planning_data.adc_position)

    planning.compute_st_data()
    planning.compute_sl_data()
    planning.compute_path_data()
    planning.compute_speed_data()
    planning.compute_init_point()


def add_listener():
    planning_sub = cyber.Node("st_plot")
    planning_sub.create_reader('/apollo/planning', planning_pb2.ADCTrajectory,
                               planning_callback)


def press_key(event):
    if event.key == '+' or event.key == '=':
        map_path_subplot.zoom_in()
    if event.key == '-' or event.key == '_':
        map_path_subplot.zoom_out()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="plot_planning is a tool to display "
                    "planning trajs on a map.",
        prog="plot_planning_old.py")
    parser.add_argument(
        "-m",
        "--map",
        action="store",
        type=str,
        required=False,
        default=None,
        help="Specify the map file in txt or binary format")
    args = parser.parse_args()
    cyber.init()
    add_listener()
    fig = plt.figure()
    fig.canvas.mpl_connect('key_press_event', press_key)

    ax = plt.subplot2grid((3, 3), (0, 0), rowspan=2, colspan=2)
    map_path_subplot = PathSubplot(ax, args.map)

    ax1 = plt.subplot2grid((3, 3), (0, 2))
    speed_subplot = SpeedSubplot(ax1)

    ax2 = plt.subplot2grid((3, 3), (2, 2))
    dp_st_main_subplot = StMainSubplot(ax2, 'QpSplineStSpeedOptimizer')

    ax3 = plt.subplot2grid((3, 3), (1, 2))
    qp_st_main_subplot = StMainSubplot(ax3, 'DpStSpeedOptimizer')

    ax4 = plt.subplot2grid((3, 3), (2, 0), colspan=1)
    sl_main_subplot = SlMainSubplot(ax4)

    ax5 = plt.subplot2grid((3, 3), (2, 1), colspan=1)
    st_speed_subplot = StSpeedSubplot(ax5, 'QpSplineStSpeedOptimizer')

    ani = animation.FuncAnimation(fig, update, interval=100)

    ax.axis('equal')
    plt.show()
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import matplotlib.animation as animation
import matplotlib.pyplot as plt

from cyber.python.cyber_py3 import cyber
from modules.planning.proto import planning_pb2
from modules.tools.mapshow.libs.planning import Planning
from modules.tools.mapshow.libs.subplot_traj_acc import TrajAccSubplot
from modules.tools.mapshow.libs.subplot_traj_path import TrajPathSubplot
from modules.tools.mapshow.libs.subplot_traj_speed import TrajSpeedSubplot


planning = Planning()


def update(frame_number):
    traj_speed_subplot.show(planning)
    traj_acc_subplot.show(planning)
    traj_path_subplot.show(planning)


def planning_callback(planning_pb):
    planning.update_planning_pb(planning_pb)
    planning.compute_traj_data()


def add_listener():
    planning_sub = cyber.Node("st_plot")
    planning_sub.create_reader('/apollo/planning', planning_pb2.ADCTrajectory,
                               planning_callback)


def press_key():
    pass


if __name__ == '__main__':
    cyber.init()
    add_listener()
    fig = plt.figure(figsize=(14, 6))
    fig.canvas.mpl_connect('key_press_event', press_key)

    ax = plt.subplot2grid((2, 2), (0, 0))
    traj_speed_subplot = TrajSpeedSubplot(ax)

    ax2 = plt.subplot2grid((2, 2), (0, 1))
    traj_acc_subplot = TrajAccSubplot(ax2)

    ax3 = plt.subplot2grid((2, 2), (1, 0))
    traj_path_subplot = TrajPathSubplot(ax3)

    ani = animation.FuncAnimation(fig, update, interval=100)

    plt.show()
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import matplotlib.animation as animation
import matplotlib.pyplot as plt

from cyber.python.cyber_py3 import cyber
from modules.planning.proto import planning_pb2
from modules.tools.mapshow.libs.planning import Planning
from modules.tools.mapshow.libs.subplot_st_main import StMainSubplot
from modules.tools.mapshow.libs.subplot_st_speed import StSpeedSubplot


planning = Planning()


def update(frame_number):
    st_main_subplot.show(planning)
    st_speed_subplot.show(planning)


def planning_callback(planning_pb):
    planning.update_planning_pb(planning_pb)
    planning.compute_st_data()


def add_listener():
    planning_sub = cyber.Node("st_plot")
    planning_sub.create_reader('/apollo/planning', planning_pb2.ADCTrajectory,
                               planning_callback)


def press_key():
    pass


if __name__ == '__main__':
    cyber.init()
    add_listener()
    fig = plt.figure(figsize=(14, 6))
    fig.canvas.mpl_connect('key_press_event', press_key)

    ax = plt.subplot2grid((1, 2), (0, 0))
    st_main_subplot = StMainSubplot(ax, 'QpSplineStSpeedOptimizer')

    ax2 = plt.subplot2grid((1, 2), (0, 1))
    st_speed_subplot = StSpeedSubplot(ax2, "QpSplineStSpeedOptimizer")

    ani = animation.FuncAnimation(fig, update, interval=100)

    plt.show()
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from modules.tools.mapshow.libs.map import Map


class PathSubplot:
    def __init__(self, ax, map_file=None):
        self.ax = ax
        self.map_width = 20
        if map_file is not None:
            map = Map()
            map.load(map_file)
            map.draw_lanes(ax, False, [])
        self.path_lines = []
        self.path_lines_size = 3
        colors = ['b', 'g', 'r', 'k']
        for i in range(self.path_lines_size):
            line, = ax.plot(
                [0], [0],
                colors[i % len(colors)],
                lw=3 + i * 3,
                alpha=0.4)
            self.path_lines.append(line)

        self.vehicle_position_line, = ax.plot([0], [0], 'go', alpha=0.3)
        self.vehicle_polygon_line, = ax.plot([0], [0], 'g-')
        self.init_point_line, = ax.plot([0], [0], 'ro', alpha=0.3)
        self.set_visible(False)
        ax.set_title("PLANNING PATH")

    def set_visible(self, visible):
        for line in self.path_lines:
            line.set_visible(visible)
        self.vehicle_position_line.set_visible(False)
        self.vehicle_polygon_line.set_visible(False)
        self.init_point_line.set_visible(False)

    def show(self, planning, localization):
        cnt = 0
        planning.path_data_lock.acquire()
        for name in planning.path_data_x.keys():
            if cnt >= self.path_lines_size:
                print("WARNING: number of path lines is more than "
                      + str(self.path_lines_size))
                continue
            if len(planning.path_data_x[name]) <= 1:
                continue
            path_line = self.path_lines[cnt]
            path_line.set_visible(True)
            path_line.set_xdata(planning.path_data_x[name])
            path_line.set_ydata(planning.path_data_y[name])
            path_line.set_label(name[0:5])
            cnt += 1
        planning.path_data_lock.release()

        planning.init_point_lock.acquire()
        self.init_point_line.set_xdata(planning.init_point_x)
        self.init_point_line.set_ydata(planning.init_point_y)
        self.init_point_line.set_visible(True)
        planning.init_point_lock.release()

        localization.localization_data_lock.acquire()
        self.draw_vehicle(localization)
        try:
            self.ax.set_xlim(
                localization.localization_pb.pose.position.x - self.map_width,
                localization.localization_pb.pose.position.x + self.map_width)
            self.ax.set_ylim(
                localization.localization_pb.pose.position.y - self.map_width,
                localization.localization_pb.pose.position.y + self.map_width)
        except:
            pass
        localization.localization_data_lock.release()

        self.ax.autoscale_view()
        self.ax.relim()
        self.ax.legend(loc="upper left", borderaxespad=0., ncol=5)
        # self.ax.axis('equal')

    def zoom_in(self):
        if self.map_width > 20:
            self.map_width -= 20

    def zoom_out(self):
        if self.map_width < 200:
            self.map_width += 20

    def draw_vehicle(self, localization):
        if localization.localization_pb is None:
            return
        self.vehicle_position_line.set_visible(True)
        self.vehicle_polygon_line.set_visible(True)

        loc_x = [localization.localization_pb.pose.position.x]
        loc_y = [localization.localization_pb.pose.position.y]
        self.vehicle_position_line.set_xdata(loc_x)
        self.vehicle_position_line.set_ydata(loc_y)

        position = []
        position.append(localization.localization_pb.pose.position.x)
        position.append(localization.localization_pb.pose.position.y)
        position.append(localization.localization_pb.pose.position.z)

        polygon = localization.get_vehicle_polygon(
            position,
            localization.localization_pb.pose.heading)
        px = []
        py = []
        for point in polygon:
            px.append(point[0])
            py.append(point[1])
        self.vehicle_polygon_line.set_xdata(px)
        self.vehicle_polygon_line.set_ydata(py)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class SlMainSubplot:
    def __init__(self, ax):
        self.ax = ax
        self.sl_static_obstacle_lower_boundary_line, = \
            ax.plot([0], [0], "r-", lw=0.3, alpha=0.8)
        self.sl_static_obstacle_upper_boundary_line, = \
            ax.plot([0], [0], "r-", lw=0.3, alpha=0.8)
        self.sl_dynamic_obstacle_lower_boundary_line, = \
            ax.plot([0], [0], "y-", lw=0.3, alpha=0.8)
        self.sl_dynamic_obstacle_upper_boundary_line, = \
            ax.plot([0], [0], "y-", lw=0.3, alpha=0.8)
        self.sl_map_lower_boundary_line, = \
            ax.plot([0], [0], "b-", lw=0.3, ms=2, alpha=0.8)
        self.sl_map_upper_boundary_line, = \
            ax.plot([0], [0], "b-", lw=0.3, ms=4, alpha=0.8)
        self.sl_path_line, = ax.plot([0], [0], "k--")
        self.sl_aggregated_boundary_low_line, = \
            ax.plot([0], [0], "k-", lw=1, ms=2)
        self.sl_aggregated_boundary_high_line, = \
            ax.plot([0], [0], "k-", lw=1, ms=2)

        ax.set_xlim([-10, 220])
        ax.set_ylim([-2.5, 2.5])
        ax.set_xlabel("s - ref_line (m)")
        ax.set_ylabel("l (m)")
        ax.set_title("QP Path - sl Graph")

        self.set_visible(False)

    def set_visible(self, visible):
        self.sl_static_obstacle_lower_boundary_line.set_visible(visible)
        self.sl_static_obstacle_upper_boundary_line.set_visible(visible)
        self.sl_dynamic_obstacle_lower_boundary_line.set_visible(visible)
        self.sl_dynamic_obstacle_upper_boundary_line.set_visible(visible)
        self.sl_map_lower_boundary_line.set_visible(visible)
        self.sl_map_upper_boundary_line.set_visible(visible)
        self.sl_path_line.set_visible(visible)
        self.sl_aggregated_boundary_low_line.set_visible(visible)
        self.sl_aggregated_boundary_high_line.set_visible(visible)

    def show(self, planning):
        planning.sl_data_lock.acquire()
        self.sl_static_obstacle_lower_boundary_line.set_visible(True)
        self.sl_static_obstacle_upper_boundary_line.set_visible(True)
        self.sl_dynamic_obstacle_lower_boundary_line.set_visible(True)
        self.sl_dynamic_obstacle_upper_boundary_line.set_visible(True)
        self.sl_map_lower_boundary_line.set_visible(True)
        self.sl_map_upper_boundary_line.set_visible(True)
        self.sl_path_line.set_visible(True)
        self.sl_aggregated_boundary_low_line.set_visible(True)
        self.sl_aggregated_boundary_high_line.set_visible(True)

        new_sampled_s = []
        for s in planning.sl_sampled_s:
            new_sampled_s.append(s)
            new_sampled_s.append(s)
        new_map_lower = []
        for l in planning.sl_map_lower_boundary:
            new_map_lower.append(l)
            new_map_lower.append(-11)
        new_map_upper = []
        for l in planning.sl_map_upper_boundary:
            new_map_upper.append(l)
            new_map_upper.append(11)
        self.sl_map_lower_boundary_line.set_xdata(new_sampled_s)
        self.sl_map_lower_boundary_line.set_ydata(new_map_lower)
        self.sl_map_upper_boundary_line.set_xdata(new_sampled_s)
        self.sl_map_upper_boundary_line.set_ydata(new_map_upper)

        self.sl_dynamic_obstacle_lower_boundary_line.set_xdata(
            planning.sl_sampled_s)
        self.sl_dynamic_obstacle_lower_boundary_line.set_ydata(
            planning.sl_dynamic_obstacle_lower_boundary)
        self.sl_dynamic_obstacle_upper_boundary_line.set_xdata(
            planning.sl_sampled_s)
        self.sl_dynamic_obstacle_upper_boundary_line.set_ydata(
            planning.sl_dynamic_obstacle_upper_boundary)

        new_static_lower = []
        for l in planning.sl_static_obstacle_lower_boundary:
            new_static_lower.append(l)
            new_static_lower.append(-11)
        new_static_upper = []
        for l in planning.sl_static_obstacle_upper_boundary:
            new_static_upper.append(l)
            new_static_upper.append(11)
        self.sl_static_obstacle_lower_boundary_line.set_xdata(new_sampled_s)
        self.sl_static_obstacle_lower_boundary_line.set_ydata(new_static_lower)
        self.sl_static_obstacle_upper_boundary_line.set_xdata(new_sampled_s)
        self.sl_static_obstacle_upper_boundary_line.set_ydata(new_static_upper)
        self.sl_path_line.set_xdata(planning.sl_path_s)
        self.sl_path_line.set_ydata(planning.sl_path_l)
        self.sl_aggregated_boundary_low_line.set_xdata(
            planning.sl_aggregated_boundary_s)
        self.sl_aggregated_boundary_low_line.set_ydata(
            planning.sl_aggregated_boundary_low_l)
        self.sl_aggregated_boundary_high_line.set_xdata(
            planning.sl_aggregated_boundary_s)
        self.sl_aggregated_boundary_high_line.set_ydata(
            planning.sl_aggregated_boundary_high_l)
        planning.sl_data_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class SpeedSubplot:
    def __init__(self, ax):
        self.ax = ax
        self.speed_lines = []
        self.speed_lines_size = 3
        colors = ['b', 'g', 'r', 'k']
        for i in range(self.speed_lines_size):
            line, = ax.plot(
                [0], [0],
                colors[i % len(colors)] + ".",
                lw=3 + i * 3,
                alpha=0.4)
            self.speed_lines.append(line)

        ax.set_xlabel("t (second)")
        ax.set_xlim([-2, 10])
        ax.set_ylim([-1, 40])
        ax.set_ylabel("speed (m/s)")
        ax.set_title("PLANNING SPEED")
        self.set_visible(False)

    def set_visible(self, visible):
        for line in self.speed_lines:
            line.set_visible(visible)

    def show(self, planning):
        cnt = 0
        planning.speed_data_lock.acquire()
        for name in planning.speed_data_time.keys():
            if cnt >= self.speed_lines_size:
                print("WARNING: number of path lines is more than "
                      + str(self.speed_lines_size))
                continue
            if len(planning.speed_data_time[name]) <= 1:
                continue
            speed_line = self.speed_lines[cnt]
            speed_line.set_visible(True)
            speed_line.set_xdata(planning.speed_data_time[name])
            speed_line.set_ydata(planning.speed_data_val[name])
            speed_line.set_label(name[0:5])
            cnt += 1

        self.ax.legend(loc="upper left", borderaxespad=0., ncol=5)
        # self.ax.axis('equal')
        planning.speed_data_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class StMainSubplot:
    def __init__(self, ax, st_name):
        self.st_curve_line, = ax.plot([0], [0], "k.", lw=3, alpha=0.5)
        self.kernel_cruise_line, = ax.plot([0], [0], "g.", lw=3, alpha=0.5)
        self.kernel_follow_line, = ax.plot([0], [0], "y.", lw=3, alpha=0.5)
        self.obstacle_boundary_lines = []
        self.obstacle_annotations = []
        self.obstacle_boundary_size = 10
        for i in range(self.obstacle_boundary_size):
            self.obstacle_boundary_lines.append(
                ax.plot([0], [0], "r-", lw=1, alpha=1)[0])
            self.obstacle_annotations.append(ax.text(0, 0, ""))

        # self.st_name = planning_config_pb2.TaskType.Name(
        #    planning_config_pb2.QP_SPLINE_ST_SPEED_OPTIMIZER)
        self.st_name = st_name
        ax.set_xlim(-3, 9)
        ax.set_ylim(-10, 220)
        ax.set_xlabel("t (second)")
        ax.set_ylabel("s (m)")
        ax.set_title(st_name)

        self.set_visible(False)

    def set_visible(self, visible):
        self.st_curve_line.set_visible(visible)
        self.kernel_cruise_line.set_visible(visible)
        self.kernel_follow_line.set_visible(visible)
        for line in self.obstacle_boundary_lines:
            line.set_visible(visible)
        for text in self.obstacle_annotations:
            text.set_visible(visible)

    def show(self, planning):
        self.set_visible(False)
        planning.st_data_lock.acquire()
        if self.st_name not in planning.st_data_boundary_s:
            planning.st_data_lock.release()
            return
        obstacles_boundary_s = planning.st_data_boundary_s[self.st_name]
        obstacles_boundary_t = planning.st_data_boundary_t[self.st_name]
        obstacles_type = planning.st_data_boundary_type[self.st_name]
        cnt = 1
        for boundary_name in obstacles_boundary_s.keys():
            if cnt >= self.obstacle_boundary_size:
                print("WARNING: number of path lines is more than "
                      + self.obstacle_boundary_size)
                continue
            boundary = self.obstacle_boundary_lines[cnt]
            boundary.set_visible(True)

            boundary.set_xdata(obstacles_boundary_t[boundary_name])
            boundary.set_ydata(obstacles_boundary_s[boundary_name])
            center_t = 0
            center_s = 0
            for i in range(len(obstacles_boundary_t[boundary_name]) - 1):
                center_s += obstacles_boundary_s[boundary_name][i]
                center_t += obstacles_boundary_t[boundary_name][i]
            center_s /= float(len(obstacles_boundary_s[boundary_name]) - 1)
            center_t /= float(len(obstacles_boundary_t[boundary_name]) - 1)

            annotation = self.obstacle_annotations[cnt]
            annotation.set_visible(True)
            annotation.set_text(boundary_name + "_"
                                + obstacles_type[boundary_name]
                                .replace("ST_BOUNDARY_TYPE_", ""))
            annotation.set_x(center_t)
            annotation.set_y(center_s)

            cnt += 1

        self.st_curve_line.set_visible(True)
        self.st_curve_line.set_xdata(planning.st_curve_t[self.st_name])
        self.st_curve_line.set_ydata(planning.st_curve_s[self.st_name])
        self.st_curve_line.set_label(self.st_name[0:5])

        self.kernel_cruise_line.set_visible(True)
        self.kernel_cruise_line.set_xdata(
            planning.kernel_cruise_t[self.st_name])
        self.kernel_cruise_line.set_ydata(
            planning.kernel_cruise_s[self.st_name])
        self.kernel_follow_line.set_visible(True)
        self.kernel_follow_line.set_xdata(
            planning.kernel_follow_t[self.st_name])
        self.kernel_follow_line.set_ydata(
            planning.kernel_follow_s[self.st_name])

        planning.st_data_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class StSpeedSubplot:
    def __init__(self, ax, st_name):
        self.speed_limit_line = ax.plot([0], [0], "r-",
                                        lw=6, alpha=0.5, label="limits")[0]
        self.speed_line = ax.plot([0], [0], "k-",
                                  lw=3, alpha=0.5, label="planned")[0]
        self.speed_upper_bound_line = \
            ax.plot([0], [0], "b-", lw=1, alpha=1, label="upper")[0]
        self.speed_lower_bound_line = \
            ax.plot([0], [0], "b-", lw=3, alpha=1, label="lower")[0]
        self.st_name = st_name
        ax.set_xlim(-10, 220)
        ax.set_ylim(-1, 40)
        ax.set_xlabel("s - qp_path(m)")
        ax.set_ylabel("v (m/s)")
        ax.set_title("QP Speed - sv graph")
        ax.legend(loc="upper left", bbox_to_anchor=(0, 1), ncol=2,
                  borderaxespad=0.)
        self.set_visible(False)

    def set_visible(self, visible):
        self.speed_limit_line.set_visible(visible)
        self.speed_line.set_visible(visible)
        self.speed_upper_bound_line.set_visible(visible)
        self.speed_lower_bound_line.set_visible(visible)

    def show(self, planning):
        self.set_visible(False)

        planning.st_data_lock.acquire()
        if self.st_name not in planning.st_curve_s:
            planning.st_data_lock.release()
            return
        planned_speed_s = planning.st_curve_s[self.st_name]
        planned_speed_v = planning.st_curve_v[self.st_name]
        self.speed_line.set_xdata(planned_speed_s)
        self.speed_line.set_ydata(planned_speed_v)
        self.speed_line.set_visible(True)

        self.speed_limit_line.set_xdata(
            planning.st_speed_limit_s[self.st_name])
        self.speed_limit_line.set_ydata(
            planning.st_speed_limit_v[self.st_name])
        self.speed_limit_line.set_visible(True)

        self.speed_upper_bound_line.set_xdata(
            planning.st_speed_constraint_s[self.st_name])
        self.speed_upper_bound_line.set_ydata(
            planning.st_speed_constraint_upper[self.st_name])
        self.speed_upper_bound_line.set_visible(True)

        self.speed_lower_bound_line.set_xdata(
            planning.st_speed_constraint_s[self.st_name])
        self.speed_lower_bound_line.set_ydata(
            planning.st_speed_constraint_lower[self.st_name])
        self.speed_lower_bound_line.set_visible(True)

        planning.st_data_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from matplotlib import cm as cmx
from matplotlib import colors as mcolors
import matplotlib.pyplot as plt


class TrajAccSubplot:
    def __init__(self, ax):
        self.ax = ax
        self.acc_lines = []
        self.acc_lines_size = 30
        self.colors = []
        self.init_colors()
        # self.colors = ['b','r', 'y', 'k']
        for i in range(self.acc_lines_size):
            line, = ax.plot(
                [0], [0],
                c=self.colors[i % len(self.colors)],
                ls="-",
                marker='',
                lw=3,
                alpha=0.8)
            self.acc_lines.append(line)

        ax.set_xlabel("t (second)")
        # ax.set_xlim([-2, 10])
        ax.set_ylim([-6, 6])
        self.ax.autoscale_view()
        # self.ax.relim()
        ax.set_ylabel("acc (m/s^2)")
        ax.set_title("PLANNING ACC")
        self.set_visible(False)

    def init_colors(self):
        self.colors = []
        values = list(range(self.acc_lines_size))
        jet = plt.get_cmap('brg')
        color_norm = mcolors.Normalize(vmin=0, vmax=values[-1])
        scalar_map = cmx.ScalarMappable(norm=color_norm, cmap=jet)
        for val in values:
            color_val = scalar_map.to_rgba(val)
            self.colors.append(color_val)

    def set_visible(self, visible):
        for line in self.acc_lines:
            line.set_visible(visible)

    def show(self, planning):
        planning.traj_data_lock.acquire()
        for i in range(len(planning.traj_speed_t_history)):
            if i >= self.acc_lines_size:
                print("WARNING: number of path lines is more than "
                      + str(self.acc_lines_size))
                continue
            speed_line = self.acc_lines[self.acc_lines_size - i - 1]

            speed_line.set_xdata(planning.traj_acc_t_history[i])
            speed_line.set_ydata(planning.traj_acc_a_history[i])
            # speed_line.set_xdata([1,2,3,4])
            # speed_line.set_ydata([1,2,3,4])
            # speed_line.set_label(name[0:5])
            speed_line.set_visible(True)

        # self.ax.legend(loc="upper left", borderaxespad=0., ncol=5)
        # self.ax.axis('equal')
        planning.traj_data_lock.release()
        self.ax.autoscale_view()
        self.ax.relim()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from matplotlib import cm as cmx
from matplotlib import colors as mcolors
import matplotlib.pyplot as plt


class TrajPathSubplot:
    def __init__(self, ax):
        self.ax = ax
        self.path_lines = []
        self.path_lines_size = 30
        self.colors = []
        self.init_colors()
        # self.colors = ['b','r', 'y', 'k']
        for i in range(self.path_lines_size):
            line, = ax.plot(
                [0], [0],
                c=self.colors[i % len(self.colors)],
                ls="-",
                marker='',
                lw=8,
                alpha=0.3)
            self.path_lines.append(line)

        ax.set_xlabel("x (m)")
        # ax.set_xlim([-2, 10])
        # ax.set_ylim([-6, 6])
        self.ax.autoscale_view()
        # self.ax.relim()
        # ax.set_ylabel("y (m)")
        ax.set_title("PLANNING ACC")
        self.set_visible(False)

    def init_colors(self):
        self.colors = []
        values = list(range(self.path_lines_size))
        jet = plt.get_cmap('brg')
        color_norm = mcolors.Normalize(vmin=0, vmax=values[-1])
        scalar_map = cmx.ScalarMappable(norm=color_norm, cmap=jet)
        for val in values:
            color_val = scalar_map.to_rgba(val)
            self.colors.append(color_val)

    def set_visible(self, visible):
        for line in self.path_lines:
            line.set_visible(visible)

    def show(self, planning):
        planning.traj_data_lock.acquire()
        for i in range(len(planning.traj_path_x_history)):
            if i >= self.path_lines_size:
                print("WARNING: number of path lines is more than "
                      + str(self.path_lines_size))
                continue
            speed_line = self.path_lines[self.path_lines_size - i - 1]

            speed_line.set_xdata(planning.traj_path_x_history[i])
            speed_line.set_ydata(planning.traj_path_y_history[i])
            speed_line.set_visible(True)

        # self.ax.legend(loc="upper left", borderaxespad=0., ncol=5)
        # self.ax.axis('equal')
        planning.traj_data_lock.release()
        self.ax.autoscale_view()
        self.ax.relim()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from matplotlib import cm as cmx
from matplotlib import colors as mcolors
import matplotlib.pyplot as plt


class TrajSpeedSubplot:
    def __init__(self, ax):
        self.ax = ax
        self.speed_lines = []
        self.speed_lines_size = 30
        self.colors = []
        self.init_colors()
        # self.colors = ['b','r', 'y', 'k']
        for i in range(self.speed_lines_size):
            line, = ax.plot(
                [0], [0],
                c=self.colors[i % len(self.colors)],
                ls="-",
                marker='',
                lw=3,
                alpha=0.8)
            self.speed_lines.append(line)

        ax.set_xlabel("t (second)")
        # ax.set_xlim([-2, 10])
        ax.set_ylim([-1, 25])
        self.ax.autoscale_view()
        # self.ax.relim()
        ax.set_ylabel("speed (m/s)")
        ax.set_title("PLANNING SPEED")
        self.set_visible(False)

    def init_colors(self):
        self.colors = []
        values = list(range(self.speed_lines_size))
        jet = plt.get_cmap('brg')
        color_norm = mcolors.Normalize(vmin=0, vmax=values[-1])
        scalar_map = cmx.ScalarMappable(norm=color_norm, cmap=jet)
        for val in values:
            color_val = scalar_map.to_rgba(val)
            self.colors.append(color_val)

    def set_visible(self, visible):
        for line in self.speed_lines:
            line.set_visible(visible)

    def show(self, planning):
        planning.traj_data_lock.acquire()
        for i in range(len(planning.traj_speed_t_history)):
            if i >= self.speed_lines_size:
                print("WARNING: number of path lines is more than "
                      + str(self.speed_lines_size))
                continue
            speed_line = self.speed_lines[self.speed_lines_size - i - 1]

            speed_line.set_xdata(planning.traj_speed_t_history[i])
            speed_line.set_ydata(planning.traj_speed_v_history[i])
            # speed_line.set_xdata([1,2,3,4])
            # speed_line.set_ydata([1,2,3,4])
            # speed_line.set_label(name[0:5])
            speed_line.set_visible(True)

        # self.ax.legend(loc="upper left", borderaxespad=0., ncol=5)
        # self.ax.axis('equal')
        planning.traj_data_lock.release()
        self.ax.autoscale_view()
        self.ax.relim()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse

import matplotlib.pyplot as plt

from modules.tools.mapshow.libs.localization import Localization
from modules.tools.mapshow.libs.map import Map
from modules.tools.mapshow.libs.path import Path


def draw(map):
    lane_ids = args.laneid
    if lane_ids is None:
        lane_ids = []
    map.draw_lanes(plt, args.showlaneids, lane_ids, args.showlanedetails)
    if args.showsignals:
        map.draw_signal_lights(plt)
    if args.showstopsigns:
        map.draw_stop_signs(plt)
    if args.showjunctions:
        map.draw_pnc_junctions(plt)
    if args.showcrosswalks:
        map.draw_crosswalks(plt)
    if args.showyieldsigns:
        map.draw_yield_signs(plt)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="Mapshow is a tool to display hdmap info on a map.",
        prog="mapshow.py")

    parser.add_argument(
        "-m", "--map", action="store", type=str, required=True,
        help="Specify the map file in txt or binary format")
    parser.add_argument(
        "-m2", "--map2", action="store", type=str, required=False,
        help="Specify the map file in txt or binary format")
    parser.add_argument(
        "-sl", "--showlaneids", action="store_const", const=True,
        help="Show all lane ids in map")
    parser.add_argument(
        "-sld", "--showlanedetails", action="store_const", const=True,
        help="Show all lane ids in map")
    parser.add_argument(
        "-l", "--laneid", nargs='+',
        help="Show specific lane id(s) in map")
    parser.add_argument(
        "-signal", "--showsignals", action="store_const", const=True,
        help="Show all signal light stop lines with ids in map")
    parser.add_argument(
        "-stopsign", "--showstopsigns", action="store_const", const=True,
        help="Show all stop sign stop lines with ids in map")
    parser.add_argument(
        "-yieldsign", "--showyieldsigns", action="store_const", const=True,
        help="Show all yield sign stop lines with ids in map")
    parser.add_argument(
        "-junction", "--showjunctions", action="store_const", const=True,
        help="Show all pnc-junctions with ids in map")
    parser.add_argument(
        "-crosswalk", "--showcrosswalks", action="store_const", const=True,
        help="Show all crosswalks with ids in map")
    parser.add_argument(
        "--loc", action="store", type=str, required=False,
        help="Specify the localization pb file in txt format")
    parser.add_argument(
        "--position", action="store", type=str, required=False,
        help="Plot the x,y coordination in string format, e.g., 343.02,332.01")

    # driving path data files are text files with data format of
    # t,x,y,heading,speed
    parser.add_argument(
        "-dp", "--drivingpath", nargs='+',
        help="Show driving paths in map")

    args = parser.parse_args()

    map = Map()
    map.load(args.map)
    draw(map)

    if args.map2 is not None:
        map2 = Map()
        map2.load(args.map2)
        draw(map2)

    if args.drivingpath is not None:
        path = Path(args.drivingpath)
        path.draw(plt)

    if args.loc is not None:
        localization = Localization()
        localization.load(args.loc)
        localization.plot_vehicle(plt)

    if args.position is not None:
        x, y = args.position.split(",")
        x, y = float(x), float(y)
        plt.plot([x], [y], 'bo')
    plt.axis('equal')
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import matplotlib.pyplot as plt
from modules.tools.mapshow.libs.map import Map

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Raodshow is a tool to display road info on a map.",
        prog="roadshow.py")

    parser.add_argument(
        "-m", "--map", action="store", type=str, required=True,
        help="Specify the map file in txt or binary format")

    args = parser.parse_args()

    map = Map()
    map.load(args.map)
    map.draw_roads(plt)

    plt.axis('equal')
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import json
import pyproj
import argparse
from yattag import Doc
import modules.tools.common.proto_utils as proto_utils
from modules.map.proto import map_pb2


def generate(api_key, left_boundaries, right_boundaries, center_lat,
             center_lon):
    """
    function to generate html code.
    """
    doc, tag, text, line = Doc().ttl()
    doc.asis('<!DOCTYPE html>')
    api_url = 'https://maps.googleapis.com/maps/api/js?key=' + \
              api_key + '&callback=initMap'
    with tag('html'):
        with tag('head'):
            with tag('title'):
                text('Gmap Viewer')
            doc.asis('<meta name="viewport" content="initial-scale=1.0">')
            doc.asis('<meta charset="utf-8">')
            with tag('style'):
                doc.asis('#map { height: 100%; }')
                doc.asis('html, body { height: 100%; margin: 0; padding: 0; }')
        with tag('body'):
            with tag('div', id='map'):
                pass
            with tag('script'):
                doc.asis('\nvar map;\n')
                doc.asis("\nvar colors = ['#e6194b', '#3cb44b', '#ffe119', \
                '#0082c8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', \
                '#d2f53c', '#fabebe', '#008080', '#e6beff', '#aa6e28', \
                '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', \
                '#000080', '#808080', '#000000']\n")
                doc.asis('function initMap() {\n')
                doc.asis("map = new google.maps.Map(\
                document.getElementById('map'), {\n")
                doc.asis('center: {lat: ' + str(center_lat) +
                         ', lng: ' + str(center_lon) + '},\n')
                doc.asis('zoom: 16\n')
                doc.asis('});\n')
                doc.asis('var left_boundaries = ' +
                         json.dumps(left_boundaries) + ';\n')
                doc.asis("""
                    for (var i = 0; i < left_boundaries.length; i++) {
                        var boundary = new google.maps.Polyline({
                            path: left_boundaries[i],
                            geodesic: true,
                            strokeColor: colors[i % colors.length],
                            strokeOpacity: 1.0,
                            strokeWeight: 3
                        });
                        boundary.setMap(map);
                    }
                """)
                doc.asis('var right_boundaries = ' +
                         json.dumps(right_boundaries) + ';\n')
                doc.asis("""
                    for (var i = 0; i < right_boundaries.length; i++) {
                        var boundary = new google.maps.Polyline({
                            path: right_boundaries[i],
                            geodesic: true,
                            strokeColor: colors[i % colors.length],
                            strokeOpacity: 1.0,
                            strokeWeight: 3
                        });
                        boundary.setMap(map);
                    }
                """)
                doc.asis('}\n')
            doc.asis('<script src="' + api_url + '"></script>')
    html = doc.getvalue()
    return html


def utm2latlon(x, y, pzone=10):
    """
    convert the utm x y to lat and lon
    """
    projector2 = pyproj.Proj(proj='utm', zone=pzone, ellps='WGS84')
    lon, lat = projector2(x, y, inverse=True)
    return lat, lon


def run(gmap_key, map_file, utm_zone):
    """
    read and process map file
    """
    map_pb = map_pb2.Map()
    proto_utils.get_pb_from_file(map_file, map_pb)

    left_boundaries = []
    right_boundaries = []
    center_lat = None
    center_lon = None
    for lane in map_pb.lane:
        for curve in lane.left_boundary.curve.segment:
            if curve.HasField('line_segment'):
                left_boundary = []
                for p in curve.line_segment.point:
                    point = {}
                    lat, lng = utm2latlon(p.x, p.y, utm_zone)
                    if center_lat is None:
                        center_lat = lat
                    if center_lon is None:
                        center_lon = lng
                    point['lat'] = lat
                    point['lng'] = lng
                    left_boundary.append(point)
                left_boundaries.append(left_boundary)
        for curve in lane.right_boundary.curve.segment:
            if curve.HasField('line_segment'):
                right_boundary = []
                for p in curve.line_segment.point:
                    point = {}
                    lat, lng = utm2latlon(p.x, p.y, utm_zone)
                    point['lat'] = lat
                    point['lng'] = lng
                    right_boundary.append(point)
                right_boundaries.append(right_boundary)

    html = generate(gmap_key, left_boundaries, right_boundaries, center_lat,
                    center_lon)

    with open('gmap.html', 'w') as file:
        file.write(html)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Mapshow is a tool to display hdmap info on a map.",
        prog="mapshow.py")

    parser.add_argument(
        "-m", "--map", action="store", type=str, required=True,
        help="Specify the HDMap file in txt or binary format")
    parser.add_argument(
        "-k", "--key", action="store", type=str, required=True,
        help="Specify your google map api key")
    parser.add_argument(
        "-z", "--zone", action="store", type=int, required=True,
        help="Specify utm zone id. e.g, -z 10")

    args = parser.parse_args()

    run(args.key, args.map, args.zone)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse

from bokeh.plotting import figure, output_file, show
from modules.map.proto import map_pb2
import modules.tools.common.proto_utils as proto_utils


def draw(map_pb, plot):
    for lane in map_pb.lane:
        for curve in lane.left_boundary.curve.segment:
            if curve.HasField('line_segment'):
                x = []
                y = []
                for p in curve.line_segment.point:
                    x.append(p.x)
                    y.append(p.y)
                plot.line(x, y, line_width=2)
        for curve in lane.right_boundary.curve.segment:
            if curve.HasField('line_segment'):
                x = []
                y = []
                for p in curve.line_segment.point:
                    x.append(p.x)
                    y.append(p.y)
                plot.line(x, y, line_width=2)


def load_map_data(map_file):
    map_pb = map_pb2.Map()
    proto_utils.get_pb_from_file(map_file, map_pb)
    return map_pb


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="HDMapViewer is a tool to display hdmap.",
        prog="hdmapviewer.py")

    parser.add_argument(
        "-m", "--map", action="store", type=str, required=True,
        help="Specify the HDMap file in txt or binary format")

    args = parser.parse_args()
    map_pb = load_map_data(args.map)

    output_file("hdmap.html")
    plot = figure(sizing_mode='scale_both', match_aspect=True)

    draw(map_pb, plot)
    show(plot)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import threading


class ChassisData:
    def __init__(self, chassis_pb=None):
        self.chassis_pb = chassis_pb

    def update(self, chassis_pb):
        self.chassis_pb = chassis_pb

    def is_auto(self):
        if self.chassis_pb is None:
            return False
        if self.chassis_pb.driving_mode is None:
            return False
        if self.chassis_pb.driving_mode == \
                self.chassis_pb.COMPLETE_AUTO_DRIVE:
            return True
        return False
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import threading


class LocalizationData:
    def __init__(self, localization_pb=None):
        self.localization_pb = localization_pb

    def update(self, localization_pb):
        self.localization_pb = localization_pb
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import threading


class MobileyeData:
    def __init__(self, mobileye_pb=None):
        self.mobileye_pb = mobileye_pb
        self.lane_data_lock = threading.Lock()
        self.next_lane_data_lock = threading.Lock()
        self.obstacle_data_lock = threading.Lock()
        self.left_lane_x = []
        self.left_lane_y = []
        self.right_lane_x = []
        self.right_lane_y = []
        self.obstacle_x = []
        self.obstacle_y = []
        self.ref_lane_x = []
        self.ref_lane_y = []

        self.next_lanes_x = []
        self.next_lanes_y = []

    def update(self, mobileye_pb):
        self.mobileye_pb = mobileye_pb

    def compute_next_lanes(self):
        if self.mobileye_pb is None:
            return

        self.next_lane_data_lock.acquire()
        self.next_lanes_x = []
        self.next_lanes_y = []
        if len(self.mobileye_pb.next_76c) != len(self.mobileye_pb.next_76d):
            print("next lanes output is incomplete!")
            self.next_lane_data_lock.release()
            return
        for i in range(len(self.mobileye_pb.next_76c)):
            lane_x = []
            lane_y = []
            c0 = self.mobileye_pb.next_76c[i].position
            c1 = self.mobileye_pb.next_76d[i].heading_angle
            c2 = self.mobileye_pb.next_76c[i].curvature
            c3 = self.mobileye_pb.next_76c[i].curvature_derivative
            rangex = self.mobileye_pb.next_76d[i].view_range
            for y in range(int(rangex)):
                lane_y.append(y)
                x = c3*(y*y*y) + c2*(y*y) + c1*y + c0
                lane_x.append(x)
            # print rangex
            self.next_lanes_x.append(lane_x)
            self.next_lanes_y.append(lane_y)
        self.next_lane_data_lock.release()

    def compute_lanes(self):
        if self.mobileye_pb is None:
            return
        self.left_lane_x = []
        self.left_lane_y = []
        self.right_lane_x = []
        self.right_lane_y = []
        self.ref_lane_x = []
        self.ref_lane_y = []

        rc0 = self.mobileye_pb.lka_768.position
        rc1 = self.mobileye_pb.lka_769.heading_angle
        rc2 = self.mobileye_pb.lka_768.curvature
        rc3 = self.mobileye_pb.lka_768.curvature_derivative
        rrangex = self.mobileye_pb.lka_769.view_range + 1
        self.lane_data_lock.acquire()
        for y in range(int(rrangex)):
            self.right_lane_y.append(y)
            x = rc3*(y*y*y) + rc2*(y*y) + rc1*y + rc0
            self.right_lane_x.append(x)
        self.lane_data_lock.release()

        lc0 = self.mobileye_pb.lka_766.position
        lc1 = self.mobileye_pb.lka_767.heading_angle
        lc2 = self.mobileye_pb.lka_766.curvature
        lc3 = self.mobileye_pb.lka_766.curvature_derivative
        lrangex = self.mobileye_pb.lka_767.view_range + 1
        self.lane_data_lock.acquire()
        for y in range(int(lrangex)):
            self.left_lane_y.append(y)
            x = lc3*(y * y * y) + lc2 * (y * y) + lc1 * y + lc0
            self.left_lane_x.append(x)
        self.lane_data_lock.release()

        c0 = (rc0 + lc0) // 2
        c1 = (rc1 + lc1) // 2
        c2 = (rc2 + lc2) // 2
        c3 = (rc3 + lc3) // 2
        rangex = (lrangex + rrangex) // 2
        self.lane_data_lock.acquire()
        for y in range(int(rangex)):
            self.ref_lane_y.append(y)
            x = c3 * (y * y * y) + c2 * (y * y) + c1 * y + c0
            self.ref_lane_x.append(x)
        self.lane_data_lock.release()

    def compute_obstacles(self):
        if self.mobileye_pb is None:
            return
        self.obstacle_x = []
        self.obstacle_y = []
        self.obstacle_data_lock.acquire()
        for i in range(len(self.mobileye_pb.details_739)):
            x = self.mobileye_pb.details_739[i].obstacle_pos_x
            y = self.mobileye_pb.details_739[i].obstacle_pos_y
            self.obstacle_x.append(x)
            self.obstacle_y.append(y * -1)
        self.obstacle_data_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import threading


class PlanningData:
    def __init__(self, planning_pb=None):
        self.path_lock = threading.Lock()
        self.path_param_lock = threading.Lock()

        self.planning_pb = planning_pb
        self.path_x = []
        self.path_y = []

        self.relative_time = []
        self.speed = []
        self.s = []
        self.theta = []

    def update(self, planning_pb):
        self.planning_pb = planning_pb

    def compute_path(self):
        if self.planning_pb is None:
            return
        path_x = []
        path_y = []
        for point in self.planning_pb.trajectory_point:
            path_x.append(-1 * point.path_point.y)
            path_y.append(point.path_point.x)
        self.path_lock.acquire()
        self.path_x = path_x
        self.path_y = path_y
        self.path_lock.release()

    def compute_path_param(self):
        if self.planning_pb is None:
            return
        relative_time = []
        speed = []
        s = []
        theta = []
        for point in self.planning_pb.trajectory_point:
            relative_time.append(point.relative_time)
            speed.append(point.v)
            s.append(point.path_point.s)
            theta.append(point.path_point.theta)
        self.path_param_lock.acquire()
        self.relative_time = relative_time
        self.speed = speed
        self.s = s
        self.theta = theta
        self.path_param_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import threading
import json


class RoutingData:
    def __init__(self, routing_str=None):
        self.routing_str = routing_str
        self.routing_debug_str = None
        self.routing_data_lock = threading.Lock()
        self.routing_x = []
        self.routing_y = []
        self.segment_x = []
        self.segment_y = []

    def update_navigation(self, navigation_info_pb):
        routing_x = []
        routing_y = []
        for navi_path in navigation_info_pb.navigation_path:
            for path_point in navi_path.path.path_point:
                routing_x.append(path_point.x)
                routing_y.append(path_point.y)
        self.routing_data_lock.acquire()
        self.routing_x = routing_x
        self.routing_y = routing_y
        self.routing_data_lock.release()

    def update(self, routing_str):
        self.routing_str = routing_str
        routing_json = json.loads(routing_str.data)
        routing_x = []
        routing_y = []
        for step in routing_json:
            points = step['polyline']['points']
            for point in points:
                routing_x.append(point[0])
                routing_y.append(point[1])

        self.routing_data_lock.acquire()
        self.routing_x = routing_x
        self.routing_y = routing_y
        self.routing_data_lock.release()

    def update_debug(self, routing_debug_str):
        self.routing_debug_str = routing_debug_str
        segment_json = json.loads(routing_debug_str.data)
        if segment_json is None:
            return
        segment_x = []
        segment_y = []
        for point in segment_json:
            segment_x.append(point[0])
            segment_y.append(point[1])

        self.routing_data_lock.acquire()
        self.segment_x = segment_x
        self.segment_y = segment_y
        self.routing_data_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
import math


class SubplotRouting:
    def __init__(self, ax):
        self.ax = ax
        self.routing_dot, = ax.plot([0], [0], 'ro', lw=3, alpha=0.4)
        self.routing_line, = ax.plot([0], [0], 'b-', lw=1, alpha=1)
        self.segment_line, = ax.plot([0], [0], 'bo', lw=1, alpha=1)

    def show(self, routing_data):
        routing_data.routing_data_lock.acquire()
        self.routing_dot.set_xdata(routing_data.routing_x)
        self.routing_dot.set_ydata(routing_data.routing_y)
        self.routing_line.set_xdata(routing_data.routing_x)
        self.routing_line.set_ydata(routing_data.routing_y)
        self.segment_line.set_xdata(routing_data.segment_x)
        self.segment_line.set_ydata(routing_data.segment_y)

        routing_data.routing_data_lock.release()
        self.ax.autoscale_view()
        self.ax.relim()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
import math


class SubplotSSpeed:
    def __init__(self, ax):
        self.s_speed_line, = ax.plot([0], [0], 'r-', lw=3, alpha=0.4)
        ax.set_xlim([-2, 100])
        ax.set_ylim([-1, 40])
        ax.set_xlabel("s (m)")
        ax.set_ylabel("speed (m/s)")

    def show(self, planning_data):
        planning_data.path_param_lock.acquire()
        self.s_speed_line.set_xdata(planning_data.s)
        self.s_speed_line.set_ydata(planning_data.speed)
        planning_data.path_param_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
import math


class SubplotSTheta:
    def __init__(self, ax):
        self.s_speed_line, = ax.plot([0], [0], 'r-', lw=3, alpha=0.4)
        ax.set_xlim([-2, 100])
        ax.set_ylim([-0.5, 0.5])
        ax.set_xlabel("s (m)")
        ax.set_ylabel("theta (r)")

    def show(self, planning_data):
        planning_data.path_param_lock.acquire()
        self.s_speed_line.set_xdata(planning_data.s)
        self.s_speed_line.set_ydata(planning_data.theta)
        planning_data.path_param_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
import math


class SubplotSTime:
    def __init__(self, ax):
        self.s_speed_line, = ax.plot([0], [0], 'r-', lw=3, alpha=0.4)
        ax.set_xlim([-2, 100])
        ax.set_ylim([-0.5, 10])
        ax.set_xlabel("s (m)")
        ax.set_ylabel("time (sec)")

    def show(self, planning_data):
        planning_data.path_param_lock.acquire()
        self.s_speed_line.set_xdata(planning_data.s)
        self.s_speed_line.set_ydata(planning_data.relative_time)
        planning_data.path_param_lock.release()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
import math


class ViewSubplot:
    def __init__(self, ax):
        # self.ax = ax
        self.right_lane, = ax.plot(
            [-10, 10, -10, 10], [-10, 150, 150, -10],
            'bo', lw=3, alpha=0.4)
        self.left_lane, = ax.plot(
            [0], [0], 'go', lw=3, alpha=0.5)
        self.obstacles, = ax.plot(
            [0], [0], 'r.', ms=20, alpha=0.5)
        self.ref_lane, = ax.plot(
            [0], [0], 'k--', lw=3, alpha=0.8)
        self.vehicle = ax.plot(
            [-1.055, 1.055, 1.055, -1.055, -1.055], [0, 0, -4.933, -4.933, 0],
            'r-', lw=1)
        self.routing, = ax.plot(
            [0], [0], 'r--', lw=3, alpha=0.8)

        self.speed_line, = ax.plot([0], [0], 'r-', lw=3, alpha=0.4)
        self.acc_line, = ax.plot([0], [0], 'y-', lw=3, alpha=1)

        ax.set_xlim([-10, 10])
        ax.set_ylim([-10, 100])
        ax.relim()
        ax.set_xlabel("lat(m)")
        self.next_lanes = []
        for i in range(8):
            lane, = ax.plot([0], [0], 'b-', lw=3, alpha=0.4)
            self.next_lanes.append(lane)

        self.left_lane.set_visible(False)
        self.right_lane.set_visible(False)
        self.ref_lane.set_visible(False)

    def show(self, mobileye_data, localization_data, planning_data,
             chassis_data, routing_data):
        self.left_lane.set_visible(True)
        self.right_lane.set_visible(True)
        self.ref_lane.set_visible(True)

        mobileye_data.lane_data_lock.acquire()
        self.right_lane.set_xdata(mobileye_data.right_lane_x)
        self.right_lane.set_ydata(mobileye_data.right_lane_y)
        self.left_lane.set_xdata(mobileye_data.left_lane_x)
        self.left_lane.set_ydata(mobileye_data.left_lane_y)
        mobileye_data.lane_data_lock.release()

        planning_data.path_lock.acquire()
        self.ref_lane.set_xdata(planning_data.path_x)
        self.ref_lane.set_ydata(planning_data.path_y)
        planning_data.path_lock.release()

        if chassis_data.is_auto():
            self.ref_lane.set_color('r')
        else:
            self.ref_lane.set_color('k')

        mobileye_data.obstacle_data_lock.acquire()
        self.obstacles.set_ydata(mobileye_data.obstacle_x)
        self.obstacles.set_xdata(mobileye_data.obstacle_y)
        mobileye_data.obstacle_data_lock.release()

        mobileye_data.next_lane_data_lock.acquire()
        for i in range(len(mobileye_data.next_lanes_x)):
            if i >= len(self.next_lanes):
                mobileye_data.next_lane_data_lock.release()
                break
            self.next_lanes[i].set_xdata(mobileye_data.next_lanes_x[i])
            self.next_lanes[i].set_ydata(mobileye_data.next_lanes_y[i])
        mobileye_data.next_lane_data_lock.release()

        if localization_data.localization_pb is None:
            return

        vx = localization_data.localization_pb.pose.position.x
        vy = localization_data.localization_pb.pose.position.y

        routing_data.routing_data_lock.acquire()
        path_x = [x - vx for x in routing_data.routing_x]
        path_y = [y - vy for y in routing_data.routing_y]
        routing_data.routing_data_lock.release()

        heading = localization_data.localization_pb.pose.heading
        npath_x = []
        npath_y = []

        for i in range(len(path_x)):
            x = path_x[i]
            y = path_y[i]
            # newx = x * math.cos(heading) - y * math.sin(heading)
            # newy = y * math.cos(heading) + x * math.sin(heading)
            newx = x * math.cos(- heading + 1.570796) - y * math.sin(
                -heading + 1.570796)
            newy = y * math.cos(- heading + 1.570796) + x * math.sin(
                -heading + 1.570796)
            npath_x.append(newx)
            npath_y.append(newy)

        self.routing.set_xdata(npath_x)
        self.routing.set_ydata(npath_y)

        speed_x = localization_data.localization_pb.pose.linear_velocity.x
        speed_y = localization_data.localization_pb.pose.linear_velocity.y
        acc_x = localization_data.localization_pb.pose.linear_acceleration.x
        acc_y = localization_data.localization_pb.pose.linear_acceleration.y
        heading = localization_data.localization_pb.pose.heading

        new_speed_x = math.cos(-heading + math.pi / 2) * speed_x - math.sin(
            -heading + math.pi / 2) * speed_y
        new_speed_y = math.sin(-heading + math.pi / 2) * speed_x + math.cos(
            -heading + math.pi / 2) * speed_y

        new_acc_x = math.cos(-heading + math.pi / 2) * acc_x - math.sin(
            -heading + math.pi / 2) * acc_y
        new_acc_y = math.sin(-heading + math.pi / 2) * acc_x + math.cos(
            -heading + math.pi / 2) * acc_y

        # self.speed_line.set_xdata([0, new_speed_x])
        # self.speed_line.set_ydata([0, new_speed_y])
        # self.acc_line.set_xdata([0, new_acc_x])
        # self.acc_line.set_ydata([0, new_acc_y])
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Insert routing request
Usage:
    mock_routing_request.py
"""
import argparse
import os
import sys
import time

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time
from modules.routing.proto import routing_pb2


def main():
    """
    Main rosnode
    """
    cyber.init()
    node = cyber.Node("mock_routing_requester")
    sequence_num = 0

    routing_request = routing_pb2.RoutingRequest()

    routing_request.header.timestamp_sec = cyber_time.Time.now().to_sec()
    routing_request.header.module_name = 'routing_request'
    routing_request.header.sequence_num = sequence_num
    sequence_num = sequence_num + 1

    waypoint = routing_request.waypoint.add()
    waypoint.pose.x = 587696.82286
    waypoint.pose.y = 4141446.66696
    waypoint.id = '1-1'
    waypoint.s = 1

    waypoint = routing_request.waypoint.add()
    waypoint.pose.x = 586948.740120
    waypoint.pose.y = 4141171.118641
    waypoint.id = '1-1'
    waypoint.s = 80

    writer = node.create_writer('/apollo/routing_request',
                                routing_pb2.RoutingRequest)
    time.sleep(2.0)
    print("routing_request", routing_request)
    writer.write(routing_request)


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
config navigation mode
"""
import sys
import configparser
from modules.dreamview.proto import hmi_config_pb2
from modules.planning.proto import planning_config_pb2
from modules.tools.common import proto_utils

DEFAULT_NAVI_CONFIG_FILE = "/apollo/modules/tools/navigation/config/default.ini"
HMI_CONF_FILE = "/apollo/modules/dreamview/conf/hmi.conf"
PLANNING_CONF_FILE = "/apollo/modules/planning/conf/planning_config_navi.pb.txt"
GLOBAL_FLAG_FILE = "/apollo/modules/common/data/global_flagfile.txt"
LOCALIZATION_FLAG_FILE = "/apollo/modules/localization/conf/localization.conf"
PLANNING_FLAG_FILE1 = "/apollo/modules/planning/conf/planning.conf"
PLANNING_FLAG_FILE2 = "/apollo/modules/planning/conf/planning_navi.conf"


def set_hmi_conf(config):
    """change hmi conf file based on navi config file"""
    hmi_conf = hmi_config_pb2.HMIConfig()
    proto_utils.get_pb_from_file(HMI_CONF_FILE, hmi_conf)

    perception = config.get('PerceptionConf', 'perception')
    navi_mode = hmi_conf.modes["Navigation"]

    if 'navigation_camera' in navi_mode.live_modules:
        navi_mode.live_modules.remove('navigation_camera')
    if 'navigation_perception' in navi_mode.live_modules:
        navi_mode.live_modules.remove('navigation_perception')

    if 'mobileye' in navi_mode.live_modules:
        navi_mode.live_modules.remove('mobileye')
    if 'third_party_perception' in navi_mode.live_modules:
        navi_mode.live_modules.remove('third_party_perception')

    if 'velodyne' in navi_mode.live_modules:
        navi_mode.live_modules.remove('velodyne')
    if 'perception' in navi_mode.live_modules:
        navi_mode.live_modules.remove('perception')

    if perception == "CAMERA":
        if 'navigation_camera' not in navi_mode.live_modules:
            navi_mode.live_modules.insert(0, 'navigation_camera')
        if 'navigation_perception' not in navi_mode.live_modules:
            navi_mode.live_modules.insert(0, 'navigation_perception')

    if perception == "MOBILEYE":
        if 'mobileye' not in navi_mode.live_modules:
            navi_mode.live_modules.insert(0, 'mobileye')
        if 'third_party_perception' not in navi_mode.live_modules:
            navi_mode.live_modules.insert(0, 'third_party_perception')

    if perception == "VELODYNE64":
        if 'velodyne' not in navi_mode.live_modules:
            navi_mode.live_modules.insert(0, 'velodyne')
        if 'perception' not in navi_mode.live_modules:
            navi_mode.live_modules.insert(0, 'perception')

    hmi_conf.modes["Navigation"].CopyFrom(navi_mode)
    proto_utils.write_pb_to_text_file(hmi_conf, HMI_CONF_FILE)


def set_planning_conf(config):
    """change planning config based on navi config"""
    planning_conf = planning_config_pb2.PlanningConfig()
    proto_utils.get_pb_from_file(PLANNING_CONF_FILE, planning_conf)
    planner_type = config.get('PlanningConf', 'planner_type')
    if planner_type == "EM":
        planning_conf.planner_type = planning_config_pb2.PlanningConfig.EM
    if planner_type == "LATTICE":
        planning_conf.planner_type = planning_config_pb2.PlanningConfig.LATTICE
    if planner_type == "NAVI":
        planning_conf.planner_type = planning_config_pb2.PlanningConfig.NAVI
    proto_utils.write_pb_to_text_file(planning_conf, PLANNING_CONF_FILE)


def set_global_flag(config):
    """update global flag file"""
    utm_zone = config.get('LocalizationConf', 'utm_zone')
    with open(GLOBAL_FLAG_FILE, 'a') as f:
        f.write('\n')
        f.write('--use_navigation_mode=true\n\n')
        f.write('--local_utm_zone_id=' + utm_zone + '\n\n')


def set_localization_flag(config):
    """update localization flag file"""
    utm_zone = config.get('LocalizationConf', 'utm_zone')
    with open(LOCALIZATION_FLAG_FILE, 'a') as f:
        f.write('\n')
        f.write('--local_utm_zone_id=' + utm_zone + '\n\n')


def set_planning_flag(config):
    """update planning flag files"""
    speed_limit = config.get('PlanningConf', 'speed_limit')
    with open(PLANNING_FLAG_FILE1, 'a') as f:
        f.write('\n')
        f.write('--planning_upper_speed_limit=' + speed_limit + '\n\n')
    with open(PLANNING_FLAG_FILE2, 'a') as f:
        f.write('\n')
        f.write('--planning_upper_speed_limit=' + speed_limit + '\n\n')


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("\nusage: python navi_config.py config.ini\n\n")
        sys.exit(0)
    config_file = sys.argv[1]
    config = configparser.ConfigParser()
    config.read(config_file)

    set_hmi_conf(config)
    set_planning_conf(config)
    set_global_flag(config)
    set_localization_flag(config)
    set_planning_flag(config)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
extract localization message from  bag files
Usage:
    python path_extract.py file1 file2 ...
"""
import sys
import datetime
from cyber.python.cyber_py3.record import RecordReader
from modules.localization.proto import localization_pb2

kLocalizationTopic = '/apollo/localization/pose'

if __name__ == '__main__':
    bag_files = sys.argv[1:]

    bag_file = bag_files[0]
    now = datetime.datetime.now().strftime("%Y-%m-%d_%H.%M.%S")
    f = open("path_" + bag_file.split('/')[-1] + ".txt", 'w')

    for bag_file in bag_files:
        print("begin to extract path from file :", bag_file)
        reader = RecordReader(bag_file)
        localization = localization_pb2.LocalizationEstimate()
        for msg in reader.read_messages():
            if msg.topic == kLocalizationTopic:
                localization.ParseFromString(msg.message)
                x = localization.pose.position.x
                y = localization.pose.position.y
                f.write(str(x) + "," + str(y) + "\n")
        print("Finished extracting path from file :", bag_file)
    f.close()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import matplotlib.pyplot as plt

fig = plt.figure()
ax = plt.subplot2grid((1, 1), (0, 0))
styles = ["b-", "r-", "y-"]
i = 0
for fn in sys.argv[1:]:
    f = open(fn, 'r')
    xs = []
    ys = []
    for line in f:
        line = line.replace("\n", '')
        data = line.split(',')
        x = float(data[0])
        y = float(data[1])
        xs.append(x)
        ys.append(y)
    f.close()
    si = i % len(styles)
    ax.plot(xs, ys, styles[si], lw=3, alpha=0.8)
    i += 1

ax.axis('equal')
plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
from shapely.geometry import LineString, Point
import matplotlib.pyplot as plt

if __name__ == "__main__":
    fpath = sys.argv[1]
    f = open(fpath, 'r')
    points_x = []
    points_y = []
    points = []

    for line in f:
        line = line.replace("\n", '')
        if len(line.strip()) == 0:
            continue
        data = line.split(',')
        x = float(data[0])
        y = float(data[1])
        points_x.append(x)
        points_y.append(y)
        points.append((x, y))
    f.close()
    line_string = LineString(points)
    new_px = []
    new_py = []
    f = open("processed_" + fpath.split("/")[-1], 'w')
    for i in range(int(line_string.length)):
        p = line_string.interpolate(i)
        new_px.append(p.x)
        new_py.append(p.y)
        f.write(str(p.x) + "," + str(p.y) + "\n")
    f.close()
    print(len(points_x))
    print(len(new_px))
    plt.figure()
    plt.plot(points_x, points_y, '-r', lw=1, label='raw')
    plt.plot(new_px, new_py, '-g', label='processed')
    plt.legend(loc='best')
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import pyproj
import matplotlib.pyplot as plt

projector = pyproj.Proj(proj='utm', zone=10, ellps='WGS84')
fig = plt.figure()
ax = plt.subplot2grid((1, 1), (0, 0))
styles = ['r-', 'b-']

i = 0
for fn in sys.argv[1:]:
    X = []
    Y = []
    f = open(fn, 'r')
    for line in f:
        line = line.replace('\n', '')
        vals = line.split(",")
        if len(vals) < 3:
            continue
        print(float(vals[-2]), float(vals[-1]))
        x, y = projector(float(vals[-1]), float(vals[-2]))
        print(x, y)
        X.append(x)
        Y.append(y)
    f.close()
    ax.plot(X, Y, styles[i % len(styles)], lw=3, alpha=0.8)
    i += 1
ax.axis('equal')
plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class ADVehicle:
    def __init__(self):
        self._chassis_pb = None
        self._localization_pb = None
        self.front_edge_to_center = 3.89
        self.back_edge_to_center = 1.043
        self.left_edge_to_center = 1.055
        self.right_edge_to_center = 1.055
        self.speed_mps = None
        self.x = None
        self.y = None
        self.heading = None

    def update_chassis(self, chassis_pb):
        self._chassis_pb = chassis_pb
        self.speed_mps = self._chassis_pb.speed_mps

    def update_localization(self, localization_pb):
        self._localization_pb = localization_pb
        self.x = self._localization_pb.pose.position.x
        self.y = self._localization_pb.pose.position.y
        self.heading = self._localization_pb.pose.heading

    def is_ready(self):
        if self._chassis_pb is None or self._localization_pb is None:
            return False
        return True
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
import math
import numpy.polynomial.polynomial as poly


class HeadingDecider:
    def __init__(self):
        self.mobileye_pb = None

    def get_path(self, x, y, path_length):
        ind = int(math.floor((abs(x[0]) * 100.0) / 1) + 1)
        newx = [0]
        newy = [0]
        w = [1000]
        if len(y) - ind > 0:
            for i in range(len(y) - ind):
                newx.append(x[i + ind])
                newy.append(y[i + ind])
                w.append(w[-1] - 10)
        else:
            newx.append(x[-1])
            newy.append(y[-1])
            w.append(w[-1] - 10)
        coefs = poly.polyfit(newy, newx, 4, w=w)  # x = f(y)
        nx = poly.polyval(y, coefs)
        return nx, y
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math


class LaneMarkerCorrector:
    def __init__(self, left_marker, right_marker):
        self.left_marker = left_marker
        self.right_marker = right_marker

    def correct(self, position, heading, routing_segment):
        return self.left_marker, self.right_marker
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class LocalPath:
    def __init__(self, points):
        self.points = points

    def init_y(self):
        if len(self.points) > 0:
            return self.points[0][1]
        return None

    def get_xy(self):
        x = []
        y = []
        for p in self.points:
            x.append(p[0])
            y.append(p[1])
        return x, y

    def range(self):
        return len(self.points) - 1

    def shift(self, dist):
        for i in range(len(self.points)):
            self.points[i][1] += dist

    def cut(self, dist):
        pass

    def resample(self):
        pass

    def merge(self, local_path, weight):
        for i in range(len(self.points)):
            y = self.points[i][1]
            if i < len(local_path.points):
                y2 = local_path.points[i][1] * weight
                self.points[i][1] = (y + y2) / (1 + weight)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class ChassisProvider:
    def __init__(self):
        self.chassis_pb = None

    def update(self, chassis_pb):
        self.chassis_pb = chassis_pb

    def get_speed_mps(self):
        if self.chassis_pb is None:
            return None
        return self.chassis_pb.speed_mps
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class LocalizationProvider:
    def __init__(self):
        self.localization_pb = None
        self.x = 0
        self.y = 0
        self.heading = 0

    def update(self, localization_pb):
        self.localization_pb = localization_pb
        self.x = self.localization_pb.pose.position.x
        self.y = self.localization_pb.pose.position.y
        self.heading = self.localization_pb.pose.heading
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
import math
from numpy.polynomial.polynomial import polyval


class ReferencePath:
    def __init__(self):
        self.MINIMUM_PATH_LENGTH = 5
        self.MAX_LAT_CHANGE = 0.1
        self.init_y_last = None

    def get_path_length(self, speed_mps):
        path_length = self.MINIMUM_PATH_LENGTH
        current_speed = speed_mps
        if current_speed is not None:
            if path_length < current_speed * 2:
                path_length = math.ceil(current_speed * 2)
        return path_length

    def get_ref_path_init_y(self, init_y_perception):
        if self.init_y_last is None:
            return 0
        if abs(init_y_perception - self.init_y_last) < self.MAX_LAT_CHANGE:
            return init_y_perception
        else:
            if init_y_perception > self.init_y_last:
                return self.init_y_last + self.MAX_LAT_CHANGE
            else:
                return self.init_y_last - self.MAX_LAT_CHANGE

    def get_ref_path_by_lm(self, perception, chassis):
        path_length = self.get_path_length(chassis.get_speed_mps())
        init_y_perception = (perception.right_lm_coef[0] +
                             perception.left_lm_coef[0]) / -2.0
        init_y = self.get_ref_path_init_y(init_y_perception)
        self.init_y_last = init_y
        path_x, path_y = self._get_perception_ref_path(
            perception, path_length, init_y)
        return path_x, path_y, path_length

    def _get_perception_ref_path(self, perception, path_length, init_y):
        path_coef = [0, 0, 0, 0]

        path_coef[0] = -1 * init_y
        quality = perception.right_lm_quality + perception.left_lm_quality
        if quality > 0:
            for i in range(1, 4):
                path_coef[i] = (perception.right_lm_coef[i] *
                                perception.right_lm_quality +
                                perception.left_lm_coef[i] *
                                perception.left_lm_quality) / quality
        path_x = []
        path_y = []
        for x in range(int(path_length)):
            y = -1 * polyval(x, path_coef)
            path_x.append(x)
            path_y.append(y)
        return path_x, path_y

    def get_ref_path_by_lmr(self, perception, routing, adv):

        path_length = self.get_path_length(adv.speed_mps)

        rpath_x, rpath_y = routing.get_local_segment_spline(adv.x,
                                                            adv.y,
                                                            adv.heading)
        init_y_perception = (perception.right_lm_coef[0] +
                             perception.left_lm_coef[0]) / -2.0
        quality = perception.right_lm_quality + perception.left_lm_quality
        quality = quality / 2.0

        if len(rpath_x) >= path_length and routing.human and rpath_y[0] <= 3:
            init_y_routing = rpath_y[0]
            init_y = self.get_ref_path_init_y(init_y_routing)
            if quality > 0.1:
                quality = 0.1
            self.init_y_last = init_y
        else:
            init_y = self.get_ref_path_init_y(init_y_perception)
            self.init_y_last = init_y

        lmpath_x, lmpath_y = self._get_perception_ref_path(
            perception, path_length, init_y)

        if len(rpath_x) < path_length:
            return lmpath_x, lmpath_y, path_length

        routing_shift = rpath_y[0] - init_y
        path_x = []
        path_y = []
        for i in range(int(path_length)):
            # TODO(yifei): more accurate shift is needed.
            y = (lmpath_y[i] * quality + rpath_y[i] - routing_shift) / (
                1 + quality)
            path_x.append(i)
            path_y.append(y)

        return path_x, path_y, path_length

    def shift_point(self, p, p2, distance):
        delta_y = p2.y - p.y
        delta_x = p2.x - p.x
        angle = 0
        if distance >= 0:
            angle = math.atan2(delta_y, delta_x) + math.pi / 2.0
        else:
            angle = math.atan2(delta_y, delta_x) - math.pi / 2.0
        p1n = []
        p1n.append(p.x + (math.cos(angle) * distance))
        p1n.append(p.y + (math.sin(angle) * distance))

        p2n = []
        p2n.append(p2.x + (math.cos(angle) * distance))
        p2n.append(p2.y + (math.sin(angle) * distance))
        return p1n, p2n
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class SpeedDecider:
    def __init__(self, max_cruise_speed, enable_follow):
        self.CRUISE_SPEED = max_cruise_speed  # m/s
        self.enable_follow = enable_follow

    def get_target_speed_and_path_length(self, mobileye_provider,
                                         chassis_provider, path_length):
        obstacle_closest_lon = 999
        obstacle_speed = None
        obstacles = mobileye_provider.obstacles
        for obs in obstacles:
            if obs.lane == 1:
                if (obs.x - obs.length / 2.0) < obstacle_closest_lon:
                    obstacle_closest_lon = obs.x - obs.length / 2.0
                    obstacle_speed = obs.rel_speed + \
                        chassis_provider.get_speed_mps()

        new_path_length = path_length
        if obstacle_closest_lon < new_path_length:
            new_path_length = obstacle_closest_lon
        if obstacle_speed is None or obstacle_speed > self.CRUISE_SPEED:
            return self.CRUISE_SPEED, new_path_length
        else:
            return obstacle_speed, new_path_length

    def get(self, mobileye_provider, chassis_provider, path_length):
        if self.enable_follow:
            return self.get_target_speed_and_path_length(mobileye_provider,
                                                         chassis_provider,
                                                         path_length)
        else:
            return self.CRUISE_SPEED, path_length
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
import math
from numpy.polynomial.polynomial import polyval
from modules.planning.proto import planning_pb2
from modules.canbus.proto import chassis_pb2
from modules.common.proto import drive_state_pb2
from cyber.python.cyber_py3 import cyber_time


def euclidean_distance(point1, point2):
    sum = (point1[0] - point2[0]) * (point1[0] - point2[0])
    sum += (point1[1] - point2[1]) * (point1[1] - point2[1])
    return math.sqrt(sum)


def get_theta(point, point_base):
    # print point
    return math.atan2(1, 0) - math.atan2(point[0] - point_base[0],
                                         point[1] - point_base[1])


class TrajectoryGenerator:
    def __init__(self):
        self.mobileye_pb = None

    def generate(self, path, final_path_length, speed,
                 start_timestamp):
        path_x, path_y = path.get_xy()
        adc_trajectory = planning_pb2.ADCTrajectory()
        adc_trajectory.header.timestamp_sec = cyber_time.Time.now().to_sec()
        adc_trajectory.header.module_name = "planning"
        adc_trajectory.gear = chassis_pb2.Chassis.GEAR_DRIVE
        adc_trajectory.latency_stats.total_time_ms = \
            (cyber_time.Time.now().to_sec() - start_timestamp) * 1000
        s = 0
        relative_time = 0
        adc_trajectory.engage_advice.advice \
            = drive_state_pb2.EngageAdvice.READY_TO_ENGAGE

        for x in range(int(final_path_length - 1)):
            y = path_y[x]

            traj_point = adc_trajectory.trajectory_point.add()
            traj_point.path_point.x = x
            traj_point.path_point.y = y
            if x > 0:
                dist = euclidean_distance((x, y), (x - 1, path_y[x - 1]))
                s += dist
                relative_time += dist / speed

            traj_point.path_point.theta = get_theta(
                (x + 1, path_y[x + 1]), (0, path_y[0]))
            traj_point.path_point.s = s
            traj_point.v = speed
            traj_point.relative_time = relative_time
        return adc_trajectory
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from datetime import datetime
import json
import sys

from modules.map.relative_map.proto import navigation_pb2


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("usage: python generator.py "
              "navi_line1.smoothed navi_line2.smoothed ...")
        sys.exit(0)
    navi_files = sys.argv[1:]
    # generate navigation info
    navigation_info = navigation_pb2.NavigationInfo()
    priority = 0
    for fdata in navi_files:
        print("processing " + fdata)
        navigation_path = navigation_info.navigation_path.add()
        navigation_path.path_priority = priority
        priority += 1
        navigation_path.path.name = "navigation"

        with open(fdata, 'r') as f:
            cnt = 0
            for line in f:
                cnt += 1
                if cnt < 3:
                    continue
                json_point = json.loads(line)
                point = navigation_path.path.path_point.add()
                point.x = json_point['x']
                point.y = json_point['y']
                point.s = json_point['s']
                point.theta = json_point['theta']
                point.kappa = json_point['kappa']
                point.dkappa = json_point['dkappa']

    datetime_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    with open(datetime_str + ".dbmap", 'w') as f:
        f.write(str(navigation_info))
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import pyproj
import math


class PointUtils:
    """point utils"""

    @staticmethod
    def utm2latlon(x, y, zone):
        """utm to latlon"""
        proj = pyproj.Proj(proj='utm', zone=zone, ellps='WGS84')
        lon, lat = proj(x, y, inverse=True)
        return lat, lon

    @staticmethod
    def latlon2utm(lat, lon):
        """latlon to utm"""
        zone = PointUtils.latlon2utmzone(lat, lon)
        projector2 = pyproj.Proj(proj='utm', zone=zone, ellps='WGS84')
        x, y = projector2(lon, lat)
        return x, y, zone

    @staticmethod
    def latlon2utmzone(lat, lon):
        """latlon to utm zone"""
        zone_num = math.floor((lon + 180) / 6) + 1
        if 56.0 <= lat < 64.0 and 3.0 <= lon < 12.0:
            zone_num = 32
        if 72.0 <= lat < 84.0:
            if 0.0 <= lon < 9.0:
                zone_num = 31
            elif 9.0 <= lon < 21.0:
                zone_num = 33
            elif 21.0 <= lon < 33.0:
                zone_num = 35
            elif 33.0 <= lon < 42.0:
                zone_num = 37
        return zone_num

    @staticmethod
    def latlon2latlondict(lat, lon):
        """latlon to latlon dictionary"""
        return {'lat': lat, 'lng': lon}

    @staticmethod
    def utm2grididx(x, y, resolution_mm):
        """utm to grid index"""
        index_str = str(int(round(x / resolution_mm)) * resolution_mm)
        index_str += ","
        index_str += str(int(round(y / resolution_mm)) * resolution_mm)
        return index_str
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import json
import sys

from yattag import Doc
import pyproj

from modules.map.relative_map.proto import navigation_pb2
import modules.tool.common.proto_utils as proto_utils


class DBMapViewer:
    def __init__(self, utm_zone):
        """
        init function
        """
        self.utm_zone = utm_zone
        self.projector = pyproj.Proj(
            proj='utm', zone=self.utm_zone, ellps='WGS84')

        self.navigation_lines = []
        self.center_lat = None
        self.center_lon = None
        self.html = ""

    def utm2latlon(self, x, y):
        """
        convert the utm x y to lat and lon
        """
        lon, lat = self.projector(x, y, inverse=True)
        return lat, lon

    def add(self, dbmap):
        for navigation_path in dbmap.navigation_path:
            navigation_line = []
            for p in navigation_path.path.path_point:
                point = {}
                lat, lng = self.utm2latlon(p.x, p.y)
                if self.center_lat is None:
                    self.center_lat = lat
                if self.center_lon is None:
                    self.center_lon = lng
                point['lat'] = lat
                point['lng'] = lng
                navigation_line.append(point)
            self.navigation_lines.append(navigation_line)

    def generate(self):
        """
        function to generate html code.
        """
        doc, tag, text, line = Doc().ttl()
        doc.asis('<!DOCTYPE html>')
        api_url = 'http://maps.google.com/maps/api/js?sensor=' \
                  'false&callback=initMap'
        with tag('html'):
            with tag('head'):
                with tag('title'):
                    text('Gmap Viewer')
                doc.asis('<meta name="viewport" content="initial-scale=1.0">')
                doc.asis('<meta charset="utf-8">')
                with tag('style'):
                    doc.asis('#map { height: 100%; }')
                    doc.asis(
                        'html, body { height: 100%; margin: 0; padding: 0; }')
            with tag('body'):
                with tag('div', id='map'):
                    pass
                with tag('script'):
                    doc.asis('\nvar map;\n')
                    doc.asis("\nvar colors = ['#e6194b', '#3cb44b', '#ffe119', "
                             "'#0082c8', '#f58231', '#911eb4', '#46f0f0', "
                             "'#f032e6', '#d2f53c', '#fabebe', '#008080', "
                             "'#e6beff', '#aa6e28', '#fffac8', '#800000', "
                             "'#aaffc3', '#808000', '#ffd8b1', '#000080', "
                             "'#808080', '#000000']\n")
                    doc.asis('function initMap() {\n')
                    doc.asis("map = new google.maps.Map("
                             "document.getElementById('map'), {\n")
                    doc.asis('center: {lat: ' + str(self.center_lat) +
                             ', lng: ' + str(self.center_lon) + '},\n')
                    doc.asis('zoom: 16\n')
                    doc.asis('});\n')
                    doc.asis('var navi_lines = ' +
                             json.dumps(self.navigation_lines) + ';\n')
                    doc.asis("""
                        for (var i = 0; i < navi_lines.length; i++) {
                            var boundary = new google.maps.Polyline({
                                path: navi_lines[i],
                                geodesic: true,
                                strokeColor: colors[i % colors.length],
                                strokeOpacity: 1.0,
                                strokeWeight: 3
                            });
                            boundary.setMap(map);
                        }
                    """)
                    doc.asis('}\n')
                doc.asis('<script src="' + api_url + '"></script>')
        self.html = doc.getvalue()
        return self.html


if __name__ == "__main__":
    import google.protobuf.text_format as text_format

    if len(sys.argv) < 2:
        print("usage: python map_viewer.py dbmap_file [utm_zone=10]")
        sys.exit(0)

    map_file = sys.argv[1]
    utm_zone = 10
    if len(sys.argv) >= 3:
        utm_zone = int(sys.argv[2])

    dbmap = navigation_pb2.NavigationInfo()
    proto_utils.get_pb_from_file(map_file, dbmap)
    with open(map_file, 'r') as file_in:
        text_format.Merge(file_in.read(), dbmap)
    viewer = DBMapViewer(utm_zone)
    viewer.add(dbmap)
    html = viewer.generate()
    with open('dbmap.html', 'w') as f:
        f.write(html)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
from datetime import datetime
from cyber.python.cyber_py3.record import RecordReader
from modules.localization.proto import localization_pb2

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("usage: python record_extractor.py record_file1 record_file2 ...")

    frecords = sys.argv[1:]
    now = datetime.now().strftime("%Y-%m-%d_%H.%M.%S")

    with open("path_" + frecords[0].split('/')[-1] + ".txt", 'w') as f:
        for frecord in frecords:
            print("processing " + frecord)
            reader = RecordReader(frecord)
            for msg in reader.read_messages():
                if msg.topic == "/apollo/localization/pose":
                    localization = localization_pb2.LocalizationEstimate()
                    localization.ParseFromString(msg.message)
                    x = localization.pose.position.x
                    y = localization.pose.position.y
                    f.write(str(x) + "," + str(y) + "\n")
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import matplotlib.pyplot as plt

fig = plt.figure()
ax = plt.subplot2grid((1, 1), (0, 0))
styles = ["b-", "r-", "y-"]
i = 0
for fn in sys.argv[1:]:
    f = open(fn, 'r')
    xs = []
    ys = []
    for line in f:
        line = line.replace("\n", '')
        data = line.split(',')
        x = float(data[0])
        y = float(data[1])
        xs.append(x)
        ys.append(y)
    f.close()
    si = i % len(styles)
    ax.plot(xs, ys, styles[si], lw=3, alpha=0.8)
    i += 1

ax.axis('equal')
plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import json
import matplotlib.pyplot as plt

import numpy
from scipy.signal import butter, lfilter, freqz


def get_s_xy_kappa(fn, ax, ax2):
    f = open(fn, 'r')
    xs = []
    ys = []
    ks = []
    theta = []
    s = []
    cnt = 0
    for line in f:
        cnt += 1
        if cnt < 3:
            continue
        line = line.replace("\n", '')
        data = json.loads(line)
        ks.append(data['kappa'])
        s.append(data['s'])
        xs.append(data['x'])
        ys.append(data['y'])
        theta.append(data['theta'])
    f.close()
    return s, xs, ys, theta, ks


def plot_raw_path(fn, ax):
    f = open(fn, 'r')
    xs = []
    ys = []
    for line in f:
        line = line.replace("\n", '')
        data = line.split(',')
        x = float(data[0])
        y = float(data[1])
        xs.append(x)
        ys.append(y)
    f.close()
    ax.plot(xs, ys, "r-", lw=3, alpha=0.8)


if __name__ == "__main__":
    fig = plt.figure()
    ax = plt.subplot2grid((2, 2), (0, 0))
    ax2 = plt.subplot2grid((2, 2), (0, 1))
    ax3 = plt.subplot2grid((2, 2), (1, 0))
    ax4 = plt.subplot2grid((2, 2), (1, 1))

    styles = ["bo", "ro", "yo"]
    i = 0

    fn = sys.argv[1]
    plot_raw_path(fn, ax)

    fn = sys.argv[2]
    s, xs, ys, theta, ks = get_s_xy_kappa(fn, ax, ax2)
    ax.plot(xs, ys, "b-", lw=8, alpha=0.5)
    ax.set_title("x-y")

    ax2.plot(s, ks, 'k-')
    ax2.set_title("s-kappa")
    ax2.axhline(y=0.0, color='b', linestyle='-')

    ax3.plot(s, theta, 'k-')
    ax3.set_title("s-theta")

    ax4.plot(s, s, 'k-')
    ax4.set_title("s-s")

    if len(sys.argv) >= 4:
        fn = sys.argv[3]
        s, xs, ys, theta, ks = get_s_xy_kappa(fn, ax, ax2)
        ax.plot(xs, ys, "r-", lw=8, alpha=0.5)
        ax.set_title("x-y")

        ax2.plot(s, ks, 'r-')
        ax2.set_title("s-kappa")
        ax2.axhline(y=0.0, color='b', linestyle='-')

        ax3.plot(s, theta, 'r-')
        ax3.set_title("s-theta")

        ax4.plot(s, s, 'r-')
        ax4.set_title("s-s")

    ax.axis('equal')
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import random

from google.protobuf.internal import decoder
from google.protobuf.internal import encoder

from modules.planning.proto import planner_open_space_config_pb2
import modules.tools.common.proto_utils as proto_utils
import distance_approach_visualizer
import hybrid_a_star_visualizer


random.seed(99999)
rand_num = 1000
original_file_path = "/apollo/modules/planning/conf/planner_open_space_config.pb.txt"
optimal_file_path = "/apollo/modules/planning/conf/optimal_planner_open_space_config_-8_4.pb.txt"
# tunning_object = "coarse_trajectory"
tunning_object = "smooth_trajectory"


def load_open_space_protobuf(filename):
    open_space_params = planner_open_space_config_pb2.PlannerOpenSpaceConfig()
    proto_utils.get_pb_from_text_file(filename, open_space_params)
    return open_space_params


def GetParamsForTunning(tunning_object):
    param_names_and_range = []
    if tunning_object == "coarse_trajectory":
        param_names_and_range.append(
            ("warm_start_config.traj_forward_penalty", 2.0))
        param_names_and_range.append(
            ("warm_start_config.traj_back_penalty", 2.0))
        param_names_and_range.append(
            ("warm_start_config.traj_gear_switch_penalty", 2.0))
        param_names_and_range.append(
            ("warm_start_config.traj_steer_penalty", 3.0))
        param_names_and_range.append(
            ("warm_start_config.traj_steer_change_penalty", 2.0))
    elif tunning_object == "smooth_trajectory":
        param_names_and_range.append(
            ("distance_approach_config.weight_steer", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_a", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_steer_rate", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_a_rate", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_x", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_y", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_phi", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_v", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_steer_stitching", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_a_stitching", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_first_order_time", 2.0))
        param_names_and_range.append(
            ("distance_approach_config.weight_second_order_time", 2.0))
    return param_names_and_range


def RandSampling(param_names_and_range, origin_open_space_params):
    params_lists = []
    for iter in range(0, rand_num):
        rand_params = planner_open_space_config_pb2.PlannerOpenSpaceConfig()
        rand_params.CopyFrom(origin_open_space_params)
        for param in param_names_and_range:
            exec("rand_params." +
                 str(param[0]) + "=random.uniform(max(rand_params." +
                 str(param[0])
                 + " - " + str(param[1]) + ",0.0)"
                 + " ,rand_params." + str(param[0]) + " + " + str(param[1]) + ")")
        params_lists.append(rand_params)
    return params_lists


def TestingParams(params_lists, tunning_object):
    key_to_evaluations = {}
    for iter in range(0, len(params_lists)):
        evaluation = ParamEvaluation(params_lists[iter], tunning_object)
        key_to_evaluations[iter] = evaluation
    return key_to_evaluations


def ParamEvaluation(params, tunning_object):
    proto_utils.write_pb_to_text_file(params, original_file_path)
    if tunning_object == "coarse_trajectory":
        visualize_flag = False
        success, x_out, y_out, phi_out, v_out, a_out, steer_out, planning_time = hybrid_a_star_visualizer.HybridAStarPlan(
            visualize_flag)
        if not success:
            return float('inf')
        else:
            return planning_time
    elif tunning_object == "smooth_trajectory":
        visualize_flag = False
        success, opt_x_out, opt_y_out, opt_phi_out, opt_v_out, opt_a_out, opt_steer_out, opt_time_out, planning_time = distance_approach_visualizer.SmoothTrajectory(
            visualize_flag)
        if not success:
            return float('inf')
        else:
            return planning_time


def GetOptimalParams(params_lists, key_to_evaluations):
    tmp = []
    for key, value in key_to_evaluations.items():
        tmptuple = (value, key)
        tmp.append(tmptuple)

    tmp = sorted(tmp)
    optimal_params = params_lists[tmp[0][1]]
    optimal_evaluation = tmp[0][0]
    return optimal_params, optimal_evaluation


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--InputConfig", help="original conf address to be tuned", type=str, default=original_file_path)
    parser.add_argument("--OutputConfig", help="tuned conf address",
                        type=str, default=optimal_file_path)
    parser.add_argument("--TunningObject",
                        help="algorithm to be tuned", type=str, default=tunning_object)
    args = parser.parse_args()
    original_file_path = args.InputConfig
    optimal_file_path = args.OutputConfig
    tunning_object = args.TunningObject
    param_names_and_range = GetParamsForTunning(tunning_object)
    origin_open_space_params = load_open_space_protobuf(original_file_path)
    params_lists = RandSampling(
        param_names_and_range, origin_open_space_params)
    key_to_evaluations = TestingParams(params_lists, tunning_object)
    optimal_params, optimal_evaluation = GetOptimalParams(
        params_lists, key_to_evaluations)
    origin_evaluation = ParamEvaluation(
        origin_open_space_params, tunning_object)
    print("optimal_evaluation is " + str(optimal_evaluation))
    print("origin_evaluation is " + str(origin_evaluation))
    improvement_percentage = (
        origin_evaluation - optimal_evaluation) / origin_evaluation
    print("improvement_percentage is " + str(improvement_percentage))
    proto_utils.write_pb_to_text_file(optimal_params, optimal_file_path)
    proto_utils.write_pb_to_text_file(
        origin_open_space_params, original_file_path)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math

from ctypes import c_bool
from ctypes import c_double
from ctypes import c_ushort
from ctypes import c_void_p
from ctypes import cdll, POINTER


lib = cdll.LoadLibrary(
    '/apollo/bazel-bin/modules/planning/open_space/tools/distance_approach_problem_wrapper_lib.so')

lib.CreateHybridAPtr.argtypes = []
lib.CreateHybridAPtr.restype = c_void_p
lib.DistanceCreateResultPtr.argtypes = []
lib.DistanceCreateResultPtr.restype = c_void_p
lib.DistanceCreateObstaclesPtr.argtypes = []
lib.DistanceCreateObstaclesPtr.restype = c_void_p
lib.AddObstacle.argtypes = [c_void_p, POINTER(c_double)]
lib.DistancePlan.restype = c_bool
lib.DistancePlan.argtypes = [c_void_p, c_void_p, c_void_p, c_double, c_double, c_double, c_double,
                             c_double, c_double, POINTER(c_double)]
lib.DistanceGetResult.argtypes = [c_void_p, c_void_p, POINTER(c_double), POINTER(c_double), POINTER(c_double),
                                  POINTER(c_double), POINTER(c_double), POINTER(
                                      c_double), POINTER(c_double),
                                  POINTER(c_double), POINTER(c_double), POINTER(
                                      c_double), POINTER(c_double),
                                  POINTER(c_double), POINTER(c_double), POINTER(
                                      c_double), POINTER(c_double),
                                  POINTER(c_ushort), POINTER(c_double), POINTER(c_double), POINTER(c_double)]


class DistancePlanner(object):
    def __init__(self):
        self.warm_start_planner = lib.CreateHybridAPtr()
        self.obstacles = lib.DistanceCreateObstaclesPtr()
        self.result = lib.DistanceCreateResultPtr()

    def AddObstacle(self, ROI_distance_approach_parking_boundary):
        lib.AddObstacle(self.obstacles, POINTER(
            c_double)(ROI_distance_approach_parking_boundary))

    def DistancePlan(self, sx, sy, sphi, ex, ey, ephi, XYbounds):
        return lib.DistancePlan(self.warm_start_planner, self.obstacles, self.result, c_double(sx),
                                c_double(sy), c_double(sphi), c_double(ex), c_double(ey), c_double(ephi), POINTER(c_double)(XYbounds))

    def DistanceGetResult(self, x, y, phi, v, a, steer, opt_x, opt_y, opt_phi, opt_v, opt_a, opt_steer, opt_time,
                          opt_dual_l, opt_dual_n, output_size, hybrid_time, dual_time, ipopt_time):
        lib.DistanceGetResult(self.result, self.obstacles, POINTER(c_double)(x), POINTER(c_double)(y),
                              POINTER(c_double)(phi), POINTER(c_double)(v), POINTER(c_double)(a), POINTER(
            c_double)(steer), POINTER(c_double)(opt_x), POINTER(c_double)(opt_y),
            POINTER(c_double)(opt_phi), POINTER(c_double)(opt_v), POINTER(c_double)(opt_a),
            POINTER(c_double)(opt_steer), POINTER(c_double)(
                opt_time), POINTER(c_double)(opt_dual_l),
            POINTER(c_double)(opt_dual_n), POINTER(c_ushort)(output_size),
            POINTER(c_double)(hybrid_time), POINTER(c_double)(dual_time), POINTER(c_double)(ipopt_time))
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
import time

from matplotlib import animation
import matplotlib.patches as patches
import matplotlib.pyplot as plt
import numpy as np

from distance_approach_python_interface import *


result_file = "/tmp/open_space_osqp_ipopt.csv"


# def SmoothTrajectory(visualize_flag):
def SmoothTrajectory(visualize_flag, sx, sy):
    # initialze object
    OpenSpacePlanner = DistancePlanner()

    # parameter(except max, min and car size is defined in proto)
    num_output_buffer = 10000
    # sx = -8
    # sy = 1.5
    # sphi = 0.5
    sphi = 0.0

    scenario = "backward"
    # scenario = "parallel"

    if scenario == "backward":
        # obstacles for distance approach(vertices coords in clock wise order)
        ROI_distance_approach_parking_boundary = (
            c_double * 20)(*[-13.6407054776,
                             0.0140634663703,
                             0.0,
                             0.0,
                             0.0515703622475,
                             -5.15258191624,
                             0.0515703622475,
                             -5.15258191624,
                             2.8237895441,
                             -5.15306980547,
                             2.8237895441,
                             -5.15306980547,
                             2.7184833539,
                             -0.0398078878812,
                             16.3592013995,
                             -0.011889513383,
                             16.3591910364,
                             5.60414234644,
                             -13.6406951857,
                             5.61797800844,
                             ])
        OpenSpacePlanner.AddObstacle(
            ROI_distance_approach_parking_boundary)
        # parking lot position
        ex = 1.359
        ey = -3.86443643718
        ephi = 1.581
        XYbounds = [-13.6406951857, 16.3591910364, -5.15258191624, 5.61797800844]

    x = (c_double * num_output_buffer)()
    y = (c_double * num_output_buffer)()
    phi = (c_double * num_output_buffer)()
    v = (c_double * num_output_buffer)()
    a = (c_double * num_output_buffer)()
    steer = (c_double * num_output_buffer)()
    opt_x = (c_double * num_output_buffer)()
    opt_y = (c_double * num_output_buffer)()
    opt_phi = (c_double * num_output_buffer)()
    opt_v = (c_double * num_output_buffer)()
    opt_a = (c_double * num_output_buffer)()
    opt_steer = (c_double * num_output_buffer)()
    opt_time = (c_double * num_output_buffer)()
    opt_dual_l = (c_double * num_output_buffer)()
    opt_dual_n = (c_double * num_output_buffer)()
    size = (c_ushort * 1)()
    XYbounds_ctype = (c_double * 4)(*XYbounds)
    hybrid_time = (c_double * 1)(0.0)
    dual_time = (c_double * 1)(0.0)
    ipopt_time = (c_double * 1)(0.0)

    success = True
    start = time.time()
    print("planning start")
    if not OpenSpacePlanner.DistancePlan(sx, sy, sphi, ex, ey, ephi, XYbounds_ctype):
        print("planning fail")
        success = False
    #   exit()
    planning_time = time.time() - start
    print("planning time is " + str(planning_time))

    x_out = []
    y_out = []
    phi_out = []
    v_out = []
    a_out = []
    steer_out = []
    opt_x_out = []
    opt_y_out = []
    opt_phi_out = []
    opt_v_out = []
    opt_a_out = []
    opt_steer_out = []
    opt_time_out = []
    opt_dual_l_out = []
    opt_dual_n_out = []

    if visualize_flag and success:
        # load result
        OpenSpacePlanner.DistanceGetResult(x, y, phi, v, a, steer, opt_x,
                                           opt_y, opt_phi, opt_v, opt_a, opt_steer, opt_time,
                                           opt_dual_l, opt_dual_n, size,
                                           hybrid_time, dual_time, ipopt_time)
        for i in range(0, size[0]):
            x_out.append(float(x[i]))
            y_out.append(float(y[i]))
            phi_out.append(float(phi[i]))
            v_out.append(float(v[i]))
            a_out.append(float(a[i]))
            steer_out.append(float(steer[i]))
            opt_x_out.append(float(opt_x[i]))
            opt_y_out.append(float(opt_y[i]))
            opt_phi_out.append(float(opt_phi[i]))
            opt_v_out.append(float(opt_v[i]))
            opt_a_out.append(float(opt_a[i]))
            opt_steer_out.append(float(opt_steer[i]))
            opt_time_out.append(float(opt_time[i]))

        for i in range(0, size[0] * 6):
            opt_dual_l_out.append(float(opt_dual_l[i]))
        for i in range(0, size[0] * 16):
            opt_dual_n_out.append(float(opt_dual_n[i]))
        # trajectories plot
        fig1 = plt.figure(1)
        ax = fig1.add_subplot(111)
        for i in range(0, size[0]):
            # warm start
            downx = 1.055 * math.cos(phi_out[i] - math.pi / 2)
            downy = 1.055 * math.sin(phi_out[i] - math.pi / 2)
            leftx = 1.043 * math.cos(phi_out[i] - math.pi)
            lefty = 1.043 * math.sin(phi_out[i] - math.pi)
            x_shift_leftbottom = x_out[i] + downx + leftx
            y_shift_leftbottom = y_out[i] + downy + lefty
            warm_start_car = patches.Rectangle((x_shift_leftbottom, y_shift_leftbottom), 3.89 + 1.043, 1.055 * 2,
                                               angle=phi_out[i] * 180 / math.pi, linewidth=1, edgecolor='r', facecolor='none')
            warm_start_arrow = patches.Arrow(
                x_out[i], y_out[i], 0.25 * math.cos(phi_out[i]), 0.25 * math.sin(phi_out[i]), 0.2, edgecolor='r',)
            # ax.add_patch(warm_start_car)
            ax.add_patch(warm_start_arrow)
            # distance approach
            downx = 1.055 * math.cos(opt_phi_out[i] - math.pi / 2)
            downy = 1.055 * math.sin(opt_phi_out[i] - math.pi / 2)
            leftx = 1.043 * math.cos(opt_phi_out[i] - math.pi)
            lefty = 1.043 * math.sin(opt_phi_out[i] - math.pi)
            x_shift_leftbottom = opt_x_out[i] + downx + leftx
            y_shift_leftbottom = opt_y_out[i] + downy + lefty
            smoothing_car = patches.Rectangle((x_shift_leftbottom, y_shift_leftbottom), 3.89 + 1.043, 1.055 * 2,
                                              angle=opt_phi_out[i] * 180 / math.pi, linewidth=1, edgecolor='y', facecolor='none')
            smoothing_arrow = patches.Arrow(
                opt_x_out[i], opt_y_out[i], 0.25 * math.cos(opt_phi_out[i]), 0.25 * math.sin(opt_phi_out[i]), 0.2, edgecolor='y',)
            ax.add_patch(smoothing_car)
            ax.add_patch(smoothing_arrow)

        ax.plot(sx, sy, "s")
        ax.plot(ex, ey, "s")
        if scenario == "backward":
            left_boundary_x = [-13.6407054776, 0.0, 0.0515703622475]
            left_boundary_y = [0.0140634663703, 0.0, -5.15258191624]
            down_boundary_x = [0.0515703622475, 2.8237895441]
            down_boundary_y = [-5.15258191624, -5.15306980547]
            right_boundary_x = [2.8237895441, 2.7184833539, 16.3592013995]
            right_boundary_y = [-5.15306980547, -0.0398078878812, -0.011889513383]
            up_boundary_x = [16.3591910364, -13.6406951857]
            up_boundary_y = [5.60414234644, 5.61797800844]
            ax.plot(left_boundary_x, left_boundary_y, "k")
            ax.plot(down_boundary_x, down_boundary_y, "k")
            ax.plot(right_boundary_x, right_boundary_y, "k")
            ax.plot(up_boundary_x, up_boundary_y, "k")

        plt.axis('equal')

        # input plot
        fig2 = plt.figure(2)
        v_graph = fig2.add_subplot(411)
        v_graph.title.set_text('v')
        v_graph.plot(np.linspace(0, size[0], size[0]), v_out)
        v_graph.plot(np.linspace(0, size[0], size[0]), opt_v_out)
        a_graph = fig2.add_subplot(412)
        a_graph.title.set_text('a')
        a_graph.plot(np.linspace(0, size[0], size[0]), a_out)
        a_graph.plot(np.linspace(0, size[0], size[0]), opt_a_out)
        steer_graph = fig2.add_subplot(413)
        steer_graph.title.set_text('steering')
        steer_graph.plot(np.linspace(0, size[0], size[0]), steer_out)
        steer_graph.plot(np.linspace(0, size[0], size[0]), opt_steer_out)
        steer_graph = fig2.add_subplot(414)
        steer_graph.title.set_text('t')
        steer_graph.plot(np.linspace(0, size[0], size[0]), opt_time_out)
        # dual variables
        fig3 = plt.figure(3)
        dual_l_graph = fig3.add_subplot(211)
        dual_l_graph.title.set_text('dual_l')
        dual_l_graph.plot(np.linspace(0, size[0] * 6, size[0] * 6), opt_dual_l_out)
        dual_n_graph = fig3.add_subplot(212)
        dual_n_graph.title.set_text('dual_n')
        dual_n_graph.plot(np.linspace(0, size[0] * 16, size[0] * 16), opt_dual_n_out)
        plt.show()
        return True

    if not visualize_flag:
        if success:
            # load result
            OpenSpacePlanner.DistanceGetResult(x, y, phi, v, a, steer, opt_x,
                                               opt_y, opt_phi, opt_v, opt_a, opt_steer, opt_time,
                                               opt_dual_l, opt_dual_n, size,
                                               hybrid_time, dual_time, ipopt_time)
            for i in range(0, size[0]):
                x_out.append(float(x[i]))
                y_out.append(float(y[i]))
                phi_out.append(float(phi[i]))
                v_out.append(float(v[i]))
                a_out.append(float(a[i]))
                steer_out.append(float(steer[i]))
                opt_x_out.append(float(opt_x[i]))
                opt_y_out.append(float(opt_y[i]))
                opt_phi_out.append(float(opt_phi[i]))
                opt_v_out.append(float(opt_v[i]))
                opt_a_out.append(float(opt_a[i]))
                opt_steer_out.append(float(opt_steer[i]))
                opt_time_out.append(float(opt_time[i]))
            # check end_pose distacne
            end_pose_dist = math.sqrt((opt_x_out[-1] - ex)**2 + (opt_y_out[-1] - ey)**2)
            end_pose_heading = abs(opt_phi_out[-1] - ephi)
            reach_end_pose = (end_pose_dist <= 0.1 and end_pose_heading <= 0.17)
        else:
            end_pose_dist = 100.0
            end_pose_heading = 100.0
            reach_end_pose = 0
        return [success, end_pose_dist, end_pose_heading, reach_end_pose, opt_x_out, opt_y_out, opt_phi_out, opt_v_out, opt_a_out, opt_steer_out, opt_time_out,
                hybrid_time, dual_time, ipopt_time, planning_time]
    return False


if __name__ == '__main__':
    # visualize_flag = True
    # SmoothTrajectory(visualize_flag)

    visualize_flag = False
    planning_time_stats = []
    hybrid_time_stats = []
    dual_time_stats = []
    ipopt_time_stats = []
    end_pose_dist_stats = []
    end_pose_heading_stats = []

    test_count = 0
    success_count = 0
    for sx in np.arange(-10, 10, 1.0):
        for sy in np.arange(2, 4, 0.5):
            print("sx is " + str(sx) + " and sy is " + str(sy))
            test_count += 1
            result = SmoothTrajectory(visualize_flag, sx, sy)
            # if result[0] and result[3]:  # success cases only
            if result[0]:
                success_count += 1
                planning_time_stats.append(result[-1])
                ipopt_time_stats.append(result[-2][0])
                dual_time_stats.append(result[-3][0])
                hybrid_time_stats.append(result[-4][0])
                end_pose_dist_stats.append(result[1])
                end_pose_heading_stats.append(result[2])

    print("success rate is " + str(float(success_count) / float(test_count)))
    print("min is " + str(min(planning_time_stats)))
    print("max is " + str(max(planning_time_stats)))
    print("average is " + str(sum(planning_time_stats) / len(planning_time_stats)))
    print("max end_pose_dist difference is: " + str(max(end_pose_dist_stats)))
    print("min end_pose_dist difference is: " + str(min(end_pose_dist_stats)))
    print("average end_pose_dist difference is: " +
          str(sum(end_pose_dist_stats) / len(end_pose_dist_stats)))
    print("max end_pose_heading difference is: " + str(max(end_pose_heading_stats)))
    print("min end_pose_heading difference is: " + str(min(end_pose_heading_stats)))
    print("average end_pose_heading difference is: " +
          str(sum(end_pose_heading_stats) / len(end_pose_heading_stats)))

    module_timing = np.asarray([hybrid_time_stats, dual_time_stats, ipopt_time_stats])
    np.savetxt(result_file, module_timing, delimiter=",")

    print("average hybrid time(s): %4.4f, with max: %4.4f, min: %4.4f" % (
        sum(hybrid_time_stats) / len(hybrid_time_stats) / 1000.0, max(hybrid_time_stats) / 1000.0,
        min(hybrid_time_stats) / 1000.0))
    print("average dual time(s): %4.4f, with max: %4.4f, min: %4.4f" % (
        sum(dual_time_stats) / len(dual_time_stats) / 1000.0, max(dual_time_stats) / 1000.0,
        min(dual_time_stats) / 1000.0))
    print("average ipopt time(s): %4.4f, with max: %4.4f, min: %4.4f" % (
        sum(ipopt_time_stats) / len(ipopt_time_stats) / 1000.0, max(ipopt_time_stats) / 1000.0,
        min(ipopt_time_stats) / 1000.0))
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math

from ctypes import c_bool
from ctypes import c_double
from ctypes import c_int
from ctypes import c_ushort
from ctypes import c_void_p


lib = cdll.LoadLibrary(
    '/apollo/bazel-bin/modules/planning/open_space/tools/hybrid_a_star_wrapper_lib.so')

lib.CreatePlannerPtr.argtypes = []
lib.CreatePlannerPtr.restype = c_void_p
lib.CreateResultPtr.argtypes = []
lib.CreateResultPtr.restype = c_void_p
lib.CreateObstaclesPtr.argtypes = []
lib.CreateObstaclesPtr.restype = c_void_p
lib.AddVirtualObstacle.argtypes = [c_void_p, POINTER(c_double), POINTER(c_double), c_int]
lib.Plan.restype = c_bool
lib.Plan.argtypes = [c_void_p, c_void_p, c_void_p, c_double, c_double, c_double, c_double,
                     c_double, c_double, POINTER(c_double)]
lib.GetResult.argtypes = [c_void_p, POINTER(c_double), POINTER(c_double), POINTER(c_double),
                          POINTER(c_double), POINTER(c_double), POINTER(c_double), POINTER(c_ushort)]


class HybridAStarPlanner(object):
    def __init__(self):
        self.planner = lib.CreatePlannerPtr()
        self.obstacles = lib.CreateObstaclesPtr()
        self.result = lib.CreateResultPtr()

    def AddVirtualObstacle(self, obstacle_x, obstacle_y, vertice_num):
        lib.AddVirtualObstacle(self.obstacles, POINTER(c_double)(obstacle_x),
                               POINTER(c_double)(obstacle_y), (c_int)(vertice_num))

    def Plan(self, sx, sy, sphi, ex, ey, ephi, XYbounds):
        return lib.Plan(self.planner, self.obstacles, self.result, c_double(sx),
                        c_double(sy), c_double(sphi), c_double(ex), c_double(ey),
                        c_double(ephi), POINTER(c_double)(XYbounds))

    def GetResult(self, x, y, phi, v, a, steer, output_size):
        lib.GetResult(self.result, POINTER(c_double)(x), POINTER(c_double)(y),
                      POINTER(c_double)(phi), POINTER(c_double)(v), POINTER(c_double)(a),
                      POINTER(c_double)(steer), POINTER(c_ushort)(output_size))
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
import time

from matplotlib import animation
import matplotlib.patches as patches
import matplotlib.pyplot as plt
import numpy as np

from hybrid_a_star_python_interface import *


def HybridAStarPlan(visualize_flag):
    # initialze object
    HybridAStar = HybridAStarPlanner()

    # parameter(except max, min and car size is defined in proto)
    num_output_buffer = 100000
    sx = -8
    sy = 4
    sphi = 0.0

    scenario = "backward"
    # scenario = "parallel"

    if scenario == "backward":
        # for parking space 11543 in sunnyvale_with_two_offices
        left_boundary_x = (
            c_double * 3)(*[-13.6407054776, 0.0, 0.0515703622475])
        left_boundary_y = (
            c_double * 3)(*[0.0140634663703, 0.0, -5.15258191624])
        down_boundary_x = (c_double * 2)(*[0.0515703622475, 2.8237895441])
        down_boundary_y = (c_double * 2)(*[-5.15258191624, -5.15306980547])
        right_boundary_x = (
            c_double * 3)(*[2.8237895441, 2.7184833539, 16.3592013995])
        right_boundary_y = (
            c_double * 3)(*[-5.15306980547, -0.0398078878812, -0.011889513383])
        up_boundary_x = (c_double * 2)(*[16.3591910364, -13.6406951857])
        up_boundary_y = (c_double * 2)(*[5.60414234644, 5.61797800844])
        # obstacles(x, y, size)
        HybridAStar.AddVirtualObstacle(left_boundary_x, left_boundary_y, 3)
        HybridAStar.AddVirtualObstacle(
            down_boundary_x, down_boundary_y, 2)
        HybridAStar.AddVirtualObstacle(
            right_boundary_x, right_boundary_y, 3)
        HybridAStar.AddVirtualObstacle(
            up_boundary_x, up_boundary_y, 2)
        ex = 1.359
        ey = -3.86443643718
        ephi = 1.581
        XYbounds = [-13.6406951857, 16.3591910364, -
                    5.15258191624, 5.61797800844]

    x = (c_double * num_output_buffer)()
    y = (c_double * num_output_buffer)()
    phi = (c_double * num_output_buffer)()
    v = (c_double * num_output_buffer)()
    a = (c_double * num_output_buffer)()
    steer = (c_double * num_output_buffer)()
    size = (c_ushort * 1)()
    XYbounds_ctype = (c_double * 4)(*XYbounds)

    start = time.time()
    print("planning start")
    success = True
    if not HybridAStar.Plan(sx, sy, sphi, ex, ey, ephi, XYbounds_ctype):
        print("planning fail")
        success = False
    end = time.time()
    planning_time = end - start
    print("planning time is " + str(planning_time))

    # load result
    x_out = []
    y_out = []
    phi_out = []
    v_out = []
    a_out = []
    steer_out = []

    if visualize_flag and success:
        HybridAStar.GetResult(x, y, phi, v, a, steer, size)
        for i in range(0, size[0]):
            x_out.append(float(x[i]))
            y_out.append(float(y[i]))
            phi_out.append(float(phi[i]))
            v_out.append(float(v[i]))
            a_out.append(float(a[i]))
            steer_out.append(float(steer[i]))

        # plot
        fig1 = plt.figure(1)
        ax = fig1.add_subplot(111)
        for i in range(0, size[0]):
            downx = 1.055 * math.cos(phi_out[i] - math.pi / 2)
            downy = 1.055 * math.sin(phi_out[i] - math.pi / 2)
            leftx = 1.043 * math.cos(phi_out[i] - math.pi)
            lefty = 1.043 * math.sin(phi_out[i] - math.pi)
            x_shift_leftbottom = x_out[i] + downx + leftx
            y_shift_leftbottom = y_out[i] + downy + lefty
            car = patches.Rectangle((x_shift_leftbottom, y_shift_leftbottom), 3.89 + 1.043, 1.055*2,
                                    angle=phi_out[i] * 180 / math.pi, linewidth=1, edgecolor='r', facecolor='none')
            arrow = patches.Arrow(
                x_out[i], y_out[i], 0.25*math.cos(phi_out[i]), 0.25*math.sin(phi_out[i]), 0.2)
            ax.add_patch(car)
            ax.add_patch(arrow)
        ax.plot(sx, sy, "s")
        ax.plot(ex, ey, "s")
        if scenario == "backward":
            left_boundary_x = [-13.6407054776, 0.0, 0.0515703622475]
            left_boundary_y = [0.0140634663703, 0.0, -5.15258191624]
            down_boundary_x = [0.0515703622475, 2.8237895441]
            down_boundary_y = [-5.15258191624, -5.15306980547]
            right_boundary_x = [2.8237895441, 2.7184833539, 16.3592013995]
            right_boundary_y = [-5.15306980547, -0.0398078878812, -0.011889513383]
            up_boundary_x = [16.3591910364, -13.6406951857]
            up_boundary_y = [5.60414234644, 5.61797800844]
            ax.plot(left_boundary_x, left_boundary_y, "k")
            ax.plot(down_boundary_x, down_boundary_y, "k")
            ax.plot(right_boundary_x, right_boundary_y, "k")
            ax.plot(up_boundary_x, up_boundary_y, "k")

        plt.axis('equal')

        fig2 = plt.figure(2)
        v_graph = fig2.add_subplot(311)
        v_graph.title.set_text('v')
        v_graph.plot(np.linspace(0, size[0], size[0]), v_out)
        a_graph = fig2.add_subplot(312)
        a_graph.title.set_text('a')
        a_graph.plot(np.linspace(0, size[0], size[0]), a_out)
        steer_graph = fig2.add_subplot(313)
        steer_graph.title.set_text('steering')
        steer_graph.plot(np.linspace(0, size[0], size[0]), steer_out)
        plt.show()
    if not visualize_flag:
        if success:
            HybridAStar.GetResult(x, y, phi, v, a, steer, size)
            for i in range(0, size[0]):
                x_out.append(float(x[i]))
                y_out.append(float(y[i]))
                phi_out.append(float(phi[i]))
                v_out.append(float(v[i]))
                a_out.append(float(a[i]))
                steer_out.append(float(steer[i]))
        return success, x_out, y_out, phi_out, v_out, a_out, steer_out, planning_time


if __name__ == '__main__':
    visualize_flag = True
    HybridAStarPlan(visualize_flag)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import ctypes
import math
from ctypes import cdll, c_ushort, c_int, c_char_p, c_double, POINTER

lib = cdll.LoadLibrary(
    '/apollo/bazel-bin/modules/planning/open_space/tools/open_space_roi_wrapper_lib.so')


class open_space_roi(object):
    def __init__(self):
        self.open_space_roi_test = lib.CreateROITestPtr()

    def ROITest(self, lane_id, parking_id,
                unrotated_roi_boundary_x, unrotated_roi_boundary_y, roi_boundary_x, roi_boundary_y,
                parking_spot_x, parking_spot_y, end_pose,
                xy_boundary, origin_pose):
        return lib.ROITest(self.open_space_roi_test, (c_char_p)(lane_id), (c_char_p)(parking_id),
                           POINTER(c_double)(unrotated_roi_boundary_x), POINTER(
                               c_double)(unrotated_roi_boundary_y),
                           POINTER(c_double)(roi_boundary_x), POINTER(
                               c_double)(roi_boundary_y), POINTER(c_double)(
            parking_spot_x), POINTER(c_double)(
            parking_spot_y), POINTER(c_double)(end_pose),
            POINTER(c_double)(xy_boundary), POINTER(c_double)(origin_pose))
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


# @file to run it, change the modules/common/configs/config_gflags.cc to use sunnyvale_with_two_offices


from open_space_roi_interface import *
import matplotlib.pyplot as plt

# initialize object
open_space_roi = open_space_roi()


lane_id = "11564dup1_1_-1"
parking_id = "11543"
num_output_buffer = 50
unrotated_roi_boundary_x = (c_double * num_output_buffer)()
roi_boundary_x = (c_double * num_output_buffer)()
parking_spot_x = (c_double * num_output_buffer)()
unrotated_roi_boundary_y = (c_double * num_output_buffer)()
roi_boundary_y = (c_double * num_output_buffer)()
parking_spot_y = (c_double * num_output_buffer)()
end_pose = (c_double * num_output_buffer)()
xy_boundary = (c_double * num_output_buffer)()
origin_pose = (c_double * num_output_buffer)()

if not open_space_roi.ROITest(lane_id, parking_id,
                              unrotated_roi_boundary_x, unrotated_roi_boundary_y, roi_boundary_x, roi_boundary_y,
                              parking_spot_x, parking_spot_y, end_pose,
                              xy_boundary, origin_pose):
    print("open_space_roi fail")
result_unrotated_roi_boundary_x = []
result_unrotated_roi_boundary_y = []
result_roi_boundary_x = []
result_roi_boundary_y = []
result_parking_spot_x = []
result_parking_spot_y = []
result_end_pose = []
result_xy_boundary = []
result_origin_pose = []

print("vertices of obstacles")
for i in range(0, 10):
    result_unrotated_roi_boundary_x.append(float(unrotated_roi_boundary_x[i]))
    result_unrotated_roi_boundary_y.append(float(unrotated_roi_boundary_y[i]))
    result_roi_boundary_x.append(float(roi_boundary_x[i]))
    result_roi_boundary_y.append(float(roi_boundary_y[i]))
    print(str(float(roi_boundary_x[i])))
    print(str(float(roi_boundary_y[i])))
print("parking spot")
for i in range(0, 4):
    result_parking_spot_x.append(float(parking_spot_x[i]))
    result_parking_spot_y.append(float(parking_spot_y[i]))
print("end_pose in x,y,phi,v")
for i in range(0, 4):
    print(str(float(end_pose[i])))
print("xy_boundary in xmin xmax ymin ymax")
for i in range(0, 4):
    print(str(float(xy_boundary[i])))
print("origin_pose")
for i in range(0, 2):
    print(str(float(origin_pose[i])))

fig = plt.figure()
ax1 = fig.add_subplot(211)
ax1.scatter(result_unrotated_roi_boundary_x, result_unrotated_roi_boundary_y)
ax1.scatter(result_parking_spot_x, result_parking_spot_y)
ax2 = fig.add_subplot(212)
ax2.scatter(result_roi_boundary_x, result_roi_boundary_y)
plt.gca().set_aspect('equal', adjustable='box')
plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import secure_upgrade_export as sec_api
import os
import sys
sys.path.append('/home/caros/secure_upgrade/python')

root_config_path = "/home/caros/secure_upgrade/config/secure_config.json"
ret = sec_api.init_secure_upgrade(root_config_path)
if ret is True:
    print('Security environment init successfully!')
else:
    print('Security environment init failed!')
    exit(1)

homedir = os.environ['HOME']
release_tgz = homedir + '/.cache/apollo_release.tar.gz'
sec_release_tgz = homedir + '/.cache/sec_apollo_release.tar.gz'
package_token = homedir + '/.cache/package_token'

ret = sec_api.sec_upgrade_get_package(
    release_tgz, sec_release_tgz, package_token)
if ret is True:
    print('Security package generated successfully!')
else:
    print('Security package generated failed!')
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import os
import requests
import sys

from configparser import ConfigParser
import secure_upgrade_export as sec_api
import urllib3

from modules.data.proto.static_info_pb2 import VehicleInfo
import modules.tools.common.proto_utils as proto_utils


sys.path.append('/home/caros/secure_upgrade/python')

root_config_path = '/home/caros/secure_upgrade/config/secure_config.json'
ret = sec_api.init_secure_upgrade(root_config_path)
if ret is False:
    print('Failed to initialize security environment!')
    sys.exit(1)


def query():
    vehicle_info = VehicleInfo()
    VEHICLE_INFO_FILE = os.path.join(
        os.path.dirname(__file__), 'vehicle_info.pb.txt')
    try:
        proto_utils.get_pb_from_text_file(VEHICLE_INFO_FILE, vehicle_info)
    except IOError:
        print('vehicle_info.pb.txt cannot be open file.')
        sys.exit(1)

    # Setup server url
    config = ConfigParser()
    CONFIG_FILE = os.path.join(os.path.dirname(__file__), 'config.ini')
    config.read(CONFIG_FILE)
    ip = config.get('Host', 'ip')
    port = config.get('Host', 'port')
    url = 'https://' + ip + ':' + port + '/query'

    # Generate device token
    ret = sec_api.sec_upgrade_get_device_token()
    if ret[0] is False:
        print('Failed to get device token.')
        sys.exit(1)
    dev_token = ret[1]

    # setup car info
    brand = VehicleInfo.Brand.Name(vehicle_info.brand)
    model = VehicleInfo.Model.Name(vehicle_info.model)
    vin = vehicle_info.vehicle_config.vehicle_id.vin
    META_FILE = '/apollo/meta.ini'
    config.read(META_FILE)
    car_info = {
        "car_type": brand + "." + model,
        "tag": config.get('Release', 'tag'),
        "vin": vin,
        "token": dev_token
    }

    urllib3.disable_warnings()
    CERT_FILE = os.path.join(os.path.dirname(__file__), 'ota.cert')
    r = requests.post(url, json=car_info, verify=CERT_FILE)
    if r.status_code == 200:
        auth_token = r.json().get("auth_token")
        if auth_token == "":
            print('Cannot get authorize token!')
            sys.exit(1)
        else:
            token_file_name = os.environ['HOME'] + \
                '/.cache/apollo_update/auth_token'
            apollo_update = os.path.dirname(token_file_name)
            if not os.path.exists(apollo_update):
                os.makedirs(apollo_update)
            with open(token_file_name, 'w') as token_file:
                token_file.write(auth_token)
        tag = r.json().get("tag")
        print(tag)
        sys.exit(0)
    elif r.status_code == 204:
        print('Release is up to date.')
        sys.exit(0)
    elif r.status_code == 400:
        print('Invalid car type.')
    else:
        print('Cannot connect to server.')

    sys.exit(1)


if __name__ == '__main__':
    query()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import requests
import os
import sys
import urllib3
from configparser import ConfigParser
from modules.data.proto.static_info_pb2 import VehicleInfo
import modules.tools.common.proto_utils as proto_utils


def update():
    # setup server url
    config = ConfigParser()
    CONFIG_FILE = os.path.join(os.path.dirname(__file__), 'config.ini')
    config.read(CONFIG_FILE)
    ip = config.get('Host', 'ip')
    port = config.get('Host', 'port')
    url = 'https://' + ip + ':' + port + '/update'

    # setup car info
    vehicle_info = VehicleInfo()
    VEHICLE_INFO_FILE = os.path.join(
        os.path.dirname(__file__), 'vehicle_info.pb.txt')
    try:
        proto_utils.get_pb_from_text_file(VEHICLE_INFO_FILE, vehicle_info)
    except IOError:
        print("vehicle_info.pb.txt cannot be open file.")
        exit()

    brand = VehicleInfo.Brand.Name(vehicle_info.brand)
    model = VehicleInfo.Model.Name(vehicle_info.model)
    vin = vehicle_info.vehicle_config.vehicle_id.vin
    car_info = {
        "car_type": brand + "." + model,
        "tag": sys.argv[1],
        "vin": vin,
    }

    urllib3.disable_warnings()
    CERT_FILE = os.path.join(os.path.dirname(__file__), 'ota.cert')
    r = requests.post(url, json=car_info, verify=CERT_FILE)
    if r.status_code == 200:
        print("Update successfully.")
        sys.exit(0)
    elif r.status_code == 400:
        print("Invalid Request.")
    else:
        print("Cannot connect to server.")
    sys.exit(1)


if __name__ == "__main__":
    update()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""OTA verify client"""

import os
import requests
import sys

from configparser import ConfigParser
import secure_upgrade_export as sec_api

from modules.data.proto.static_info_pb2 import VehicleInfo
import modules.tools.common.proto_utils as proto_utils


sys.path.append('/home/caros/secure_upgrade/python')

root_config_path = "/home/caros/secure_upgrade/config/secure_config.json"
ret = sec_api.init_secure_upgrade(root_config_path)
if ret is True:
    print('Security environment init successfully!')
else:
    print('Security environment init failed!')
    sys.exit(1)


def verify():
    # Generate orig update package
    token_file_name = os.environ['HOME'] + '/.cache/apollo_update/auth_token'
    with open(token_file_name, 'r') as token_file:
        auth_token = token_file.read()
    sec_package = os.environ['HOME'] + '/.cache/sec_apollo_release.tar.gz'
    orig_package = os.environ['HOME'] + '/.cache/apollo_release.tar.gz'
    ret = sec_api.sec_upgrade_verify_package(auth_token, sec_package,
                                             orig_package)
    if ret is True:
        print('Verify package successfully!')
        sys.exit(0)
    else:
        print('Verify package failed!!!')
        sys.exit(1)


if __name__ == "__main__":
    verify()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
this module creates a node and fake prediction data based
on json configurations
"""
import argparse
import math
import time

import numpy
import simplejson
from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time

from modules.prediction.proto.prediction_obstacle_pb2 import PredictionObstacles


def prediction_publisher(prediction_channel, rate):
    """publisher"""
    cyber.init()
    node = cyber.Node("prediction")
    writer = node.create_writer(prediction_channel, PredictionObstacles)
    sleep_time = 1.0 / rate
    seq_num = 1
    while not cyber.is_shutdown():
        prediction = PredictionObstacles()
        prediction.header.sequence_num = seq_num
        prediction.header.timestamp_sec = cyber_time.Time.now().to_sec()
        prediction.header.module_name = "prediction"
        print(str(prediction))
        writer.write(prediction)
        seq_num += 1
        time.sleep(sleep_time)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="create empty prediction message",
                                     prog="replay_prediction.py")
    parser.add_argument("-c", "--channel", action="store", type=str, default="/apollo/prediction",
                        help="set the prediction channel")
    parser.add_argument("-r", "--rate", action="store", type=int, default=10,
                        help="set the prediction channel publish time duration")
    args = parser.parse_args()
    prediction_publisher(args.channel, args.rate)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
print received prediction message
"""
import argparse
import math
import sys

import numpy

import modules.tools.common.proto_utils as proto_utils
from modules.prediction.proto.prediction_obstacle_pb2 import PredictionObstacles


def distance(p1, p2):
    """distance between two trajectory points"""
    return math.sqrt((p1.y - p2.y)**2 + (p1.x - p2.x)**2)


def get_trajectory_length(trajectory):
    """get_trajectory_length"""
    total = 0.0
    for i in range(1, len(trajectory.trajectory_point)):
        total += distance(trajectory.trajectory_point[i - 1].path_point,
                          trajectory.trajectory_point[i].path_point)
    return total


def extend_prediction(prediction, min_length, min_time):
    """extend prediction"""
    for obstacle in prediction.prediction_obstacle:
        i = 0
        for trajectory in obstacle.trajectory:
            points = trajectory.trajectory_point
            point_num = len(points)
            trajectory_length = get_trajectory_length(trajectory)
            sys.stderr.write("obstacle_id :%s trajectory_id: %s length: %s\n" % (
                obstacle.perception_obstacle.id, i, trajectory_length))
            i += 1
            if trajectory_length < min_length:
                second_last = points[point_num - 2]
                last_point = points[point_num - 1]
                x_diff = last_point.path_point.x - second_last.path_point.x
                y_diff = last_point.path_point.y - second_last.path_point.y
                t_diff = last_point.path_point.theta - second_last.path_point.theta
                delta_diff = math.sqrt(x_diff ** 2 + y_diff ** 2)
                cur_len = trajectory_length
                while cur_len < min_length and abs(cur_len) > 0.000001:
                    last_point.path_point.x += x_diff
                    last_point.path_point.y += y_diff
                    last_point.path_point.theta += t_diff
                    p = points.add()
                    p.CopyFrom(last_point)
                    last_point = p
                    cur_len += delta_diff
    return prediction


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="extend prediction trajectory")
    parser.add_argument("prediction", action="store",
                        type=str, help="set the prediction file")
    parser.add_argument("-p", "--period", action="store", type=float, default=10.0,
                        help="set the prediction period")
    parser.add_argument("-d", "--distance", action="store", type=float, default=70.0,
                        help="set the prediction distance")
    args = parser.parse_args()
    prediction_data = proto_utils.get_pb_from_file(
        args.prediction, PredictionObstacles())
    extended_prediction = extend_prediction(
        prediction_data, args.distance, args.period)
    print(extended_prediction)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
print received perception message
"""
import argparse
from cyber.python.cyber_py3 import cyber

from modules.perception.proto.perception_obstacle_pb2 import PerceptionObstacles


def receiver(data):
    """receiver"""
    print(data)


def perception_receiver(perception_channel):
    """publisher"""
    cyber.init()
    node = cyber.Node("perception")
    node.create_reader(perception_channel, PerceptionObstacles, receiver)
    node.spin()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="create fake perception obstacles",
                                     prog="print_perception.py")
    parser.add_argument("-c", "--channel", action="store", type=str,
                        default="/apollo/perception/obstacles",
                        help="set the perception channel")

    args = parser.parse_args()
    perception_receiver(args.channel)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
This module creates a node and fake perception data based
on json configurations
"""

import argparse
import math
import time

import simplejson

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time
from modules.common.proto.geometry_pb2 import Point3D
from modules.perception.proto.perception_obstacle_pb2 import PerceptionObstacle
from modules.perception.proto.perception_obstacle_pb2 import PerceptionObstacles


_s_seq_num = 0
_s_delta_t = 0.1
_s_epsilon = 1e-8


def get_seq_num():
    """
    Return the sequence number
    """
    global _s_seq_num
    _s_seq_num += 1
    return _s_seq_num


def get_velocity(theta, speed):
    """
    Get velocity from theta and speed
    """
    point = Point3D()
    point.x = math.cos(theta) * speed
    point.y = math.sin(theta) * speed
    point.z = 0.0
    return point


def generate_polygon(point, heading, length, width):
    """
    Generate polygon
    """
    points = []
    half_l = length / 2.0
    half_w = width / 2.0
    sin_h = math.sin(heading)
    cos_h = math.cos(heading)
    vectors = [(half_l * cos_h - half_w * sin_h,
                half_l * sin_h + half_w * cos_h),
               (-half_l * cos_h - half_w * sin_h,
                - half_l * sin_h + half_w * cos_h),
               (-half_l * cos_h + half_w * sin_h,
                - half_l * sin_h - half_w * cos_h),
               (half_l * cos_h + half_w * sin_h,
                half_l * sin_h - half_w * cos_h)]
    for x, y in vectors:
        p = Point3D()
        p.x = point.x + x
        p.y = point.y + y
        p.z = point.z
        points.append(p)

    return points


def load_descrptions(files):
    """
    Load description files
    """
    objects = []
    for file in files:
        with open(file, 'r') as fp:
            obstacles = simplejson.loads(fp.read())
            # Multiple obstacle in one file saves as a list[obstacles]
            if isinstance(obstacles, list):
                for obstacle in obstacles:
                    trace = obstacle.get('trace', [])
                    for i in range(1, len(trace)):
                        if same_point(trace[i], trace[i - 1]):
                            print('same trace point found in obstacle: %s' % obstacle["id"])
                            return None
                    objects.append(obstacle)
            else:  # Default case. handles only one obstacle
                obstacle = obstacles
                trace = obstacle.get('trace', [])
                for i in range(1, len(trace)):
                    if same_point(trace[i], trace[i - 1]):
                        print('same trace point found in obstacle: %s' % obstacle["id"])
                        return None
                objects.append(obstacle)

    return objects


def get_point(a, b, ratio):
    """
    Get point from a to b with ratio
    """
    p = Point3D()
    p.x = a[0] + ratio * (b[0] - a[0])
    p.y = a[1] + ratio * (b[1] - a[1])
    p.z = a[2] + ratio * (b[2] - a[2])
    return p


def init_perception(description):
    """
    Create perception from description
    """
    perception = PerceptionObstacle()
    perception.id = description["id"]
    perception.position.x = description["position"][0]
    perception.position.y = description["position"][1]
    perception.position.z = description["position"][2]
    perception.theta = description["theta"]
    perception.velocity.CopyFrom(get_velocity(
        description["theta"], description["speed"]))
    perception.length = description["length"]
    perception.width = description["width"]
    perception.height = description["height"]
    perception.polygon_point.extend(generate_polygon(perception.position,
                                                     perception.theta,
                                                     perception.length,
                                                     perception.width))
    perception.tracking_time = description["tracking_time"]
    perception.type = PerceptionObstacle.Type.Value(description["type"])
    perception.timestamp = cyber_time.Time.now().to_sec()

    return perception


def same_point(a, b):
    """
    Test if a and b are the same point
    """
    return math.fabs(b[0] - a[0]) < _s_epsilon and \
        math.fabs(b[1] - a[1]) < _s_epsilon


def inner_product(a, b):
    """
    Get the a, b inner product
    """
    return a[0] * b[0] + a[1] * b[1] + a[2] * b[2]


def cross_product(a, b):
    """
    Cross product
    """
    return a[0] * b[1] - a[1] * b[0]


def distance(a, b):
    """
    Return distance between a and b
    """
    return math.sqrt((b[0] - a[0])**2 + (b[1] - a[1])**2 + (b[2] - a[2])**2)


def is_within(a, b, c):
    """
    Check if c is in [a, b]
    """
    if b < a:
        b, a = a, b
    return a - _s_epsilon < c < b + _s_epsilon


def on_segment(a, b, c):
    """
    Test if c is in line segment a-b
    """
    ab = (b[0] - a[0], b[1] - a[1], b[2] - a[2])
    ac = (c[0] - a[0], c[1] - a[1], c[2] - a[2])
    if math.fabs(cross_product(ac, ab)) > _s_epsilon:
        return False
    return is_within(a[0], b[0], c[0]) and is_within(a[1], b[1], c[1]) \
        and is_within(a[2], b[2], c[2])


def linear_project_perception(description, prev_perception):
    """
    Get perception from linear projection of description
    """
    perception = PerceptionObstacle()
    perception = prev_perception
    perception.timestamp = cyber_time.Time.now().to_sec()
    if "trace" not in description:
        return perception
    trace = description["trace"]
    prev_point = (prev_perception.position.x, prev_perception.position.y,
                  prev_perception.position.z)
    delta_s = description["speed"] * _s_delta_t
    for i in range(1, len(trace)):
        if on_segment(trace[i - 1], trace[i], prev_point):
            dist = distance(trace[i - 1], trace[i])
            delta_s += distance(trace[i - 1], prev_point)
            while dist < delta_s:
                delta_s -= dist
                i += 1
                if i < len(trace):
                    dist = distance(trace[i - 1], trace[i])
                else:
                    return init_perception(description)
            ratio = delta_s / dist
            perception.position.CopyFrom(
                get_point(trace[i - 1], trace[i], ratio))
            perception.theta = math.atan2(trace[i][1] - trace[i - 1][1],
                                          trace[i][0] - trace[i - 1][0])

            perception.ClearField("polygon_point")
            perception.polygon_point.extend(generate_polygon(perception.position, perception.theta,
                                                             perception.length, perception.width))
            return perception

    return perception


def generate_perception(perception_description, prev_perception):
    """
    Generate perception data
    """
    perceptions = PerceptionObstacles()
    perceptions.header.sequence_num = get_seq_num()
    perceptions.header.module_name = "perception"
    perceptions.header.timestamp_sec = cyber_time.Time.now().to_sec()
    if not perception_description:
        return perceptions
    if prev_perception is None:
        for description in perception_description:
            p = perceptions.perception_obstacle.add()
            p.CopyFrom(init_perception(description))
        return perceptions
    # Linear projection
    description_dict = {desc["id"]: desc for desc in perception_description}
    for obstacle in prev_perception.perception_obstacle:
        description = description_dict[obstacle.id]
        next_obstacle = linear_project_perception(description, obstacle)
        perceptions.perception_obstacle.add().CopyFrom(next_obstacle)
    return perceptions


def perception_publisher(perception_channel, files, period):
    """
    Publisher
    """
    cyber.init()
    node = cyber.Node("perception")
    writer = node.create_writer(perception_channel, PerceptionObstacles)
    perception_description = load_descrptions(files)
    sleep_time = int(1.0 / period)  # 10Hz
    global _s_delta_t
    _s_delta_t = period
    perception = None
    while not cyber.is_shutdown():
        perception = generate_perception(perception_description, perception)
        print(str(perception))
        writer.write(perception)
        time.sleep(sleep_time)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="create fake perception obstacles",
                                     prog="replay_perception.py")
    parser.add_argument("files", action="store", type=str, nargs="*",
                        help="obstacle description files")
    parser.add_argument("-c", "--channel", action="store", type=str,
                        default="/apollo/perception/obstacles",
                        help="set the perception channel")
    parser.add_argument("-p", "--period", action="store", type=float, default=0.1,
                        help="set the perception channel publish time duration")
    args = parser.parse_args()

    perception_publisher(args.channel, args.files, args.period)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys

import matplotlib.pyplot as plt

import modules.tools.common.proto_utils as proto_utils
from modules.tools.planning.plot_trajectory import mkz_polygon
from modules.planning.proto.planning_pb2 import ADCTrajectory
from modules.localization.proto.localization_pb2 import LocalizationEstimate


def plot_trajectory(planning_pb, ax):
    points_x = []
    points_y = []
    points_t = []
    base_time_sec = planning_pb.header.timestamp_sec
    for trajectory_point in planning_pb.adc_trajectory_point:
        points_x.append(trajectory_point.x)
        points_y.append(trajectory_point.y)
        points_t.append(base_time_sec + trajectory_point.relative_time)
    ax.plot(points_x, points_y, "r.")


def find_closest_t(points_t, current_t):
    if len(points_t) == 0:
        return -1
    if len(points_t) == 1:
        return points_t[0]
    if len(points_t) == 2:
        if abs(points_t[0] - current_t) < abs(points_t[1] - current_t):
            return points_t[0]
        else:
            return points_t[1]
    if points_t[len(points_t) // 2] > current_t:
        return find_closest_t(points_t[0:len(points_t) // 2], current_t)
    elif points_t[len(points_t) // 2] < current_t:
        return find_closest_t(points_t[len(points_t) // 2 + 1:], current_t)
    else:
        return current_t


def find_closest_traj_point(planning_pb, current_t):
    points_x = []
    points_y = []
    points_t = []
    base_time_sec = planning_pb.header.timestamp_sec
    for trajectory_point in planning_pb.adc_trajectory_point:
        points_x.append(trajectory_point.x)
        points_y.append(trajectory_point.y)
        points_t.append(base_time_sec + trajectory_point.relative_time)

    matched_t = find_closest_t(points_t, current_t)
    idx = points_t.index(matched_t)
    return planning_pb.adc_trajectory_point[idx]


def plot_traj_point(planning_pb, traj_point, ax):
    matched_t = planning_pb.header.timestamp_sec \
        + traj_point.relative_time
    ax.plot([traj_point.x], [traj_point.y], "bs")
    content = "t = " + str(matched_t) + "\n"
    content += "speed = " + str(traj_point.speed) + "\n"
    content += "acc = " + str(traj_point.acceleration_s)
    lxy = [-80, -80]
    ax.annotate(
        content,
        xy=(traj_point.x, traj_point.y),
        xytext=lxy,
        textcoords='offset points',
        ha='right',
        va='top',
        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.3),
        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'),
        alpha=0.8)


def plot_vehicle(localization_pb, ax):
    loc_x = [localization_pb.pose.position.x]
    loc_y = [localization_pb.pose.position.y]
    current_t = localization_pb.header.timestamp_sec
    ax.plot(loc_x, loc_y, "bo")
    position = []
    position.append(localization_pb.pose.position.x)
    position.append(localization_pb.pose.position.y)
    position.append(localization_pb.pose.position.z)

    mkz_polygon.plot(position, localization_pb.pose.heading, ax)
    content = "t = " + str(current_t) + "\n"
    content += "speed @y = " + \
        str(localization_pb.pose.linear_velocity.y) + "\n"
    content += "acc @y = " + \
        str(localization_pb.pose.linear_acceleration_vrf.y)
    lxy = [-80, 80]
    ax.annotate(
        content,
        xy=(loc_x[0], loc_y[0]),
        xytext=lxy,
        textcoords='offset points',
        ha='left',
        va='top',
        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.3),
        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'),
        alpha=0.8)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("usage: %s <planning.pb.txt> <localization.pb.txt>" % sys.argv[0])
        sys.exit(0)

    planning_pb_file = sys.argv[1]
    localization_pb_file = sys.argv[2]
    planning_pb = proto_utils.get_pb_from_text_file(
        planning_pb_file, ADCTrajectory())
    localization_pb = proto_utils.get_pb_from_text_file(
        localization_pb_file, LocalizationEstimate())

    plot_trajectory(planning_pb, plt)
    plot_vehicle(localization_pb, plt)

    current_t = localization_pb.header.timestamp_sec
    trajectory_point = find_closest_traj_point(planning_pb, current_t)
    plot_traj_point(planning_pb, trajectory_point, plt)

    plt.axis('equal')
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math


def get(position, heading):

    front_edge_to_center = 3.89
    back_edge_to_center = 1.043
    left_edge_to_center = 1.055
    right_edge_to_center = 1.055

    cos_h = math.cos(heading)
    sin_h = math.sin(heading)
    #  (p3)  -------- (p0)
    #        | o     |
    #   (p2) -------- (p1)
    p0_x, p0_y = front_edge_to_center, left_edge_to_center
    p1_x, p1_y = front_edge_to_center, -right_edge_to_center
    p2_x, p2_y = -back_edge_to_center, -left_edge_to_center
    p3_x, p3_y = -back_edge_to_center, right_edge_to_center

    p0_x, p0_y = p0_x * cos_h - p0_y * sin_h, p0_x * sin_h + p0_y * cos_h
    p1_x, p1_y = p1_x * cos_h - p1_y * sin_h, p1_x * sin_h + p1_y * cos_h
    p2_x, p2_y = p2_x * cos_h - p2_y * sin_h, p2_x * sin_h + p2_y * cos_h
    p3_x, p3_y = p3_x * cos_h - p3_y * sin_h, p3_x * sin_h + p3_y * cos_h

    [x, y, z] = position
    polygon = []
    polygon.append([p0_x + x, p0_y + y, 0])
    polygon.append([p1_x + x, p1_y + y, 0])
    polygon.append([p2_x + x, p2_y + y, 0])
    polygon.append([p3_x + x, p3_y + y, 0])
    return polygon


def plot(position, quaternion, ax):
    polygon = get(position, quaternion)
    px = []
    py = []
    for point in polygon:
        px.append(point[0])
        py.append(point[1])
    point = polygon[0]
    px.append(point[0])
    py.append(point[1])
    ax.plot(px, py, "g-")
    ax.plot([position[0]], [position[1]], 'go')
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import gflags
from cyber.python.cyber_py3 import cyber
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from modules.control.proto import control_cmd_pb2
BRAKE_LINE_DATA = []
TROTTLE_LINE_DATA = []
STEERING_LINE_DATA = []

FLAGS = gflags.FLAGS
gflags.DEFINE_integer("data_length", 500, "Control plot data length")


def callback(control_cmd_pb):
    global STEERING_LINE_DATA
    global TROTTLE_LINE_DATA, BRAKE_LINE_DATA

    STEERING_LINE_DATA.append(control_cmd_pb.steering_target)
    if len(STEERING_LINE_DATA) > FLAGS.data_length:
        STEERING_LINE_DATA = STEERING_LINE_DATA[-FLAGS.data_length:]

    BRAKE_LINE_DATA.append(control_cmd_pb.brake)
    if len(BRAKE_LINE_DATA) > FLAGS.data_length:
        BRAKE_LINE_DATA = BRAKE_LINE_DATA[-FLAGS.data_length:]

    TROTTLE_LINE_DATA.append(control_cmd_pb.throttle)
    if len(TROTTLE_LINE_DATA) > FLAGS.data_length:
        TROTTLE_LINE_DATA = TROTTLE_LINE_DATA[-FLAGS.data_length:]


def listener():
    cyber.init()
    test_node = cyber.Node("control_listener")
    test_node.create_reader("/apollo/control",
                            control_cmd_pb2.ControlCommand, callback)
    test_node.spin()
    cyber.shutdown()


def compensate(data_list):
    comp_data = [0] * FLAGS.data_length
    comp_data.extend(data_list)
    if len(comp_data) > FLAGS.data_length:
        comp_data = comp_data[-FLAGS.data_length:]
    return comp_data


def update(frame_number):
    brake_data = compensate(BRAKE_LINE_DATA)
    brake_line.set_ydata(brake_data)

    throttle_data = compensate(TROTTLE_LINE_DATA)
    throttle_line.set_ydata(throttle_data)

    steering_data = compensate(STEERING_LINE_DATA)
    steering_line.set_ydata(steering_data)

    brake_text.set_text('brake = %.1f' % brake_data[-1])
    throttle_text.set_text('throttle = %.1f' % throttle_data[-1])
    steering_text.set_text('steering = %.1f' % steering_data[-1])


if __name__ == '__main__':
    argv = FLAGS(sys.argv)
    listener()
    fig, ax = plt.subplots()
    X = range(FLAGS.data_length)
    Xs = [i * -1 for i in X]
    Xs.sort()
    steering_line, = ax.plot(
        Xs, [0] * FLAGS.data_length, 'b', lw=3, alpha=0.5, label='steering')
    throttle_line, = ax.plot(
        Xs, [0] * FLAGS.data_length, 'g', lw=3, alpha=0.5, label='throttle')
    brake_line, = ax.plot(
        Xs, [0] * FLAGS.data_length, 'r', lw=3, alpha=0.5, label='brake')
    brake_text = ax.text(0.75, 0.85, '', transform=ax.transAxes)
    throttle_text = ax.text(0.75, 0.90, '', transform=ax.transAxes)
    steering_text = ax.text(0.75, 0.95, '', transform=ax.transAxes)
    ani = animation.FuncAnimation(fig, update, interval=100)
    ax.set_ylim(-100, 120)
    ax.set_xlim(-1 * FLAGS.data_length, 10)
    ax.legend(loc="upper left")
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""Real Time ACC Calculate Test Tool Based on Speed"""

import argparse
import datetime
import os
import sys

from cyber.python.cyber_py3 import cyber
from modules.canbus.proto import chassis_pb2
from modules.localization.proto import localization_pb2


SmoothParam = 9


class RealTimeTest(object):

    def __init__(self):
        self.last_t = None
        self.last_speed = None
        self.last_acc = None
        self.acc = None
        self.accs = []
        self.buff = []
        self.count = 0
        self.acclimit = 0

    def chassis_callback(self, chassis_pb2):
        """Calculate ACC from Chassis Speed"""
        speedmps = chassis_pb2.speed_mps
        t = chassis_pb2.header.timestamp_sec
        #speedkmh = speedmps * 3.6

        self.buff.append(speedmps)
        if len(self.buff) < SmoothParam:
            return
        if self.last_t is not None:
            self.count += 1
            deltt = t - self.last_t
            deltv = sum(self.buff) / len(self.buff) - self.last_speed
            if deltt <= 1e-10:
                deltt = 0.000000000001
                print("delt=0 ", t, ",", self.last_t)
            self.acc = deltv / deltt

            self.accs.append(self.acc)
            if abs(self.acc) > self.acclimit:
                print(t, "\t", (sum(self.buff) / len(self.buff)) * 3.6, "\t",
                      self.acc, "\t", self.count, "\t", self.acclimit)
        self.last_acc = self.acc
        self.last_t = t
        self.last_speed = sum(self.buff) / len(self.buff)
        self.buff = []


if __name__ == '__main__':
    """Main function"""
    parser = argparse.ArgumentParser(
        description="Test car realtime status.",
        prog="RealTimeTest.py",
        usage="python realtime_test.py")
    parser.add_argument(
        "--acc",
        type=int,
        required=False,
        default=2,
        help="Acc limit default must > 0")
    args = parser.parse_args()
    if args.acc < 0:
        print("acc must larger than 0")
    cyber.init()
    rttest = RealTimeTest()
    rttest.acclimit = args.acc
    cyber_node = cyber.Node("RealTimeTest")
    cyber_node.create_reader("/apollo/canbus/chassis",
                             chassis_pb2.Chassis, rttest.chassis_callback)
    cyber_node.spin()
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
from modules.tools.plot_planning.record_reader import RecordItemReader


class ChassisSpeed:

    def __init__(self):
        self.timestamp_list = []
        self.speed_list = []

    def add(self, chassis):
        timestamp_sec = chassis.header.timestamp_sec
        speed_mps = chassis.speed_mps

        self.timestamp_list.append(timestamp_sec)
        self.speed_list.append(speed_mps)

    def get_speed_list(self):
        return self.speed_list

    def get_timestamp_list(self):
        return self.timestamp_list

    def get_lastest_speed(self):
        if len(self.speed_list) > 0:
            return self.speed_list[-1]
        else:
            return None

    def get_lastest_timestamp(self):
        if len(self.timestamp_list) > 0:
            return self.timestamp_list[-1]
        else:
            return None


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    from os import listdir
    from os.path import isfile, join

    folders = sys.argv[1:]
    fig, ax = plt.subplots()
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            processor = ChassisSpeed()
            last_chassis_data = None
            topics = ["/apollo/canbus/chassis"]
            for data in reader.read(topics):
                if "chassis" in data:
                    last_chassis_data = data["chassis"]
                    processor.add(last_chassis_data)
                    last_pose_data = None
                    last_chassis_data = None

            data_x = processor.get_timestamp_list()
            data_y = processor.get_speed_list()

            ax.scatter(data_x, data_y, c=color, marker=marker, alpha=0.4)

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
from modules.tools.plot_planning.record_reader import RecordItemReader


class ImuAcc:

    def __init__(self):
        self.timestamp_list = []
        self.corrected_acc_list = []
        self.acc_list = []

        self.last_corrected_acc = None
        self.last_timestamp = None

    def add(self, location_est):
        timestamp = location_est.measurement_time
        acc = location_est.pose.linear_acceleration.x * \
            math.cos(location_est.pose.heading) + \
            location_est.pose.linear_acceleration.y * \
            math.sin(location_est.pose.heading)

        if self.last_corrected_acc is not None:
            corrected_acc = self._correct_acc(acc, self.last_corrected_acc)
        else:
            corrected_acc = acc

        self.acc_list.append(acc)
        self.corrected_acc_list.append(corrected_acc)
        self.timestamp_list.append(timestamp)

        self.last_timestamp = timestamp
        self.last_corrected_acc = corrected_acc

    def get_acc_list(self):
        return self.acc_list

    def get_corrected_acc_list(self):
        return self.corrected_acc_list

    def get_timestamp_list(self):
        return self.timestamp_list

    def get_lastest_corrected_acc(self):
        if len(self.corrected_acc_list) > 0:
            return self.corrected_acc_list[-1]
        else:
            return None

    def get_lastest_acc(self):
        if len(self.acc_list) > 0:
            return self.acc_list[-1]
        else:
            return None

    def get_lastest_timestamp(self):
        if len(self.timestamp_list) > 0:
            return self.timestamp_list[-1]
        else:
            return None

    def _correct_acc(self, acc, last_acc):
        if last_acc is None:
            return last_acc
        delta = abs(acc - last_acc) / abs(last_acc)
        if delta > 0.4:
            corrected = acc / 2.0
            return corrected
        else:
            return acc


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    from os import listdir
    from os.path import isfile, join

    folders = sys.argv[1:]
    fig, ax = plt.subplots()
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            processor = ImuAcc()
            last_pose_data = None
            last_chassis_data = None
            topics = ["/apollo/localization/pose"]
            for data in reader.read(topics):
                if "pose" in data:
                    last_pose_data = data["pose"]
                    processor.add(last_pose_data)
                    last_pose_data = None
                    last_chassis_data = None

            data_x = processor.get_timestamp_list()
            data_y = processor.get_corrected_acc_list()
            ax.scatter(data_x, data_y, c=color, marker=marker, alpha=0.4)
            data_y = processor.get_acc_list()
            ax.scatter(data_x, data_y, c="k", marker="+", alpha=0.4)

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
from modules.tools.plot_planning.record_reader import RecordItemReader


class ImuAngularVelocity:
    def __init__(self):
        self.timestamp_list = []
        self.angular_velocity_list = []
        self.corrected_angular_velocity_list = []

        self.last_corrected_angular_velocity = None
        self.last_timestamp = None

    def add(self, location_est):
        timestamp_sec = location_est.header.timestamp_sec
        angular_velocity = location_est.pose.angular_velocity.z

        if self.last_corrected_angular_velocity is not None:
            corrected = self.correct_angular_velocity(
                angular_velocity, timestamp_sec)
        else:
            corrected = angular_velocity

        self.timestamp_list.append(timestamp_sec)
        self.angular_velocity_list.append(angular_velocity)
        self.corrected_angular_velocity_list.append(corrected)

        self.last_corrected_angular_velocity = corrected
        self.last_timestamp = timestamp_sec

    def correct_angular_velocity(self, angular_velocity, timestamp_sec):
        if self.last_corrected_angular_velocity is None:
            return angular_velocity
        delta = abs(angular_velocity - self.last_corrected_angular_velocity)\
            / abs(self.last_corrected_angular_velocity)

        if delta > 0.25:
            corrected = angular_velocity / 2.0
            return corrected
        else:
            return angular_velocity

    def get_anglular_velocity_list(self):
        return self.angular_velocity_list

    def get_corrected_anglular_velocity_list(self):
        return self.corrected_angular_velocity_list

    def get_timestamp_list(self):
        return self.timestamp_list

    def get_latest_angular_velocity(self):
        if len(self.angular_velocity_list) == 0:
            return None
        else:
            return self.angular_velocity_list[-1]

    def get_latest_corrected_angular_velocity(self):
        if len(self.corrected_angular_velocity_list) == 0:
            return None
        else:
            return self.corrected_angular_velocity_list[-1]

    def get_latest_timestamp(self):
        if len(self.timestamp_list) == 0:
            return None
        else:
            return self.timestamp_list[-1]


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    from os import listdir
    from os.path import isfile, join

    folders = sys.argv[1:]
    fig, ax = plt.subplots()
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        fns.sort()
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            processor = ImuAngularVelocity()
            for data in reader.read(["/apollo/localization/pose"]):
                processor.add(data["pose"])

            data_x = processor.get_timestamp_list()
            data_y = processor.get_corrected_anglular_velocity_list()
            ax.scatter(data_x, data_y, c=color, marker=marker, alpha=0.4)

            data_y = processor.get_anglular_velocity_list()
            ax.scatter(data_x, data_y, c='k', marker="+", alpha=0.8)

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
from modules.tools.plot_planning.record_reader import RecordItemReader
from modules.tools.plot_planning.imu_angular_velocity import ImuAngularVelocity
from modules.tools.plot_planning.imu_speed import ImuSpeed


class ImuAvCurvature:
    def __init__(self):
        self.timestamp_list = []
        self.curvature_list = []

        self.last_angular_velocity_z = None

        self.imu_angular_velocity = ImuAngularVelocity()
        self.imu_speed = ImuSpeed()

    def add(self, location_est):
        timestamp_sec = location_est.header.timestamp_sec

        self.imu_angular_velocity.add(location_est)
        self.imu_speed.add(location_est)

        angular_velocity_z \
            = self.imu_angular_velocity.get_latest_corrected_angular_velocity()
        speed_mps = self.imu_speed.get_lastest_speed()
        if speed_mps > 0.03:
            kappa = angular_velocity_z / speed_mps
        else:
            kappa = 0

        self.timestamp_list.append(timestamp_sec)
        self.curvature_list.append(kappa)

        self.last_angular_velocity_z = angular_velocity_z

    def get_timestamp_list(self):
        return self.timestamp_list

    def get_curvature_list(self):
        return self.curvature_list

    def get_last_timestamp(self):
        if len(self.timestamp_list) > 0:
            return self.timestamp_list[-1]
        return None

    def get_last_curvature(self):
        if len(self.curvature_list) > 0:
            return self.curvature_list[-1]
        return None


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    from os import listdir
    from os.path import isfile, join

    folders = sys.argv[1:]
    fig, ax = plt.subplots()
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        fns.sort()
        for fn in fns:
            print(fn)
            reader = RecordItemReader(folder+"/"+fn)
            curvature_processor = ImuAvCurvature()
            speed_processor = ImuSpeed()
            av_processor = ImuAngularVelocity()
            last_pose_data = None
            last_chassis_data = None
            for data in reader.read(["/apollo/localization/pose"]):
                if "pose" in data:
                    last_pose_data = data["pose"]
                    curvature_processor.add(last_pose_data)
                    speed_processor.add(last_pose_data)
                    av_processor.add(last_pose_data)

            data_x = curvature_processor.get_timestamp_list()
            data_y = curvature_processor.get_curvature_list()
            ax.scatter(data_x, data_y, c=color, marker=marker, alpha=0.4)

            data_x = speed_processor.get_timestamp_list()
            data_y = speed_processor.get_speed_list()
            ax.scatter(data_x, data_y, c='r', marker=marker, alpha=0.4)

            data_x = av_processor.get_timestamp_list()
            data_y = av_processor.get_corrected_anglular_velocity_list()
            ax.scatter(data_x, data_y, c='b', marker=marker, alpha=0.4)

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
from modules.tools.plot_planning.record_reader import RecordItemReader


class ImuSpeed:

    def __init__(self, is_lateral=False):
        self.timestamp_list = []
        self.speed_list = []

        self.last_speed_mps = None
        self.last_imu_speed = None

        self.is_lateral = is_lateral

    def add(self, location_est):
        timestamp_sec = location_est.measurement_time
        self.timestamp_list.append(timestamp_sec)
        if self.is_lateral:
            speed = -1 * location_est.pose.linear_velocity.x \
                * math.sin(location_est.pose.heading) + \
                location_est.pose.linear_velocity.y * \
                math.cos(location_est.pose.heading)
        else:
            speed = location_est.pose.linear_velocity.x \
                * math.cos(location_est.pose.heading) + \
                location_est.pose.linear_velocity.y * \
                math.sin(location_est.pose.heading)
        self.speed_list.append(speed)

    def get_speed_list(self):
        return self.speed_list

    def get_timestamp_list(self):
        return self.timestamp_list

    def get_lastest_speed(self):
        if len(self.speed_list) > 0:
            return self.speed_list[-1]
        else:
            return None

    def get_lastest_timestamp(self):
        if len(self.timestamp_list) > 0:
            return self.timestamp_list[-1]
        else:
            return None


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    from os import listdir
    from os.path import isfile, join

    folders = sys.argv[1:]
    fig, ax = plt.subplots(2, 1)
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            lat_speed_processor = ImuSpeed(True)
            lon_speed_processor = ImuSpeed(False)

            last_pose_data = None
            last_chassis_data = None
            topics = ["/apollo/localization/pose"]
            for data in reader.read(topics):
                if "pose" in data:
                    last_pose_data = data["pose"]
                    lat_speed_processor.add(last_pose_data)
                    lon_speed_processor.add(last_pose_data)

            data_x = lon_speed_processor.get_timestamp_list()
            data_y = lon_speed_processor.get_speed_list()
            ax[0].scatter(data_x, data_y, c=color, marker=marker, alpha=0.4)

            data_x = lat_speed_processor.get_timestamp_list()
            data_y = lat_speed_processor.get_speed_list()
            ax[1].scatter(data_x, data_y, c=color, marker=marker, alpha=0.4)

    ax[0].set_xlabel('Timestamp')
    ax[0].set_ylabel('Lon Acc')
    ax[1].set_xlabel('Timestamp')
    ax[1].set_ylabel('Lat Acc')

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math

from modules.tools.plot_planning.imu_speed import ImuSpeed
from modules.tools.plot_planning.record_reader import RecordItemReader


class ImuSpeedAcc:

    def __init__(self, is_lateral=False):
        self.timestamp_list = []
        self.acc_list = []
        self.imu_speed = ImuSpeed(is_lateral)

    def add(self, location_est):
        self.imu_speed.add(location_est)
        speed_timestamp_list = self.imu_speed.get_timestamp_list()

        index_50ms = len(speed_timestamp_list) - 1
        found_index_50ms = False
        last_timestamp = speed_timestamp_list[-1]
        while index_50ms >= 0:
            current_timestamp = speed_timestamp_list[index_50ms]
            if (last_timestamp - current_timestamp) >= 0.05:
                found_index_50ms = True
                break
            index_50ms -= 1

        if found_index_50ms:
            speed_list = self.imu_speed.get_speed_list()
            acc = (speed_list[-1] - speed_list[index_50ms]) / \
                (speed_timestamp_list[-1] - speed_timestamp_list[index_50ms])
            self.acc_list.append(acc)
            self.timestamp_list.append(speed_timestamp_list[-1])

    def get_acc_list(self):
        return self.acc_list

    def get_timestamp_list(self):
        return self.timestamp_list

    def get_lastest_acc(self):
        if len(self.acc_list) > 0:
            return self.acc_list[-1]
        else:
            return None

    def get_lastest_timestamp(self):
        if len(self.timestamp_list) > 0:
            return self.timestamp_list[-1]
        else:
            return None


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    import numpy as np
    from os import listdir
    from os.path import isfile, join

    def plot_freq(x, y, ax, color):
        Fs = len(y) / float(x[-1] - x[0])
        n = len(y)
        k = np.arange(n)
        T = n / Fs
        frq = k / T
        frq = frq[range(n // 2)]

        Y = np.fft.fft(y) / n
        Y = Y[range(n // 2)]
        ax.plot(frq, abs(Y), c=color)

    folders = sys.argv[1:]
    fig, ax = plt.subplots(2, 2)
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        lat_time = []
        lat_acc = []
        lon_time = []
        lon_acc = []

        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        fns.sort()
        for fn in fns:
            reader = RecordItemReader(folder + "/" + fn)
            lat_acc_processor = ImuSpeedAcc(is_lateral=True)
            lon_acc_processor = ImuSpeedAcc(is_lateral=False)

            last_pose_data = None
            last_chassis_data = None
            topics = ["/apollo/localization/pose"]
            for data in reader.read(topics):
                if "pose" in data:
                    last_pose_data = data["pose"]
                    lat_acc_processor.add(last_pose_data)
                    lon_acc_processor.add(last_pose_data)

            data_x = lat_acc_processor.get_timestamp_list()
            data_y = lat_acc_processor.get_acc_list()

            lat_time.extend(data_x)
            lat_acc.extend(data_y)

            data_x = lon_acc_processor.get_timestamp_list()
            data_y = lon_acc_processor.get_acc_list()

            lon_time.extend(data_x)
            lon_acc.extend(data_y)

        if len(lat_time) == 0:
            continue

        ax[0][0].plot(lon_time, lon_acc, c=color, alpha=0.4)

        ax[0][1].plot(lat_time, lat_acc, c=color, alpha=0.4)

        ax[1][0].plot(lat_acc, lon_acc, '.', c=color, alpha=0.4)
    ax[0][0].set_xlabel('Timestamp')
    ax[0][0].set_ylabel('Lon Acc')
    ax[0][1].set_xlabel('Timestamp')
    ax[0][1].set_ylabel('Lat Acc')

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
from modules.tools.plot_planning.record_reader import RecordItemReader
from modules.tools.plot_planning.imu_speed_acc import ImuSpeedAcc


class ImuSpeedJerk:

    def __init__(self, is_lateral=False):
        self.timestamp_list = []
        self.jerk_list = []
        self.imu_speed_acc = ImuSpeedAcc(is_lateral)

    def add(self, location_est):
        self.imu_speed_acc.add(location_est)
        acc_timestamp_list = self.imu_speed_acc.get_timestamp_list()
        if len(acc_timestamp_list) <= 0:
            return

        index_500ms = len(acc_timestamp_list) - 1
        found_index_500ms = False
        last_timestamp = acc_timestamp_list[-1]
        while index_500ms >= 0:
            current_timestamp = acc_timestamp_list[index_500ms]
            if (last_timestamp - current_timestamp) >= 0.5:
                found_index_500ms = True
                break
            index_500ms -= 1

        if found_index_500ms:
            acc_list = self.imu_speed_acc.get_acc_list()
            jerk = (acc_list[-1] - acc_list[index_500ms]) / \
                (acc_timestamp_list[-1] - acc_timestamp_list[index_500ms])
            self.jerk_list.append(jerk)
            self.timestamp_list.append(acc_timestamp_list[-1])

    def get_jerk_list(self):
        return self.jerk_list

    def get_timestamp_list(self):
        return self.timestamp_list

    def get_lastest_jerk(self):
        if len(self.jerk_list) > 0:
            return self.jerk_list[-1]
        else:
            return None

    def get_lastest_timestamp(self):
        if len(self.timestamp_list) > 0:
            return self.timestamp_list[-1]
        else:
            return None


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    import numpy as np
    from os import listdir
    from os.path import isfile, join

    folders = sys.argv[1:]
    fig, ax = plt.subplots(1, 1)
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        x = []
        y = []
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        fns.sort()
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            processor = ImuSpeedJerk(True)
            last_pose_data = None
            last_chassis_data = None
            topics = ["/apollo/localization/pose"]
            for data in reader.read(topics):
                if "pose" in data:
                    last_pose_data = data["pose"]
                    processor.add(last_pose_data)

            data_x = processor.get_timestamp_list()
            data_y = processor.get_jerk_list()

            x.extend(data_x)
            y.extend(data_y)

        if len(x) <= 0:
            continue
        ax.scatter(x, y, c=color, marker=marker, alpha=0.4)
        #ax.plot(x, y, c=color, alpha=0.4)

        ax.set_xlabel('Timestamp')
        ax.set_ylabel('Jerk')

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class PlanningSpeed:

    def __init__(self):
        self.timestamp_list = []
        self.speed_list = []

        self.last_speed_mps = None
        self.last_imu_speed = None

    def add(self, planning_pb):
        timestamp_sec = planning_pb.header.timestamp_sec
        relative_time = planning_pb.debug.planning_data.init_point.relative_time
        self.timestamp_list.append(timestamp_sec + relative_time)

        speed = planning_pb.debug.planning_data.init_point.v
        self.speed_list.append(speed)

    def get_speed_list(self):
        return self.speed_list

    def get_timestamp_list(self):
        return self.timestamp_list

    def get_lastest_speed(self):
        if len(self.speed_list) > 0:
            return self.speed_list[-1]
        else:
            return None

    def get_lastest_timestamp(self):
        if len(self.timestamp_list) > 0:
            return self.timestamp_list[-1]
        else:
            return None


if __name__ == "__main__":
    import sys
    import math
    import matplotlib.pyplot as plt
    from os import listdir
    from os.path import isfile, join
    from record_reader import RecordItemReader

    folders = sys.argv[1:]
    fig, ax = plt.subplots()
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]

    for i in range(len(folders)):
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            processor = PlanningSpeed()
            last_pose_data = None
            last_chassis_data = None
            topics = ["/apollo/planning"]
            for data in reader.read(topics):
                if "planning" in data:
                    planning_pb = data["planning"]
                    processor.add(planning_pb)

            data_x = processor.get_timestamp_list()
            data_y = processor.get_speed_list()
            ax.scatter(data_x, data_y, c=color, marker=marker, alpha=0.4)

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
import sys
import matplotlib.pyplot as plt
import numpy as np
from os import listdir
from os.path import isfile, join

from modules.tools.plot_planning.record_reader import RecordItemReader
from modules.tools.plot_planning.imu_speed_jerk import ImuSpeedJerk
from modules.tools.plot_planning.imu_speed_acc import ImuSpeedAcc


def grid(data_list, shift):
    data_grid = []
    for data in data_list:
        data_grid.append(round(data) + shift/10.0)
    return data_grid


if __name__ == "__main__":
    folders = sys.argv[1:]
    fig, ax = plt.subplots(1, 1)
    colors = ["g", "b", "r", "m", "y"]
    markers = [".", ".", ".", "."]
    for i in range(len(folders)):
        x = []
        y = []
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        fns.sort()
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            jerk_processor = ImuSpeedJerk()
            acc_processor = ImuSpeedAcc()

            topics = ["/apollo/localization/pose"]
            for data in reader.read(topics):
                if "pose" in data:
                    pose_data = data["pose"]
                    acc_processor.add(pose_data)
                    jerk_processor.add(pose_data)

            data_x = grid(acc_processor.get_acc_list(), i + 1)
            data_y = grid(jerk_processor.get_jerk_list(), i + 1)
            data_x = data_x[-1 * len(data_y):]
            x.extend(data_x)
            y.extend(data_y)

        if len(x) <= 0:
            continue
        ax.scatter(x, y, c=color, marker=marker, alpha=0.4)
        #ax.plot(x, y, c=color, alpha=0.4)

        ax.set_xlabel('Acc')
        ax.set_ylabel('Jerk')

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import threading

import gflags
import matplotlib.animation as animation
import matplotlib.pyplot as plt

from cyber.python.cyber_py3 import cyber
from modules.canbus.proto import chassis_pb2
from modules.control.proto import control_cmd_pb2


INIT_ACC_DATA = []
INIT_T_DATA = []

begin_t = None
last_t = None
last_v = None
lock = threading.Lock()

FLAGS = gflags.FLAGS
gflags.DEFINE_integer("data_length", 500, "Planning plot data length")


def callback(chassis_pb):
    global INIT_ACC_DATA, INIT_T_DATA
    global begin_t, last_t, last_v

    if begin_t is None:
        begin_t = chassis_pb.header.timestamp_sec
        last_t = begin_t
    current_t = chassis_pb.header.timestamp_sec
    current_v = chassis_pb.speed_mps

    print(current_v)
    if abs(current_t - last_t) < 0.015:
        return

    lock.acquire()
    if last_t is not None and abs(current_t - last_t) > 1:
        begin_t = chassis_pb.header.timestamp_sec

        INIT_ACC_DATA = []
        INIT_T_DATA = []

        last_t = None
        last_v = None

    if last_t is not None and last_v is not None and current_t > last_t:
        INIT_T_DATA.append(current_t - begin_t)
        INIT_ACC_DATA.append((current_v - last_v) / (current_t - last_t))

    lock.release()

    last_t = current_t
    last_v = current_v


def listener():
    cyber.init()
    test_node = cyber.Node("chassis_acc_listener")
    test_node.create_reader("/apollo/canbus/chassis",
                            chassis_pb2.Chassis, callback)


def compensate(data_list):
    comp_data = [0] * FLAGS.data_length
    comp_data.extend(data_list)
    if len(comp_data) > FLAGS.data_length:
        comp_data = comp_data[-FLAGS.data_length:]
    return comp_data


def update(frame_number):
    lock.acquire()
    init_data_line.set_xdata(INIT_T_DATA)
    init_data_line.set_ydata(INIT_ACC_DATA)
    lock.release()
    #brake_text.set_text('brake = %.1f' % brake_data[-1])
    #throttle_text.set_text('throttle = %.1f' % throttle_data[-1])
    if len(INIT_ACC_DATA) > 0:
        init_data_text.set_text('chassis acc = %.1f' % INIT_ACC_DATA[-1])


if __name__ == '__main__':
    argv = FLAGS(sys.argv)
    listener()
    fig, ax = plt.subplots()
    X = range(FLAGS.data_length)
    Xs = [i * -1 for i in X]
    Xs.sort()
    init_data_line, = ax.plot(
        INIT_T_DATA, INIT_ACC_DATA, 'b', lw=2, alpha=0.7, label='chassis acc')

    #brake_text = ax.text(0.75, 0.85, '', transform=ax.transAxes)
    #throttle_text = ax.text(0.75, 0.90, '', transform=ax.transAxes)
    init_data_text = ax.text(0.75, 0.95, '', transform=ax.transAxes)
    ani = animation.FuncAnimation(fig, update, interval=100)
    ax.set_ylim(-6, 3)
    ax.set_xlim(-1, 60)
    ax.legend(loc="upper left")
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import threading

import gflags
import matplotlib.animation as animation
import matplotlib.pyplot as plt

from cyber.python.cyber_py3 import cyber
from modules.control.proto import control_cmd_pb2
from modules.planning.proto import planning_pb2


LAST_TRAJ_DATA = []
LAST_TRAJ_T_DATA = []
CURRENT_TRAJ_DATA = []
CURRENT_TRAJ_T_DATA = []
INIT_V_DATA = []
INIT_T_DATA = []

begin_t = None
last_t = None
last_v = None
lock = threading.Lock()

FLAGS = gflags.FLAGS
gflags.DEFINE_integer("data_length", 500, "Planning plot data length")


def callback(planning_pb):
    global INIT_V_DATA, INIT_T_DATA
    global CURRENT_TRAJ_DATA, LAST_TRAJ_DATA
    global CURRENT_TRAJ_T_DATA, LAST_TRAJ_T_DATA
    global begin_t, last_t, last_v

    lock.acquire()

    if begin_t is None:
        begin_t = planning_pb.header.timestamp_sec
    current_t = planning_pb.header.timestamp_sec
    current_v = planning_pb.debug.planning_data.init_point.v

    if last_t is not None and abs(current_t - last_t) > 1:
        begin_t = planning_pb.header.timestamp_sec
        LAST_TRAJ_DATA = []
        LAST_TRAJ_T_DATA = []

        CURRENT_TRAJ_DATA = []
        CURRENT_TRAJ_T_DATA = []

        INIT_V_DATA = []
        INIT_T_DATA = []

        last_t = None
        last_v = None

    if last_t is not None and last_v is not None and current_t > last_t:
        INIT_T_DATA.append(current_t - begin_t)
        INIT_V_DATA.append((current_v - last_v) / (current_t - last_t))

        LAST_TRAJ_DATA = []
        for v in CURRENT_TRAJ_DATA:
            LAST_TRAJ_DATA.append(v)

        LAST_TRAJ_T_DATA = []
        for t in CURRENT_TRAJ_T_DATA:
            LAST_TRAJ_T_DATA.append(t)

        CURRENT_TRAJ_DATA = []
        CURRENT_TRAJ_T_DATA = []
        traj_point_last_v = None
        traj_point_last_t = None
        for traj_point in planning_pb.trajectory_point:
            if traj_point_last_v is None:
                CURRENT_TRAJ_DATA.append(traj_point.a)
            else:
                # CURRENT_TRAJ_DATA.append(traj_point.a)
                cal_a = (traj_point.v - traj_point_last_v) / \
                    (traj_point.relative_time - traj_point_last_t)
                CURRENT_TRAJ_DATA.append(cal_a)
            CURRENT_TRAJ_T_DATA.append(current_t - begin_t + traj_point.relative_time)
            traj_point_last_t = traj_point.relative_time
            traj_point_last_v = traj_point.v
    lock.release()

    last_t = current_t
    last_v = current_v


def listener():
    cyber.init()
    test_node = cyber.Node("planning_acc_listener")
    test_node.create_reader("/apollo/planning",
                            planning_pb2.ADCTrajectory, callback)


def compensate(data_list):
    comp_data = [0] * FLAGS.data_length
    comp_data.extend(data_list)
    if len(comp_data) > FLAGS.data_length:
        comp_data = comp_data[-FLAGS.data_length:]
    return comp_data


def update(frame_number):
    lock.acquire()
    last_traj.set_xdata(LAST_TRAJ_T_DATA)
    last_traj.set_ydata(LAST_TRAJ_DATA)

    current_traj.set_xdata(CURRENT_TRAJ_T_DATA)
    current_traj.set_ydata(CURRENT_TRAJ_DATA)

    init_data_line.set_xdata(INIT_T_DATA)
    init_data_line.set_ydata(INIT_V_DATA)
    lock.release()
    #brake_text.set_text('brake = %.1f' % brake_data[-1])
    #throttle_text.set_text('throttle = %.1f' % throttle_data[-1])
    if len(INIT_V_DATA) > 0:
        init_data_text.set_text('init point a = %.1f' % INIT_V_DATA[-1])


if __name__ == '__main__':
    argv = FLAGS(sys.argv)
    listener()
    fig, ax = plt.subplots()
    X = range(FLAGS.data_length)
    Xs = [i * -1 for i in X]
    Xs.sort()
    init_data_line, = ax.plot(
        INIT_T_DATA, INIT_V_DATA, 'b', lw=2, alpha=0.7, label='init_point_a')
    current_traj, = ax.plot(
        CURRENT_TRAJ_T_DATA, CURRENT_TRAJ_DATA, 'r', lw=1, alpha=0.5, label='current_traj')
    last_traj, = ax.plot(
        LAST_TRAJ_T_DATA, LAST_TRAJ_DATA, 'g', lw=1, alpha=0.5, label='last_traj')

    #brake_text = ax.text(0.75, 0.85, '', transform=ax.transAxes)
    #throttle_text = ax.text(0.75, 0.90, '', transform=ax.transAxes)
    init_data_text = ax.text(0.75, 0.95, '', transform=ax.transAxes)
    ani = animation.FuncAnimation(fig, update, interval=100)
    ax.set_ylim(-6, 3)
    ax.set_xlim(-1, 60)
    ax.legend(loc="upper left")
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
import threading

import gflags
import matplotlib.animation as animation
import matplotlib.pyplot as plt

from cyber.python.cyber_py3 import cyber
from modules.control.proto import control_cmd_pb2
from modules.planning.proto import planning_pb2


LAST_TRAJ_DATA = []
LAST_TRAJ_T_DATA = []
CURRENT_TRAJ_DATA = []
CURRENT_TRAJ_T_DATA = []
INIT_V_DATA = []
INIT_T_DATA = []

begin_t = None
last_t = None
lock = threading.Lock()

FLAGS = gflags.FLAGS
gflags.DEFINE_integer("data_length", 500, "Planning plot data length")


def callback(planning_pb):
    global INIT_V_DATA, INIT_T_DATA
    global CURRENT_TRAJ_DATA, LAST_TRAJ_DATA
    global CURRENT_TRAJ_T_DATA, LAST_TRAJ_T_DATA
    global begin_t, last_t

    lock.acquire()

    if begin_t is None:
        begin_t = planning_pb.header.timestamp_sec
    current_t = planning_pb.header.timestamp_sec
    if last_t is not None and abs(current_t - last_t) > 1:
        begin_t = planning_pb.header.timestamp_sec
        LAST_TRAJ_DATA = []
        LAST_TRAJ_T_DATA = []

        CURRENT_TRAJ_DATA = []
        CURRENT_TRAJ_T_DATA = []

        INIT_V_DATA = []
        INIT_T_DATA = []

    INIT_T_DATA.append(current_t - begin_t)
    INIT_V_DATA.append(planning_pb.debug.planning_data.init_point.v)

    LAST_TRAJ_DATA = []
    for v in CURRENT_TRAJ_DATA:
        LAST_TRAJ_DATA.append(v)

    LAST_TRAJ_T_DATA = []
    for t in CURRENT_TRAJ_T_DATA:
        LAST_TRAJ_T_DATA.append(t)

    CURRENT_TRAJ_DATA = []
    CURRENT_TRAJ_T_DATA = []
    for traj_point in planning_pb.trajectory_point:
        CURRENT_TRAJ_DATA.append(traj_point.v)
        CURRENT_TRAJ_T_DATA.append(current_t - begin_t + traj_point.relative_time)

    lock.release()

    last_t = current_t


def listener():
    cyber.init()
    test_node = cyber.Node("planning_listener")
    test_node.create_reader("/apollo/planning",
                            planning_pb2.ADCTrajectory, callback)


def compensate(data_list):
    comp_data = [0] * FLAGS.data_length
    comp_data.extend(data_list)
    if len(comp_data) > FLAGS.data_length:
        comp_data = comp_data[-FLAGS.data_length:]
    return comp_data


def update(frame_number):
    lock.acquire()
    last_traj.set_xdata(LAST_TRAJ_T_DATA)
    last_traj.set_ydata(LAST_TRAJ_DATA)

    current_traj.set_xdata(CURRENT_TRAJ_T_DATA)
    current_traj.set_ydata(CURRENT_TRAJ_DATA)

    init_data_line.set_xdata(INIT_T_DATA)
    init_data_line.set_ydata(INIT_V_DATA)
    lock.release()
    #brake_text.set_text('brake = %.1f' % brake_data[-1])
    #throttle_text.set_text('throttle = %.1f' % throttle_data[-1])
    if len(INIT_V_DATA) > 0:
        init_data_text.set_text('init point v = %.1f' % INIT_V_DATA[-1])


if __name__ == '__main__':
    argv = FLAGS(sys.argv)
    listener()
    fig, ax = plt.subplots()
    X = range(FLAGS.data_length)
    Xs = [i * -1 for i in X]
    Xs.sort()
    init_data_line, = ax.plot(
        INIT_T_DATA, INIT_V_DATA, 'b', lw=2, alpha=0.7, label='init_point_v')
    current_traj, = ax.plot(
        CURRENT_TRAJ_T_DATA, CURRENT_TRAJ_DATA, 'r', lw=1, alpha=0.5, label='current_traj')
    last_traj, = ax.plot(
        LAST_TRAJ_T_DATA, LAST_TRAJ_DATA, 'g', lw=1, alpha=0.5, label='last_traj')

    #brake_text = ax.text(0.75, 0.85, '', transform=ax.transAxes)
    #throttle_text = ax.text(0.75, 0.90, '', transform=ax.transAxes)
    init_data_text = ax.text(0.75, 0.95, '', transform=ax.transAxes)
    ani = animation.FuncAnimation(fig, update, interval=100)
    ax.set_ylim(-1, 30)
    ax.set_xlim(-1, 60)
    ax.legend(loc="upper left")
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from os import listdir
from os.path import isfile, join
import math
import sys

import matplotlib.pyplot as plt
import numpy as np

from modules.tools.plot_planning.imu_speed import ImuSpeed
from modules.tools.plot_planning.imu_speed_jerk import ImuSpeedJerk
from modules.tools.plot_planning.record_reader import RecordItemReader


def grid(data_list, shift):
    data_grid = []
    for data in data_list:
        data_grid.append(round(data) + shift / 10.0)
    return data_grid


def generate_speed_jerk_dict(speed_jerk_dict, speed_list, jerk_list):
    for i in range(len(speed_list)):
        speed = int(speed_list[i])
        jerk = int(jerk_list[i])
        if speed in speed_jerk_dict:
            if jerk not in speed_jerk_dict[speed]:
                speed_jerk_dict[speed].append(jerk)
        else:
            speed_jerk_dict[speed] = [jerk]
    return speed_jerk_dict


if __name__ == "__main__":

    folders = sys.argv[1:]
    fig, ax = plt.subplots(1, 1)
    colors = ["g", "b", "r", "m", "y"]
    markers = [".", ".", ".", "."]
    speed_jerk_dict = {}

    for i in range(len(folders)):
        x = []
        y = []
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        fns.sort()
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            jerk_processor = ImuSpeedJerk(True)
            speed_processor = ImuSpeed(True)

            topics = ["/apollo/localization/pose"]
            for data in reader.read(topics):
                if "pose" in data:
                    pose_data = data["pose"]
                    speed_processor.add(pose_data)
                    jerk_processor.add(pose_data)

            data_x = grid(speed_processor.get_speed_list(), i + 1)
            data_y = grid(jerk_processor.get_jerk_list(), i + 1)
            data_x = data_x[-1 * len(data_y):]
            x.extend(data_x)
            y.extend(data_y)
            speed_jerk_dict = generate_speed_jerk_dict(speed_jerk_dict, x, y)

        if len(x) <= 0:
            continue
        ax.scatter(x, y, c=color, marker=marker, alpha=0.4)
        #ax.plot(x, y, c=color, alpha=0.4)

        ax.set_xlabel('Speed')
        ax.set_ylabel('Jerk')
    print(speed_jerk_dict)
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


import sys

import matplotlib.pyplot as plt

from cyber.python.cyber_py3.record import RecordReader
from modules.canbus.proto import chassis_pb2


def process(reader):
    last_steering_percentage = None
    last_speed_mps = None
    last_timestamp_sec = None
    speed_data = []
    d_steering_data = []

    for msg in reader.read_messages():
        if msg.topic == "/apollo/canbus/chassis":
            chassis = chassis_pb2.Chassis()
            chassis.ParseFromString(msg.message)

            steering_percentage = chassis.steering_percentage
            speed_mps = chassis.speed_mps
            timestamp_sec = chassis.header.timestamp_sec

            if chassis.driving_mode != chassis_pb2.Chassis.COMPLETE_AUTO_DRIVE:
                last_steering_percentage = steering_percentage
                last_speed_mps = speed_mps
                last_timestamp_sec = timestamp_sec
                continue

            if last_timestamp_sec is None:
                last_steering_percentage = steering_percentage
                last_speed_mps = speed_mps
                last_timestamp_sec = timestamp_sec
                continue

            if (timestamp_sec - last_timestamp_sec) > 0.02:
                d_steering = (steering_percentage - last_steering_percentage) \
                    / (timestamp_sec - last_timestamp_sec)
                speed_data.append(speed_mps)
                d_steering_data.append(d_steering)

                last_steering_percentage = steering_percentage
                last_speed_mps = speed_mps
                last_timestamp_sec = timestamp_sec

    return speed_data, d_steering_data


if __name__ == "__main__":
    fns = sys.argv[1:]
    fig, ax = plt.subplots()

    for fn in fns:
        reader = RecordReader(fn)
        speed_data, d_steering_data = process(reader)
        ax.scatter(speed_data, d_steering_data)
    ax.set_xlim(-5, 40)
    ax.set_ylim(-300, 300)
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from cyber.python.cyber_py3.record import RecordReader
from modules.canbus.proto import chassis_pb2
from modules.localization.proto import localization_pb2
from modules.planning.proto import planning_pb2


class RecordItemReader:
    def __init__(self, record_file):
        self.record_file = record_file

    def read(self, topics):
        reader = RecordReader(self.record_file)
        for msg in reader.read_messages():
            if msg.topic not in topics:
                continue
            if msg.topic == "/apollo/canbus/chassis":
                chassis = chassis_pb2.Chassis()
                chassis.ParseFromString(msg.message)
                data = {"chassis": chassis}
                yield data

            if msg.topic == "/apollo/localization/pose":
                location_est = localization_pb2.LocalizationEstimate()
                location_est.ParseFromString(msg.message)
                data = {"pose": location_est}
                yield data

            if msg.topic == "/apollo/planning":
                planning = planning_pb2.ADCTrajectory()
                planning.ParseFromString(msg.message)
                data = {"planning": planning}
                yield data
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys
from modules.tools.plot_planning.record_reader import RecordItemReader
import matplotlib.pyplot as plt
from cyber.python.cyber_py3.record import RecordReader
from modules.canbus.proto import chassis_pb2


class SpeedDsteeringData:
    def __init__(self):
        self.last_steering_percentage = None
        self.last_speed_mps = None
        self.last_timestamp_sec = None
        self.speed_data = []
        self.d_steering_data = []

    def add(self, chassis):
        steering_percentage = chassis.steering_percentage
        speed_mps = chassis.speed_mps
        timestamp_sec = chassis.header.timestamp_sec

        if self.last_timestamp_sec is None:
            self.last_steering_percentage = steering_percentage
            self.last_speed_mps = speed_mps
            self.last_timestamp_sec = timestamp_sec
            return

        if (timestamp_sec - self.last_timestamp_sec) > 0.02:
            d_steering = (steering_percentage - self.last_steering_percentage) \
                / (timestamp_sec - self.last_timestamp_sec)
            self.speed_data.append(speed_mps)
            self.d_steering_data.append(d_steering)

            self.last_steering_percentage = steering_percentage
            self.last_speed_mps = speed_mps
            self.last_timestamp_sec = timestamp_sec

    def get_speed_dsteering(self):
        return self.speed_data, self.d_steering_data


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    from os import listdir
    from os.path import isfile, join

    folders = sys.argv[1:]
    fig, ax = plt.subplots()
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        for fn in fns:
            reader = RecordItemReader(folder+"/"+fn)
            processor = SpeedDsteeringData()
            last_pose_data = None
            last_chassis_data = None
            topics = ["/apollo/localization/pose", "/apollo/canbus/chassis"]
            for data in reader.read(topics):
                if "chassis" in data:
                    last_chassis_data = data["chassis"]
                if last_chassis_data is not None:
                    processor.add(last_chassis_data)
                    #last_pose_data = None
                    #last_chassis_data = None

            data_x, data_y = processor.get_speed_dsteering()
            ax.scatter(data_x, data_y, c=color, marker=marker, alpha=0.2)

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from modules.tools.plot_planning.record_reader import RecordItemReader
from modules.tools.plot_planning.time_angular_velocity_data import TimeAngularVelocityData
from modules.tools.plot_planning.time_speed_data import TimeSpeedData
import math


class TimeCurvatureData:
    def __init__(self):
        self.timestamp_list = []
        self.curvature_list = []
        self.speed_list = []

        self.corrected_timestamp_list = []
        self.corrected_velocity_list = []

        self.last_angular_velocity_z = None

        self.angular_velocity_data = TimeAngularVelocityData()
        self.speed_data = TimeSpeedData()

    def add(self, location_est, chassis):
        timestamp_sec = location_est.header.timestamp_sec

        self.angular_velocity_data.add_location_estimation(location_est)
        self.speed_data.add(location_est, chassis)

        angular_velocity_z = self.angular_velocity_data.get_latest()
        speed_mps = self.speed_data.get_imu_based_lastest_speed()

        if speed_mps > 0.5:
            kappa = angular_velocity_z / speed_mps
            if kappa > 0.05:
                self.timestamp_list.append(timestamp_sec)
                self.curvature_list.append(kappa)
                self.speed_list.append(speed_mps)

        self.last_angular_velocity_z = angular_velocity_z

    def get_time_curvature(self):
        return self.timestamp_list, self.curvature_list

    def get_speed_curvature(self):
        return self.speed_list, self.curvature_list

    def get_fixed_ca_speed_curvature(self):
        speed_list = list(range(1, 31))
        curvature_list = []
        for speed in speed_list:
            curvature = 2.0 / (speed * speed)
            curvature_list.append(curvature)
        return speed_list, curvature_list


if __name__ == "__main__":
    import sys
    import matplotlib.pyplot as plt
    from os import listdir
    from os.path import isfile, join

    folders = sys.argv[1:]
    fig, ax = plt.subplots()
    colors = ["g", "b", "r", "m", "y"]
    markers = ["o", "o", "o", "o"]
    for i in range(len(folders)):
        folder = folders[i]
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        fns = [f for f in listdir(folder) if isfile(join(folder, f))]
        for fn in fns:
            print(fn)
            reader = RecordItemReader(folder+"/"+fn)
            processor = TimeCurvatureData()
            last_pose_data = None
            last_chassis_data = None
            for data in reader.read(["/apollo/localization/pose",
                                     "/apollo/canbus/chassis"]):
                if "pose" in data:
                    last_pose_data = data["pose"]
                if "chassis" in data:
                    last_chassis_data = data["chassis"]
                if last_chassis_data is not None and last_pose_data is not None:
                    processor.add(last_pose_data, last_chassis_data)

            data_x, data_y = processor.get_speed_curvature()
            data_y = [abs(i) for i in data_y]
            ax.scatter(data_x, data_y, c=color, marker=marker, alpha=0.4)
            #data_x, data_y = processor.speed_data.get_time_speed()
            #ax.scatter(data_x, data_y, c=color, marker="+", alpha=0.4)
    processor = TimeCurvatureData()
    x, y = processor.get_fixed_ca_speed_curvature()
    ax.plot(x, y)
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from subprocess import call
import sys

from google.protobuf import text_format
from mpl_toolkits.mplot3d import Axes3D
import matplotlib
import matplotlib.animation as animation
import matplotlib.pyplot as plt
import numpy as np

from modules.canbus.proto import chassis_pb2
from modules.localization.proto import localization_pb2
from modules.planning.proto import planning_pb2


g_args = None


def get_3d_trajectory(planning_pb):
    x = [p.path_point.x for p in planning_pb.trajectory_point]
    y = [p.path_point.y for p in planning_pb.trajectory_point]
    z = [p.v for p in planning_pb.trajectory_point]
    return (x, y, z)


def get_debug_paths(planning_pb):
    if not planning_pb.HasField("debug"):
        return None
    if not planning_pb.debug.HasField("planning_data"):
        return None
    results = []
    for path in planning_pb.debug.planning_data.path:
        x = [p.x for p in path.path_point]
        y = [p.y for p in path.path_point]
        results.append((path.name, (x, y)))
    return results


def plot_planning(ax, planning_file):
    with open(planning_file, 'r') as fp:
        planning_pb = planning_pb2.ADCTrajectory()
        text_format.Merge(fp.read(), planning_pb)
        trajectory = get_3d_trajectory(planning_pb)
        ax.plot(trajectory[0], trajectory[1], trajectory[2],
                label="Trajectory:%s" % planning_file)
        paths = get_debug_paths(planning_pb)
        if paths:
            for name, path in paths:
                ax.plot(path[0], path[1], label="%s:%s" % (name, planning_file))
        ax.legend()


def press_key(event):
    if event.key == 'c':
        files = g_args.planning_files
        if len(files) != 2:
            print('Need more than two files.')
            return
        command = ["cp"]
        for f in files:
            command.append(f)
        if call(command) == 0:
            print('command success: %s' % " ".join(command))
            sys.exit(0)
        else:
            print('Failed to run command: %s ' % " ".join(command))
            sys.exit(1)


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(
        description="""A visualization tool that can plot one or multiple planning "
        results, so that we can compare the differences.
        Example: plot_planning_result.py result_file1.pb.txt result_file2.pb.txt"""
    )
    parser.add_argument(
        "planning_files",
        action='store',
        nargs="+",
        help="The planning results")
    parser.add_argument(
        "--figure",
        action='store',
        type=str,
        help="Save the planning results to picture, if not set, show on screen"
    )
    g_args = parser.parse_args()

    matplotlib.rcParams['legend.fontsize'] = 10
    fig = plt.figure()
    fig.canvas.mpl_connect('key_press_event', press_key)
    ax = fig.gca(projection='3d')
    ax.set_xlabel("x")
    ax.set_ylabel("y")
    ax.set_zlabel("speed")

    for planning_file in g_args.planning_files:
        plot_planning(ax, planning_file)

    if g_args.figure:
        plt.savefig(g_args.figure)
        print('picture saved to %s' % g_args.figure)
    else:
        plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys

import matplotlib.animation as animation
import matplotlib.pyplot as plt
import numpy as np

from cyber.python.cyber_py3 import cyber
from modules.canbus.proto import chassis_pb2
from modules.localization.proto import localization_pb2


GPS_X = list()
GPS_Y = list()
GPS_LINE = None
DRIVING_MODE_TEXT = ""
CHASSIS_TOPIC = "/apollo/canbus/chassis"
LOCALIZATION_TOPIC = "/apollo/localization/pose"
IS_AUTO_MODE = False


def chassis_callback(chassis_data):
    global IS_AUTO_MODE
    if chassis_data.driving_mode == chassis_pb2.Chassis.COMPLETE_AUTO_DRIVE:
        IS_AUTO_MODE = True
    else:
        IS_AUTO_MODE = False

    DRIVING_MODE_TEXT = str(chassis_data.driving_mode)


def localization_callback(localization_data):
    global GPS_X
    global GPS_Y
    global IS_AUTO_MODE
    if IS_AUTO_MODE:
        GPS_X.append(localization_data.pose.position.x)
        GPS_Y.append(localization_data.pose.position.y)


def setup_listener(node):
    node.create_reader(CHASSIS_TOPIC, chassis_pb2.Chassis, chassis_callback)
    node.create_reader(LOCALIZATION_TOPIC,
                       localization_pb2.LocalizationEstimate,
                       localization_callback)
    while not cyber.is_shutdown():
        time.sleep(0.002)


def update(frame_number):
    global GPS_X
    global GPS_Y
    if IS_AUTO_MODE and len(GPS_X) > 1:
        min_len = min(len(GPS_X), len(GPS_Y)) - 1
        GPS_LINE.set_data(GPS_X[-min_len:], GPS_Y[-min_len:])


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(
        description="""A visualization tool that can plot a manual driving trace produced by the rtk_player tool,
        and plot the autonomous driving trace in real time.
        The manual driving trace is the blue lines, and the autonomous driving trace is the red lines.
        It is visualization a way to verify the precision of the autonomous driving trace.
        If you have a cyber record file, you can play the record and the tool will plot the received localization
        message in realtime. To do that, start this tool first with a manual driving trace, and then
        play record use another terminal with the following command [replace your_file.record to your
        own record file]: cyber_record play -f your_file.record
        """)
    parser.add_argument(
        "trace",
        action='store',
        type=str,
        help='the manual driving trace produced by rtk_player')

    args = parser.parse_args()

    fig, ax = plt.subplots()

    with open(args.trace, 'r') as fp:
        trace_data = np.genfromtxt(handle, delimiter=',', names=True)
        ax.plot(trace_data['x'], trace_data['y'], 'b-', alpha=0.5, linewidth=1)

    cyber.init()
    node = cyber.Node("plot_trace")
    setup_listener(node)

    x_min = min(trace_data['x'])
    x_max = max(trace_data['x'])
    y_min = min(trace_data['y'])
    y_max = max(trace_data['y'])

    GPS_LINE, = ax.plot(GPS_X, GPS_Y, 'r', linewidth=3, label="gps")

    ani = animation.FuncAnimation(fig, update, interval=100)

    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


from modules.tools.prediction.data_pipelines.common.vector2d import Vector2
from modules.tools.prediction.data_pipelines.common.rotation2d import rotate_fast
from modules.tools.prediction.data_pipelines.common.util import segment_overlap


class BoundingRectangle:
    def __init__(self, x, y, theta, length, width):

        self.vertices = [None] * 4
        dx = 0.5 * length
        dy = 0.5 * width

        cos_theta = cos(theta)
        sin_theta = sin(theta)

        self.vertices[0] = rotate_fast(Vector2(dx, -dy), cos_theta, sin_theta)
        self.vertices[1] = rotate_fast(Vector2(dx, dy), cos_theta, sin_theta)
        self.vertices[2] = rotate_fast(Vector2(-dx, dy), cos_theta, sin_theta)
        self.vertices[3] = rotate_fast(Vector2(-dx, -dy), cos_theta, sin_theta)

        for i in range(4):
            self.vertices[i].x += x
            self.vertices[i].y += y

    def overlap(self, rect):
        for i in range(4):
            v0 = self.vertices[i]
            v1 = self.vertices[(i + 1) % 4]

            range_self = self.project(v0, v1)
            range_other = rect.project(v0, v1)

            if segment_overlap(range_self[0], range_self[1], range_other[0], range_other[1]) == False:
                return False

        for i in range(4):
            v0 = rect.vertices[i]
            v1 = rect.vertices[(i + 1) % 4]

            range_self = self.project(v0, v1)
            range_other = rect.project(v0, v1)

            if segment_overlap(range_self[0], range_self[1], range_other[0], range_other[1]) == False:
                return False

        return True

    def project(self, p0, p1):
        v = p1.subtract(p0)
        n = v.norm()

        rmin = float("inf")
        rmax = float("-inf")

        for i in range(4):
            t = self.vertices[i].subtract(p0)
            r = t.dot(v) / n

            if r < rmin:
                rmin = r

            if r > rmax:
                rmax = r

        return [rmin, rmax]

    def print_vertices(self):
        for i in range(4):
            print(str(self.vertices[i].x) + "\t" +
                  str(self.vertices[i].y) + "\n")
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

parameters = {
    'config': {
        'need_to_label': True,
        'maximum_observation_time': 8.0
    },
    'mlp': {
        'train_data_rate': 0.8,
        'size_obstacle_feature': 22,
        'size_lane_sequence_feature': 40,
        'dim_input': 22 + 40,
        'dim_hidden_1': 30,
        'dim_hidden_2': 15,
        'dim_output': 1
    },
    'cruise_mlp': {
        'dim_input': 23 + 5 * 9 + 20 * 4 + 8,
        'dim_hidden_1': 50,
        'dim_hidden_2': 18,
        'dim_output': 1
    },
    'junction_mlp': {
        'dim_input': 3 + 60,
        'dim_hidden_1': 30,
        'dim_hidden_2': 15,
        'dim_output': 12
    },
    'feature': {
        'threshold_label_time_delta': 1.0,
        'prediction_label_timeframe': 3.0,
        'maximum_maneuver_finish_time': 3.0,

        # Lane change is defined to be finished if the ratio of deviation
        # from center-line to the lane width is within this: (must be < 0.5)
        'lane_change_finish_condition': 0.1,
        'maximum_observation_time': 6.0
    }
}

labels = {'go_false': 0, 'go_true': 1, 'cutin_false': -1, 'cutin_true': 2}
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import os
import h5py
import numpy as np
from random import choice
from random import randint
from random import shuffle
from time import time


def load_h5(filename):
    if not (os.path.exists(filename)):
        logging.error("file: {}, does not exist".format(filename))
        os._exit(1)
    if os.path.splitext(filename)[1] != '.h5':
        logging.error("file: {} is not an hdf5 file".format(filename))
        os._exit(1)

    samples = dict()
    h5_file = h5py.File(filename, 'r')
    for key in h5_file.keys():
        samples[key] = h5_file[key][:]

    return samples['data']


def down_sample(data):
    cutin_false_drate = 0.5
    go_false_drate = 0.8
    go_true_drate = 0.9
    cutin_true_drate = 0.0

    label = data[:, -1]
    size = np.shape(label)[0]

    cutin_false_index = (label == -1)
    go_false_index = (label == 0)
    go_true_index = (label == 1)
    cutin_true_index = (label == 2)

    rand = np.random.random((size))

    cutin_false_select = np.logical_and(cutin_false_index,
                                        rand > cutin_false_drate)
    cutin_true_select = np.logical_and(cutin_true_index,
                                       rand > cutin_true_drate)
    go_false_select = np.logical_and(go_false_index, rand > go_false_drate)
    go_true_select = np.logical_and(go_true_index, rand > go_true_drate)

    all_select = np.logical_or(cutin_false_select, cutin_true_select)
    all_select = np.logical_or(all_select, go_false_select)
    all_select = np.logical_or(all_select, go_true_select)

    data_downsampled = data[all_select, :]

    return data_downsampled


def train_test_split(data, train_rate):
    data_size = np.shape(data)[0]
    train_size = int(data_size * train_rate)
    train = data[0:train_size, ]
    test = data[train_size:, ]
    return train, test
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import copy
import logging
import sys

from google.protobuf.internal import decoder
from google.protobuf.internal import encoder
import google.protobuf.text_format as text_format

from modules.prediction.proto import feature_pb2
from modules.prediction.proto import offline_features_pb2


def readVarint32(stream):
    """
    read block size from file stream
    """
    mask = 0x80  # (1 << 7)
    raw_varint32 = []
    while 1:
        b = stream.read(1)
        if b == "":
            break
        raw_varint32.append(b)
        if not (ord(b) & mask):
            break
    return raw_varint32


def load_protobuf(filename):
    """
    read a file in protobuf binary
    """
    offline_features = offline_features_pb2.Features()
    with open(filename, 'rb') as file_in:
        offline_features.ParseFromString(file_in.read())
    return offline_features.feature


def load_label_feature(filename):
    features = []
    with open(filename, 'rb') as f:
        size = readVarint32(f)
        while size:
            read_bytes, _ = decoder._DecodeVarint32(size, 0)
            data = f.read(read_bytes)
            if len(data) < read_bytes:
                print("Failed to load protobuf")
                break
            fea = feature_pb2.Feature()
            fea.ParseFromString(data)
            features.append(fea)
            size = readVarint32(f)
    return features


def save_protobuf(filename, feature_trajectories):
    """
    save a features in the given filename
    """
    with open(filename, 'wb') as f:
        for features in feature_trajectories:
            for fea in features:
                serializedMessage = fea.SerializeToString()
                delimiter = encoder._VarintBytes(len(serializedMessage))
                f.write(delimiter + serializedMessage)


def build_trajectory(features):
    """
    classify features by id and build trajectories of feature
    """
    fea_dict = dict()
    for fea in features:
        if fea.id in fea_dict.keys():
            fea_dict[fea.id].append(fea)
        else:
            fea_dict[fea.id] = [fea]

    for k in fea_dict.keys():
        if len(fea_dict[k]) < 2:
            del fea_dict[k]
            continue
        fea_dict[k].sort(key=lambda x: x.timestamp)

    return fea_dict
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import os
import logging
import logging.handlers


def init_log(
        log_path,
        level=logging.INFO,
        when="D",
        backup=7,
        format="%(levelname)s: %(asctime)s: %(filename)s:%(lineno)d * %(thread)d %(message)s",
        datefmt="%m-%d %H:%M:%S"):
    formatter = logging.Formatter(format, datefmt)
    logger = logging.getLogger()
    logger.setLevel(level)

    dir = os.path.dirname(log_path)
    if not os.path.isdir(dir):
        os.makedirs(dir)

    handler = logging.handlers.TimedRotatingFileHandler(
        log_path + ".log", when=when, backupCount=backup)
    handler.setLevel(level)
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    handler = logging.handlers.TimedRotatingFileHandler(
        log_path + ".log.wf", when=when, backupCount=backup)
    handler.setLevel(logging.WARNING)
    handler.setFormatter(formatter)
    logger.addHandler(handler)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import abc
import logging
import math

from google.protobuf.internal import decoder
from google.protobuf.internal import encoder
import numpy as np

from modules.prediction.proto import offline_features_pb2
from modules.tools.prediction.data_pipelines.common.bounding_rectangle import BoundingRectangle
from modules.tools.prediction.data_pipelines.common.configure import parameters


param_fea = parameters['feature']


class LabelGenerator(object):

    def __init__(self):
        self.filepath = None
        '''
        feature_dict contains the organized Feature in the following way:
            obstacle_ID --> [Feature1, Feature2, Feature3, ...] (sequentially sorted)
        '''
        self.feature_dict = dict()

        '''
        observation_dict contains the important observations of the subsequent
        Features for each obstacle at every timestamp:
            obstacle_ID@timestamp --> dictionary of observations
        where dictionary of observations contains:
            'obs_traj': the trajectory points (x, y, vel_heading) up to
                        max_observation_time this trajectory poitns must
                        be consecutive (0.1sec sampling period)
            'obs_traj_len': length of trajectory points
            'obs_actual_lane_ids': the actual sequence of lane_segment ids
                                   the obstacle steps on
            'has_started_lane_change': whether the obstacle has started lane
                                       changing within max_observation_time
            'has_finished_lane_change': whether it has finished lane changing
            'lane_change_start_time':
            'lane_change_finish_time':
            'is_jittering':
            'new_lane_id':
            'total_observed_time_span':
        This observation_dict, once constructed, can be reused by various labeling
        functions.
        '''
        self.observation_dict = dict()
        self.future_status_dict = dict()
        self.cruise_label_dict = dict()
        self.junction_label_dict = dict()

    def LoadFeaturePBAndSaveLabelFiles(self, input_filepath):
        '''
        This function will be used to replace all the functionalities in
        generate_cruise_label.py
        '''
        self.filepath = input_filepath
        feature_sequences = self.LoadPBFeatures(input_filepath)
        self.OrganizeFeatures(feature_sequences)
        del feature_sequences  # Try to free up some memory
        self.ObserveAllFeatureSequences()

    '''
    @brief: parse the pb file of Feature of all obstacles at all times.
    @input filepath: the path of the pb file that contains all the features of
                     every obstacle at every timestamp.
    @output: python readable format of the same content.
    '''

    def LoadPBFeatures(self, filepath):
        self.filepath = filepath
        offline_features = offline_features_pb2.Features()
        with open(filepath, 'rb') as file_in:
            offline_features.ParseFromString(file_in.read())
        return offline_features.feature

    '''
    @brief: save the feature_sequences to an output protobuf file.
    @input filepath: the path of the output pb file.
    @input feature_sequences: the content to be saved.
    '''
    @staticmethod
    def SaveOutputPB(filepath, pb_message):
        with open(filepath, 'wb') as file:
            serializedMessage = pb_message.SerializeToString()
            file.write(serializedMessage)

    '''
    @brief: organize the features by obstacle IDs first, then sort each
            obstacle's feature according to time sequence.
    @input features: the unorganized features
    @output: organized (meaning: grouped by obstacle ID and sorted by time)
             features.
    '''

    def OrganizeFeatures(self, features):
        # Organize Feature by obstacle_ID (put those belonging to the same obstacle together)
        for feature in features:
            if feature.id in self.feature_dict.keys():
                self.feature_dict[feature.id].append(feature)
            else:
                self.feature_dict[feature.id] = [feature]

        # For the same obstacle, sort the Feature sequentially.
        for obs_id in self.feature_dict.keys():
            if len(self.feature_dict[obs_id]) < 2:
                del self.feature_dict[obs_id]
                continue
            self.feature_dict[obs_id].sort(key=lambda x: x.timestamp)

    '''
    @brief: observe all feature sequences and build observation_dict.
    @output: the complete observation_dict.
    '''

    def ObserveAllFeatureSequences(self):
        for obs_id, feature_sequence in self.feature_dict.items():
            for idx, feature in enumerate(feature_sequence):
                if not feature.HasField('lane') or \
                   not feature.lane.HasField('lane_feature'):
                    # print('No lane feature, cancel labeling')
                    continue
                self.ObserveFeatureSequence(feature_sequence, idx)
        np.save(self.filepath + '.npy', self.observation_dict)

    '''
    @brief: Observe the sequence of Features following the Feature at
            idx_curr and save some important observations in the class
            so that it can be used by various label functions.
    @input feature_sequence: A sorted sequence of Feature corresponding to
                             one obstacle.
    @input idx_curr: The index of the current Feature to be labelled.
                     We will look at the subsequent Features following this
                     one to complete labeling.
    @output: All saved as class variables in observation_dict,
             including: its trajectory info and its lane changing info.
    '''

    def ObserveFeatureSequence(self, feature_sequence, idx_curr):
        # Initialization.
        feature_curr = feature_sequence[idx_curr]
        dict_key = "{}@{:.3f}".format(feature_curr.id, feature_curr.timestamp)
        if dict_key in self.observation_dict.keys():
            return

        # Record all the lane segments belonging to the lane sequence that the
        # obstacle is currently on.
        curr_lane_segments = set()
        for lane_sequence in feature_curr.lane.lane_graph.lane_sequence:
            if lane_sequence.vehicle_on_lane:
                for lane_segment in lane_sequence.lane_segment:
                    curr_lane_segments.add(lane_segment.lane_id)
        if len(curr_lane_segments) == 0:
            # print("Obstacle is not on any lane.")
            return

        # Declare needed varables.
        new_lane_id = None
        has_started_lane_change = False
        has_finished_lane_change = False
        lane_change_start_time = None
        lane_change_finish_time = None
        is_jittering = False
        feature_seq_len = len(feature_sequence)
        prev_timestamp = -1.0
        obs_actual_lane_ids = []
        obs_traj = []
        total_observed_time_span = 0.0

        # This goes through all the subsequent features in this sequence
        # of features up to the maximum_observation_time.
        for j in range(idx_curr, feature_seq_len):
            # If timespan exceeds max. observation time, then end observing.
            time_span = feature_sequence[j].timestamp - feature_curr.timestamp
            if time_span > param_fea['maximum_observation_time']:
                break
            total_observed_time_span = time_span

            #####################################################################
            # Update the obstacle trajectory:
            # Only update for consecutive (sampling rate = 0.1sec) points.
            obs_traj.append((feature_sequence[j].position.x,
                             feature_sequence[j].position.y,
                             feature_sequence[j].velocity_heading,
                             feature_sequence[j].speed,
                             feature_sequence[j].length,
                             feature_sequence[j].width,
                             feature_sequence[j].timestamp))

            #####################################################################
            # Update the lane-change info (mainly for cruise scenario):
            if feature_sequence[j].HasField('lane') and \
               feature_sequence[j].lane.HasField('lane_feature'):
                # If jittering or done, then jump over this part.
                if (is_jittering or has_finished_lane_change):
                    continue
                # Record the sequence of lane_segments the obstacle stepped on.
                lane_id_j = feature_sequence[j].lane.lane_feature.lane_id
                if lane_id_j not in obs_actual_lane_ids:
                    obs_actual_lane_ids.append(lane_id_j)
                # If step into another lane, label lane change to be started.
                if lane_id_j not in curr_lane_segments:
                    # If it's the first time, log new_lane_id
                    if not has_started_lane_change:
                        has_started_lane_change = True
                        lane_change_start_time = time_span
                        new_lane_id = lane_id_j
                else:
                    # If it stepped into other lanes and now comes back, it's jittering!
                    if has_started_lane_change:
                        is_jittering = True
                        continue
                # If roughly get to the center of another lane, label lane change to be finished.
                left_bound = feature_sequence[j].lane.lane_feature.dist_to_left_boundary
                right_bound = feature_sequence[j].lane.lane_feature.dist_to_right_boundary
                if left_bound / (left_bound + right_bound) > (0.5 - param_fea['lane_change_finish_condition']) and \
                   left_bound / (left_bound + right_bound) < (0.5 + param_fea['lane_change_finish_condition']):
                    if has_started_lane_change:
                        # This means that the obstacle has finished lane change.
                        has_finished_lane_change = True
                        lane_change_finish_time = time_span
                    else:
                        # This means that the obstacle moves back to the center
                        # of the original lane for the first time.
                        if lane_change_finish_time is None:
                            lane_change_finish_time = time_span

        if len(obs_actual_lane_ids) == 0:
            # print("No lane id")
            return

        # Update the observation_dict:
        dict_val = dict()
        dict_val['obs_traj'] = obs_traj
        dict_val['obs_traj_len'] = len(obs_traj)
        dict_val['obs_actual_lane_ids'] = obs_actual_lane_ids
        dict_val['has_started_lane_change'] = has_started_lane_change
        dict_val['has_finished_lane_change'] = has_finished_lane_change
        dict_val['lane_change_start_time'] = lane_change_start_time
        dict_val['lane_change_finish_time'] = lane_change_finish_time
        dict_val['is_jittering'] = is_jittering
        dict_val['new_lane_id'] = new_lane_id
        dict_val['total_observed_time_span'] = total_observed_time_span
        self.observation_dict["{}@{:.3f}".format(
            feature_curr.id, feature_curr.timestamp)] = dict_val
        return

    '''
    @brief Based on the observation, label each lane sequence accordingly:
              - label whether the obstacle is on the lane_sequence
                within a certain amount of time.
              - if there is lane chage, label the time it takes to get to that lane.
    '''

    def LabelSingleLane(self, period_of_interest=3.0):
        output_features = offline_features_pb2.Features()
        for obs_id, feature_sequence in self.feature_dict.items():
            feature_seq_len = len(feature_sequence)
            for idx, feature in enumerate(feature_sequence):
                if not feature.HasField('lane') or \
                   not feature.lane.HasField('lane_feature'):
                    # print "No lane feature, cancel labeling"
                    continue

                # Observe the subsequent Features
                if "{}@{:.3f}".format(feature.id, feature.timestamp) not in self.observation_dict:
                    continue
                observed_val = self.observation_dict["{}@{:.3f}".format(
                    feature.id, feature.timestamp)]

                lane_sequence_dict = dict()
                # Based on the observation, label data.
                for lane_sequence in feature.lane.lane_graph.lane_sequence:
                    # Sanity check.
                    if len(lane_sequence.lane_segment) == 0:
                        print('There is no lane segment in this sequence.')
                        continue

                    # Handle jittering data
                    if observed_val['is_jittering']:
                        lane_sequence.label = -10
                        lane_sequence.time_to_lane_center = -1.0
                        lane_sequence.time_to_lane_edge = -1.0
                        continue

                    # Handle the case that we didn't obesrve enough Features to label
                    if observed_val['total_observed_time_span'] < period_of_interest and \
                       not observed_val['has_started_lane_change']:
                        lane_sequence.label = -20
                        lane_sequence.time_to_lane_center = -1.0
                        lane_sequence.time_to_lane_edge = -1.0

                    # The current lane is obstacle's original lane. (labels: 0,2,4)
                    if lane_sequence.vehicle_on_lane:
                        # Obs is following ONE OF its original lanes:
                        if not observed_val['has_started_lane_change'] or \
                           observed_val['lane_change_start_time'] > period_of_interest:
                            # Record this lane_sequence's lane_ids
                            current_lane_ids = []
                            for k in range(len(lane_sequence.lane_segment)):
                                if lane_sequence.lane_segment[k].HasField('lane_id'):
                                    current_lane_ids.append(lane_sequence.lane_segment[k].lane_id)

                            is_following_this_lane = True
                            for l_id in range(1, min(len(current_lane_ids),
                                                     len(observed_val['obs_actual_lane_ids']))):
                                if current_lane_ids[l_id] != observed_val['obs_actual_lane_ids'][l_id]:
                                    is_following_this_lane = False
                                    break

                            # Obs is following this original lane:
                            if is_following_this_lane:
                                # Obstacle is following this original lane and moved to lane-center
                                if observed_val['lane_change_finish_time'] is not None:
                                    lane_sequence.label = 4
                                    lane_sequence.time_to_lane_edge = -1.0
                                    lane_sequence.time_to_lane_center = -1.0
                                # Obstacle is following this original lane but is never at lane-center:
                                else:
                                    lane_sequence.label = 2
                                    lane_sequence.time_to_lane_edge = -1.0
                                    lane_sequence.time_to_lane_center = -1.0
                            # Obs is following another original lane:
                            else:
                                lane_sequence.label = 0
                                lane_sequence.time_to_lane_edge = -1.0
                                lane_sequence.time_to_lane_center = -1.0

                        # Obs has stepped out of this lane within period_of_interest.
                        else:
                            lane_sequence.label = 0
                            lane_sequence.time_to_lane_edge = -1.0
                            lane_sequence.time_to_lane_center = -1.0

                    # The current lane is NOT obstacle's original lane. (labels: -1,1,3)
                    else:
                        # Obstacle is following the original lane.
                        if not observed_val['has_started_lane_change'] or \
                           observed_val['lane_change_start_time'] > period_of_interest:
                            lane_sequence.label = -1
                            lane_sequence.time_to_lane_edge = -1.0
                            lane_sequence.time_to_lane_center = -1.0
                        else:
                            new_lane_id_is_in_this_lane_seq = False
                            for lane_segment in lane_sequence.lane_segment:
                                if lane_segment.lane_id == observed_val['new_lane_id']:
                                    new_lane_id_is_in_this_lane_seq = True
                                    break
                            # Obstacle has changed to this lane.
                            if new_lane_id_is_in_this_lane_seq:
                                # Obstacle has finished lane changing within time_of_interest.
                                if observed_val['has_finished_lane_change'] and \
                                   observed_val['lane_change_finish_time'] < period_of_interest:
                                    lane_sequence.label = 3
                                    lane_sequence.time_to_lane_edge = observed_val['lane_change_start_time']
                                    lane_sequence.time_to_lane_center = observed_val['lane_change_finish_time']
                                # Obstacle started lane changing but haven't finished yet.
                                else:
                                    lane_sequence.label = 1
                                    lane_sequence.time_to_lane_edge = observed_val['lane_change_start_time']
                                    lane_sequence.time_to_lane_center = -1.0

                            # Obstacle has changed to some other lane.
                            else:
                                lane_sequence.label = -1
                                lane_sequence.time_to_lane_edge = -1.0
                                lane_sequence.time_to_lane_center = -1.0

                for lane_sequence in feature.lane.lane_graph.lane_sequence:
                    lane_sequence_dict[lane_sequence.lane_sequence_id] = [lane_sequence.label,
                                                                          lane_sequence.time_to_lane_center, lane_sequence.time_to_lane_edge]
                self.cruise_label_dict["{}@{:.3f}".format(
                    feature.id, feature.timestamp)] = lane_sequence_dict
        np.save(self.filepath + '.cruise_label.npy', self.cruise_label_dict)

    def LabelTrajectory(self, period_of_interest=3.0):
        output_features = offline_features_pb2.Features()
        for obs_id, feature_sequence in self.feature_dict.items():
            for idx, feature in enumerate(feature_sequence):
                # Observe the subsequent Features
                if "{}@{:.3f}".format(feature.id, feature.timestamp) not in self.observation_dict:
                    continue
                observed_val = self.observation_dict["{}@{:.3f}".format(
                    feature.id, feature.timestamp)]
                self.future_status_dict["{}@{:.3f}".format(
                    feature.id, feature.timestamp)] = observed_val['obs_traj']
        np.save(self.filepath + '.future_status.npy', self.future_status_dict)
        #         for point in observed_val['obs_traj']:
        #             traj_point = feature.future_trajectory_points.add()
        #             traj_point.path_point.x = point[0]
        #             traj_point.path_point.y = point[1]
        #             traj_point.path_point.velocity_heading = point[2]
        #             traj_point.timestamp = point[3]

        #         output_features.feature.add().CopyFrom(feature)

        # self.SaveOutputPB(self.filepath + '.future_status.label', output_features)

    def LabelJunctionExit(self):
        '''
        label feature trajectory according to real future lane sequence in 7s
        '''
        output_features = offline_features_pb2.Features()
        for obs_id, feature_sequence in self.feature_dict.items():
            feature_seq_len = len(feature_sequence)
            for i, fea in enumerate(feature_sequence):
                # Sanity check.
                if not fea.HasField('junction_feature') or \
                   not len(fea.junction_feature.junction_exit):
                    # print("No junction_feature, junction_exit, or junction_mlp_feature, not labeling this frame.")
                    continue
                curr_pos = np.array([fea.position.x, fea.position.y])
                # Only keep speed > 1
                # TODO(all) consider recovery
                # if fea.speed <= 1:
                #     continue
                heading = math.atan2(fea.raw_velocity.y, fea.raw_velocity.x)
                # Construct dictionary of all exit with dict[exit_lane_id] = np.array(exit_position)
                exit_dict = dict()
                exit_pos_dict = dict()
                mask = [0] * 12
                for junction_exit in fea.junction_feature.junction_exit:
                    if junction_exit.HasField('exit_lane_id'):
                        exit_dict[junction_exit.exit_lane_id] = \
                            BoundingRectangle(junction_exit.exit_position.x,
                                              junction_exit.exit_position.y,
                                              junction_exit.exit_heading,
                                              0.01,
                                              junction_exit.exit_width)
                        exit_pos = np.array([junction_exit.exit_position.x,
                                             junction_exit.exit_position.y])
                        exit_pos_dict[junction_exit.exit_lane_id] = exit_pos
                        delta_pos = exit_pos - curr_pos
                        angle = math.atan2(delta_pos[1], delta_pos[0]) - heading
                        d_idx = int((angle / (2.0 * np.pi) + 1.0 / 24) * 12 % 12)
                        mask[d_idx] = 1

                # Searching for up to 100 frames (10 seconds)
                for j in range(i, min(i + 100, feature_seq_len)):
                    car_bounding = BoundingRectangle(feature_sequence[j].position.x,
                                                     feature_sequence[j].position.y,
                                                     math.atan2(feature_sequence[j].raw_velocity.y,
                                                                feature_sequence[j].raw_velocity.x),
                                                     feature_sequence[j].length,
                                                     feature_sequence[j].width)
                    for key, value in exit_dict.items():
                        if car_bounding.overlap(value):
                            exit_pos = exit_pos_dict[key]
                            delta_pos = exit_pos - curr_pos
                            angle = math.atan2(
                                delta_pos[1], delta_pos[0]) - heading
                            d_idx = int((angle / (2.0 * np.pi) + 1.0 / 24) * 12 % 12)
                            label = [0] * 12
                            label[d_idx] = 1
                            fea.junction_feature.junction_mlp_label.extend(label)
                            self.junction_label_dict["{}@{:.3f}".format(
                                fea.id, fea.timestamp)] = label + mask
                            break  # actually break two level
                    else:
                        continue
                    break
        np.save(self.filepath + '.junction_label.npy', self.junction_label_dict)
        #         if fea.HasField('junction_feature') and \
        #            len(fea.junction_feature.junction_mlp_label) > 0:
        #             output_features.feature.add().CopyFrom(fea)

        # self.SaveOutputPB(self.filepath + '.junction.label', output_features)

    def Label(self):
        self.LabelTrajectory()
        self.LabelSingleLane()
        self.LabelJunctionExit()
        # TODO(all):
        #   - implement label multiple lane
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


from math import cos, sin
from modules.tools.prediction.data_pipelines.common.vector2d import Vector2


def rotate(v, theta):
    cos_theta = cos(theta)
    sin_theta = sin(theta)

    return rotate_fast(v, cos_theta, sin_theta)


def rotate_fast(v, cos_theta, sin_theta):
    x = cos_theta * v.x - sin_theta * v.y
    y = sin_theta * v.x + cos_theta * v.y

    return Vector2(x, y)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import abc
import logging
import math

import numpy as np

from modules.tools.prediction.data_pipelines.common.bounding_rectangle import BoundingRectangle
from modules.tools.prediction.data_pipelines.common.configure import parameters


param_fea = parameters['feature']


class TrajectoryToSample(object, metaclass=abc.ABCMeta):

    def __call__(self, trajectory):
        self.clean(trajectory)
        self.label(trajectory)
        data = self.pack(trajectory)
        return data

    @staticmethod
    def clean(trajectory):
        '''
        Clean up the feature points when lane_id changing abruptly,
        meaning that if the lane_id of current timestamp is different
        from that of the previous one and that of the next one, remove
        this contaminated data.
        '''
        results = []
        traj_len = len(trajectory)
        for i in range(traj_len - 2, 0, -1):
            if not trajectory[i].HasField('lane') or \
               not trajectory[i].lane.HasField('lane_feature'):
                continue

            lane_seq_sz = len(trajectory[i].lane.lane_graph.lane_sequence)
            if lane_seq_sz == 0:
                continue
            elif lane_seq_sz > 10:
                print("Too many lane sequences:", lane_seq_sz)

            fea_prev = trajectory[i - 1]
            fea_curr = trajectory[i]
            fea_post = trajectory[i + 1]

            if fea_prev.HasField('lane') and \
               fea_prev.lane.HasField('lane_feature'):
                lane_id_prev = fea_prev.lane.lane_feature.lane_id
            else:
                continue

            if fea_curr.HasField('lane') and \
               fea_curr.lane.HasField('lane_feature'):
                lane_id_curr = fea_curr.lane.lane_feature.lane_id
            else:
                continue

            if fea_post.HasField('lane') and \
               fea_post.lane.HasField('lane_feature'):
                lane_id_post = fea_post.lane.lane_feature.lane_id
            else:
                continue

            if lane_id_curr == lane_id_prev or lane_id_curr == lane_id_post:
                results.append(trajectory[i])

        results.reverse()
        return results

    @staticmethod
    def cmp_lane_seq(real_seq, predict_seq):
        '''
        -1: False Cutin
        0:  False Go
        1:  True Go
        2:  True Cutin
        '''
        if real_seq[0] == predict_seq[0]:
            for i in range(1, len(real_seq)):
                if len(real_seq) > len(predict_seq):
                    return 0
                if real_seq[i] != predict_seq[i]:
                    return 0
            return 1

        else:
            if len(real_seq) == 1:
                return -1

            for i in range(1, len(real_seq)):
                if len(real_seq) - 1 > len(predict_seq):
                    return -1
                if real_seq[i] != predict_seq[i - 1]:
                    return -1
            return 2

    def is_successor_lane(self, feature, lane_id):
        '''
        return True if lane_id is the successor lane of feature
        '''
        if feature.HasField('lane') and \
           feature.lane.HasField('lane_graph') and \
           len(feature.lane.lane_graph.lane_sequence) > 0:
            for lane_seq in feature.lane.lane_graph.lane_sequence:
                seq_lane_ids = []
                for lan_seq in lane_seq.lane_segment:
                    seq_lane_ids.append(lane_seg.lane_id)
                if feature.lane.lane_feature.lane_id in seq_lane_ids and \
                   lane_id in seq_lane_ids:
                    return True
            return False
        else:
            return True

    @classmethod
    def label(cls, trajectory):
        '''
        label feature trajectory according to real future lane sequence in 3s
        '''
        traj_len = len(trajectory)
        for i, fea in enumerate(trajectory):
            if not fea.HasField('lane') or \
               not fea.lane.HasField('lane_feature'):
                print("No lane feature, cancel labeling")
                continue

            future_lane_ids = []
            for j in range(i, traj_len):
                time_span = trajectory[j].timestamp - fea.timestamp
                if time_span > param_fea['prediction_label_timeframe']:
                    break
                if not trajectory[j].HasField('lane') or \
                   not trajectory[j].lane.HasField('lane_feature'):
                    continue

                lane_id_j = trajectory[j].lane.lane_feature.lane_id
                trajectory[i].label_update_time_delta = time_span
                if lane_id_j in future_lane_ids:
                    continue
                else:
                    future_lane_ids.append(lane_id_j)

            if len(future_lane_ids) < 1:
                print("No lane id")
                continue

            seq_size = len(fea.lane.lane_graph.lane_sequence)
            for j in range(seq_size):
                seq = fea.lane.lane_graph.lane_sequence[j]
                if len(seq.lane_segment) == 0:
                    continue
                predict_lane_ids = []
                for k in range(len(seq.lane_segment)):
                    if seq.lane_segment[k].HasField('lane_id'):
                        predict_lane_ids.append(seq.lane_segment[k].lane_id)

                seq.label = cls.cmp_lane_seq(future_lane_ids, predict_lane_ids)
        return trajectory

    @classmethod
    def label_cruise(cls, feature_sequence):
        '''
        Label feature trajectory according to real future lane sequence
        in 6sec
        '''
        feature_seq_len = len(feature_sequence)
        for i, fea in enumerate(feature_sequence):
            # Sanity check.
            if not fea.HasField('lane') or \
               not fea.lane.HasField('lane_feature'):
                print("No lane feature, cancel labeling")
                continue

            # Find the lane_sequence at which the obstacle is located,
            # and put all the lane_segment ids into a set.
            curr_lane_seq = set()
            for lane_sequence in fea.lane.lane_graph.lane_sequence:
                if lane_sequence.vehicle_on_lane:
                    for lane_segment in lane_sequence.lane_segment:
                        curr_lane_seq.add(lane_segment.lane_id)
            if len(curr_lane_seq) == 0:
                print("Obstacle is not on any lane.")
                continue

            new_lane_id = None
            has_started_lane_change = False
            has_finished_lane_change = False
            lane_change_start_time = None
            lane_change_finish_time = None
            is_jittering = False

            # This goes through all the subsequent features in this sequence
            # of features (this is the GROUND_TRUTH!)
            obs_actual_lane_ids = []
            for j in range(i, feature_seq_len):
                # If timespan exceeds max. maneuver finish time, then break.
                time_span = feature_sequence[j].timestamp - fea.timestamp
                if time_span > param_fea['maximum_maneuver_finish_time']:
                    break

                # Sanity check.
                if not feature_sequence[j].HasField('lane') or \
                   not feature_sequence[j].lane.HasField('lane_feature'):
                    continue
                fea.label_update_time_delta = time_span

                # If step into another lane, label lane change to be started.
                lane_id_j = feature_sequence[j].lane.lane_feature.lane_id

                if lane_id_j not in obs_actual_lane_ids:
                    obs_actual_lane_ids.append(lane_id_j)

                if lane_id_j not in curr_lane_seq:
                    # If it's the first time, log new_lane_id
                    if has_started_lane_change == False:
                        has_started_lane_change = True
                        lane_change_start_time = time_span
                        new_lane_id = lane_id_j
                else:
                    # If it stepped into other lanes and now comes back, it's jittering!
                    if has_started_lane_change:
                        is_jittering = True
                        # This is to let such data not be eliminated by label_file function
                        fea.label_update_time_delta = param_fea['maximum_maneuver_finish_time']
                        break

                # If roughly get to the center of another lane, label lane change to be finished.
                left_bound = feature_sequence[j].lane.lane_feature.dist_to_left_boundary
                right_bound = feature_sequence[j].lane.lane_feature.dist_to_right_boundary
                if left_bound / (left_bound + right_bound) > (0.5 - param_fea['lane_change_finish_condition']) and \
                   left_bound / (left_bound + right_bound) < (0.5 + param_fea['lane_change_finish_condition']):
                    if has_started_lane_change:
                        has_finished_lane_change = True
                        lane_change_finish_time = time_span
                        # new_lane_id = lane_id_j

                        # This is to let such data not be eliminated by label_file function
                        fea.label_update_time_delta = param_fea['maximum_maneuver_finish_time']
                        break
                    else:
                        # This means that the obstacle moves back to the center
                        # of the original lane for the first time.
                        if lane_change_finish_time is None:
                            lane_change_finish_time = time_span

            if len(obs_actual_lane_ids) < 1:
                print("No lane id")
                continue

            '''
            For every lane_sequence in the lane_graph,
            assign a label and a finish_time.

            -10: Lane jittering

            -1: False Cut-in
            1: True Cut-in but not to lane_center
            3: True Cut-in and reached lane_center

            0: Fales Go
            2: True Go but not to lane_center
            4: True Go and reached lane_center
            '''

            # This is to label each saved lane_sequence.
            for lane_sequence in fea.lane.lane_graph.lane_sequence:
                # Sanity check.
                if len(lane_sequence.lane_segment) == 0:
                    continue

                if is_jittering:
                    lane_sequence.label = -10
                    lane_sequence.time_to_lane_center = -1.0
                    lane_sequence.time_to_lane_edge = -1.0
                    continue

                # The current lane is obstacle's original lane.
                if lane_sequence.vehicle_on_lane:

                    # Obs is following ONE OF its original lanes:
                    if not has_started_lane_change:
                        # Record this lane_sequence's lane_ids
                        current_lane_ids = []
                        for k in range(len(lane_sequence.lane_segment)):
                            if lane_sequence.lane_segment[k].HasField('lane_id'):
                                current_lane_ids.append(
                                    lane_sequence.lane_segment[k].lane_id)

                        is_following_this_lane = True
                        for l_id in range(1, min(len(current_lane_ids), len(obs_actual_lane_ids))):
                            if current_lane_ids[l_id] != obs_actual_lane_ids[l_id]:
                                is_following_this_lane = False
                                break

                        # Obs is following this original lane:
                        if is_following_this_lane:
                            # Obstacle is following this original lane and moved to lane-center
                            if lane_change_finish_time is not None:
                                lane_sequence.label = 4
                                lane_sequence.time_to_lane_edge = -1.0
                                lane_sequence.time_to_lane_center = lane_change_finish_time
                            # Obstacle is following this original lane but is never at lane-center:
                            else:
                                lane_sequence.label = 2
                                lane_sequence.time_to_lane_edge = -1.0
                                lane_sequence.time_to_lane_center = -1.0
                        # Obs is following another original lane:
                        else:
                            lane_sequence.label = 0
                            lane_sequence.time_to_lane_edge = -1.0
                            lane_sequence.time_to_lane_center = -1.0

                    # Obs has stepped out of this lane within 6sec.
                    else:
                        lane_sequence.label = 0
                        lane_sequence.time_to_lane_edge = -1.0
                        lane_sequence.time_to_lane_center = -1.0

                # The current lane is NOT obstacle's original lane.
                else:
                    # Obstacle is following the original lane.
                    if not has_started_lane_change:
                        lane_sequence.label = -1
                        lane_sequence.time_to_lane_edge = -1.0
                        lane_sequence.time_to_lane_center = -1.0
                    else:
                        new_lane_id_is_in_this_lane_seq = False
                        for lane_segment in lane_sequence.lane_segment:
                            if lane_segment.lane_id == new_lane_id:
                                new_lane_id_is_in_this_lane_seq = True
                                break
                        # Obstacle has changed to this lane.
                        if new_lane_id_is_in_this_lane_seq:
                            # Obstacle has finished lane changing within 6 sec.
                            if has_finished_lane_change:
                                lane_sequence.label = 3
                                lane_sequence.time_to_lane_edge = lane_change_start_time
                                lane_sequence.time_to_lane_center = lane_change_finish_time
                            # Obstacle started lane changing but haven't finished yet.
                            else:
                                lane_sequence.label = 1
                                lane_sequence.time_to_lane_edge = lane_change_start_time
                                lane_sequence.time_to_lane_center = -1.0

                        # Obstacle has changed to some other lane.
                        else:
                            lane_sequence.label = -1
                            lane_sequence.time_to_lane_edge = -1.0
                            lane_sequence.time_to_lane_center = -1.0

        return feature_sequence

    @classmethod
    def label_junction(cls, trajectory):
        '''
        label feature trajectory according to real future lane sequence in 7s
        '''
        traj_len = len(trajectory)
        for i, fea in enumerate(trajectory):
            # Sanity check.
            if not fea.HasField('junction_feature') or \
               not len(fea.junction_feature.junction_exit) or \
               not len(fea.junction_feature.junction_mlp_feature):
                # print("No junction_feature, junction_exit, or junction_mlp_feature, not labeling this frame.")
                continue
            curr_pos = np.array([fea.position.x, fea.position.y])
            # Only keep speed > 1
            # TODO(all) consider recovery
            # if fea.speed <= 1:
            #     continue
            heading = math.atan2(fea.raw_velocity.y, fea.raw_velocity.x)
            # Construct dictionary of all exit with dict[exit_lane_id] = np.array(exit_position)
            exit_dict = dict()
            exit_pos_dict = dict()
            for junction_exit in fea.junction_feature.junction_exit:
                if junction_exit.HasField('exit_lane_id'):
                    exit_dict[junction_exit.exit_lane_id] = \
                        BoundingRectangle(junction_exit.exit_position.x,
                                          junction_exit.exit_position.y,
                                          junction_exit.exit_heading,
                                          0.01,
                                          junction_exit.exit_width)
                    exit_pos_dict[junction_exit.exit_lane_id] = np.array(
                        [junction_exit.exit_position.x, junction_exit.exit_position.y])
            # Searching for up to 100 frames (10 seconds)
            for j in range(i, min(i + 100, traj_len)):
                car_bounding = BoundingRectangle(trajectory[j].position.x,
                                                 trajectory[j].position.y,
                                                 math.atan2(trajectory[j].raw_velocity.y,
                                                            trajectory[j].raw_velocity.x),
                                                 trajectory[j].length,
                                                 trajectory[j].width)
                for key, value in exit_dict.items():
                    if car_bounding.overlap(value):
                        exit_pos = exit_pos_dict[key]
                        delta_pos = exit_pos - curr_pos
                        angle = math.atan2(
                            delta_pos[1], delta_pos[0]) - heading
                        d_idx = int((angle / (2.0 * np.pi)) * 12 % 12)
                        label = [0 for idx in range(12)]
                        label[d_idx] = 1
                        fea.junction_feature.junction_mlp_label.extend(label)
                        break  # actually break two level
                else:
                    continue
                break
        return trajectory

    @abc.abstractmethod
    def pack(self, trajectory):
        """ abstractmethod"""
        raise NotImplementedError
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


def segment_overlap(a, b, x, y):
    if b < x or a > y:
        return False

    return True


def vector_projection_overlap(p0, p1, p2, p3):
    v = p1.subtract(p0)
    n_square = v.norm_square()

    v0 = p2.subtract(p0)
    v1 = p3.subtract(p0)

    t0 = v0.dot(v)
    t1 = v1.dot(v)

    if t0 > t1:
        t = t0
        t0 = t1
        t1 = t

    return segment_overlap(t0, t1, 0.0, n_square)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
from math import sqrt


class Vector2:
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def add(self, v):
        return Vector2(self.x + v.x, self.y + v.y)

    def subtract(self, v):
        return Vector2(self.x - v.x, self.y - v.y)

    def dot(self, v):
        return self.x * v.x + self.y * v.y

    def norm(self):
        return sqrt(self.x * self.x + self.y * self.y)

    def norm_square(self):
        return self.x * self.x + self.y * self.y

    def print_point(self):
        print(str(self.x) + "\t" + str(self.y) + "\n")
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
@requirement:
    pytorch 0.4.1
"""

import argparse
import logging
import os

from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from torch.autograd import Variable
from torch.utils.data import Dataset, DataLoader, sampler
import h5py
import numpy as np
import sklearn
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from modules.tools.prediction.data_pipelines.common.configure import parameters
from modules.tools.prediction.data_pipelines.cruise_models import FullyConn_NN, FCNN_CNN1D
from modules.tools.prediction.data_pipelines.proto.cruise_model_pb2 import TensorParameter, InputParameter,\
    Conv1dParameter, DenseParameter, ActivationParameter, MaxPool1dParameter,\
    AvgPool1dParameter, LaneFeatureConvParameter, ObsFeatureFCParameter,\
    ClassifyParameter, RegressParameter, CruiseModelParameter


# TODO(panjiacheng): the data-loader part needs to be modified.

# Constants
dim_input = parameters['cruise_mlp']['dim_input']
dim_hidden_1 = parameters['cruise_mlp']['dim_hidden_1']
dim_hidden_2 = parameters['cruise_mlp']['dim_hidden_2']
dim_output = parameters['cruise_mlp']['dim_output']

# Setup
cuda_is_available = torch.cuda.is_available()
logging.basicConfig(filename='training.log', level=logging.INFO)


def load_Conv1dParameter(model, key, stride=1):

    model_pb = Conv1dParameter()

    model_pb.shape.extend(list(model.state_dict()[key+'.weight'].shape))

    model_pb.use_bias = True

    kernel_param = TensorParameter()
    kernel_param.shape.extend(list(model.state_dict()[key+'.weight'].shape))
    kernel_param.data.extend(
        list(model.state_dict()[key+'.weight'].numpy().reshape(-1)))
    model_pb.kernel.CopyFrom(kernel_param)

    bias_param = TensorParameter()
    bias_param.shape.extend(list(model.state_dict()[key+'.bias'].shape))
    bias_param.data.extend(
        list(model.state_dict()[key+'.bias'].numpy().reshape(-1)))
    model_pb.bias.CopyFrom(bias_param)

    model_pb.stride = stride

    return model_pb


def load_DenseParameter(model, key):

    model_pb = DenseParameter()

    model_pb.use_bias = True

    weights_param = TensorParameter()
    weights_param.shape.extend(
        list(model.state_dict()[key+'.weight'].numpy().T.shape))
    weights_param.data.extend(
        list(model.state_dict()[key+'.weight'].numpy().T.reshape(-1)))
    model_pb.weights.CopyFrom(weights_param)

    bias_param = TensorParameter()
    bias_param.shape.extend(
        list(model.state_dict()[key+'.bias'].numpy().shape))
    bias_param.data.extend(list(model.state_dict()[key+'.bias'].numpy()))
    model_pb.bias.CopyFrom(bias_param)

    model_pb.units = model_pb.bias.shape[0]

    return model_pb


def save_FCNN_CNN1D(model, filename):

    model_pb = CruiseModelParameter()

    lane_feature_conv = LaneFeatureConvParameter()
    lane_feature_conv.conv1d_0.CopyFrom(
        load_Conv1dParameter(model, 'lane_feature_conv.0', stride=1))
    lane_feature_conv.activation_1.activation = 'relu'
    lane_feature_conv.conv1d_2.CopyFrom(
        load_Conv1dParameter(model, 'lane_feature_conv.2', stride=2))
    lane_feature_conv.activation_3.activation = 'relu'
    lane_feature_conv.conv1d_4.CopyFrom(
        load_Conv1dParameter(model, 'lane_feature_conv.4', stride=2))

    lane_feature_maxpool = MaxPool1dParameter()
    lane_feature_maxpool.kernel_size = 3
    lane_feature_maxpool.stride = 3

    lane_feature_avgpool = AvgPool1dParameter()
    lane_feature_avgpool.kernel_size = 3
    lane_feature_avgpool.stride = 3

    obs_feature_fc = ObsFeatureFCParameter()
    obs_feature_fc.linear_0.CopyFrom(
        load_DenseParameter(model, 'obs_feature_fc.0'))
    obs_feature_fc.activation_1.activation = 'sigmoid'
    obs_feature_fc.linear_3.CopyFrom(
        load_DenseParameter(model, 'obs_feature_fc.3'))
    obs_feature_fc.activation_4.activation = 'sigmoid'

    classify = ClassifyParameter()
    classify.linear_0.CopyFrom(load_DenseParameter(model, 'classify.0'))
    classify.activation_1.activation = 'sigmoid'
    classify.linear_3.CopyFrom(load_DenseParameter(model, 'classify.3'))
    classify.activation_4.activation = 'sigmoid'
    classify.linear_6.CopyFrom(load_DenseParameter(model, 'classify.6'))
    classify.activation_7.activation = 'sigmoid'
    classify.linear_9.CopyFrom(load_DenseParameter(model, 'classify.9'))
    classify.activation_10.activation = 'sigmoid'

    regress = RegressParameter()
    regress.linear_0.CopyFrom(load_DenseParameter(model, 'regress.0'))
    regress.activation_1.activation = 'relu'
    regress.linear_3.CopyFrom(load_DenseParameter(model, 'regress.3'))
    regress.activation_4.activation = 'relu'
    regress.linear_6.CopyFrom(load_DenseParameter(model, 'regress.6'))
    regress.activation_7.activation = 'relu'
    regress.linear_9.CopyFrom(load_DenseParameter(model, 'regress.9'))
    regress.activation_10.activation = 'relu'

    model_pb.lane_feature_conv.CopyFrom(lane_feature_conv)
    model_pb.lane_feature_maxpool.CopyFrom(lane_feature_maxpool)
    model_pb.lane_feature_avgpool.CopyFrom(lane_feature_avgpool)
    model_pb.obs_feature_fc.CopyFrom(obs_feature_fc)
    model_pb.classify.CopyFrom(classify)
    model_pb.regress.CopyFrom(regress)

    with open(filename, 'wb') as params_file:
        params_file.write(model_pb.SerializeToString())


'''
Custom defined loss function that lumps the loss of classification and
of regression together.
'''


def loss_fn(c_pred, r_pred, target, balance):
    loss_C = nn.BCEWithLogitsLoss(
        pos_weight=torch.FloatTensor([balance]).cuda())  # nn.BCELoss()
    loss_R = nn.MSELoss()

    #loss = loss_C(c_pred, target[:,0].view(target.shape[0],1))
    loss = 4 * loss_C(c_pred, target[:, 0].view(target.shape[0], 1)) + \
        loss_R(((target[:, 2] > 0.0) * (target[:, 2] <= 3.0)).float().view(target.shape[0], 1) * r_pred +
               ((target[:, 2] <= 0.0) + (target[:, 2] > 3.0)).float().view(
                   target.shape[0], 1) * target[:, 2].view(target.shape[0], 1),
               target[:, 2].view(target.shape[0], 1))
    # loss_R((target[:,1] < 10.0).float().view(target.shape[0],1) * r_pred + \
    #        (target[:,1] >= 10.0).float().view(target.shape[0],1) * target[:,1].view(target.shape[0],1), \
    #        target[:,1].view(target.shape[0],1))
    return loss


# ========================================================================
# Helper functions
'''
Get the full path of all files under the directory: 'dirName'
'''


def getListOfFiles(dirName):
    listOfFiles = os.listdir(dirName)
    allFiles = list()

    for entry in listOfFiles:
        fullPath = os.path.join(dirName, entry)
        if os.path.isdir(fullPath):
            allFiles = allFiles + getListOfFiles(fullPath)
        else:
            allFiles.append(fullPath)

    return allFiles


'''
Print the distribution of data labels.
'''


def print_dist(label):
    unique_labels = np.unique(label)
    for l in unique_labels:
        print('Label = {}: {}%'.format(l, np.sum(label == l)/len(label)*100))


# ========================================================================


# ========================================================================
# Data Loading and preprocessing (Non Data-Loader case)


def load_data(filename):
    '''
    Load the data from h5 file to the numpy format.
    (Only for non data-loader case)
    '''
    if not (os.path.exists(filename)):
        logging.error("file: {}, does not exist".format(filename))
        os._exit(1)
    if os.path.splitext(filename)[1] != '.h5':
        logging.error("file: {} is not an hdf5 file".format(filename))
        os._exit(1)

    samples = dict()
    h5_file = h5py.File(filename, 'r')
    for key in h5_file.keys():
        samples[key] = h5_file[key][:]

    print("load file success")
    return samples['data']


def load_npy_data(dir):
    '''
    Load all .npy files under a certain dir;
    merge them together into one;
    return.
    '''


def data_preprocessing(data):
    '''
    Preprocess the data.
    (Only for non data-loader case)
        - separate input X and output y
        - process output label from {-1,0,1,2,3,4} to {0,1}
        - Take out only those meaningful features
        - shuffle data
    '''
    # Various input features separation
    X_obs_old_features = data[:, 0:23]
    X_surround_obs = data[:, -dim_output-8:-dim_output]
    X_obs_now = data[:, 23:32]
    X_obs_hist_5 = data[:, 23:68]
    X_lane = data[:, 68:-dim_output-8]

    # mask out those that don't have any history
    # mask5 = (data[:,53] != 100)

    X = np.concatenate((X_obs_old_features, X_obs_hist_5, X_lane), axis=1)
    # X = X[mask5, :]
    y = data[:, -dim_output:]
    # y = y[mask5, :]

    # Binary classification
    y[:, 0] = (y[:, 0] > 0).astype(float)
    #y[:, 0] = np.logical_and((y[:, 0] > 0), (y[:, 1] < 1.0))

    # Random shuffling
    X_new, X_dummy, y_new, y_dummy = train_test_split(
        X, y, test_size=0.0, random_state=233)

    return X_new, y_new  # , X_dummy, y_dummy

# ========================================================================


# ========================================================================
# Data Loading and preprocessing (Data-Loader case)

'''
TODO: implement custom collate_fn to incorporate down-sampling function
for certain labels.
'''


def collate_wDownSample(batch):
    return None


'''
If datasets are too large, use Dataloader to load from disk.
'''


class TrainValidDataset(Dataset):
    '''
    Args:
      - root_dir (string): Directory containing all folders with different
        dates, each folder containing .cruise.h5 data files.
    '''

    def __init__(self, list_of_files):
        self.list_of_files_ = list_of_files
        self.data_size_until_this_file_ = []
        self.dataset_size = 0
        for file in self.list_of_files_:
            with h5py.File(file, 'r') as h5_file:
                data_size = h5_file[list(h5_file.keys())[0]].shape[0]
            self.dataset_size += data_size
            self.data_size_until_this_file_.append(self.dataset_size)
        #print ('Total size of dataset: {}'.format(self.data_size_until_this_file_))

    def __len__(self):
        return self.dataset_size

    def __getitem__(self, index):
        bin_idx = self.FindBin(index, 0, len(
            self.data_size_until_this_file_)-1)
        with h5py.File(self.list_of_files_[bin_idx], 'r') as h5_file:
            idx_offset = self.data_size_until_this_file_[bin_idx] - \
                h5_file[list(h5_file.keys())[0]].shape[0]
            data = h5_file[list(h5_file.keys())[0]][index-idx_offset]
        label = data[-dim_output:]
        label[0] = (label[0] > 0.0).astype(float)
        return data[:-dim_output], label

    # Binary search to expedite the data-loading process.
    def FindBin(self, index, start, end):
        if (start == end):
            return start

        mid = int((start+end)/2.0)
        if (self.data_size_until_this_file_[mid] <= index):
            return self.FindBin(index, mid+1, end)
        else:
            return self.FindBin(index, start, mid)
# ========================================================================


# ========================================================================
# Data training and validation

'''
Train the data. (vanilla version without dataloader)
'''


def train_vanilla(train_X, train_y, model, optimizer, epoch, batch_size=2048, balance=1.0):
    model.train()

    loss_history = []
    logging.info('Epoch: {}'.format(epoch+1))
    print('Epoch: {}.'.format(epoch+1))
    num_of_data = train_X.shape[0]
    num_of_batch = int(num_of_data / batch_size) + 1
    pred_y = None
    for i in range(num_of_batch):
        optimizer.zero_grad()
        X = train_X[i*batch_size: min(num_of_data, (i+1)*batch_size), ]
        y = train_y[i*batch_size: min(num_of_data, (i+1)*batch_size), ]
        c_pred, r_pred = model(X)
        loss = loss_fn(c_pred, r_pred, y, balance)
        loss_history.append(loss.data)
        loss.backward()
        optimizer.step()

        c_pred = c_pred.data.cpu().numpy()
        c_pred = c_pred.reshape(c_pred.shape[0], 1)
        pred_y = np.concatenate((pred_y, c_pred), axis=0) if pred_y is not None \
            else c_pred

        if (i > 0) and (i % 100 == 0):
            logging.info('Step: {}, train_loss: {}'.format(
                i, np.mean(loss_history[-100:])))
            print("Step: {}, training loss: {}".format(
                i, np.mean(loss_history[-100:])))

    pred_y = (pred_y > 0.0)
    train_y = train_y.data.cpu().numpy()
    training_accuracy = sklearn.metrics.accuracy_score(
        train_y[:, 0], pred_y.reshape(-1))
    train_loss = np.mean(loss_history)
    logging.info('Training loss: {}'.format(train_loss))
    logging.info('Training Accuracy: {}.'.format(training_accuracy))

    print('Training Loss: {}. Training Accuracy: {}'
          .format(train_loss, training_accuracy))


'''
Validation (vanilla version without dataloader)
'''


def validate_vanilla(valid_X, valid_y, model, batch_size=2048, balance=1.0, pos_label=1.0):
    model.eval()

    loss_history = []
    num_of_data = valid_X.shape[0]
    num_of_batch = int(num_of_data / batch_size) + 1
    pred_y = None
    for i in range(num_of_batch):
        X = valid_X[i*batch_size: min(num_of_data, (i+1)*batch_size), ]
        y = valid_y[i*batch_size: min(num_of_data, (i+1)*batch_size), ]
        c_pred, r_pred = model(X)
        valid_loss = loss_fn(c_pred, r_pred, y, balance)
        loss_history.append(valid_loss.data)

        c_pred = c_pred.data.cpu().numpy()
        c_pred = c_pred.reshape(c_pred.shape[0], 1)

        pred_y = np.concatenate((pred_y, c_pred), axis=0) if pred_y is not None \
            else c_pred

    valid_y = valid_y.data.cpu().numpy()
    valid_auc = sklearn.metrics.roc_auc_score(
        valid_y[:, 0], pred_y.reshape(-1))
    pred_y = (pred_y > 0.0)
    valid_accuracy = sklearn.metrics.accuracy_score(
        valid_y[:, 0], pred_y.reshape(-1))
    valid_precision = sklearn.metrics.precision_score(
        valid_y[:, 0], pred_y.reshape(-1), pos_label=pos_label)
    valid_recall = sklearn.metrics.recall_score(
        valid_y[:, 0], pred_y.reshape(-1), pos_label=pos_label)

    logging.info('Validation loss: {}. Accuracy: {}.\
                  Precision: {}. Recall: {}. AUC: {}.'
                 .format(np.mean(loss_history), valid_accuracy, valid_precision,
                         valid_recall, valid_auc))
    print('Validation loss: {}. Accuracy: {}.\
            Precision: {}. Recall: {}. AUC: {}.'
          .format(np.mean(loss_history), valid_accuracy, valid_precision,
                  valid_recall, valid_auc))

    return np.mean(loss_history)


'''
Train the data. (using dataloader)
'''


def train_dataloader(train_loader, model, optimizer, epoch, balance=1.0):
    model.train()

    loss_history = []
    train_correct_class = 0
    total_size = 0
    logging.info('Epoch: {}'.format(epoch))
    for i, (inputs, targets) in enumerate(train_loader):
        total_size += targets.shape[0]
        optimizer.zero_grad()
        if cuda_is_available:
            X = (inputs).float().cuda()
            y = (targets).float().cuda()
        c_pred, r_pred = model(X)
        loss = loss_fn(c_pred, r_pred, y, balance)
        # loss.data[0].cpu().numpy()
        loss_history.append(loss.data)
        loss.backward()
        optimizer.step()

        train_correct_class += \
            np.sum((c_pred.data.cpu().numpy() > 0.5).astype(float) ==
                   y[:, 0].data.cpu().numpy().reshape(c_pred.data.cpu().numpy().shape[0], 1))

        # if i > 100:
        #    break
        if i % 100 == 0:
            logging.info('Step: {}, train_loss: {}'.format(
                i, np.mean(loss_history[-100:])))
            print("Step: {}, training loss: {}".format(
                i, np.mean(loss_history[-100:])))

    train_loss = np.mean(loss_history)
    logging.info('Training loss: {}'.format(train_loss))
    print('Epoch: {}. Training Loss: {}'.format(epoch, train_loss))


'''
Validation (using dataloader)
'''


def validate_dataloader(valid_loader, model, balance=1.0):
    model.eval()

    loss_history = []
    valid_correct_class = 0.0
    total_size = 0

    for i, (X, y) in enumerate(valid_loader):
        total_size += y.shape[0]
        if cuda_is_available:
            X = X.float().cuda()
            y = y.float().cuda()
        c_pred, r_pred = model(X)
        valid_loss = loss_fn(c_pred, r_pred, y, balance)
        loss_history.append(valid_loss.data)
        valid_correct_class += \
            np.sum((c_pred.data.cpu().numpy() > 0.5).astype(float) ==
                   y[:, 0].data.cpu().numpy().reshape(c_pred.data.cpu().numpy().shape[0], 1))

    valid_classification_accuracy = valid_correct_class / total_size
    logging.info('Validation loss: {}. Validation classification accuracy: {}'
                 .format(np.mean(loss_history), valid_classification_accuracy))
    print('Validation loss: {}. Classification accuracy: {}.'
          .format(np.mean(loss_history), valid_classification_accuracy))

    return valid_loss
# ========================================================================


# ========================================================================
# Main function:

if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='train neural network based on feature files and save parameters')
    parser.add_argument('train_file', type=str, help='training data (h5)')
    parser.add_argument('valid_file', type=str, help='validation data (h5)')
    parser.add_argument('-n', '--network-structure', type=int, default=1,
                        help='Specify which network to use:\n \
              \t 0: Fully connected neural network.\n \
              \t 1: 1D-CNN for lane feature extraction.')
    parser.add_argument('-d', '--data-loader', action='store_true',
                        help='Use the dataloader (when memory size is smaller than dataset size)')
    parser.add_argument('-s', '--save-path', type=str, default='./',
                        help='Specify the directory to save trained models.')
    parser.add_argument('-g', '--go', action='store_true',
                        help='It is training lane-follow (go) cases.')
    parser.add_argument('-b', '--balance', type=float, default=1.0,
                        help='Specify the weight for positive predictions.')
    # parser.add_argument('-g', '--gpu_num', type=int, default=0, \
    #    help='Specify which GPU to use.')

    args = parser.parse_args()

    # os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' #specifies the same order as nvidia-smi
    #os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_num)

    if not args.data_loader:

        # Load from file and print out general information of the data.
        train_file = args.train_file
        valid_file = args.valid_file
        train_data = load_data(train_file)
        valid_data = load_data(valid_file)
        print('Data loaded successfully.')
        classes_train = np.asarray(train_data[:, -dim_output])
        print('Total number of training samples: {}'.format(len(classes_train)))
        print('Training set distribution:')
        print_dist(classes_train)
        classes_valid = np.asarray(valid_data[:, -dim_output])
        print('Total number of validation samples: {}'.format(len(classes_valid)))
        print('Validation set distribution:')
        print_dist(classes_valid)

        # Data preprocessing
        X_train, y_train = data_preprocessing(train_data)
        X_valid, y_valid = data_preprocessing(valid_data)

        # Model declaration
        model = None
        if args.network_structure == 0:
            model = FullyConn_NN()
        elif args.network_structure == 1:
            model = FCNN_CNN1D()
        print("The model used is: ")
        print(model)
        learning_rate = 6.561e-4
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, factor=0.3, patience=2, min_lr=1e-8, verbose=1, mode='min')

        # CUDA set-up:
        cuda_is_available = torch.cuda.is_available()
        if (cuda_is_available):
            print("Using CUDA to speed up training.")
            model.cuda()
            X_train = Variable(torch.FloatTensor(X_train).cuda())
            X_valid = Variable(torch.FloatTensor(X_valid).cuda())
            y_train = Variable(torch.FloatTensor(y_train).cuda())
            y_valid = Variable(torch.FloatTensor(y_valid).cuda())

        # Model training:
        pos_label = 1.0
        if args.go:
            pos_label = 0.0
        best_valid_loss = float('+inf')
        for epoch in range(50):
            train_vanilla(X_train, y_train, model, optimizer,
                          epoch, balance=args.balance)
            valid_loss = validate_vanilla(
                X_valid, y_valid, model, balance=args.balance, pos_label=pos_label)
            scheduler.step(valid_loss)
            if valid_loss < best_valid_loss:
                best_valid_loss = valid_loss
                torch.save(model.state_dict(), args.save_path + 'cruise_model{}_epoch{}_valloss{:.6f}.pt'
                           .format(args.network_structure, epoch+1, valid_loss))

    else:
        train_dir = args.train_file
        valid_dir = args.valid_file

        # Data preprocessing (training data balancing).
        list_of_training_files = getListOfFiles(train_dir)
        list_of_validation_files = getListOfFiles(valid_dir)

        classes_train = []
        for file in list_of_training_files:
            with h5py.File(file, 'r') as h5_file:
                data = h5_file[list(h5_file.keys())[0]][:, -2]
                classes_train.append(data.tolist())
        # "Flattening" the list of lists
        classes_train = [item for sublist in classes_train for item in sublist]
        classes_train = np.asarray(classes_train)
        print('Total number of training samples: {}'.format(len(classes_train)))
        print('Training set distribution:')
        print_dist(classes_train)

        classes_valid = []
        for file in list_of_validation_files:
            with h5py.File(file, 'r') as h5_file:
                data = h5_file[list(h5_file.keys())[0]][:, -2]
                classes_valid.append(data.tolist())
        # "Flattening" the list of lists
        classes_valid = [item for sublist in classes_valid for item in sublist]
        classes_valid = np.asarray(classes_valid)
        print('Total number of validation samples: {}'.format(len(classes_valid)))
        print('Validation set distribution:')
        print_dist(classes_valid)

        #class_weights = class_weight.compute_class_weight('balanced', np.unique(classes_train), classes_train)
        #weights = [class_weights[int(i+1)] for i in classes_train]
        #weights = torch.DoubleTensor(weights)
        #train_sampler = sampler.WeightedRandomSampler(weights, int(len(weights)/1), replacement=True)

        model = FCNN_CNN1D()
        learning_rate = 6.561e-4
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, factor=0.3, patience=2, min_lr=1e-8, verbose=1, mode='min')
        if (cuda_is_available):
            print('Using CUDA to speed up training.')
            model.cuda()

        train_dataset = TrainValidDataset(list_of_training_files)
        valid_dataset = TrainValidDataset(list_of_validation_files)

        train_loader = DataLoader(train_dataset, batch_size=1024, num_workers=8,
                                  pin_memory=True, shuffle=True)  # sampler=train_sampler)
        valid_loader = DataLoader(
            valid_dataset, batch_size=1024, num_workers=8, pin_memory=True)

        for epoch in range(100):
            train_dataloader(train_loader, model, optimizer, epoch)
            valid_loss = validate_dataloader(valid_loader, model)
            scheduler.step(valid_loss)

# ========================================================================
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

'''
This .py file includes functions for data preprocessing:
    - splitting data into two categories: go and cut-in for separate training.
    - balancing the datasets
'''

import argparse
import datetime
import os

import h5py
import numpy as np


def getListOfFiles(dirName):
    '''
    Given a directory (dirName), return a list containing the full-path
    of all files inside that directory (including all hierarchy).
    '''
    listOfFiles = os.listdir(dirName)
    allFiles = list()

    for entry in listOfFiles:
        fullPath = os.path.join(dirName, entry)
        if os.path.isdir(fullPath):
            allFiles = allFiles + getListOfFiles(fullPath)
        else:
            allFiles.append(fullPath)

    return allFiles


def load_hdf5(filename):
    """
    load training samples from *.hdf5 file
    """
    if not(os.path.exists(filename)):
        print("file:", filename, "does not exist")
        os._exit(1)
    if os.path.splitext(filename)[1] != '.h5':
        print("file:", filename, "is not an hdf5 file")
        os._exit(1)

    h5_file = h5py.File(filename, 'r')
    values = h5_file[list(h5_file.keys())[0]]
    #values = h5_file.values()[0]
    print("load data size:", values.shape[0])
    return values


def data_splitting(feature):
    '''
    Split data into two categories: go and cut-in.
    '''

    # Don't consider those anomaly data
    idx_normal = (feature[:, -3] != -10)
    go_idx = (feature[:, -3] % 2 == 0)
    cutin_idx = (feature[:, -3] % 2 == 1)

    go_idx = np.logical_and(go_idx, idx_normal)
    cutin_idx = np.logical_and(cutin_idx, idx_normal)

    feature = np.asarray(feature)

    return feature[go_idx], feature[cutin_idx]


def down_sample(feature, label, drop_rate):
    '''
    feature: the input data
    label and drop_rate: one-to-one mapping of the drop-rate for each
    specific label
    '''
    fea_label = feature[:, -2]
    selected_idx = np.zeros(fea_label.shape[0], dtype=bool)
    mask_random = np.random.random(fea_label.shape[0])

    for i in range(len(label)):
        l = label[i]
        dr = drop_rate[i]

        idx_of_curr_label = (fea_label == l)
        selected_idx_of_curr_label = np.logical_and(idx_of_curr_label,
                                                    mask_random > dr)
        selected_idx = np.logical_or(selected_idx, selected_idx_of_curr_label)

    data_downsampled = feature[selected_idx, :]
    return data_downsampled


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Data preprocessing.')
    parser.add_argument('directory', type=str,
                        help='directory contains feature files in .h5')
    parser.add_argument('-m', '--merge_files', action='store_true',
                        help='Merge output files into one.')
    parser.add_argument('-s', '--split_category', action='store_true',
                        help='Split the output into Go and Cutin.')

    args = parser.parse_args()

    path = args.directory
    print("Loading h5 from directory: {}".format(path))

    if not args.merge_files:

        if os.path.isdir(path):

            h5_files = getListOfFiles(path)
            print("Total number of files:", len(h5_files))

            # For each file in the total list of files:
            for i, file in enumerate(h5_files):
                print("Process File", i, ":", file)
                feature = load_hdf5(file)
                if np.any(np.isinf(feature)):
                    print("inf data found")

                if args.split_category:
                    # Split data into two categories:
                    fea_go, fea_cutin = data_splitting(feature)

                    # Balance data by down-sampling oversized bins:
                    #fea_go = down_sample(fea_go, [0, 1, 4], [0.0, 0.95, 0.83])
                    #fea_cutin = down_sample(fea_cutin, [-1, 2, 3], [0.985 ,0.0, 0.0])

                    go_path = path + 'go/' + \
                        file.split('/')[-2] + '-' + file.split('/')[-1]
                    h5_file = h5py.File(go_path, 'w')
                    h5_file.create_dataset('data', data=fea_go)
                    h5_file.close()

                    cutin_path = path + 'cutin/' + \
                        file.split('/')[-2] + '-' + file.split('/')[-1]
                    h5_file = h5py.File(cutin_path, 'w')
                    h5_file.create_dataset('data', data=fea_cutin)
                    h5_file.close()

                else:
                    print(None)
                    # TODO: implement those non-splitting category
        else:
            print("Fail to find", path)
            os._exit(-1)

    else:

        if os.path.isdir(path):
            features_go = None
            features_cutin = None
            features = None
            labels = None

            h5_files = getListOfFiles(path)
            print("Total number of files:", len(h5_files))

            # For each file in the total list of files:
            for i, file in enumerate(h5_files):
                print("Process File", i, ":", file)
                feature = load_hdf5(file)
                if np.any(np.isinf(feature)):
                    print("inf data found")

                if args.split_category:
                    # Split data into two categories:
                    fea_go, fea_cutin = data_splitting(feature)

                    # Balance data by down-sampling oversized bins:
                    #fea_go = down_sample(fea_go, [0, 1, 4], [0.0, 0.95, 0.83])
                    #fea_cutin = down_sample(fea_cutin, [-1, 2, 3], [0.985 ,0.0, 0.0])

                    features_go = np.concatenate((features_go, fea_go), axis=0) if features_go is not None \
                        else fea_go
                    features_cutin = np.concatenate((features_cutin, fea_cutin), axis=0) if features_cutin is not None \
                        else fea_cutin
        else:
            print("Fail to find", path)
            os._exit(-1)

        if args.split_category:
            date = datetime.datetime.now().strftime('%Y-%m-%d')
            sample_file = path + 'merged_go' + date + '.h5'
            print("Save samples file to:", sample_file)
            h5_file = h5py.File(sample_file, 'w')
            h5_file.create_dataset('data', data=features_go)
            h5_file.close()

            sample_file = path + 'merged_cutin' + date + '.h5'
            print("Save samples file to:", sample_file)
            h5_file = h5py.File(sample_file, 'w')
            h5_file.create_dataset('data', data=features_cutin)
            h5_file.close()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import logging
import os

from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from torch.autograd import Variable
from torch.utils.data import Dataset, DataLoader, sampler
import h5py
import numpy as np
import sklearn
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from modules.tools.prediction.data_pipelines.common.configure import parameters
from proto.cruise_model_pb2 import TensorParameter, InputParameter,\
    Conv1dParameter, DenseParameter, ActivationParameter, MaxPool1dParameter,\
    AvgPool1dParameter, LaneFeatureConvParameter, ObsFeatureFCParameter,\
    ClassifyParameter, RegressParameter, CruiseModelParameter


"""
@requirement:
    pytorch 0.4.1
"""

'''
This file includes all model definitions and related loss functions.
'''


'''
Model details:
    - Fully-connected layers for classification and regression, respectively.
    - It will compute a classification score indicating the probability
      of the obstacle choosing the given lane.
    - It will also compute a time indicating how soon the obstacle will reach
      the center of the given lane.
'''


class FullyConn_NN(torch.nn.Module):
    def __init__(self):
        super(FullyConn_NN, self).__init__()
        self.classify = torch.nn.Sequential(
            nn.Linear(174, 88),
            nn.Sigmoid(),
            nn.Dropout(0.3),

            nn.Linear(88, 55),
            nn.Sigmoid(),
            nn.Dropout(0.2),

            nn.Linear(55, 23),
            nn.Sigmoid(),
            nn.Dropout(0.3),

            nn.Linear(23, 10),
            nn.Sigmoid(),
            nn.Dropout(0.0),

            nn.Linear(10, 1),
            nn.Sigmoid()
        )
        self.regress = torch.nn.Sequential(
            nn.Linear(174, 88),
            nn.ReLU(),
            nn.Dropout(0.1),

            nn.Linear(88, 23),
            nn.ReLU(),
            nn.Dropout(0.1),

            nn.Linear(23, 1),
            nn.ReLU()
        )

    def forward(self, x):
        out_c = self.classify(x)
        out_r = self.regress(x)
        return out_c, out_r


class FCNN_CNN1D(torch.nn.Module):
    def __init__(self):
        super(FCNN_CNN1D, self).__init__()
        self.lane_feature_conv = torch.nn.Sequential(
            nn.Conv1d(4, 10, 3, stride=1),\
            # nn.BatchNorm1d(10),\
            nn.ReLU(),\
            #nn.Conv1d(10, 16, 3, stride=2),\
            # nn.BatchNorm1d(16),\
            # nn.ReLU(),\
            nn.Conv1d(10, 25, 3, stride=2),\
            # nn.BatchNorm1d(25)
        )
        self.lane_feature_maxpool = nn.MaxPool1d(4)
        self.lane_feature_avgpool = nn.AvgPool1d(4)
        self.lane_feature_dropout = nn.Dropout(0.0)

        self.obs_feature_fc = torch.nn.Sequential(
            nn.Linear(68, 40),
            nn.Sigmoid(),
            nn.Dropout(0.0),
            nn.Linear(40, 24),
            nn.Sigmoid(),
            nn.Dropout(0.0),
        )

        self.classify = torch.nn.Sequential(
            nn.Linear(124, 66),
            nn.Sigmoid(),
            nn.Dropout(0.3),

            nn.Linear(66, 48),
            nn.Sigmoid(),
            nn.Dropout(0.1),

            nn.Linear(48, 11),
            nn.Sigmoid(),
            nn.Dropout(0.1),

            nn.Linear(11, 1),\
            # nn.Sigmoid()
        )
        self.regress = torch.nn.Sequential(
            nn.Linear(125, 77),
            nn.ReLU(),
            nn.Dropout(0.2),

            nn.Linear(77, 46),
            nn.ReLU(),
            nn.Dropout(0.2),

            nn.Linear(46, 12),
            nn.ReLU(),
            nn.Dropout(0.1),

            nn.Linear(12, 1),
            nn.ReLU()
        )

    def forward(self, x):
        lane_fea = x[:, -80:]
        lane_fea = lane_fea.view(lane_fea.size(0), 4, 20)

        obs_fea = x[:, :-80]

        lane_fea = self.lane_feature_conv(lane_fea)

        lane_fea_max = self.lane_feature_maxpool(lane_fea)
        lane_fea_avg = self.lane_feature_avgpool(lane_fea)

        lane_fea = torch.cat([lane_fea_max.view(lane_fea_max.size(0), -1),
                              lane_fea_avg.view(lane_fea_avg.size(0), -1)], 1)
        lane_fea = self.lane_feature_dropout(lane_fea)

        obs_fea = self.obs_feature_fc(obs_fea)

        tot_fea = torch.cat([lane_fea, obs_fea], 1)
        out_c = self.classify(tot_fea)
        out_r = self.regress(torch.cat([tot_fea, out_c], 1))

        return out_c, out_r
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import os
import re

from modules.tools.prediction.data_pipelines.data_preprocessing.features_labels_utils import CombineFeaturesAndLabels, MergeCombinedFeaturesAndLabels


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Merge all label_dicts in each'
                                                 'terminal folder.')
    parser.add_argument('features_dirpath', type=str,
                        help='Path of terminal folder for data_for_learn.')
    parser.add_argument('labels_dirpath', type=str,
                        help='Path of terminal folder for labels')
    args = parser.parse_args()

    list_of_files = os.listdir(args.features_dirpath)
    for file in list_of_files:
        full_file_path = os.path.join(args.features_dirpath, file)
        if file.split('.')[-1] == 'bin' and \
           file.split('.')[0] == 'datalearn':
            label_path = args.labels_dirpath
            CombineFeaturesAndLabels(full_file_path, label_path + '/labels.npy')

    MergeCombinedFeaturesAndLabels(args.features_dirpath)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import os
import re

from modules.tools.prediction.data_pipelines.data_preprocessing.features_labels_utils import CombineFeaturesAndLabels


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='Merge all label_dicts in each terminal folder.')
    parser.add_argument('features_dirpath', type=str,
                        help='Path of terminal folder for data_for_learn.')
    parser.add_argument('labels_dirpath', type=str,
                        help='Path of terminal folder for labels')
    args = parser.parse_args()

    list_of_files = os.listdir(args.features_dirpath)
    for file in list_of_files:
        full_file_path = os.path.join(args.features_dirpath, file)
        if file.split('.')[-1] == 'bin' and \
           file.split('.')[0] == 'datalearn':
            label_path = args.labels_dirpath
            CombineFeaturesAndLabels(full_file_path, label_path +
                                     '/junction_label.npy', 'junction_label')
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


import h5py
import numpy as np
import os

from modules.prediction.proto import offline_features_pb2


junction_label_label_dim = 12
future_status_label_dim = 30

'''
Read a single dataforlearn.bin file and output a list of DataForLearning
that is contained in that file.
'''


def LoadDataForLearning(filepath):
    list_of_data_for_learning = \
        offline_features_pb2.ListDataForLearning()
    with open(filepath, 'rb') as file_in:
        list_of_data_for_learning.ParseFromString(file_in.read())
    return list_of_data_for_learning.data_for_learning


'''
Read a single .npy dictionary file and get its content.
'''


def LoadLabels(filepath):
    mydict = np.load(filepath).item()
    return mydict


'''
Merge two dictionary into a single one and return.
'''


def MergeTwoDicts(dict1, dict2):
    newdict = dict1.copy()
    newdict.update(dict2)
    return newdict


'''
Merge all dictionaries directly under a directory
'''


def MergeDicts(dirpath, dict_name='future_status'):
    list_of_files = os.listdir(dirpath)
    dict_merged = None

    for file in list_of_files:
        full_path = os.path.join(dirpath, file)
        if file.split('.')[-1] == 'npy' and file.split('.')[-2] == dict_name:
            dict_curr = LoadLabels(full_path)
            if dict_merged is None:
                dict_merged = dict_curr.copy()
            else:
                dict_merged.update(dict_curr)

    np.save(dirpath + '/' + dict_name + '.npy', dict_merged)
    return dict_merged


'''
Go through every entry of data_for_learn proto and get the corresponding labels.
Save the output file into h5 format (array of lists with each list being a data
point for training/validating).
'''


def CombineFeaturesAndLabels(feature_path, label_path, dict_name='future_status'):
    list_of_data_for_learning = LoadDataForLearning(feature_path)
    dict_labels = LoadLabels(label_path)

    output_np_array = []
    for data_for_learning in list_of_data_for_learning:
        # features_for_learning: list of doubles
        features_for_learning = list(data_for_learning.features_for_learning)
        key = "{}@{:.3f}".format(data_for_learning.id, data_for_learning.timestamp)

        # Sanity checks to see if this data-point is valid or not.
        if key not in dict_labels:
            print('Cannot find a feature-to-label mapping.')
            continue

        labels = None
        list_curr = None
        if dict_name == 'junction_label':
            if len(dict_labels[key]) != junction_label_label_dim:
                continue
            labels = dict_labels[key]
            list_curr = features_for_learning + labels
        elif dict_name == 'future_status':
            if len(dict_labels[key]) < future_status_label_dim:
                continue
            labels = dict_labels[key][:30]
            list_curr = [len(features_for_learning)] + \
                features_for_learning + labels

        output_np_array.append(list_curr)

    output_np_array = np.array(output_np_array)

    np.save(feature_path + '.features+' + dict_name + '.npy', output_np_array)


'''
Merge all files of features+labels into a single one
'''


def MergeCombinedFeaturesAndLabels(dirpath):
    list_of_files = os.listdir(dirpath)

    features_labels_merged = []
    for file in list_of_files:
        full_path = os.path.join(dirpath, file)
        if file.split('.')[-1] == 'npy' and \
           file.split('.')[-2] == 'labels' and \
           file.split('.')[0] == 'datalearn':
            features_labels_curr = np.load(full_path).tolist()
            features_labels_merged += features_labels_curr

    np.save(dirpath + '/training_data.npy', np.array(features_labels_merged))


'''
It takes terminal folder as input, then
1. Merge all label dicts.
2. Go through every data_for_learn proto, and find the corresponding label
3. Merge all features+labels files into a single one: data.npy
'''


def PrepareDataForTraining(dirpath):
    MergeDicts(dirpath)

    list_of_files = os.listdir(dirpath)
    for file in list_of_files:
        full_path = os.path.join(dirpath, file)
        if file.split('.')[-1] == 'bin' and \
           file.split('.')[0] == 'datalearn':
            CombineFeaturesAndLabels(full_path, dirpath + 'labels.npy')

    MergeCombinedFeaturesAndLabels(dirpath)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import glob
import logging
import os
import sys

from modules.tools.prediction.data_pipelines.common.online_to_offline import LabelGenerator


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Generate labels')
    parser.add_argument('input', type=str, help='input file')
    args = parser.parse_args()

    label_gen = LabelGenerator()

    print("Create Label {}".format(args.input))
    if os.path.isfile(args.input):
        label_gen.LoadFeaturePBAndSaveLabelFiles(args.input)
        label_gen.LabelSingleLane()
    else:
        print("{} is not a valid file".format(args.input))
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import glob
import logging
import os
import sys

from modules.tools.prediction.data_pipelines.common.online_to_offline import LabelGenerator


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Generate labels')
    parser.add_argument('input', type=str, help='input file')
    args = parser.parse_args()

    label_gen = LabelGenerator()

    print("Create Label {}".format(args.input))
    if os.path.isfile(args.input):
        label_gen.LoadFeaturePBAndSaveLabelFiles(args.input)
        label_gen.LabelTrajectory()
    else:
        print("{} is not a valid file".format(args.input))
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import glob
import logging
import os
import sys

from modules.tools.prediction.data_pipelines.common.online_to_offline import LabelGenerator


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Generate labels')
    parser.add_argument('input', type=str, help='input file')
    args = parser.parse_args()

    label_gen = LabelGenerator()

    print("Create Label {}".format(args.input))
    if os.path.isfile(args.input):
        label_gen.LoadFeaturePBAndSaveLabelFiles(args.input)
        label_gen.LabelJunctionExit()
    else:
        print("{} is not a valid file".format(args.input))
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import glob
import logging
import os
import sys

from modules.tools.prediction.data_pipelines.common.online_to_offline import LabelGenerator


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Generate labels')
    parser.add_argument('input', type=str, help='input file')
    args = parser.parse_args()

    label_gen = LabelGenerator()

    print("Create Label {}".format(args.input))
    if os.path.isfile(args.input):
        label_gen.LoadFeaturePBAndSaveLabelFiles(args.input)
        label_gen.Label()
    else:
        print("{} is not a valid file".format(args.input))
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse

import modules.tools.prediction.data_pipelines.data_preprocessing.features_labels_utils as features_labels_utils


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Merge all label_dicts in each'
                                                 'terminal folder.')
    parser.add_argument('dirpath', type=str, help='Path of terminal folder.')
    args = parser.parse_args()

    features_labels_utils.MergeDicts(args.dirpath, dict_name='future_status')
    features_labels_utils.MergeDicts(args.dirpath, dict_name='junction_label')
    features_labels_utils.MergeDicts(args.dirpath, dict_name='cruise_label')
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
@requirement:
    tensorflow 1.11
"""

import os
import h5py
import logging
import argparse
import numpy as np
import tensorflow as tf
from modules.tools.prediction.data_pipelines.proto import fnn_model_pb2
from fnn_model_pb2 import FnnModel, Layer
from sklearn.model_selection import train_test_split

dim_input = 7 + 72
dim_output = 12


def load_data(filename):
    """
    Load the data from h5 file to the format of numpy
    """
    if not (os.path.exists(filename)):
        logging.error("file: {}, does not exist".format(filename))
        os._exit(1)
    if os.path.splitext(filename)[1] != '.h5':
        logging.error("file: {} is not an hdf5 file".format(filename))
        os._exit(1)
    samples = dict()
    h5_file = h5py.File(filename, 'r')
    for key in h5_file.keys():
        samples[key] = h5_file[key][:]
    print("load file success")
    return samples['data']


def data_preprocessing(data):
    X = data[:, :dim_input]
    Y = data[:, -dim_output:]
    return X, Y


def save_model(model, filename):
    """
    Save the trained model parameters into protobuf binary format file
    """
    net_params = FnnModel()
    net_params.num_layer = 0
    for layer in model.layers:
        net_params.num_layer += 1
        net_layer = net_params.layer.add()
        config = layer.get_config()
        net_layer.layer_input_dim = dim_input
        net_layer.layer_output_dim = dim_output
        if config['activation'] == 'relu':
            net_layer.layer_activation_func = fnn_model_pb2.Layer.RELU
        elif config['activation'] == 'tanh':
            net_layer.layer_activation_func = fnn_model_pb2.Layer.TANH
        elif config['activation'] == 'sigmoid':
            net_layer.layer_activation_func = fnn_model_pb2.Layer.SIGMOID
        elif config['activation'] == 'softmax':
            net_layer.layer_activation_func = fnn_model_pb2.Layer.SOFTMAX

        weights, bias = layer.get_weights()
        net_layer.layer_bias.columns.extend(bias.reshape(-1).tolist())
        for col in weights.tolist():
            row = net_layer.layer_input_weight.rows.add()
            row.columns.extend(col)
    net_params.dim_input = dim_input
    net_params.dim_output = dim_output
    with open(filename, 'wb') as params_file:
        params_file.write(net_params.SerializeToString())


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='train neural network based on feature files and save parameters')
    parser.add_argument('filename', type=str, help='h5 file of data.')
    args = parser.parse_args()
    file = args.filename
    # load_data
    data = load_data(file)
    print("Data load success, with data shape: " + str(data.shape))
    train_data, test_data = train_test_split(data, test_size=0.2)
    X_train, Y_train = data_preprocessing(train_data)
    X_test, Y_test = data_preprocessing(test_data)
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(30, activation=tf.nn.relu),
        tf.keras.layers.Dense(20, activation=tf.nn.relu),
        tf.keras.layers.Dense(12, activation=tf.nn.softmax)])
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  # loss='MSE',
                  metrics=['accuracy'])
    model.fit(X_train, Y_train, epochs=5)
    model_path = os.path.join(os.getcwd(), "junction_mlp_vehicle_model.bin")
    save_model(model, model_path)
    print("Model saved to: " + model_path)
    score = model.evaluate(X_test, Y_test)
    print("Testing accuracy is: " + str(score))
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import datetime
import os

import numpy as np
import h5py


def getListOfFiles(dirName):
    listOfFiles = os.listdir(dirName)
    allFiles = list()

    for entry in listOfFiles:
        fullPath = os.path.join(dirName, entry)
        if os.path.isdir(fullPath):
            allFiles = allFiles + getListOfFiles(fullPath)
        else:
            allFiles.append(fullPath)

    return allFiles


def load_hdf5(filename):
    """
    load training samples from *.hdf5 file
    """
    if not(os.path.exists(filename)):
        print("file:", filename, "does not exist")
        os._exit(1)
    if os.path.splitext(filename)[1] != '.h5':
        print("file:", filename, "is not an hdf5 file")
        os._exit(1)

    h5_file = h5py.File(filename, 'r')
    values = list(h5_file.values())[0]
    print("load data size:", values.shape[0])
    return values


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='generate training samples\
            from a specified directory')
    parser.add_argument('directory', type=str,
                        help='directory contains feature files in .h5')
    parser.add_argument('-n', '--npy', action='store_true',
                        help='if is .npy rather than .h5, use this.')
    args = parser.parse_args()
    path = args.directory

    if not args.npy:
        print("load h5 from directory: {}".format(path))
        if os.path.isdir(path):
            features = None
            labels = None

            h5_files = getListOfFiles(path)
            print("Total number of files:", len(h5_files))
            for i, h5_file in enumerate(h5_files):
                print("Process File", i, ":", h5_file)
                feature = load_hdf5(h5_file)
                if np.any(np.isinf(feature)):
                    print("inf data found")
                features = np.concatenate((features, feature), axis=0) if features is not None \
                    else feature
        else:
            print("Fail to find", path)
            os._exit(-1)

        date = datetime.datetime.now().strftime('%Y-%m-%d')
        sample_file = path + '/merged' + date + '.h5'
        print("Save samples file to:", sample_file)
        h5_file = h5py.File(sample_file, 'w')
        h5_file.create_dataset('data', data=features)
        h5_file.close()
    else:
        print("load npy from directory: {}".format(path))
        if os.path.isdir(path):
            features_go = None
            features_cutin = None
            npy_files = getListOfFiles(path)
            print("Total number of files:", len(npy_files))
            for i, npy_file in enumerate(npy_files):
                print("Process File", i, ":", npy_file)
                temp_features = np.load(npy_file)
                feature_go = np.zeros((temp_features.shape[0], 157))
                feature_cutin = np.zeros((temp_features.shape[0], 157))
                count_go = 0
                count_cutin = 0
                for j in range(temp_features.shape[0]):
                    fea = np.asarray(temp_features[j])
                    if fea.shape[0] != 157:
                        continue
                    if fea[-1] < -1 or fea[-1] > 4:
                        continue
                    fea = fea.reshape((1, 157))
                    if fea[0, -1] % 2 == 0:
                        feature_go[count_go] = fea
                        count_go += 1
                    else:
                        feature_cutin[count_cutin] = fea
                        count_cutin += 1

                feature_go = feature_go[:count_go]
                feature_cutin = feature_cutin[:count_cutin]
                features_go = np.concatenate((features_go, feature_go), axis=0) if features_go is not None \
                    else feature_go
                features_cutin = np.concatenate((features_cutin, feature_cutin), axis=0) if features_cutin is not None \
                    else feature_cutin
        else:
            print("Fail to find", path)
            os._exit(-1)

        print(features_go.shape)
        print(features_cutin.shape)
        date = datetime.datetime.now().strftime('%Y-%m-%d')
        sample_file_go = path + '/merged_go_' + date + '.h5'
        sample_file_cutin = path + '/merged_cutin_' + date + '.h5'
        h5_file_go = h5py.File(sample_file_go, 'w')
        h5_file_go.create_dataset('data', data=features_go)
        h5_file_go.close()
        h5_file_cutin = h5py.File(sample_file_cutin, 'w')
        h5_file_cutin.create_dataset('data', data=features_cutin)
        h5_file_cutin.close()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
@requirement:
    tensorflow- 1.3.0
    Keras-1.2.2
"""

import argparse
import logging
import os

import h5py
import numpy as np

from keras.callbacks import ModelCheckpoint
from keras.metrics import mse
from keras.models import Sequential, Model
from keras.layers.normalization import BatchNormalization
from keras.layers import Activation
from keras.layers import Dense, Input
from keras.layers import Dropout
from keras.regularizers import l2, l1
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
import google.protobuf.text_format as text_format

from modules.tools.prediction.data_pipelines.proto import fnn_model_pb2
from modules.tools.prediction.data_pipelines.common import log
from modules.tools.prediction.data_pipelines.common.data_preprocess import load_h5
from modules.tools.prediction.data_pipelines.common.data_preprocess import down_sample
from modules.tools.prediction.data_pipelines.common.data_preprocess import train_test_split
from modules.tools.prediction.data_pipelines.common.configure import parameters
from modules.tools.prediction.data_pipelines.common.configure import labels
from fnn_model_pb2 import FnnModel, Layer


# Constants
dim_input = parameters['mlp']['dim_input']
dim_hidden_1 = parameters['mlp']['dim_hidden_1']
dim_hidden_2 = parameters['mlp']['dim_hidden_2']
dim_output = parameters['mlp']['dim_output']
train_data_rate = parameters['mlp']['train_data_rate']

evaluation_log_path = os.path.join(os.getcwd(), "evaluation_report")
log.init_log(evaluation_log_path, level=logging.DEBUG)


def load_data(filename):
    """
    Load the data from h5 file to the format of numpy
    """
    if not (os.path.exists(filename)):
        logging.error("file: {}, does not exist".format(filename))
        os._exit(1)
    if os.path.splitext(filename)[1] != '.h5':
        logging.error("file: {} is not an hdf5 file".format(filename))
        os._exit(1)

    samples = dict()
    h5_file = h5py.File(filename, 'r')
    for key in h5_file.keys():
        samples[key] = h5_file[key][:]

    print("load file success")

    return samples['data']


def down_sample(data):
    cutin_false_drate = 0.9
    go_false_drate = 0.9
    go_true_drate = 0.7
    cutin_true_drate = 0.0

    label = data[:, -1]
    size = np.shape(label)[0]

    cutin_false_index = (label == -1)
    go_false_index = (label == 0)
    go_true_index = (label == 1)
    cutin_true_index = (label == 2)

    rand = np.random.random((size))

    cutin_false_select = np.logical_and(cutin_false_index,
                                        rand > cutin_false_drate)
    cutin_true_select = np.logical_and(cutin_true_index,
                                       rand > cutin_true_drate)
    go_false_select = np.logical_and(go_false_index, rand > go_false_drate)
    go_true_select = np.logical_and(go_true_index, rand > go_true_drate)

    all_select = np.logical_or(cutin_false_select, cutin_true_select)
    all_select = np.logical_or(all_select, go_false_select)
    all_select = np.logical_or(all_select, go_true_select)

    data_downsampled = data[all_select, :]

    return data_downsampled


def get_param_norm(feature):
    """
    Normalize the samples and save normalized parameters
    """
    fea_mean = np.mean(feature, axis=0)
    fea_std = np.std(feature, axis=0) + 1e-6
    param_norm = (fea_mean, fea_std)
    return param_norm


def setup_model():
    """
    Set up neural network based on keras.Sequential
    """
    model = Sequential()
    model.add(
        Dense(
            dim_hidden_1,
            input_dim=dim_input,
            init='he_normal',
            activation='relu',
            W_regularizer=l2(0.01)))

    model.add(
        Dense(
            dim_hidden_2,
            init='he_normal',
            activation='relu',
            W_regularizer=l2(0.01)))

    model.add(
        Dense(
            dim_output,
            init='he_normal',
            activation='sigmoid',
            W_regularizer=l2(0.01)))

    model.compile(
        loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

    return model


def evaluate_model(y, pred):
    """
    give the performance [recall, precision] of nn model

    Parameters
    ----------
    y: numpy.array;     real classess
    pred: numpy.array;  prediction classes

    Returns
    -------
    performance dict, store the performance in log file
    """
    y = y.reshape(-1)
    pred = pred.reshape(-1)

    go_true = (y == labels['go_true']).sum()
    go_false = (y == labels['go_false']).sum()
    index_go = np.logical_or(y == labels['go_false'], y == labels['go_true'])
    go_positive = (pred[index_go] == 1).sum()
    go_negative = (pred[index_go] == 0).sum()

    cutin_true = (y == labels['cutin_true']).sum()
    cutin_false = (y == labels['cutin_false']).sum()
    index_cutin = np.logical_or(y == labels['cutin_false'],
                                y == labels['cutin_true'])
    cutin_positive = (pred[index_cutin] == 1).sum()
    cutin_negative = (pred[index_cutin] == 0).sum()

    logging.info("data size: {}, included:".format(y.shape[0]))
    logging.info("\t  True    False   Positive   Negative")
    logging.info(" Go:  {:7} {:7} {:7} {:7}".format(go_true, go_false,
                                                    go_positive, go_negative))
    logging.info("Cutin:{:7} {:7} {:7} {:7}".format(
        cutin_true, cutin_false, cutin_positive, cutin_negative))

    logging.info("--------------------SCORE-----------------------------")
    logging.info("          recall   precision    F1-score")
    ctrue = float(go_true + cutin_true)
    positive = float(go_positive + cutin_positive)
    tp = float((pred[y > 0.1] == 1).sum())
    recall = tp / ctrue if ctrue != 0 else 0.0
    precision = tp / positive if positive != 0 else 0.0
    fscore = 2 * precision * recall / (
        precision + recall) if precision + recall != 0 else 0.0
    logging.info("Positive:{:6.3}     {:6.3}     {:6.3}".format(
        recall, precision, fscore))

    go_tp = float((pred[y == 1] == 1).sum())
    go_recall = go_tp / go_true if go_true != 0 else 0.0
    go_precision = go_tp / go_positive if go_positive != 0 else 0.0
    go_fscore = 2 * go_precision * go_recall / (
        go_precision + go_recall) if go_precision + go_recall != 0 else 0.0
    logging.info("      Go:{:6.3}     {:6.3}     {:6.3}".format(
        go_recall, go_precision, go_fscore))

    cutin_tp = float((pred[y == 2] == 1).sum())
    cutin_recall = cutin_tp / cutin_true if cutin_true != 0 else 0.0
    cutin_precision = cutin_tp / cutin_positive if cutin_positive != 0 else 0.0
    cutin_fscore = 2 * cutin_precision * cutin_recall / (
        cutin_precision +
        cutin_recall) if cutin_precision + cutin_recall != 0 else 0.0
    logging.info("   Cutin:{:6.3}     {:6.3}     {:6.3}".format(
        cutin_recall, cutin_precision, cutin_fscore))
    logging.info("-----------------------------------------------------\n\n")

    performance = {
        'recall': [recall, go_recall, cutin_recall],
        'precision': [precision, go_precision, cutin_precision]
    }
    return performance


def save_model(model, param_norm, filename):
    """
    Save the trained model parameters into protobuf binary format file
    """
    net_params = FnnModel()
    net_params.samples_mean.columns.extend(param_norm[0].reshape(-1).tolist())
    net_params.samples_std.columns.extend(param_norm[1].reshape(-1).tolist())
    net_params.num_layer = 0
    for layer in model.flattened_layers:
        net_params.num_layer += 1
        net_layer = net_params.layer.add()
        config = layer.get_config()
        net_layer.layer_input_dim = dim_input
        net_layer.layer_output_dim = dim_output
        if config['activation'] == 'relu':
            net_layer.layer_activation_func = fnn_model_pb2.Layer.RELU
        elif config['activation'] == 'tanh':
            net_layer.layer_activation_func = fnn_model_pb2.Layer.TANH
        elif config['activation'] == 'sigmoid':
            net_layer.layer_activation_func = fnn_model_pb2.Layer.SIGMOID

        weights, bias = layer.get_weights()
        net_layer.layer_bias.columns.extend(bias.reshape(-1).tolist())
        for col in weights.tolist():
            row = net_layer.layer_input_weight.rows.add()
            row.columns.extend(col)
    net_params.dim_input = dim_input
    net_params.dim_output = dim_output
    with open(filename, 'wb') as params_file:
        params_file.write(net_params.SerializeToString())


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='train neural network based on feature files and save parameters')
    parser.add_argument('filename', type=str, help='h5 file of data.')

    args = parser.parse_args()
    file = args.filename

    data = load_data(file)
    data = down_sample(data)
    print("Data load success.")
    print("data size =", data.shape)

    train_data, test_data = train_test_split(data, train_data_rate)

    print("training size =", train_data.shape)

    X_train = train_data[:, 0:dim_input]
    Y_train = train_data[:, -1]
    Y_trainc = Y_train > 0.1

    X_test = test_data[:, 0:dim_input]
    Y_test = test_data[:, -1]
    Y_testc = Y_test > 0.1

    param_norm = get_param_norm(X_train)

    X_train = (X_train - param_norm[0]) / param_norm[1]

    X_test = (X_test - param_norm[0]) / param_norm[1]

    model = setup_model()

    model.fit(X_train, Y_trainc, shuffle=True, nb_epoch=20, batch_size=32)
    print("Model trained success.")

    X_test = (X_test - param_norm[0]) / param_norm[1]

    score = model.evaluate(X_test, Y_testc)
    print("\nThe accuracy on testing dat is", score[1])

    logging.info("Test data loss: {}, accuracy: {} ".format(
        score[0], score[1]))
    Y_train_hat = model.predict_classes(X_train, batch_size=32)
    Y_test_hat = model.predict_proba(X_test, batch_size=32)
    logging.info("## Training Data:")
    evaluate_model(Y_train, Y_train_hat)
    for thres in [x / 100.0 for x in range(20, 80, 5)]:
        logging.info("##threshond = {} Testing Data:".format(thres))
        performance = evaluate_model(Y_test, Y_test_hat > thres)
    performance['accuracy'] = [score[1]]

    print("\nFor more detailed evaluation results, please refer to",
          evaluation_log_path + ".log")

    model_path = os.path.join(os.getcwd(), "mlp_model.bin")
    save_model(model, param_norm, model_path)
    print("Model has been saved to", model_path)
#!/usr/bin/env python3

###############################################################################
# Modification Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""Converts MLP data to TFRecords file format with Example protos."""

import argparse
import os
import sys

import numpy as np
import tensorflow as tf


FLAGS = None
feature_dim = 62


def _float_feature(value):
    return tf.train.Feature(float_list=tf.train.FloatList(value=value))


def convert_to(bin_data, name):
    """Converts bin_data to tfrecords."""
    if bin_data.shape[0] % (feature_dim + 1) != 0:
        raise ValueError(
            'data size (%d) must be multiple of feature_dim + 1 (%d).' %
            (bin_data.shape[0], feature_dim + 1))
    num_examples = bin_data.shape[0] // (feature_dim + 1)
    print("num_examples:", num_examples)
    filename = os.path.join(name + '.tfrecords')
    print('Writing', filename)
    with tf.python_io.TFRecordWriter(filename) as writer:
        for index in range(0, num_examples):
            data_raw = bin_data[index * (feature_dim + 1):index *
                                (feature_dim + 1) + feature_dim]
            label_raw = np.array(
                [bin_data[index*(feature_dim + 1)+feature_dim]])
            example = tf.train.Example(
                features=tf.train.Features(
                    feature={
                        'data': _float_feature(data_raw),
                        'label': _float_feature(label_raw)
                    }))
            writer.write(example.SerializeToString())


def main(unused_argv):
    # Get the data.
    for path, subdirs, files in os.walk(FLAGS.directory):
        print("path:", path)
        print("subdirs:", subdirs)
        for name in files:
            filename = os.path.join(path, name)
            print("processing ", filename)
            bin_data = np.fromfile(filename, dtype=np.float32)

            # Convert to Examples and write the result to TFRecords.
            convert_to(bin_data, filename)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--directory',
        type=str,
        default='/tmp/data/prediction',
        help='Directory to download data files and write the converted result')
    FLAGS, unparsed = parser.parse_known_args()
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import numpy as np
import os
from collections import Counter
from glob import glob

feature_dim = 62
count = Counter()
filenames = glob('/tmp/data/feature_v1_bin/*/*.label.bin')
for filename in filenames:
    bin_data = np.fromfile(filename, dtype=np.float32)
    if bin_data.shape[0] % (feature_dim + 1) != 0:
        raise ValueError('data size (%d) must be multiple of feature_dim + 1 (%d).' %
                         (bin_data.shape[0], feature_dim + 1))
    label = bin_data[feature_dim::(feature_dim+1)].astype(np.int32)
    count.update(label)

print(count)
#!/usr/bin/env python3

###############################################################################
# Modification Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

"""Prediction data set"""

import os

import tensorflow as tf


dim_input = 62


class MlpDataSet(object):
    """Prediction mlp data set.

    """

    def __init__(self, data_dir, subset='train'):
        self.data_dir = data_dir
        self.subset = subset

    def get_filenames(self):
        if self.subset in ['train', 'validation', 'eval']:
            return [os.path.join(self.data_dir, self.subset + '.tfrecords')]
        else:
            raise ValueError('Invalid data subset "%s"' % self.subset)

    def parser(self, serialized_example):
        """Parses a single tf.Example into image and label tensors."""
        # Dimensions of the images in the CIFAR-10 dataset.

        features = tf.parse_single_example(
            serialized_example,
            features={
                'data': tf.FixedLenFeature([62], tf.float32),
                'label': tf.FixedLenFeature([1], tf.float32),
            })

        image = features['data']
        label = tf.cast(features['label'], tf.int32)+1
        return image, label

    def make_batch(self, batch_size):
        """Read the images and labels from 'filenames'."""
        filenames = self.get_filenames()
        # Repeat infinitely.
        dataset = tf.data.TFRecordDataset(filenames).repeat()

        # Parse records.
        dataset = dataset.map(self.parser, num_parallel_calls=batch_size)

        # Potentially shuffle records.
        if self.subset == 'train':
            min_queue_examples = int(
                MlpDataSet.num_examples_per_epoch(self.subset) * 0.1)
            # Ensure that the capacity is sufficiently large to provide good random
            # shuffling.
            dataset = dataset.shuffle(buffer_size=min_queue_examples +
                                      3 * batch_size)

        # Batch it up.
        dataset = dataset.batch(batch_size)
        iterator = dataset.make_one_shot_iterator()
        image_batch, label_batch = iterator.get_next()

        return image_batch, label_batch

    @staticmethod
    def num_examples_per_epoch(subset='train'):
        if subset == 'train':
            return 13000000
        elif subset == 'validation':
            return 1600000
        elif subset == 'eval':
            return 1600000
        else:
            raise ValueError('Invalid data subset "%s"' % subset)
#!/usr/bin/env python3

###############################################################################
# Modification Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""Mlp model for classifying prediction from Mlp dataset.

"""

import argparse
import functools
import itertools
import os
import six

import modules.tools.multiple_gpu_estimator.mlp_data
import modules.tools.multiple_gpu_estimator.mlp_model
import modules.tools.multiple_gpu_estimator.mlp_utils
import numpy as np
import tensorflow as tf


tf.logging.set_verbosity(tf.logging.INFO)


def get_model_fn(num_gpus, variable_strategy, num_workers):
    """Returns a function that will build the mlp model."""

    def _mlp_model_fn(features, labels, mode, params):
        """Mlp model body.

        Support single host, one or more GPU training. Parameter distribution can
        be either one of the following scheme.
        1. CPU is the parameter server and manages gradient updates.
        2. Parameters are distributed evenly across all GPUs, and the first GPU
             manages gradient updates.

        Args:
            features: a list of tensors, one for each tower
            labels: a list of tensors, one for each tower
            mode: ModeKeys.TRAIN or EVAL
            params: Hyperparameters suitable for tuning
        Returns:
            A EstimatorSpec object.
        """
        is_training = (mode == tf.estimator.ModeKeys.TRAIN)
        weight_decay = params.weight_decay
        momentum = params.momentum

        tower_features = features
        tower_labels = labels
        tower_losses = []
        tower_gradvars = []
        tower_preds = []

        # channels first (NCHW) is normally optimal on GPU and channels last (NHWC)
        # on CPU. The exception is Intel MKL on CPU which is optimal with
        # channels_last.
        data_format = params.data_format
        if not data_format:
            if num_gpus == 0:
                data_format = 'channels_last'
            else:
                data_format = 'channels_first'

        if num_gpus == 0:
            num_devices = 1
            device_type = 'cpu'
        else:
            num_devices = num_gpus
            device_type = 'gpu'

        for i in range(num_devices):
            worker_device = '/{}:{}'.format(device_type, i)
            if variable_strategy == 'CPU':
                device_setter = mlp_utils.local_device_setter(
                    worker_device=worker_device)
            elif variable_strategy == 'GPU':
                device_setter = mlp_utils.local_device_setter(
                    ps_device_type='gpu',
                    worker_device=worker_device,
                    ps_strategy=tf.contrib.training.
                    GreedyLoadBalancingStrategy(
                        num_gpus, tf.contrib.training.byte_size_load_fn))
            with tf.variable_scope('mlp', reuse=bool(i != 0)):
                with tf.name_scope('tower_%d' % i) as name_scope:
                    with tf.device(device_setter):
                        loss, gradvars, preds = _tower_fn(
                            is_training, weight_decay, tower_features[i],
                            tower_labels[i], data_format,
                            params.batch_norm_decay, params.batch_norm_epsilon)
                        tower_losses.append(loss)
                        tower_gradvars.append(gradvars)
                        tower_preds.append(preds)
                        if i == 0:
                            # Only trigger batch_norm moving mean and variance update from
                            # the 1st tower. Ideally, we should grab the updates from all
                            # towers but these stats accumulate extremely fast so we can
                            # ignore the other stats from the other towers without
                            # significant detriment.
                            update_ops = tf.get_collection(
                                tf.GraphKeys.UPDATE_OPS, name_scope)

        # Now compute global loss and gradients.
        gradvars = []
        with tf.name_scope('gradient_averaging'):
            all_grads = {}
            for grad, var in itertools.chain(*tower_gradvars):
                if grad is not None:
                    all_grads.setdefault(var, []).append(grad)
            for var, grads in six.iteritems(all_grads):
                # Average gradients on the same device as the variables
                # to which they apply.
                with tf.device(var.device):
                    if len(grads) == 1:
                        avg_grad = grads[0]
                    else:
                        avg_grad = tf.multiply(
                            tf.add_n(grads), 1. / len(grads))
                gradvars.append((avg_grad, var))

        # Device that runs the ops to apply global gradient updates.
        consolidation_device = '/gpu:0' if variable_strategy == 'GPU' else '/cpu:0'
        with tf.device(consolidation_device):
            num_batches_per_epoch = mlp_data.MlpDataSet.num_examples_per_epoch(
                'train') // (params.train_batch_size * num_workers)
            boundaries = [
                num_batches_per_epoch * x
                for x in np.array([20, 50, 80], dtype=np.int64)
            ]
            staged_lr = [
                params.learning_rate * x for x in [1, 0.1, 0.01, 0.002]
            ]

            learning_rate = tf.train.piecewise_constant(
                tf.train.get_global_step(), boundaries, staged_lr)

            loss = tf.reduce_mean(tower_losses, name='loss')

            examples_sec_hook = mlp_utils.ExamplesPerSecondHook(
                params.train_batch_size, every_n_steps=10)

            tensors_to_log = {'learning_rate': learning_rate, 'loss': loss}

            logging_hook = tf.train.LoggingTensorHook(
                tensors=tensors_to_log, every_n_iter=100)

            train_hooks = [logging_hook, examples_sec_hook]

            optimizer = tf.train.MomentumOptimizer(
                learning_rate=learning_rate, momentum=momentum)

            if params.sync:
                optimizer = tf.train.SyncReplicasOptimizer(
                    optimizer, replicas_to_aggregate=num_workers)
                sync_replicas_hook = optimizer.make_session_run_hook(
                    params.is_chief)
                train_hooks.append(sync_replicas_hook)

            # Create single grouped train op
            train_op = [
                optimizer.apply_gradients(
                    gradvars, global_step=tf.train.get_global_step())
            ]
            train_op.extend(update_ops)
            train_op = tf.group(*train_op)

            predictions = {
                'classes':
                tf.concat([p['classes'] for p in tower_preds], axis=0),
                'probabilities':
                tf.concat([p['probabilities'] for p in tower_preds], axis=0)
            }
            stacked_labels = tf.concat(labels, axis=0)
            metrics = {
                'accuracy':
                tf.metrics.accuracy(stacked_labels, predictions['classes'])
            }

        return tf.estimator.EstimatorSpec(
            mode=mode,
            predictions=predictions,
            loss=loss,
            train_op=train_op,
            training_hooks=train_hooks,
            eval_metric_ops=metrics)

    return _mlp_model_fn


def _tower_fn(is_training, weight_decay, feature, label, data_format,
              batch_norm_decay, batch_norm_epsilon):
    """Build computation tower.

    Args:
        is_training: true if is training graph.
        weight_decay: weight regularization strength, a float.
        feature: a Tensor.
        label: a Tensor.
        data_format: channels_last (NHWC) or channels_first (NCHW).
        batch_norm_decay: decay for batch normalization, a float.
        batch_norm_epsilon: epsilon for batch normalization, a float.

    Returns:
        A tuple with the loss for the tower, the gradients and parameters, and
        predictions.

    """
    model = mlp_model.MlpModel(
        batch_norm_decay=batch_norm_decay,
        batch_norm_epsilon=batch_norm_epsilon,
        is_training=is_training,
        data_format=data_format)
    logits = model.forward_pass(feature, input_data_format='channels_last')
    tower_pred = {
        'classes': tf.argmax(input=logits, axis=1),
        'probabilities': tf.nn.softmax(logits)
    }

    tower_loss = tf.losses.sparse_softmax_cross_entropy(
        logits=logits, labels=label)
    tower_loss = tf.reduce_mean(tower_loss)

    model_params = tf.trainable_variables()
    tower_loss += weight_decay * tf.add_n(
        [tf.nn.l2_loss(v) for v in model_params])

    tower_grad = tf.gradients(tower_loss, model_params)

    return tower_loss, list(zip(tower_grad, model_params)), tower_pred


def input_fn(data_dir, subset, num_shards, batch_size):
    """Create input graph for model.

    Args:
        data_dir: Directory where TFRecords representing the dataset are located.
        subset: one of 'train', 'validate' and 'eval'.
        num_shards: num of towers participating in data-parallel training.
        batch_size: total batch size for training to be divided by the number of
        shards.
    Returns:
        two lists of tensors for features and labels, each of num_shards length.
    """
    with tf.device('/cpu:0'):
        dataset = mlp_data.MlpDataSet(data_dir, subset)
        image_batch, label_batch = dataset.make_batch(batch_size)
        if num_shards <= 1:
            # No GPU available or only 1 GPU.
            return [image_batch], [label_batch]

        # Note that passing num=batch_size is safe here, even though
        # dataset.batch(batch_size) can, in some cases, return fewer than batch_size
        # examples. This is because it does so only when repeating for a limited
        # number of epochs, but our dataset repeats forever.
        image_batch = tf.unstack(image_batch, num=batch_size, axis=0)
        label_batch = tf.unstack(label_batch, num=batch_size, axis=0)
        feature_shards = [[] for i in range(num_shards)]
        label_shards = [[] for i in range(num_shards)]
        for i in range(batch_size):
            idx = i % num_shards
            feature_shards[idx].append(image_batch[i])
            label_shards[idx].append(label_batch[i])
        feature_shards = [tf.parallel_stack(x) for x in feature_shards]
        label_shards = [tf.parallel_stack(x) for x in label_shards]
        return feature_shards, label_shards


def get_experiment_fn(
        data_dir,
        num_gpus,
        variable_strategy,
):
    """Returns an Experiment function.

    Experiments perform training on several workers in parallel,
    in other words experiments know how to invoke train and eval in a sensible
    fashion for distributed training. Arguments passed directly to this
    function are not tunable, all other arguments should be passed within
    tf.HParams, passed to the enclosed function.

    Args:
            data_dir: str. Location of the data for input_fns.
            num_gpus: int. Number of GPUs on each worker.
            variable_strategy: String. CPU to use CPU as the parameter server
            and GPU to use the GPUs as the parameter server.
    Returns:
            A function (tf.estimator.RunConfig, tf.contrib.training.HParams) ->
            tf.contrib.learn.Experiment.

            Suitable for use by tf.contrib.learn.learn_runner, which will run various
            methods on Experiment (train, evaluate) based on information
            about the current runner in `run_config`.
    """

    def _experiment_fn(run_config, hparams):
        """Returns an Experiment."""
        # Create estimator.
        train_input_fn = functools.partial(
            input_fn,
            data_dir,
            subset='train',
            num_shards=num_gpus,
            batch_size=hparams.train_batch_size)

        eval_input_fn = functools.partial(
            input_fn,
            data_dir,
            subset='eval',
            batch_size=hparams.eval_batch_size,
            num_shards=num_gpus)

        num_eval_examples = mlp_data.MlpDataSet.num_examples_per_epoch('eval')
        if num_eval_examples % hparams.eval_batch_size != 0:
            raise ValueError(
                'validation set size must be multiple of eval_batch_size')

        train_steps = hparams.train_steps
        eval_steps = num_eval_examples // hparams.eval_batch_size

        classifier = tf.estimator.Estimator(
            model_fn=get_model_fn(num_gpus, variable_strategy,
                                  run_config.num_worker_replicas or 1),
            config=run_config,
            params=hparams)

        # Create experiment.
        return tf.contrib.learn.Experiment(
            classifier,
            train_input_fn=train_input_fn,
            eval_input_fn=eval_input_fn,
            train_steps=train_steps,
            eval_steps=eval_steps)

    return _experiment_fn


def main(job_dir, data_dir, num_gpus, variable_strategy, log_device_placement,
         num_intra_threads, **hparams):
    # The env variable is on deprecation path, default is set to off.
    os.environ['TF_SYNC_ON_FINISH'] = '0'
    os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'

    # Session configuration.
    sess_config = tf.ConfigProto(
        allow_soft_placement=True,
        log_device_placement=log_device_placement,
        intra_op_parallelism_threads=num_intra_threads,
        gpu_options=tf.GPUOptions(force_gpu_compatible=True))

    config = mlp_utils.RunConfig(session_config=sess_config, model_dir=job_dir)
    tf.contrib.learn.learn_runner.run(
        get_experiment_fn(data_dir, num_gpus, variable_strategy),
        run_config=config,
        hparams=tf.contrib.training.HParams(
            is_chief=config.is_chief, **hparams))


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--data-dir',
        type=str,
        required=True,
        help='The directory where the CIFAR-10 input data is stored.')
    parser.add_argument(
        '--job-dir',
        type=str,
        required=True,
        help='The directory where the model will be stored.')
    parser.add_argument(
        '--variable-strategy',
        choices=['CPU', 'GPU'],
        type=str,
        default='CPU',
        help='Where to locate variable operations')
    parser.add_argument(
        '--num-gpus',
        type=int,
        default=1,
        help='The number of gpus used. Uses only CPU if set to 0.')
    parser.add_argument(
        '--train-steps',
        type=int,
        default=20000,
        help='The number of steps to use for training.')
    parser.add_argument(
        '--train-batch-size',
        type=int,
        default=10000,
        help='Batch size for training.')
    parser.add_argument(
        '--eval-batch-size',
        type=int,
        default=10000,
        help='Batch size for validation.')
    parser.add_argument(
        '--momentum',
        type=float,
        default=0.9,
        help='Momentum for MomentumOptimizer.')
    parser.add_argument(
        '--weight-decay',
        type=float,
        default=2e-4,
        help='Weight decay for convolutions.')
    parser.add_argument(
        '--learning-rate',
        type=float,
        default=0.1,
        help="""\
            This is the initial learning rate value. The learning rate will decrease
            during training. For more details check the model_fn implementation in
            this file.\
            """)
    parser.add_argument(
        '--sync',
        action='store_true',
        default=False,
        help="""\
            If present when running in a distributed environment will run on sync mode.\
            """)
    parser.add_argument(
        '--num-intra-threads',
        type=int,
        default=0,
        help="""\
            Number of threads to use for intra-op parallelism. When training on CPU
            set to 0 to have the system pick the appropriate number or alternatively
            set it to the number of physical CPU cores.\
            """)
    parser.add_argument(
        '--num-inter-threads',
        type=int,
        default=0,
        help="""\
            Number of threads to use for inter-op parallelism. If set to 0, the
            system will pick an appropriate number.\
            """)
    parser.add_argument(
        '--data-format',
        type=str,
        default=None,
        help="""\
            If not set, the data format best for the training device is used.
            Allowed values: channels_first (NCHW) channels_last (NHWC).\
            """)
    parser.add_argument(
        '--log-device-placement',
        action='store_true',
        default=False,
        help='Whether to log device placement.')
    parser.add_argument(
        '--batch-norm-decay',
        type=float,
        default=0.997,
        help='Decay for batch norm.')
    parser.add_argument(
        '--batch-norm-epsilon',
        type=float,
        default=1e-5,
        help='Epsilon for batch norm.')
    args = parser.parse_args()

    if args.num_gpus > 0:
        assert tf.test.is_gpu_available(), "Requested GPUs but none found."
    if args.num_gpus < 0:
        raise ValueError(
            'Invalid GPU count: \"--num-gpus\" must be 0 or a positive integer.'
        )
    if args.num_gpus == 0 and args.variable_strategy == 'GPU':
        raise ValueError(
            'num-gpus=0, CPU must be used as parameter server. Set'
            '--variable-strategy=CPU.')
    if args.num_gpus != 0 and args.train_batch_size % args.num_gpus != 0:
        raise ValueError('--train-batch-size must be multiple of --num-gpus.')
    if args.num_gpus != 0 and args.eval_batch_size % args.num_gpus != 0:
        raise ValueError('--eval-batch-size must be multiple of --num-gpus.')

    main(**vars(args))
#!/usr/bin/env python3

###############################################################################
# Modification Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import tensorflow as tf

import modules.tools.prediction.multiple_gpu_estimator.model_base


dim_input = 62
dim_hidden_1 = 30
dim_hidden_2 = 15
dim_output = 4


class MlpModel(model_base.ModelBase):
    """prediction model with fully connected layers."""

    def __init__(self,
                 is_training=True,
                 batch_norm_decay=0.999,
                 batch_norm_epsilon=0.001,
                 data_format='channels_last'):
        super(MlpModel, self).__init__(is_training, data_format,
                                       batch_norm_decay, batch_norm_epsilon)

    def forward_pass(self, x, input_data_format='channels_last'):
        """Build the core model within the graph."""
        x = self._fully_connected_with_bn(
            x,
            dim_input,
            kernel_initializer=tf.contrib.keras.initializers.he_normal(),
            kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))
        x = self._fully_connected_with_bn(
            x,
            dim_hidden_1,
            kernel_initializer=tf.contrib.keras.initializers.he_normal(),
            kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))
        x = self._fully_connected_with_bn(
            x,
            dim_hidden_2,
            kernel_initializer=tf.contrib.keras.initializers.he_normal(),
            kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))
        x = self._fully_connected(x, dim_output)
        return x

    def _fully_connected_with_bn(self,
                                 x,
                                 out_dim,
                                 kernel_initializer=None,
                                 kernel_regularizer=None):
        x = self._fully_connected(
            x,
            out_dim,
            kernel_initializer=kernel_initializer,
            kernel_regularizer=kernel_regularizer)
        x = self._relu(x)
        x = self._batch_norm(x)
        return x
#!/usr/bin/env python3

###############################################################################
# Modification Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import collections
import six

from tensorflow.contrib.learn.python.learn import run_config
from tensorflow.core.framework import node_def_pb2
from tensorflow.python.framework import device as pydev
from tensorflow.python.platform import tf_logging as logging
from tensorflow.python.training import basic_session_run_hooks
from tensorflow.python.training import device_setter
from tensorflow.python.training import session_run_hook
from tensorflow.python.training import training_util
import tensorflow as tf


class RunConfig(tf.contrib.learn.RunConfig):
    def uid(self, whitelist=None):
        """Generates a 'Unique Identifier' based on all internal fields.
        Caller should use the uid string to check `RunConfig` instance integrity
        in one session use, but should not rely on the implementation details, which
        is subject to change.
        Args:
            whitelist: A list of the string names of the properties uid should not
                include. If `None`, defaults to `_DEFAULT_UID_WHITE_LIST`, which
                includes most properties user allowes to change.
        Returns:
            A uid string.
        """
        if whitelist is None:
            whitelist = run_config._DEFAULT_UID_WHITE_LIST

        state = {
            k: v
            for k, v in self.__dict__.items() if not k.startswith('__')
        }
        # Pop out the keys in whitelist.
        for k in whitelist:
            state.pop('_' + k, None)

        ordered_state = collections.OrderedDict(
            sorted(list(state.items()), key=lambda t: t[0]))
        # For class instance without __repr__, some special cares are required.
        # Otherwise, the object address will be used.
        if '_cluster_spec' in ordered_state:
            ordered_state['_cluster_spec'] = collections.OrderedDict(
                sorted(
                    list(ordered_state['_cluster_spec'].as_dict().items()),
                    key=lambda t: t[0]))
        return ', '.join(
            '%s=%r' % (k, v) for (k, v) in six.iteritems(ordered_state))


class ExamplesPerSecondHook(session_run_hook.SessionRunHook):
    """Hook to print out examples per second.

        Total time is tracked and then divided by the total number of steps
        to get the average step time and then batch_size is used to determine
        the running average of examples per second. The examples per second for the
        most recent interval is also logged.
    """

    def __init__(
            self,
            batch_size,
            every_n_steps=100,
            every_n_secs=None,
    ):
        """Initializer for ExamplesPerSecondHook.

            Args:
            batch_size: Total batch size used to calculate examples/second from
            global time.
            every_n_steps: Log stats every n steps.
            every_n_secs: Log stats every n seconds.
        """
        if (every_n_steps is None) == (every_n_secs is None):
            raise ValueError('exactly one of every_n_steps'
                             ' and every_n_secs should be provided.')
        self._timer = basic_session_run_hooks.SecondOrStepTimer(
            every_steps=every_n_steps, every_secs=every_n_secs)

        self._step_train_time = 0
        self._total_steps = 0
        self._batch_size = batch_size

    def begin(self):
        self._global_step_tensor = training_util.get_global_step()
        if self._global_step_tensor is None:
            raise RuntimeError(
                'Global step should be created to use StepCounterHook.')

    def before_run(self, run_context):  # pylint: disable=unused-argument
        return basic_session_run_hooks.SessionRunArgs(self._global_step_tensor)

    def after_run(self, run_context, run_values):
        _ = run_context

        global_step = run_values.results
        if self._timer.should_trigger_for_step(global_step):
            elapsed_time, elapsed_steps = self._timer.update_last_triggered_step(
                global_step)
            if elapsed_time is not None:
                steps_per_sec = elapsed_steps / elapsed_time
                self._step_train_time += elapsed_time
                self._total_steps += elapsed_steps

                average_examples_per_sec = self._batch_size * (
                    self._total_steps / self._step_train_time)
                current_examples_per_sec = steps_per_sec * self._batch_size
                # Average examples/sec followed by current examples/sec
                logging.info('%s: %g (%g), step = %g', 'Average examples/sec',
                             average_examples_per_sec,
                             current_examples_per_sec, self._total_steps)


def local_device_setter(num_devices=1,
                        ps_device_type='cpu',
                        worker_device='/cpu:0',
                        ps_ops=None,
                        ps_strategy=None):
    if ps_ops is None:
        ps_ops = ['Variable', 'VariableV2', 'VarHandleOp']

    if ps_strategy is None:
        ps_strategy = device_setter._RoundRobinStrategy(num_devices)
    if not six.callable(ps_strategy):
        raise TypeError("ps_strategy must be callable")

    def _local_device_chooser(op):
        current_device = pydev.DeviceSpec.from_string(op.device or "")

        node_def = op if isinstance(op, node_def_pb2.NodeDef) else op.node_def
        if node_def.op in ps_ops:
            ps_device_spec = pydev.DeviceSpec.from_string('/{}:{}'.format(
                ps_device_type, ps_strategy(op)))
            ps_device_spec.merge_from(current_device)
            return ps_device_spec.to_string()

        worker_device_spec = pydev.DeviceSpec.from_string(worker_device or "")
        worker_device_spec.merge_from(current_device)
        return worker_device_spec.to_string()

    return _local_device_chooser
#!/usr/bin/env python3

###############################################################################
# Modification Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import tensorflow as tf


class ModelBase(object):
    def __init__(self,
                 is_training=True,
                 data_format='channels_last',
                 batch_norm_decay=0.999,
                 batch_norm_epsilon=0.001):
        """ModelBase constructor.

    Args:
      is_training: if build training or inference model.
      data_format: the data_format used during computation.
                   one of 'channels_first' or 'channels_last'.
    """
        self._batch_norm_decay = batch_norm_decay
        self._batch_norm_epsilon = batch_norm_epsilon
        self._is_training = is_training
        assert data_format in ('channels_first', 'channels_last')
        self._data_format = data_format

    def forward_pass(self, x):
        raise NotImplementedError(
            'forward_pass() is implemented in ResNet sub classes')

    def _conv(self, x, kernel_size, filters, strides, is_atrous=False):
        """Convolution."""

        padding = 'SAME'
        if not is_atrous and strides > 1:
            pad = kernel_size - 1
            pad_beg = pad // 2
            pad_end = pad - pad_beg
            if self._data_format == 'channels_first':
                x = tf.pad(
                    x,
                    [[0, 0], [0, 0], [pad_beg, pad_end], [pad_beg, pad_end]])
            else:
                x = tf.pad(
                    x,
                    [[0, 0], [pad_beg, pad_end], [pad_beg, pad_end], [0, 0]])
            padding = 'VALID'
        return tf.layers.conv2d(
            inputs=x,
            kernel_size=kernel_size,
            filters=filters,
            strides=strides,
            padding=padding,
            use_bias=False,
            data_format=self._data_format)

    def _batch_norm(self, x):
        if self._data_format == 'channels_first':
            data_format = 'NCHW'
        else:
            data_format = 'NHWC'
        return tf.contrib.layers.batch_norm(
            x,
            decay=self._batch_norm_decay,
            center=True,
            scale=True,
            epsilon=self._batch_norm_epsilon,
            is_training=self._is_training,
            fused=True,
            data_format=data_format)

    def _relu(self, x):
        return tf.nn.relu(x)

    def _fully_connected(self,
                         x,
                         out_dim,
                         kernel_initializer=None,
                         kernel_regularizer=None):
        with tf.name_scope('fully_connected') as name_scope:
            x = tf.layers.dense(
                x,
                out_dim,
                kernel_initializer=kernel_initializer,
                kernel_regularizer=kernel_regularizer)

        tf.logging.info('image after unit %s: %s', name_scope, x.get_shape())
        return x
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import tensorflow as tf
import numpy as np
from glob import glob

feature_dim = 62
train_data = np.zeros([20000000, feature_dim+1], dtype=np.float32)
test_data = np.zeros([2000000, feature_dim+1], dtype=np.float32)
eval_data = np.zeros([2000000, feature_dim+1], dtype=np.float32)
train_idx, test_idx, eval_idx = 0, 0, 0
filenames = glob('/tmp/data/feature_v1_bin/*/*.label.bin')
for filename in filenames:
    print(filename)
    bin_data = np.fromfile(filename, dtype=np.float32)
    if bin_data.shape[0] % (feature_dim + 1) != 0:
        raise ValueError('data size (%d) must be multiple of feature_dim + 1 (%d).' %
                         (bin_data.shape[0], feature_dim + 1))
    num_examples = bin_data.shape[0] // (feature_dim + 1)
    for i in range(num_examples):
        label = int(bin_data[i*(feature_dim + 1)+feature_dim])
        data = bin_data[i*(feature_dim + 1):(i+1) *
                        (feature_dim + 1)].reshape([1, (feature_dim+1)])
        if label == 2:
            times = 17
            new_data = np.repeat(data, times, axis=0)
        elif label == 1:
            times = np.random.choice([2, 2, 2, 3, 3])
            new_data = np.repeat(data, times, axis=0)
        else:
            times = 1
            new_data = data

        if i % 10 == 8:
            test_data[test_idx:test_idx+times, :] = new_data
            test_idx += times
        elif i % 10 == 9:
            eval_data[eval_idx:eval_idx+times, :] = new_data
            eval_idx += times
        else:
            train_data[train_idx:train_idx+times, :] = new_data
            train_idx += times

train_data = train_data[:train_idx, :]
np.random.shuffle(train_data)
print(train_data.shape, train_idx)

test_data = test_data[:test_idx, :]
np.random.shuffle(test_data)
print(test_data.shape, test_idx)

eval_data = eval_data[:eval_idx, :]
np.random.shuffle(eval_data)
print(eval_data.shape, eval_idx)

# write to file
train_data[:13000000, :].tofile('/tmp/data/prediction/train.bin')
test_data[:1600000, :].tofile('/tmp/data/prediction/test.bin')
eval_data[:1600000, :].tofile('/tmp/data/prediction/eval.bin')
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Time Value Item
"""
import numpy
from matplotlib import lines


class Item(object):
    """
    Specific item to plot
    """

    def __init__(self, ax, title, xlabel, ylabel, ymin, ymax):
        self.ax = ax

        self.title = title
        self.ax.set_title(title)
        self.ax.set_xlabel(xlabel, fontsize=10)
        self.ax.set_ylabel(ylabel, fontsize=10)
        self.ymin = ymin
        self.ymax = ymax
        self.ax.set_ylim([ymin, ymax])

        self.lines = []

        self.cartimehist = []
        self.carvaluehist = []
        self.targettime = []
        self.targethist = []

        self.targethistidx = -1
        self.histidx = -1

        self.prev_auto = False

        self.planningavailable = False

    def reset(self):
        """
        Reset
        """
        del self.lines[:]

        del self.cartimehist[:]
        del self.carvaluehist[:]
        del self.targettime[:]
        del self.targethist[:]

        self.ax.cla()

        self.ax.set_ylim([self.ymin, self.ymax])
        self.targethistidx = -1
        self.histidx = -1

        self.prev_auto = False

        self.planningavailable = False

    def new_planning(self, time, values):
        """
        new planning
        """
        self.planningtime = time
        self.planningvalues = values

        if self.planningavailable == False:
            self.ax.set_xlim([time[0] - 1, time[-1] + 10])
            self.current_line = lines.Line2D(time, values, color='red', lw=1.5)
            self.ax.add_line(self.current_line)

        else:
            self.current_line.set_data(time, values)

            xmin, xmax = self.ax.get_xlim()
            if (time[-1] >= (xmax - 1)):
                self.ax.set_xlim([time[0] - 1, time[-1] + 10])

        self.planningavailable = True

    def new_carstatus(self, time, value, autodriving):
        """
        new carstatus
        """
        if autodriving and not self.prev_auto:
            self.starttime = time
            self.endtime = time + 50
            self.ax.axvspan(self.starttime, self.endtime, fc='0.1', alpha=0.3)
        elif autodriving and time >= (self.endtime - 20):
            self.endtime = time + 50
            self.ax.patches[-1].remove()
            self.ax.axvspan(self.starttime, self.endtime, fc='0.1', alpha=0.3)
        elif not autodriving and self.prev_auto:
            self.endtime = time
            self.ax.patches[-1].remove()
            self.ax.axvspan(self.starttime, self.endtime, fc='0.1', alpha=0.3)

        self.prev_auto = autodriving

        self.cartimehist.append(time)
        self.carvaluehist.append(value)

        if self.planningavailable:
            target = numpy.interp(time, self.planningtime, self.planningvalues)
            self.targettime.append(time)
            self.targethist.append(target)

            if self.targethistidx == -1:
                self.ax.plot(
                    self.targettime, self.targethist, color='green', lw=1.5)
                self.targethistidx = len(self.ax.lines) - 1
            else:
                self.ax.lines[self.targethistidx].set_data(
                    self.targettime, self.targethist)

        if self.histidx == -1:
            self.ax.plot(self.cartimehist, self.carvaluehist, color='blue')
            self.histidx = len(self.ax.lines) - 1

        else:
            self.ax.lines[self.histidx].set_data(self.cartimehist,
                                                 self.carvaluehist)

    def draw_lines(self):
        """
        plot lines
        """
        for polygon in self.ax.patches:
            self.ax.draw_artist(polygon)

        for line in self.ax.lines:
            self.ax.draw_artist(line)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""Real Time Plotting of planning and control"""

import math
import sys
import threading

import gflags
import matplotlib.pyplot as plt
import numpy as np

from cyber.python.cyber_py3 import cyber
from modules.tools.realtime_plot.item import Item
from modules.canbus.proto.chassis_pb2 import Chassis
from modules.localization.proto.localization_pb2 import LocalizationEstimate
from modules.planning.proto.planning_pb2 import ADCTrajectory
from modules.tools.realtime_plot.stitem import Stitem
from modules.tools.realtime_plot.xyitem import Xyitem
import modules.tools.common.proto_utils as proto_utils


VehicleLength = 2.85
HistLine2display = 2  # The number of lines to display
MaxSteerAngle = 470  # Maximum Steering Angle
SteerRatio = 16
WindowSize = 80

FLAGS = gflags.FLAGS
gflags.DEFINE_boolean('show_heading', False,
                      'Show heading instead of acceleration')
gflags.DEFINE_boolean('show_st_graph', False, 'Show st graph')


class Plotter(object):
    """Plotter Class"""

    def __init__(self, ax1, ax2, ax3, ax4, stgraph):
        self.ax = [ax1, ax2, ax3, ax4]

        self.updategraph = False
        self.planningavailable = False

        self.closed = False
        self.carspeed = 0.0
        self.steer_angle = 0.0
        self.autodrive = False
        self.carcurvature = 0.0

        self.stgraph = stgraph

        self.lock = threading.Lock()

    def callback_planning(self, data):
        """New Planning Trajectory"""
        if self.stgraph:
            st_s, st_t, polygons_s, polygons_t = proto_utils.flatten(
                data.debug.planning_data.st_graph,
                ['speed_profile.s',
                 'speed_profile.t',
                 'boundary.point.s',
                 'boundary.point.t'])

            with self.lock:
                for i in range(len(st_s)):
                    self.ax[i].new_planning(st_t[i], st_s[i],
                                            polygons_t[i], polygons_s[i])

        else:
            if len(data.trajectory_point) == 0:
                print(data)
                return

            x, y, speed, theta, kappa, acc, relative_time = np.array(
                proto_utils.flatten(data.trajectory_point,
                                    ['path_point.x',
                                     'path_point.y',
                                     'v',
                                     'path_point.theta',
                                     'path_point.kappa',
                                     'a',
                                     'relative_time']))
            relative_time += data.header.timestamp_sec

            with self.lock:
                self.ax[0].new_planning(relative_time, x, y)
                self.ax[1].new_planning(relative_time, speed)

                if self.ax[2].title == "Curvature":
                    self.ax[2].new_planning(relative_time, kappa)

                if self.ax[3].title == "Heading":
                    self.ax[3].new_planning(relative_time, theta)
                else:
                    self.ax[3].new_planning(relative_time, acc)

    def callback_chassis(self, data):
        """New localization pose"""
        if self.stgraph:
            return
        self.carspeed = data.speed_mps
        self.steer_angle = \
            data.steering_percentage / 100 * MaxSteerAngle / SteerRatio

        self.autodrive = (data.driving_mode == Chassis.COMPLETE_AUTO_DRIVE)
        self.carcurvature = math.tan(
            math.radians(self.steer_angle)) / VehicleLength

    def callback_localization(self, data):
        """New localization pose"""
        if self.stgraph:
            return
        carheading = data.pose.heading
        carx = data.pose.position.x
        cary = data.pose.position.y
        cartime = data.header.timestamp_sec
        with self.lock:
            self.ax[0].new_carstatus(cartime, carx, cary, carheading,
                                     self.steer_angle, self.autodrive)
            self.ax[1].new_carstatus(cartime, self.carspeed, self.autodrive)
            self.ax[2].new_carstatus(
                cartime, self.carcurvature, self.autodrive)

            if self.ax[3].title == "Heading":
                self.ax[3].new_carstatus(cartime, carheading, self.autodrive)
            else:
                acc = data.pose.linear_acceleration_vrf.y
                self.ax[3].new_carstatus(cartime, acc, self.autodrive)

    def press(self, event):
        """Keyboard events during plotting"""
        if event.key == 'q' or event.key == 'Q':
            plt.close('all')
            self.closed = True

        if event.key == 'x' or event.key == 'X':
            self.updategraph = True

        if event.key == 'a' or event.key == 'A':
            fig = plt.gcf()
            fig.gca().autoscale()
            fig.canvas.draw()

        if event.key == 'n' or event.key == 'N':
            with self.lock:
                for ax in self.ax:
                    ax.reset()
            self.updategraph = True


def main(argv):
    """Main function"""
    argv = FLAGS(argv)

    print("""
    Keyboard Shortcut:
        [q]: Quit Tool
        [s]: Save Figure
        [a]: Auto-adjust x, y axis to display entire plot
        [x]: Update Figure to Display last few Planning Trajectory instead of all
        [h][r]: Go back Home, Display all Planning Trajectory
        [f]: Toggle Full Screen
        [n]: Reset all Plots
        [b]: Unsubscribe Topics

    Legend Description:
        Red Line: Current Planning Trajectory
        Blue Line: Past Car Status History
        Green Line: Past Planning Target History at every Car Status Frame
        Cyan Dashed Line: Past Planning Trajectory Frames
    """)
    cyber.init()
    planning_sub = cyber.Node("stat_planning")

    fig = plt.figure()

    if not FLAGS.show_st_graph:
        ax1 = plt.subplot(2, 2, 1)
        item1 = Xyitem(ax1, WindowSize, VehicleLength, "Trajectory", "X [m]",
                       "Y [m]")

        ax2 = plt.subplot(2, 2, 2)
        item2 = Item(ax2, "Speed", "Time [sec]", "Speed [m/s]", 0, 30)

        ax3 = plt.subplot(2, 2, 3, sharex=ax2)
        item3 = Item(ax3, "Curvature", "Time [sec]", "Curvature [m-1]", -0.2,
                     0.2)

        ax4 = plt.subplot(2, 2, 4, sharex=ax2)
        if not FLAGS.show_heading:
            item4 = Item(ax4, "Acceleration", "Time [sec]",
                         "Acceleration [m/sec^2]", -5, 5)
        else:
            item4 = Item(ax4, "Heading", "Time [sec]", "Heading [radian]", -4,
                         4)
    else:
        ax1 = plt.subplot(2, 2, 1)
        item1 = Stitem(ax1, "ST Graph", "Time [sec]", "S [m]")

        ax2 = plt.subplot(2, 2, 2)
        item2 = Stitem(ax2, "ST Graph", "Time [sec]", "S [m]")

        ax3 = plt.subplot(2, 2, 3)
        item3 = Stitem(ax3, "ST Graph", "Time [sec]", "S [m]")

        ax4 = plt.subplot(2, 2, 4)
        item4 = Stitem(ax4, "ST Graph", "Time [sec]", "S [m]")

    plt.tight_layout(pad=0.20)
    plt.ion()
    plt.show()

    plotter = Plotter(item1, item2, item3, item4, FLAGS.show_st_graph)
    fig.canvas.mpl_connect('key_press_event', plotter.press)
    planning_sub.create_reader('/apollo/planning',
                               ADCTrajectory, plotter.callback_planning)
    if not FLAGS.show_st_graph:
        localization_sub = cyber.Node("localization_sub")
        localization_sub.create_reader('/apollo/localization/pose',
                                       LocalizationEstimate, plotter.callback_localization)
        chassis_sub = cyber.Node("chassis_sub")
        chassis_sub.create_reader('/apollo/canbus/chassis',
                                  Chassis, plotter.callback_chassis)

    while not cyber.is_shutdown():
        ax1.draw_artist(ax1.patch)
        ax2.draw_artist(ax2.patch)
        ax3.draw_artist(ax3.patch)
        ax4.draw_artist(ax4.patch)

        with plotter.lock:
            item1.draw_lines()
            item2.draw_lines()
            item3.draw_lines()
            item4.draw_lines()

        fig.canvas.blit(ax1.bbox)
        fig.canvas.blit(ax2.bbox)
        fig.canvas.blit(ax3.bbox)
        fig.canvas.blit(ax4.bbox)
        fig.canvas.flush_events()


if __name__ == '__main__':
    main(sys.argv)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""S T Item"""

import numpy as np
from matplotlib import lines
from matplotlib.patches import Polygon


class Stitem(object):
    """Specific item to plot"""

    def __init__(self, ax, title, xlabel, ylabel):
        self.ax = ax
        self.title = title
        self.ax.set_title(title)
        self.ax.set_xlabel(xlabel, fontsize=10)
        self.ax.set_ylabel(ylabel, fontsize=10)
        self.planningavailable = False

    def reset(self):
        """Reset"""
        self.ax.cla()
        self.ax.set_xlim([-0.1, 0.1])
        self.ax.set_ylim([-0.1, 0.1])

    def new_planning(self, time, values, polygons_t, polygons_s):
        """new planning"""
        max_time = max(time) + 1
        max_value = max(values) + 1
        if self.planningavailable == False:
            self.ax.set_xlim([0, max_time])
            self.ax.set_ylim([0, max_value])
            self.ymax = max_value
            self.tmax = max_time
            self.current_line = lines.Line2D(time, values, color='red', lw=1.5)
            self.ax.add_line(self.current_line)
        else:
            self.current_line.set_data(time, values)
            _, xmax = self.ax.get_xlim()
            if max_time > xmax:
                self.ax.set_xlim([0, max_time])
            _, ymax = self.ax.get_ylim()
            if max_value > ymax:
                self.ax.set_ylim([0, max_value])

        self.ax.patches = []
        for i in range(len(polygons_s)):
            points = np.vstack((polygons_t[i], polygons_s[i])).T
            polygon = Polygon(points)
            self.ax.add_patch(polygon)

        self.planningavailable = True

    def draw_lines(self):
        """plot lines"""
        for polygon in self.ax.patches:
            self.ax.draw_artist(polygon)

        for line in self.ax.lines:
            self.ax.draw_artist(line)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
X Y Item
"""
import math

import numpy as np
from matplotlib import lines
from matplotlib import patches


class Xyitem(object):
    """XY item to plot"""

    def __init__(self, ax, windowsize, vehiclelength, title, xlabel, ylabel):
        self.ax = ax
        self.windowsize = windowsize
        self.vehiclelength = vehiclelength

        self.ax.set_title(title)
        self.ax.set_xlabel(xlabel, fontsize=10)
        self.ax.set_ylabel(ylabel, fontsize=10)

        self.lines = []

        self.pathstartx = []
        self.pathstarty = []

        self.carxhist = []
        self.caryhist = []

        self.targetx = []
        self.targety = []

        self.pathstartidx = -1
        self.carxyhistidx = -1
        self.carposidx = -1
        self.targethistidx = -1

        self.axx = float('inf')
        self.axy = float('inf')

        self.planningavailable = False

    def reset(self):
        """Reset"""
        del self.pathstartx[:]
        del self.pathstarty[:]

        del self.carxhist[:]
        del self.caryhist[:]

        del self.targetx[:]
        del self.targety[:]

        self.ax.cla()

        self.pathstartidx = -1
        self.carxyhistidx = -1
        self.carposidx = -1
        self.targethistidx = -1

        self.axx = float('inf')
        self.axy = float('inf')

        self.planningavailable = False

    def new_planning(self, time, x, y):
        """new planning"""
        self.planningtime = time
        self.planningx = x
        self.planningy = y

        self.pathstartx.append(x[0])
        self.pathstarty.append(y[0])

        if self.pathstartidx == -1:
            self.ax.plot(
                self.pathstartx,
                self.pathstarty,
                color='red',
                marker='*',
                ls='None')
            self.pathstartidx = len(self.ax.lines) - 1
            self.current_line = lines.Line2D(x, y, color='red', lw=1.5)
            self.ax.add_line(self.current_line)
        else:
            self.ax.lines[self.pathstartidx].set_data(self.pathstartx,
                                                      self.pathstarty)
            self.current_line.set_data(x, y)

        self.planningavailable = True

    def new_carstatus(self, time, x, y, heading, steer_angle, autodriving):
        """new carstatus"""
        self.carxhist.append(x)
        self.caryhist.append(y)

        angle = math.degrees(heading) - 90
        carcolor = 'red' if autodriving else 'blue'
        if self.carxyhistidx == -1:
            self.ax.plot(self.carxhist, self.caryhist, color="blue")
            self.carxyhistidx = len(self.ax.lines) - 1

            self.ax.plot(
                self.carxhist,
                self.caryhist,
                marker=(3, 0, angle),
                markersize=20,
                mfc=carcolor)
            self.carposidx = len(self.ax.lines) - 1

        else:
            self.ax.lines[self.carxyhistidx].set_data(self.carxhist,
                                                      self.caryhist)
            self.ax.lines[self.carposidx].set_data(x, y)
            self.ax.lines[self.carposidx].set_marker((3, 0, angle))
            self.ax.lines[self.carposidx].set_mfc(carcolor)
            self.ax.patches[0].remove()

        if self.planningavailable:
            xtarget = np.interp(time, self.planningtime, self.planningx)
            self.targetx.append(xtarget)
            ytarget = np.interp(time, self.planningtime, self.planningy)
            self.targety.append(ytarget)

            if self.targethistidx == -1:
                self.ax.plot(self.targetx, self.targety, color="green", lw=1.5)
                self.targethistidx = len(self.ax.lines) - 1
            else:
                self.ax.lines[self.targethistidx].set_data(
                    self.targetx, self.targety)

        self.ax.add_patch(self.gen_steer_curve(x, y, heading, steer_angle))
        # Update Window X, Y Axis Limits
        xcenter = x + math.cos(heading) * 40
        ycenter = y + math.sin(heading) * 40
        if xcenter >= (self.axx + 20) or xcenter <= (self.axx - 20) or \
                ycenter >= (self.axy + 20) or ycenter <= (self.axy - 20):
            scale = self.ax.get_window_extent(
            )._transform._boxout._bbox.get_points()[1]
            original = self.ax.get_position().get_points()
            finalscale = (original[1] - original[0]) * scale
            ratio = finalscale[1] / finalscale[0]
            self.axx = xcenter
            self.axy = ycenter
            self.ax.set_xlim(
                [xcenter - self.windowsize, xcenter + self.windowsize])
            self.ax.set_ylim([
                ycenter - self.windowsize * ratio,
                ycenter + self.windowsize * ratio
            ])

    def gen_steer_curve(self, x, y, heading, steer_angle):
        """Generate Steering Curve to predict car trajectory"""
        if abs(math.tan(math.radians(steer_angle))) > 0.0001:
            R = self.vehiclelength / math.tan(math.radians(steer_angle))
        else:
            R = 100000

        radius = abs(R)
        lengthangle = 7200 / (2 * math.pi * radius)
        if R >= 0:
            centerangle = math.pi / 2 + heading
            startangle = math.degrees(heading - math.pi / 2)
            theta1 = 0
            theta2 = lengthangle
        else:
            centerangle = heading - math.pi / 2
            startangle = math.degrees(math.pi / 2 + heading)
            theta1 = -lengthangle
            theta2 = 0

        centerx = x + math.cos(centerangle) * radius
        centery = y + math.sin(centerangle) * radius

        curve = patches.Arc(
            (centerx, centery),
            2 * radius,
            2 * radius,
            angle=startangle,
            theta1=theta1,
            theta2=theta2,
            linewidth=2,
            zorder=2)
        return curve

    def draw_lines(self):
        """plot lines"""
        for polygon in self.ax.patches:
            self.ax.draw_artist(polygon)

        for line in self.ax.lines:
            self.ax.draw_artist(line)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from modules.tools.record_analyzer.common.statistical_analyzer import PrintColors


class DistributionAnalyzer:
    """statistical analzer class"""

    def print_distribution_results(self, data):
        """distribution analyzer"""
        if len(data) == 0:
            print(PrintColors.FAIL + "No Data Generated!" + PrintColors.ENDC)
            return

        total = 0
        for k, v in data.items():
            total += v

        for k, v in data.items():
            percentage = "{0:.2f}".format((float(v) / total) * 100)
            print(PrintColors.OKBLUE + k + " = " + str(v) +
                  "(" + percentage + "%)" + PrintColors.ENDC)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from modules.common.proto import error_code_pb2
from modules.tools.record_analyzer.common.statistical_analyzer import PrintColors
from modules.tools.record_analyzer.common.distribution_analyzer import DistributionAnalyzer


class ErrorCodeAnalyzer:
    """class"""

    def __init__(self):
        """init"""
        self.error_code_count = {}

    def put(self, error_code):
        """put"""
        error_code_name = \
            error_code_pb2.ErrorCode.Name(error_code)
        if error_code_name not in self.error_code_count:
            self.error_code_count[error_code_name] = 1
        else:
            self.error_code_count[error_code_name] += 1

    def print_results(self):
        """print"""
        DistributionAnalyzer().print_distribution_results(self.error_code_count)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from modules.common.proto import error_code_pb2
from modules.tools.record_analyzer.common.statistical_analyzer import PrintColors
from modules.tools.record_analyzer.common.distribution_analyzer import DistributionAnalyzer


class ErrorMsgAnalyzer:
    """class"""

    def __init__(self):
        """init"""
        self.error_msg_count = {}

    def put(self, error_msg):
        """put"""
        if len(error_msg) == 0:
            return
        if error_msg not in self.error_msg_count:
            self.error_msg_count[error_msg] = 1
        else:
            self.error_msg_count[error_msg] += 1

    def print_results(self):
        """print"""
        DistributionAnalyzer().print_distribution_results(self.error_msg_count)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math

import numpy as np


def euclidean_distance(pt1, pt2):
    return math.sqrt((pt2[0] - pt1[0]) * (pt2[0]-pt1[0]) +
                     (pt2[1] - pt1[1]) * (pt2[1] - pt1[1]))


def _c(ca, i, j, P, Q):
    if ca[i, j] > -1:
        return ca[i, j]
    elif i == 0 and j == 0:
        ca[i, j] = euclidean_distance(P[0], Q[0])
    elif i > 0 and j == 0:
        ca[i, j] = max(_c(ca, i-1, 0, P, Q), euclidean_distance(P[i], Q[0]))
    elif i == 0 and j > 0:
        ca[i, j] = max(_c(ca, 0, j-1, P, Q), euclidean_distance(P[0], Q[j]))
    elif i > 0 and j > 0:
        ca[i, j] = max(min(_c(ca, i-1, j, P, Q),
                           _c(ca, i-1, j-1, P, Q),
                           _c(ca, i, j-1, P, Q)),
                       euclidean_distance(P[i], Q[j]))
    else:
        ca[i, j] = float("inf")
    return ca[i, j]


def frechet_distance(P, Q):
    ca = np.ones((len(P), len(Q)))
    ca = np.multiply(ca, -1)
    dist = None
    try:
        dist = _c(ca, len(P)-1, len(Q)-1, P, Q)
    except:
        print("calculate frechet_distance exception.")
    return dist


if __name__ == "__main__":
    """test"""
    P = [[1, 1], [2, 1], [2, 2]]
    Q = [[2, 2], [0, 1], [2, 4]]
    print(frechet_distance(P, Q))  # 2

    P = [[1, 1], [2, 1], [2, 2]]
    Q = [[1, 1], [2, 1], [2, 2]]
    print(frechet_distance(P, Q))  # 0
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import numpy as np


class PrintColors:
    """ output color schema"""
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


class StatisticalAnalyzer:
    """statistical analzer class"""

    def print_statistical_results(self, data):
        """ statistical analyzer"""
        if len(data) == 0:
            print(PrintColors.FAIL + "No Data Generated!" + PrintColors.ENDC)
            return

        arr = np.array(data)

        v = np.average(arr)
        print(PrintColors.OKBLUE + "Average: \t" + PrintColors.ENDC,
              "{0:.2f}".format(v))

        std = np.std(arr)
        print(PrintColors.OKBLUE + "STD: \t\t" + PrintColors.ENDC,
              "{0:.2f}".format(std))

        p = np.percentile(arr, 10)
        print(PrintColors.OKBLUE + "10 Percentile: \t" + PrintColors.ENDC,
              "{0:.2f}".format(p))

        p = np.percentile(arr, 50)
        print(PrintColors.OKBLUE + "50 Percentile: \t" + PrintColors.ENDC,
              "{0:.2f}".format(p))

        p = np.percentile(arr, 90)
        print(PrintColors.OKBLUE + "90 Percentile: \t" + PrintColors.ENDC,
              "{0:.2f}".format(p))

        p = np.percentile(arr, 99)
        print(PrintColors.OKBLUE + "99 Percentile: \t" + PrintColors.ENDC,
              "{0:.2f}".format(p))

        p = np.min(arr)
        print(PrintColors.OKBLUE + "min: \t" + PrintColors.ENDC,
              "{0:.2f}".format(p))

        p = np.max(arr)
        print(PrintColors.OKBLUE + "max: \t" + PrintColors.ENDC,
              "{0:.2f}".format(p))
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from modules.tools.record_analyzer.common.statistical_analyzer import PrintColors
from modules.tools.record_analyzer.common.statistical_analyzer import StatisticalAnalyzer


class LidarEndToEndAnalyzer(object):
    """
    Control analyzer
    """

    def __init__(self):
        """
        Init
        """
        self.modules = ['control', 'planning', 'prediction', 'perception']
        self.endtoend_latency = {}
        self.unprocessed_lidar_timestamps = {}
        for m in self.modules:
            self.endtoend_latency[m] = []
            self.unprocessed_lidar_timestamps[m] = []

    def put_pb(self, module_name, pb_msg):
        """
        Put  data
        """
        if module_name not in self.unprocessed_lidar_timestamps:
            print(module_name, " is not supported")
            return

        if pb_msg.header.lidar_timestamp in \
                self.unprocessed_lidar_timestamps[module_name]:
            ind = self.unprocessed_lidar_timestamps[module_name].index(
                pb_msg.header.lidar_timestamp)
            del (self.unprocessed_lidar_timestamps[module_name][ind])
            self.endtoend_latency[module_name].append(
                (pb_msg.header.timestamp_sec -
                 pb_msg.header.lidar_timestamp * 1.0e-9) * 1000.0)

    def put_lidar(self, point_cloud):
        """
        Put lidar data
        """
        for m in self.modules:
            self.unprocessed_lidar_timestamps[m].append(
                point_cloud.header.lidar_timestamp)

    def print_endtoend_latency(self):
        """
        Print end to end latency
        """
        print("\n\n")
        for m in self.modules:
            print(PrintColors.HEADER + "* End to End (" + m
                  + ") Latency (ms)" + PrintColors.ENDC)
            analyzer = StatisticalAnalyzer()
            analyzer.print_statistical_results(self.endtoend_latency[m])

            print(PrintColors.FAIL + "  - MISS # OF LIDAR: " +
                  str(len(self.unprocessed_lidar_timestamps[m])) +
                  PrintColors.ENDC)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import sys

import matplotlib.pyplot as plt

from cyber.python.cyber_py3.record import RecordReader
from modules.tools.record_analyzer.lidar_endtoend_analyzer import LidarEndToEndAnalyzer
from modules.canbus.proto import chassis_pb2
from modules.control.proto import control_cmd_pb2
from modules.drivers.proto import pointcloud_pb2
from modules.perception.proto import perception_obstacle_pb2
from modules.planning.proto import planning_pb2
from modules.prediction.proto import prediction_obstacle_pb2
from modules.tools.record_analyzer.module_control_analyzer import ControlAnalyzer
from modules.tools.record_analyzer.module_planning_analyzer import PlannigAnalyzer


def process(control_analyzer, planning_analyzer, lidar_endtoend_analyzer,
            is_simulation, plot_planning_path, plot_planning_refpath, all_data):
    is_auto_drive = False

    for msg in reader.read_messages():
        if msg.topic == "/apollo/canbus/chassis":
            chassis = chassis_pb2.Chassis()
            chassis.ParseFromString(msg.message)
            if chassis.driving_mode == \
                    chassis_pb2.Chassis.COMPLETE_AUTO_DRIVE:
                is_auto_drive = True
            else:
                is_auto_drive = False

        if msg.topic == "/apollo/control":
            if (not is_auto_drive and not all_data) or \
                    is_simulation or plot_planning_path or plot_planning_refpath:
                continue
            control_cmd = control_cmd_pb2.ControlCommand()
            control_cmd.ParseFromString(msg.message)
            control_analyzer.put(control_cmd)
            lidar_endtoend_analyzer.put_pb('control', control_cmd)

        if msg.topic == "/apollo/planning":
            if (not is_auto_drive) and (not all_data):
                continue
            adc_trajectory = planning_pb2.ADCTrajectory()
            adc_trajectory.ParseFromString(msg.message)
            planning_analyzer.put(adc_trajectory)
            lidar_endtoend_analyzer.put_pb('planning', adc_trajectory)

            if plot_planning_path:
                planning_analyzer.plot_path(plt, adc_trajectory)
            if plot_planning_refpath:
                planning_analyzer.plot_refpath(plt, adc_trajectory)

        if msg.topic == "/apollo/sensor/velodyne64/compensator/PointCloud2" or \
                msg.topic == "/apollo/sensor/lidar128/compensator/PointCloud2":
            if ((not is_auto_drive) and (not all_data)) or is_simulation or \
                    plot_planning_path or plot_planning_refpath:
                continue
            point_cloud = pointcloud_pb2.PointCloud()
            point_cloud.ParseFromString(msg.message)
            lidar_endtoend_analyzer.put_lidar(point_cloud)

        if msg.topic == "/apollo/perception/obstacles":
            if ((not is_auto_drive) and (not all_data)) or is_simulation or \
                    plot_planning_path or plot_planning_refpath:
                continue
            perception = perception_obstacle_pb2.PerceptionObstacles()
            perception.ParseFromString(msg.message)
            lidar_endtoend_analyzer.put_pb('perception', perception)

        if msg.topic == "/apollo/prediction":
            if ((not is_auto_drive) and (not all_data)) or is_simulation or \
                    plot_planning_path or plot_planning_refpath:
                continue
            prediction = prediction_obstacle_pb2.PredictionObstacles()
            prediction.ParseFromString(msg.message)
            lidar_endtoend_analyzer.put_pb('prediction', prediction)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("usage: python main.py record_file")
    parser = argparse.ArgumentParser(
        description="Recode Analyzer is a tool to analyze record files.",
        prog="main.py")

    parser.add_argument(
        "-f", "--file", action="store", type=str, required=True,
        help="Specify the record file for analysis.")

    parser.add_argument(
        "-sim", "--simulation", action="store_const", const=True,
        help="For dreamland API call")

    parser.add_argument(
        "-path", "--planningpath", action="store_const", const=True,
        help="plot planing paths in cartesian coordinate.")

    parser.add_argument(
        "-refpath", "--planningrefpath", action="store_const", const=True,
        help="plot planing reference paths in cartesian coordinate.")

    parser.add_argument(
        "-a", "--alldata", action="store_const", const=True,
        help="Analyze all data (both auto and manual), otherwise auto data only without this option.")

    parser.add_argument(
        "-acc", "--showacc", action="store_const", const=True,
        help="Analyze all data (both auto and manual), otherwise auto data only without this option.")

    args = parser.parse_args()

    record_file = args.file
    reader = RecordReader(record_file)

    control_analyzer = ControlAnalyzer()
    planning_analyzer = PlannigAnalyzer(args)
    lidar_endtoend_analyzer = LidarEndToEndAnalyzer()

    process(control_analyzer, planning_analyzer,
            lidar_endtoend_analyzer, args.simulation, args.planningpath,
            args.planningrefpath, args.alldata)

    if args.simulation:
        planning_analyzer.print_sim_results()
    elif args.planningpath or args.planningrefpath:
        plt.axis('equal')
        plt.show()
    else:
        control_analyzer.print_latency_statistics()
        planning_analyzer.print_latency_statistics()
        lidar_endtoend_analyzer.print_endtoend_latency()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import numpy as np


class Curvature:
    def __init__(self):
        self.curvature_list = []
        self.curvature_derivative_list = []

    def put(self, adc_trajectory):
        init_point = adc_trajectory.debug.planning_data.init_point
        self.curvature_list.append(abs(init_point.path_point.kappa))
        self.curvature_derivative_list.append(abs(init_point.path_point.dkappa))

    def get_curvature(self):
        curvature = {}
        if len(self.curvature_list) == 0:
            curvature["max"] = 0
            curvature["avg"] = 0
            return curvature

        curvature["max"] = max(self.curvature_list, key=abs)
        curvature["avg"] = np.average(np.absolute(self.curvature_list))

        return curvature

    def get_curvature_derivative(self):
        curvature_derivative = {}
        if len(self.curvature_derivative_list) == 0:
            curvature_derivative["max"] = 0
            curvature_derivative["avg"] = 0

        curvature_derivative["max"] = max(self.curvature_derivative_list, key=abs)
        curvature_derivative["avg"] = np.average(np.absolute(self.curvature_derivative_list))

        return curvature_derivative
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################


class FrameCount:
    def __init__(self):
        self.count = 0

    def put(self, adc_trajectory):
        self.count += 1

    def get(self):
        frame_count = {}
        frame_count["total"] = self.count
        return frame_count
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math

import numpy as np


class LatAcceleration:
    def __init__(self):
        self.centripetal_accel_list = []
        self.centripetal_jerk_list = []

    def put(self, adc_trajectory):
        init_point = adc_trajectory.debug.planning_data.init_point
        # centripetal_jerk
        centripetal_jerk = 2 * init_point.v * init_point.a \
            * init_point.path_point.kappa + init_point.v \
            * init_point.v * init_point.path_point.dkappa
        if not math.isnan(centripetal_jerk):
            self.centripetal_jerk_list.append(centripetal_jerk)

        # centripetal_accel
        centripetal_accel = init_point.v * init_point.v \
            * init_point.path_point.kappa

        if not math.isnan(centripetal_accel):
            self.centripetal_accel_list.append(centripetal_accel)

    def get_acceleration(self):
        # [1, 2) [-2, -1)
        LAT_ACCEL_M_LB_P = 1
        LAT_ACCEL_M_UB_P = 2
        LAT_ACCEL_M_LB_N = -2
        LAT_ACCEL_M_UB_N = -1
        lat_accel_medium_cnt = 0

        # [2, inf)  [-inf,-2)
        LAT_ACCEL_H_LB_P = 2
        LAT_ACCEL_H_UB_N = -2
        lat_accel_high_cnt = 0

        for centripetal_accel in self.centripetal_accel_list:
            if LAT_ACCEL_M_LB_P <= centripetal_accel < LAT_ACCEL_M_UB_P \
                    or LAT_ACCEL_M_LB_N < centripetal_accel <= LAT_ACCEL_M_UB_N:
                lat_accel_medium_cnt += 1
            if centripetal_accel >= LAT_ACCEL_H_LB_P \
                    or centripetal_accel <= LAT_ACCEL_H_UB_N:
                lat_accel_high_cnt += 1

        # centripetal_accel
        lat_accel = {}
        if len(self.centripetal_accel_list) > 0:
            lat_accel["max"] = abs(max(self.centripetal_accel_list, key=abs))
            accel_avg = np.average(np.absolute(self.centripetal_accel_list))
            lat_accel["avg"] = accel_avg
        else:
            lat_accel["max"] = 0
            lat_accel["avg"] = 0
        lat_accel["medium_cnt"] = lat_accel_medium_cnt
        lat_accel["high_cnt"] = lat_accel_high_cnt

        return lat_accel

    def get_jerk(self):
        # [0.5,1) [-1, -0.5)
        LAT_JERK_M_LB_P = 0.5
        LAT_JERK_M_UB_P = 1
        LAT_JERK_M_LB_N = -1
        LAT_JERK_M_UB_N = -0.5
        lat_jerk_medium_cnt = 0

        # [1, inf)  [-inf,-1)
        LAT_JERK_H_LB_P = 1
        LAT_JERK_H_UB_N = -1
        lat_jerk_high_cnt = 0

        for centripetal_jerk in self.centripetal_jerk_list:
            if LAT_JERK_M_LB_P <= centripetal_jerk < LAT_JERK_M_UB_P \
                    or LAT_JERK_M_LB_N < centripetal_jerk <= LAT_JERK_M_UB_N:
                lat_jerk_medium_cnt += 1
            if centripetal_jerk >= LAT_JERK_H_LB_P \
                    or centripetal_jerk <= LAT_JERK_H_UB_N:
                lat_jerk_high_cnt += 1

        # centripetal_jerk
        lat_jerk = {}
        if len(self.centripetal_jerk_list) > 0:
            lat_jerk["max"] = abs(max(self.centripetal_jerk_list, key=abs))
            jerk_avg = np.average(np.absolute(self.centripetal_jerk_list))
            lat_jerk["avg"] = jerk_avg
        else:
            lat_jerk["max"] = 0
            lat_jerk["avg"] = 0
        lat_jerk["medium_cnt"] = lat_jerk_medium_cnt
        lat_jerk["high_cnt"] = lat_jerk_high_cnt

        return lat_jerk
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import numpy as np


class Latency:
    def __init__(self):
        self.latency_list = []

    def put(self, adc_trajectory):
        self.latency_list.append(adc_trajectory.latency_stats.total_time_ms)

    def get(self):
        if len(self.latency_list) > 0:
            planning_latency = {
                "max": max(self.latency_list),
                "min": min(self.latency_list),
                "avg": np.average(self.latency_list)
            }
        else:
            planning_latency = {
                "max": 0.0,
                "min": 0.0,
                "avg": 0.0
            }
        return planning_latency
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
import numpy as np


class LonAcceleration:
    def __init__(self):
        self.last_velocity = None
        self.last_velocity_timestamp = None
        self.last_acceleration = None
        self.last_acceleration_timestamp = None
        self.acceleration_list = []
        self.deceleration_list = []
        self.acc_jerk_list = []
        self.dec_jerk_list = []

    def put(self, adc_trajectory):
        init_point = adc_trajectory.debug.planning_data.init_point
        current_velocity_timestamp = adc_trajectory.header.timestamp_sec + \
            init_point.relative_time
        current_velocity = init_point.v

        if self.last_velocity_timestamp is not None and self.last_velocity is not None:
            # acceleration
            duration = current_velocity_timestamp - self.last_velocity_timestamp
            if duration > 0.03:
                current_acceleration = (
                    current_velocity - self.last_velocity) / duration
                if current_acceleration > 0 and not math.isnan(current_acceleration):
                    self.acceleration_list.append(current_acceleration)
                elif current_acceleration < 0 and not math.isnan(current_acceleration):
                    self.deceleration_list.append(current_acceleration)

                if self.last_acceleration is not None and self.last_acceleration_timestamp is not None:
                    # jerk
                    acc_duration = current_velocity_timestamp - self.last_acceleration_timestamp
                    if acc_duration > 0.03:
                        current_jerk = (current_acceleration -
                                        self.last_acceleration) / acc_duration
                        if current_acceleration > 0 and not math.isnan(current_jerk):
                            self.acc_jerk_list.append(current_jerk)
                        elif current_acceleration < 0 and not math.isnan(current_jerk):
                            self.dec_jerk_list.append(current_jerk)

                self.last_acceleration = current_acceleration
                self.last_acceleration_timestamp = current_velocity_timestamp

        self.last_velocity_timestamp = current_velocity_timestamp
        self.last_velocity = current_velocity

    def get_acceleration(self):
        # [2, 4) unit m/s^2
        ACCEL_M_LB = 2
        ACCEL_M_UB = 4
        accel_medium_cnt = 0

        # [4, ) unit m/s^2
        ACCEL_H_LB = 4
        accel_high_cnt = 0

        lon_acceleration = {}
        for accel in self.acceleration_list:
            if ACCEL_M_LB <= accel < ACCEL_M_UB:
                accel_medium_cnt += 1
            if ACCEL_H_LB <= accel:
                accel_high_cnt += 1

        if len(self.acceleration_list) > 0:
            lon_acceleration["max"] = max(self.acceleration_list)
            lon_acceleration["avg"] = np.average(self.acceleration_list)
        else:
            lon_acceleration["max"] = 0.0
            lon_acceleration["avg"] = 0.0
        lon_acceleration["medium_cnt"] = accel_medium_cnt
        lon_acceleration["high_cnt"] = accel_high_cnt

        return lon_acceleration

    def get_deceleration(self):
        # [-4, -2)
        DECEL_M_LB = -4
        DECEL_M_UB = -2
        decel_medium_cnt = 0

        # [-4, )
        DECEL_H_UB = -4
        decel_high_cnt = 0

        for accel in self.deceleration_list:
            if DECEL_M_LB < accel <= DECEL_M_UB:
                decel_medium_cnt += 1
            if accel <= DECEL_H_UB:
                decel_high_cnt += 1

        lon_deceleration = {}
        if len(self.deceleration_list) > 0:
            lon_deceleration["max"] = abs(max(self.deceleration_list, key=abs))
            lon_deceleration["avg"] = np.average(
                np.absolute(self.deceleration_list))
        else:
            lon_deceleration["max"] = 0.0
            lon_deceleration["avg"] = 0.0
        lon_deceleration["medium_cnt"] = decel_medium_cnt
        lon_deceleration["high_cnt"] = decel_high_cnt

        return lon_deceleration

    def get_acc_jerk(self):
        # [1,2) (-2, -1]
        JERK_M_LB_P = 1
        JERK_M_UB_P = 2
        JERK_M_LB_N = -2
        JERK_M_UB_N = -1
        jerk_medium_cnt = 0

        # [2, inf) (-inf, -2]
        JERK_H_LB_P = 2
        JERK_H_UB_N = -2
        jerk_high_cnt = 0

        for jerk in self.acc_jerk_list:
            if JERK_M_LB_P <= jerk < JERK_M_UB_P or \
                    JERK_M_LB_N < jerk <= JERK_M_UB_N:
                jerk_medium_cnt += 1
            if jerk >= JERK_H_LB_P or jerk <= JERK_H_UB_N:
                jerk_high_cnt += 1

        lon_acc_jerk = {}
        if len(self.acc_jerk_list) > 0:
            lon_acc_jerk["max"] = abs(max(self.acc_jerk_list, key=abs))
            jerk_avg = np.average(np.absolute(self.acc_jerk_list))
            lon_acc_jerk["avg"] = jerk_avg
        else:
            lon_acc_jerk["max"] = 0
            lon_acc_jerk["avg"] = 0
        lon_acc_jerk["medium_cnt"] = jerk_medium_cnt
        lon_acc_jerk["high_cnt"] = jerk_high_cnt

        return lon_acc_jerk

    def get_dec_jerk(self):
        # [1,2) (-2, -1]
        JERK_M_LB_P = 1
        JERK_M_UB_P = 2
        JERK_M_LB_N = -2
        JERK_M_UB_N = -1
        jerk_medium_cnt = 0

        # [2, inf) (-inf, -2]
        JERK_H_LB_P = 2
        JERK_H_UB_N = -2
        jerk_high_cnt = 0

        for jerk in self.dec_jerk_list:
            if JERK_M_LB_P <= jerk < JERK_M_UB_P or \
                    JERK_M_LB_N < jerk <= JERK_M_UB_N:
                jerk_medium_cnt += 1
            if jerk >= JERK_H_LB_P or jerk <= JERK_H_UB_N:
                jerk_high_cnt += 1

        lon_dec_jerk = {}
        if len(self.dec_jerk_list) > 0:
            lon_dec_jerk["max"] = abs(max(self.dec_jerk_list, key=abs))
            jerk_avg = np.average(np.absolute(self.dec_jerk_list))
            lon_dec_jerk["avg"] = jerk_avg
        else:
            lon_dec_jerk["max"] = 0
            lon_dec_jerk["avg"] = 0
        lon_dec_jerk["medium_cnt"] = jerk_medium_cnt
        lon_dec_jerk["high_cnt"] = jerk_high_cnt

        return lon_dec_jerk
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys

import numpy as np


class ReferenceLine:

    def __init__(self):
        self.rl_is_offroad_cnt = 0
        self.rl_minimum_boundary = sys.float_info.max
        self.rl_kappa_rms_list = []
        self.rl_dkappa_rms_list = []
        self.rl_kappa_max_abs_list = []
        self.rl_dkappa_max_abs_list = []

    def put(self, adc_trajectory):
        for ref_line_debug in adc_trajectory.debug.planning_data.reference_line:
            if ref_line_debug.HasField("is_offroad") and ref_line_debug.is_offroad:
                self.rl_is_offroad_cnt += 1
            if ref_line_debug.HasField("minimum_boundary") and \
                    ref_line_debug.minimum_boundary < self.rl_minimum_boundary:
                self.rl_minimum_boundary = ref_line_debug.minimum_boundary
            if ref_line_debug.HasField("kappa_rms"):
                self.rl_kappa_rms_list.append(ref_line_debug.kappa_rms)
            if ref_line_debug.HasField("dkappa_rms"):
                self.rl_dkappa_rms_list.append(ref_line_debug.dkappa_rms)
            if ref_line_debug.HasField("kappa_max_abs"):
                self.rl_kappa_max_abs_list.append(ref_line_debug.kappa_max_abs)
            if ref_line_debug.HasField("dkappa_max_abs"):
                self.rl_dkappa_max_abs_list.append(ref_line_debug.dkappa_max_abs)

    def get(self):
        kappa_rms = 0
        if len(self.rl_kappa_rms_list) > 0:
            kappa_rms = np.average(self.rl_kappa_rms_list)

        dkappa_rms = 0
        if len(self.rl_dkappa_rms_list) > 0:
            dkappa_rms = np.average(self.rl_dkappa_rms_list)

        if self.rl_minimum_boundary > 999:
            self.rl_minimum_boundary = 0

        kappa_max_abs = 0
        if len(self.rl_kappa_max_abs_list) > 0:
            kappa_max_abs = max(self.rl_kappa_max_abs_list)

        dkappa_max_abs = 0
        if len(self.rl_dkappa_max_abs_list) > 0:
            dkappa_max_abs = max(self.rl_dkappa_max_abs_list)

        reference_line = {
            "is_offroad": self.rl_is_offroad_cnt,
            "minimum_boundary": self.rl_minimum_boundary,
            "kappa_rms": kappa_rms,
            "dkappa_rms": dkappa_rms,
            "kappa_max_abs": kappa_max_abs,
            "dkappa_max_abs": dkappa_max_abs
        }
        return reference_line
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

from modules.tools.record_analyzer.common.error_code_analyzer import ErrorCodeAnalyzer
from modules.tools.record_analyzer.common.error_msg_analyzer import ErrorMsgAnalyzer
from modules.tools.record_analyzer.common.statistical_analyzer import PrintColors
from modules.tools.record_analyzer.common.statistical_analyzer import StatisticalAnalyzer

class ControlAnalyzer:
    """control analyzer"""

    def __init__(self):
        """init"""
        self.module_latency = []
        self.error_code_analyzer = ErrorCodeAnalyzer()
        self.error_msg_analyzer = ErrorMsgAnalyzer()
        self.lon_station_error = []
        self.lon_speed_error = []
        self.lat_lateral_error = []
        self.lat_heading_error = []

    def put(self, control_cmd):
        """put data"""
        latency = control_cmd.latency_stats.total_time_ms
        self.module_latency.append(latency)
        self.error_code_analyzer.put(control_cmd.header.status.error_code)
        self.error_msg_analyzer.put(control_cmd.header.status.msg)
        lon_debug = control_cmd.debug.simple_lon_debug
        self.lon_station_error.append(lon_debug.station_error)
        self.lon_speed_error.append(lon_debug.speed_error)
        lat_debug = control_cmd.debug.simple_lat_debug
        self.lat_lateral_error.append(lat_debug.lateral_error)
        self.lat_heading_error.append(lat_debug.heading_error)

    def print_latency_statistics(self):
        """print_latency_statistics"""
        print("\n\n")
        print(PrintColors.HEADER + "--- Control Latency (ms) ---" +
              PrintColors.ENDC)
        analyzer = StatisticalAnalyzer()
        analyzer.print_statistical_results(self.module_latency)

        print(PrintColors.HEADER + "--- station error ---" +
              PrintColors.ENDC)
        analyzer.print_statistical_results(self.lon_station_error)

        print(PrintColors.HEADER + "--- speed error ---" +
              PrintColors.ENDC)
        analyzer.print_statistical_results(self.lon_speed_error)

        print(PrintColors.HEADER + "--- lateral error ---" +
              PrintColors.ENDC)
        analyzer.print_statistical_results(self.lat_lateral_error)

        print(PrintColors.HEADER + "--- heading error ---" +
              PrintColors.ENDC)
        analyzer.print_statistical_results(self.lat_heading_error)

        print(PrintColors.HEADER + "--- Control Error Code Distribution ---" +
              PrintColors.ENDC)
        self.error_code_analyzer.print_results()

        print(PrintColors.HEADER + "--- Control Error Msg Distribution ---" +
              PrintColors.ENDC)
        self.error_msg_analyzer.print_results()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import json
import sys

import numpy as np

from modules.tools.record_analyzer.common.distribution_analyzer import DistributionAnalyzer
from modules.tools.record_analyzer.common.error_code_analyzer import ErrorCodeAnalyzer
from modules.tools.record_analyzer.common.error_msg_analyzer import ErrorMsgAnalyzer
from modules.tools.record_analyzer.common.frechet_distance import frechet_distance
from modules.tools.record_analyzer.common.statistical_analyzer import PrintColors
from modules.tools.record_analyzer.common.statistical_analyzer import StatisticalAnalyzer
from modules.tools.record_analyzer.metrics.curvature import Curvature
from modules.tools.record_analyzer.metrics.frame_count import FrameCount
from modules.tools.record_analyzer.metrics.latency import Latency
from modules.tools.record_analyzer.metrics.lat_acceleration import LatAcceleration
from modules.tools.record_analyzer.metrics.lon_acceleration import LonAcceleration
from modules.tools.record_analyzer.metrics.reference_line import ReferenceLine
from modules.planning.proto import planning_pb2
from shapely.geometry import LineString, Point


class PlannigAnalyzer:
    """planning analyzer"""

    def __init__(self, arguments):
        """init"""
        self.module_latency = []
        self.trajectory_type_dist = {}
        self.estop_reason_dist = {}
        self.error_code_analyzer = ErrorCodeAnalyzer()
        self.error_msg_analyzer = ErrorMsgAnalyzer()
        self.last_adc_trajectory = None
        self.frechet_distance_list = []
        self.is_sim = arguments.simulation
        self.hard_break_list = []
        self.total_cycle_num = 0

        self.curvature_analyzer = Curvature()
        self.frame_count_analyzer = FrameCount()
        self.lat_acceleration_analyzer = LatAcceleration()
        self.lon_acceleration_analyzer = LonAcceleration()
        self.latency_analyzer = Latency()
        self.reference_line = ReferenceLine()

        self.bag_start_time_t = None
        self.print_acc = arguments.showacc

    def put(self, adc_trajectory):
        self.total_cycle_num += 1
        if not self.is_sim:
            latency = adc_trajectory.latency_stats.total_time_ms
            self.module_latency.append(latency)

            self.error_code_analyzer.put(
                adc_trajectory.header.status.error_code)
            self.error_msg_analyzer.put(adc_trajectory.header.status.msg)

            traj_type = planning_pb2.ADCTrajectory.TrajectoryType.Name(
                adc_trajectory.trajectory_type)
            self.trajectory_type_dist[traj_type] = \
                self.trajectory_type_dist.get(traj_type, 0) + 1

            if adc_trajectory.estop.is_estop:
                self.estop_reason_dist[adc_trajectory.estop.reason] = \
                    self.estop_reason_dist.get(
                        adc_trajectory.estop.reason, 0) + 1

        else:
            self.curvature_analyzer.put(adc_trajectory)
            self.frame_count_analyzer.put(adc_trajectory)
            self.lat_acceleration_analyzer.put(adc_trajectory)
            self.lon_acceleration_analyzer.put(adc_trajectory)
            self.latency_analyzer.put(adc_trajectory)
            self.reference_line.put(adc_trajectory)

    def find_common_path(self, current_adc_trajectory, last_adc_trajectory):
        current_path_points = current_adc_trajectory.trajectory_point
        last_path_points = last_adc_trajectory.trajectory_point

        current_path = []
        for point in current_path_points:
            current_path.append([point.path_point.x, point.path_point.y])
            if point.path_point.s > 5.0:
                break
        last_path = []
        for point in last_path_points:
            last_path.append([point.path_point.x, point.path_point.y])
            if point.path_point.s > 5.0:
                break

        if len(current_path) == 0 or len(last_path) == 0:
            return [], []

        current_ls = LineString(current_path)
        last_ls = LineString(last_path)
        current_start_point = Point(current_path[0])

        dist = last_ls.project(current_start_point)
        cut_lines = self.cut(last_ls, dist)
        if len(cut_lines) == 1:
            return [], []
        last_ls = cut_lines[1]
        dist = current_ls.project(Point(last_path[-1]))
        if dist <= current_ls.length:
            current_ls = self.cut(current_ls, dist)[0]
        else:
            dist = last_ls.project(Point(current_path[-1]))
            last_ls = self.cut(last_ls, dist)[0]
        return current_ls.coords, last_ls.coords

    def cut(self, line, distance):
        if distance <= 0.0 or distance >= line.length:
            return [LineString(line)]
        coords = list(line.coords)
        for i, p in enumerate(coords):
            pd = line.project(Point(p))
            if pd == distance:
                return [
                    LineString(coords[:i+1]),
                    LineString(coords[i:])]
            if pd > distance:
                cp = line.interpolate(distance)
                return [
                    LineString(coords[:i] + [(cp.x, cp.y)]),
                    LineString([(cp.x, cp.y)] + coords[i:])]

    def print_latency_statistics(self):
        """print_latency_statistics"""
        print("\n\n")
        print(PrintColors.HEADER + "--- Planning Latency (ms) ---" +
              PrintColors.ENDC)
        StatisticalAnalyzer().print_statistical_results(self.module_latency)

        print(PrintColors.HEADER + "--- Planning Trajectroy Type Distribution"
                                   " ---" + PrintColors.ENDC)
        DistributionAnalyzer().print_distribution_results(
            self.trajectory_type_dist)

        print(PrintColors.HEADER + "--- Planning Estop Distribution"
                                   " ---" + PrintColors.ENDC)
        DistributionAnalyzer().print_distribution_results(
            self.estop_reason_dist)

        print(PrintColors.HEADER + "--- Planning Error Code Distribution---" +
              PrintColors.ENDC)
        self.error_code_analyzer.print_results()
        print(PrintColors.HEADER + "--- Planning Error Msg Distribution ---" +
              PrintColors.ENDC)
        self.error_msg_analyzer.print_results()

        print(PrintColors.HEADER + "--- Planning Trajectory Frechet Distance (m) ---" +
              PrintColors.ENDC)
        StatisticalAnalyzer().print_statistical_results(self.frechet_distance_list)

    def print_sim_results(self):
        """
        dreamland metrics for planning v2
        """
        v2_results = {}

        # acceleration
        v2_results["accel"] = self.lon_acceleration_analyzer.get_acceleration()

        # deceleration
        v2_results["decel"] = self.lon_acceleration_analyzer.get_deceleration()

        # jerk
        v2_results["acc_jerk"] = self.lon_acceleration_analyzer.get_acc_jerk()
        v2_results["dec_jerk"] = self.lon_acceleration_analyzer.get_dec_jerk()

        # centripetal_jerk
        v2_results["lat_jerk"] = self.lat_acceleration_analyzer.get_jerk()

        # centripetal_accel
        v2_results["lat_accel"] = self.lat_acceleration_analyzer.get_acceleration()

        # frame_count
        v2_results["frame_count"] = self.frame_count_analyzer.get()

        # latency
        v2_results["planning_latency"] = self.latency_analyzer.get()

        # reference line
        v2_results["reference_line"] = self.reference_line.get()

        # output final reuslts
        print(json.dumps(v2_results))

    def plot_path(self, plt, adc_trajectory):
        path_coords = self.trim_path_by_distance(adc_trajectory, 5.0)
        x = []
        y = []
        for point in path_coords:
            x.append(point[0])
            y.append(point[1])
        plt.plot(x, y, 'r-', alpha=0.5)

    def plot_refpath(self, plt, adc_trajectory):
        for path in adc_trajectory.debug.planning_data.path:
            if path.name != 'planning_reference_line':
                continue
            path_coords = self.trim_path_by_distance(adc_trajectory, 5.0)

            ref_path_coord = []
            for point in path.path_point:
                ref_path_coord.append([point.x, point.y])
            ref_path = LineString(ref_path_coord)

            start_point = Point(path_coords[0])
            dist = ref_path.project(start_point)
            ref_path = self.cut(ref_path, dist)[1]

            end_point = Point(path_coords[-1])
            dist = ref_path.project(end_point)
            ref_path = self.cut(ref_path, dist)[0]

            x = []
            y = []
            for point in ref_path.coords:
                x.append(point[0])
                y.append(point[1])

            plt.plot(x, y, 'b--', alpha=0.5)

    def trim_path_by_distance(self, adc_trajectory, s):
        path_coords = []
        path_points = adc_trajectory.trajectory_point
        for point in path_points:
            if point.path_point.s <= s:
                path_coords.append([point.path_point.x, point.path_point.y])
        return path_coords
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import sys

from cyber.python.cyber_py3.record import RecordReader
from modules.canbus.proto import chassis_pb2
from modules.control.proto import control_cmd_pb2
from modules.drivers.proto import pointcloud_pb2
from modules.perception.proto import perception_obstacle_pb2
from modules.planning.proto import planning_pb2


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Recode Analyzer is a tool to analyze record files.",
        prog="main.py")

    parser.add_argument(
        "-f", "--file", action="store", type=str, required=True,
        help="Specify the record file for message dumping.")

    parser.add_argument(
        "-m", "--message", action="store", type=str, required=True,
        help="Specify the message topic for dumping.")

    parser.add_argument(
        "-t", "--timestamp", action="store", type=float, required=True,
        help="Specify the timestamp for dumping.")

    args = parser.parse_args()

    record_file = args.file
    reader = RecordReader(record_file)

    for msg in reader.read_messages():
        timestamp = msg.timestamp / float(1e9)
        if msg.topic == args.message and abs(timestamp - args.timestamp) <= 1:
            if msg.topic == "/apollo/perception/obstacles":
                perception_obstacles = \
                    perception_obstacle_pb2.PerceptionObstacles()
                perception_obstacles.ParseFromString(msg.message)
                with open('perception_obstacles.txt', 'w') as f:
                    f.write(str(perception_obstacles))
                print(str(perception_obstacles))
                break
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import time
import argparse
import google.protobuf.text_format as text_format
from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time
from modules.perception.proto import perception_obstacle_pb2


def update(perception_obstacles):
    """update perception obstacles timestamp"""
    now = cyber_time.Time.now().to_sec()
    perception_obstacles.header.timestamp_sec = now
    perception_obstacles.header.lidar_timestamp = \
        (int(now) - int(0.5)) * int(1e9)

    for perception_obstacle in perception_obstacles.perception_obstacle:
        perception_obstacle.timestamp = now - 0.5
        for measure in perception_obstacle.measurements:
            measure.timestamp = now - 0.5
    return perception_obstacles


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Recode Analyzer is a tool to analyze record files.",
        prog="main.py")

    parser.add_argument(
        "-f", "--file", action="store", type=str, required=True,
        help="Specify the message file for sending.")

    args = parser.parse_args()

    cyber.init()
    node = cyber.Node("perception_obstacle_sender")
    perception_pub = node.create_writer(
        "/apollo/perception/obstacles",
        perception_obstacle_pb2.PerceptionObstacles)

    perception_obstacles = perception_obstacle_pb2.PerceptionObstacles()
    with open(args.file, 'r') as f:
        text_format.Merge(f.read(), perception_obstacles)

    while not cyber.is_shutdown():
        now = cyber_time.Time.now().to_sec()
        perception_obstacles = update(perception_obstacles)
        perception_pub.write(perception_obstacles)
        sleep_time = 0.1 - (cyber_time.Time.now().to_sec() - now)
        if sleep_time > 0:
            time.sleep(sleep_time)

    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
function to parse camera images from *.record files, created using Apollo-Auto

parsed data is saved to *.jpeg file, for each capture

"""

import os
import sys

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record
from modules.drivers.proto.sensor_image_pb2 import CompressedImage


def parse_data(channelname, msg, out_folder):
    """
    parser images from Apollo record file
    """
    msg_camera = CompressedImage()
    msg_camera.ParseFromString(str(msg))

    tstamp = msg_camera.measurement_time

    temp_time = str(tstamp).split('.')
    if len(temp_time[1]) == 1:
        temp_time1_adj = temp_time[1] + '0'
    else:
        temp_time1_adj = temp_time[1]
    image_time = temp_time[0] + '_' + temp_time1_adj

    image_filename = "image_" + image_time + ".jpeg"
    f = open(out_folder + image_filename, 'w+b')
    f.write(msg_camera.data)
    f.close()

    return tstamp

#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
function to parse lidar data from *.record files, created using Apollo-Auto

parsed data is saved to *.txt file, for each scan

current implementation for:
* Velodyne VLS-128 lidar

"""

import os
import sys

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record
from modules.drivers.proto.pointcloud_pb2 import PointCloud


def parse_data(channelname, msg, out_folder):
    """
    """
    msg_lidar = PointCloud()
    msg_lidar.ParseFromString(msg)
    nPts = len(msg_lidar.point)

    pcd = []
    for j in range(nPts):
        p = msg_lidar.point[j]
        pcd.append([p.x, p.y, p.z, p.intensity])

    tstamp = msg_lidar.measurement_time
    temp_time = str(tstamp).split('.')

    if len(temp_time[1]) == 1:
        temp_time1_adj = temp_time[1] + '0'
    else:
        temp_time1_adj = temp_time[1]

    pcd_time = temp_time[0] + '_' + temp_time1_adj
    pcd_filename = "pcd_" + pcd_time + ".txt"

    with open(out_folder + pcd_filename, 'w') as outfile:
        for item in pcd:
            data = str(item)[1:-1]
            outfile.write("%s\n" % data)

    return tstamp
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
function to parse radar data from *.record files, created using Apollo-Auto

parsed data is saved to *.txt file, for each scan

currently implementation for:
* Continental ARS-408 radar

"""

import json
import os
import sys

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record
from modules.drivers.proto.conti_radar_pb2 import ContiRadar


class RadarMessageConti408(object):
    def __init__(self):
        self.radarDetectionList = []
        self.timestamp_sec = None
        self.num_of_detections = None
        self.radar_module = None
        self.sequence_num = None
        self.radar_channel = None
        self.additional_notes = None

    def toJSON(self):
        return json.dumps(self, default=lambda o: o.__dict__,
                          sort_keys=True, indent=4)


class ContiRadarARS408Detection(object):
    def __init__(self):
        self.clusterortrack = None
        self.obstacle_id = None
        self.longitude_dist = None
        self.lateral_dist = None
        self.longitude_vel = None
        self.lateral_vel = None
        self.rcs = None
        self.dynprop = None
        self.longitude_dist_rms = None
        self.lateral_dist_rms = None
        self.longitude_vel_rms = None
        self.lateral_vel_rms = None
        self.probexist = None
        self.meas_state = None
        self.longitude_accel = None
        self.lateral_accel = None
        self.oritation_angle = None
        self.longitude_accel_rms = None
        self.lateral_accel_rms = None
        self.oritation_angle_rms = None
        self.length = None
        self.width = None
        self.obstacle_class = None


def pull_conti_radar_detections(obs):
    """
    file to convert structure from c++ to python format
    """

    dets = ContiRadarARS408Detection()

    dets.clusterortrack = obs.clusterortrack
    dets.obstacle_id = obs.obstacle_id
    dets.longitude_dist = obs.longitude_dist
    dets.lateral_dist = obs.lateral_dist
    dets.longitude_vel = obs.longitude_vel
    dets.lateral_vel = obs.lateral_vel
    dets.rcs = obs.rcs
    dets.dynprop = obs.dynprop
    dets.longitude_dist_rms = obs.longitude_dist_rms
    dets.lateral_dist_rms = obs.lateral_dist_rms
    dets.longitude_vel_rms = obs.longitude_vel_rms
    dets.lateral_vel_rms = obs.lateral_vel_rms
    dets.probexist = obs.probexist
    dets.meas_state = obs.meas_state
    dets.longitude_accel = obs.longitude_accel
    dets.lateral_accel = obs.lateral_accel
    dets.oritation_angle = obs.oritation_angle
    dets.longitude_accel_rms = obs.longitude_accel_rms
    dets.lateral_accel_rms = obs.lateral_accel_rms
    dets.oritation_angle_rms = obs.oritation_angle_rms
    dets.length = obs.length
    dets.width = obs.width
    dets.obstacle_class = obs.obstacle_class

    return dets

def parse_data(channelname, msg, out_folder):
    """
    parser for record-file data from continental ars-408 radar
    """

    msg_contiradar = ContiRadar()
    msg_contiradar.ParseFromString(msg)
    n = len(msg_contiradar.contiobs)

    detections = []
    radar_msg = RadarMessageConti408()

    head_msg = msg_contiradar.contiobs[0].header
    radar_msg.timestamp_sec = head_msg.timestamp_sec
    radar_msg.num_of_detections = n
    radar_msg.radar_module = head_msg.module_name
    radar_msg.sequence_num = head_msg.sequence_num
    radar_msg.radar_channel = channelname

    for i in range(len(msg_contiradar.contiobs)):
        detections.append(pull_conti_radar_detections(msg_contiradar.contiobs[i]))

    radar_msg.radarDetectionList = detections

    json_data = radar_msg.toJSON()
    tstamp = json_data.split()[-2].ljust(20, '0')

    # write this scan to file
    scan_filename = "radar_scan_" + tstamp.replace('.', '_') + ".txt"
    with open(out_folder + scan_filename, 'w') as outfile:
        outfile.write(json_data)

    return tstamp

#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
function to parse data from *.record files, created using Apollo-Auto

current implementation illustrates sample record file parsing for
* radar (Continental ars-408)
* camera (Leopard Imaging 6mm)
* lidar (Velodyne vls-128)

* saves extracted images in separate folder using *.jpg format
* saves radar and lidar data in respective folders in *.txt format for each scan
* also saves timestamp in separate text files

"""

import os
import sys
import time

from importlib import import_module
import yaml

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record


os.system('clear')

def read_parameters(yaml_file):
    """
    function to read YAML parameter file and define output destinations
    """
    with open(yaml_file, 'r') as f:
        params = yaml.safe_load(f)
    # record file params
    RECORD_FOLDER = params['records']['filepath']
    parse_type = params['parse']

    # define destinations
    dest_path = os.path.split(RECORD_FOLDER)
    if not dest_path[-1]:
        dest_path = os.path.split(dest_path[0])

    OUT_FOLDER = dest_path[0] + '/'
    temp_path = os.path.split(dest_path[0])
    FOLDER_PREFIX = temp_path[1].replace("-", "")

    parse_dict = {"params": params,
                  "parse_type": parse_type,
                  "out_folder": OUT_FOLDER,
                  "prefix": FOLDER_PREFIX,
                  "record_folder": RECORD_FOLDER}

    return parse_dict

def define_destinations(parse_dict):
    """
    define destination for extracted files
    """
    dest_dict = {
        "channel_name": "",
        "timestamp_file": "",
        "destination_folder": ""
    }

    parse_type = parse_dict["parse_type"]
    params = parse_dict["params"]
    dest_folder = parse_dict["out_folder"]
    prefix = parse_dict["prefix"]

    parser_func = 'parse_' + parse_type

    dest_dict['channel_name'] = params[parse_type]['channel_name']
    dest_dict['timestamp_file'] = dest_folder + prefix + params[parse_type]['timestamp_file_extn']
    dest_dict['destination_folder'] = dest_folder + \
        prefix + params[parse_type]['out_folder_extn'] + '/'

    if not os.path.exists(dest_dict["destination_folder"]):
        os.makedirs(dest_dict["destination_folder"])

    return dest_dict, parser_func

def parse_apollo_record(parse_dict, dest_dict, parser_func):
    """
    """
    record_folder_path = parse_dict["record_folder"]
    parse_type = parse_dict["parse_type"]
    record_files = sorted(os.listdir(parse_dict["record_folder"]))
    parse_timestamp = []
    parse_mod = import_module(parser_func)

    print("=" * 60)
    print('--------- Parsing data for: ' + parse_type + ' ---------')

    for rfile in record_files:
        print("=" * 60)
        print("parsing record file: %s" % rfile)
        freader = record.RecordReader(record_folder_path + rfile)
        time.sleep(.025)

        for channelname, msg, datatype, timestamp in freader.read_messages():
            if channelname == dest_dict["channel_name"]:
                tstamp = parse_mod.parse_data(channelname, msg, dest_dict['destination_folder'])
                parse_timestamp.append(tstamp)

        # write radar-timestamp files
        with open(dest_dict["timestamp_file"], 'w+') as f:
            for item in parse_timestamp:
                f.write("%s\n" % item)

    print("=" * 60)
    print('DONE: records parsed and data saved to: \n  ' + dest_dict['destination_folder'])
    print("=" * 60)

if __name__ == '__main__':
    cyber.init()
    parse_dict = read_parameters('modules/tools/record_parse_save/parser_params.yaml')
    dest_dict, parser_func = define_destinations(parse_dict)
    parse_apollo_record(parse_dict, dest_dict, parser_func)

    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Generate Planning Path
"""

import argparse
import atexit
import logging
import math
import os
import sys
import time

from numpy import genfromtxt
import scipy.signal as signal

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time
from modules.tools.common.logger import Logger
from modules.canbus.proto import chassis_pb2
from modules.common.configs.proto import vehicle_config_pb2
from modules.common.proto import drive_state_pb2
from modules.common.proto import pnc_point_pb2
from modules.control.proto import pad_msg_pb2
from modules.localization.proto import localization_pb2
from modules.planning.proto import planning_pb2
import modules.tools.common.proto_utils as proto_utils

# TODO(all): hard-coded path temporarily. Better approach needed.
APOLLO_ROOT = "/apollo"

SEARCH_INTERVAL = 5000
CHANGE_TO_COM = False


class RtkPlayer(object):
    """
    rtk player class
    """

    def __init__(self, record_file, node, speedmultiplier, completepath,
                 replan):
        """Init player."""
        self.firstvalid = False
        self.logger = Logger.get_logger(tag="RtkPlayer")
        self.logger.info("Load record file from: %s" % record_file)
        try:
            file_handler = open(record_file, 'r')
        except (FileNotFoundError, IOError) as ex:
            self.logger.error("Error opening {}: {}".format(record_file, ex))
            sys.exit(1)

        self.data = genfromtxt(file_handler, delimiter=',', names=True)
        file_handler.close()

        self.localization = localization_pb2.LocalizationEstimate()
        self.chassis = chassis_pb2.Chassis()
        self.padmsg = pad_msg_pb2.PadMessage()
        self.localization_received = False
        self.chassis_received = False

        self.planning_pub = node.create_writer('/apollo/planning',
                                               planning_pb2.ADCTrajectory)

        self.speedmultiplier = speedmultiplier / 100
        self.terminating = False
        self.sequence_num = 0

        b, a = signal.butter(6, 0.05, 'low')
        self.data['acceleration'] = signal.filtfilt(b, a,
                                                    self.data['acceleration'])

        self.start = 0
        self.end = 0
        self.closestpoint = 0
        self.automode = False

        self.replan = (replan == 't')
        self.completepath = (completepath == 't')

        self.estop = False
        self.logger.info("Planning Ready")

        vehicle_config = vehicle_config_pb2.VehicleConfig()
        proto_utils.get_pb_from_text_file(
            "/apollo/modules/common/data/vehicle_param.pb.txt", vehicle_config)
        self.vehicle_param = vehicle_config.vehicle_param

    def localization_callback(self, data):
        """
        New localization Received
        """
        self.localization.CopyFrom(data)
        self.carx = self.localization.pose.position.x
        self.cary = self.localization.pose.position.y
        self.carz = self.localization.pose.position.z
        self.localization_received = True

    def chassis_callback(self, data):
        """
        New chassis Received
        """
        self.chassis.CopyFrom(data)
        self.automode = (self.chassis.driving_mode
                         == chassis_pb2.Chassis.COMPLETE_AUTO_DRIVE)
        self.chassis_received = True

    def padmsg_callback(self, data):
        """
        New message received
        """
        if self.terminating is True:
            self.logger.info("terminating when receive padmsg")
            return

        self.padmsg.CopyFrom(data)

    def restart(self):
        self.logger.info("before replan self.start=%s, self.closestpoint=%s" %
                         (self.start, self.closestpoint))
        self.logger.debug("replan!")

        self.closestpoint = self.closest_dist()
        self.start = max(self.closestpoint - 1, 0)
        self.logger.debug("replan_start: %s" % self.start)
        self.starttime = cyber_time.Time.now().to_sec()
        self.logger.debug("at time %s" % self.starttime)
        self.end = self.next_gear_switch_time(self.start, len(self.data))
        self.logger.debug("replan_end: %s" % self.end)
        self.logger.info("finish replan at time %s, self.closestpoint=%s" %
                         (self.starttime, self.closestpoint))

    def closest_dist(self):
        shortest_dist_sqr = float('inf')
        self.logger.info("before closest self.start=%s" % (self.start))
        search_start = max(self.start - SEARCH_INTERVAL // 2, 0)
        search_end = min(self.start + SEARCH_INTERVAL // 2, len(self.data))
        self.logger.debug("search_start: %s" % search_start)
        self.logger.debug("search_end: %s" % search_end)
        closest_dist_point = self.start
        self.logger.debug("self.start: %s" % self.start)
        for i in range(search_start, search_end):
            dist_sqr = (self.carx - self.data['x'][i]) ** 2 + \
                (self.cary - self.data['y'][i]) ** 2
            if dist_sqr <= shortest_dist_sqr and self.data['gear'][i] == self.chassis.gear_location:
                closest_dist_point = i
                shortest_dist_sqr = dist_sqr

        # failed to find a trajectory matches current gear position
        if shortest_dist_sqr == float('inf'):
            self.logger.info(
                'no trajectory point matches current gear position, check gear position')
            return closest_dist_point + 1  # remain current start point

        return closest_dist_point

    def closest_time(self):
        time_elapsed = cyber_time.Time.now().to_sec() - self.starttime
        closest_time = self.start
        time_diff = self.data['time'][closest_time] - \
            self.data['time'][self.closestpoint]

        while time_diff < time_elapsed and closest_time < (len(self.data) - 1):
            closest_time = closest_time + 1
            time_diff = self.data['time'][closest_time] - \
                self.data['time'][self.closestpoint]

        return closest_time

    def next_gear_switch_time(self, start, end):
        for i in range(start, end):
            # trajectory with gear switch
            # include gear_neutral at the beginning of a trajectory
            if (i < end - 1
                and self.data['gear'][i] in {1, 2}
                    and self.data['gear'][i + 1] != self.data['gear'][i]):
                self.logger.debug("enter i in while loop: [ %s ]" % i)
                self.logger.debug(
                    "self.data['gear'][i] != 1: %s" % self.data['gear'][i])
                self.logger.debug(
                    "self.data['gear'][i] != 2: %s" % self.data['gear'][i])
                # find next gear = 1 or 2
                i += 1
                while i < end and (self.data['gear'][i] != 1) and (self.data['gear'][i] != 2):
                    i += 1
                self.logger.debug("i in while loop: [ %s ]" % i)
                return i - 1
        # trajectory without gear switch
        self.logger.debug("i at end: [ %s ]" % i)
        return min(i, end - 1)

    def publish_planningmsg(self):
        """
        Generate New Path
        """
        if not self.localization_received:
            self.logger.warning(
                "localization not received yet when publish_planningmsg")
            return

        planningdata = planning_pb2.ADCTrajectory()
        now = cyber_time.Time.now().to_sec()
        planningdata.header.timestamp_sec = now
        planningdata.header.module_name = "planning"
        planningdata.header.sequence_num = self.sequence_num
        self.sequence_num = self.sequence_num + 1

        self.logger.debug(
            "publish_planningmsg: before adjust start: self.start=%s, self.end=%s"
            % (self.start, self.end))
        if self.replan or self.sequence_num <= 1 or not self.automode:
            self.logger.info(
                "trigger replan: self.replan=%s, self.sequence_num=%s, self.automode=%s"
                % (self.replan, self.sequence_num, self.automode))
            self.restart()
        else:
            timepoint = self.closest_time()
            distpoint = self.closest_dist()

            if self.data['gear'][timepoint] == self.data['gear'][distpoint]:
                self.start = max(min(timepoint, distpoint), 0)
            elif self.data['gear'][timepoint] == self.chassis.gear_location:
                self.start = timepoint
            else:
                self.start = distpoint

            self.logger.debug("timepoint:[%s]" % timepoint)
            self.logger.debug("distpoint:[%s]" % distpoint)
            self.logger.debug(
                "trajectory start point: [%s], gear is [%s]" % (self.start, self.data['gear'][self.start]))

            self.end = self.next_gear_switch_time(self.start, len(self.data))
            self.logger.debug("len of data: ", len(self.data))
            self.logger.debug("trajectory end point: [%s], gear is [%s]" %
                              (self.end, self.data['gear'][self.end]))

            xdiff_sqr = (self.data['x'][timepoint] - self.carx)**2
            ydiff_sqr = (self.data['y'][timepoint] - self.cary)**2
            if xdiff_sqr + ydiff_sqr > 4.0:
                self.logger.info("trigger replan: distance larger than 2.0")
                self.restart()

        if self.completepath:
            self.start = 0
            self.end = len(self.data) - 1

        self.logger.debug(
            "publish_planningmsg: after adjust start: self.start=%s, self.end=%s"
            % (self.start, self.end))

        planningdata.total_path_length = self.data['s'][self.end] - \
            self.data['s'][self.start]
        self.logger.info("total number of planning data point: %d" %
                         (self.end - self.start))
        planningdata.total_path_time = self.data['time'][self.end] - \
            self.data['time'][self.start]
        planningdata.gear = int(self.data['gear'][self.closest_time()])
        planningdata.engage_advice.advice = \
            drive_state_pb2.EngageAdvice.READY_TO_ENGAGE

        for i in range(self.start, self.end):
            adc_point = pnc_point_pb2.TrajectoryPoint()
            adc_point.path_point.x = self.data['x'][i]
            adc_point.path_point.y = self.data['y'][i]
            adc_point.path_point.z = self.data['z'][i]
            adc_point.v = self.data['speed'][i] * self.speedmultiplier
            adc_point.a = self.data['acceleration'][i] * self.speedmultiplier
            adc_point.path_point.kappa = self.data['curvature'][i]
            adc_point.path_point.dkappa = self.data['curvature_change_rate'][i]
            adc_point.path_point.theta = self.data['theta'][i]
            adc_point.path_point.s = self.data['s'][i]

            if CHANGE_TO_COM:
                # translation vector length(length / 2 - back edge to center)
                adc_point.path_point.x = adc_point.path_point.x + \
                    (self.vehicle_param.length // 2 - self.vehicle_param.back_edge_to_center) * \
                    math.cos(adc_point.path_point.theta)
                adc_point.path_point.y = adc_point.path_point.y + \
                    (self.vehicle_param.length // 2 - self.vehicle_param.back_edge_to_center) * \
                    math.sin(adc_point.path_point.theta)

            if planningdata.gear == chassis_pb2.Chassis.GEAR_REVERSE:
                adc_point.v = -adc_point.v
                adc_point.path_point.s = -adc_point.path_point.s

            time_diff = self.data['time'][i] - \
                self.data['time'][self.closestpoint]

            adc_point.relative_time = time_diff / self.speedmultiplier - (
                now - self.starttime)

            planningdata.trajectory_point.extend([adc_point])

        planningdata.estop.is_estop = self.estop

        self.planning_pub.write(planningdata)
        self.logger.debug("Generated Planning Sequence: "
                          + str(self.sequence_num - 1))

    def shutdown(self):
        """
        shutdown cyber
        """
        self.terminating = True
        self.logger.info("Shutting Down...")
        time.sleep(0.2)

    def quit(self, signum, frame):
        """
        shutdown the keypress thread
        """
        sys.exit(0)


def main():
    """
    Main cyber
    """
    parser = argparse.ArgumentParser(
        description='Generate Planning Trajectory from Data File')
    parser.add_argument(
        '-s',
        '--speedmulti',
        help='Speed multiplier in percentage (Default is 100) ',
        type=float,
        default='100')
    parser.add_argument(
        '-c', '--complete', help='Generate complete path (t/F)', default='F')
    parser.add_argument(
        '-r',
        '--replan',
        help='Always replan based on current position(t/F)',
        default='F')
    args = vars(parser.parse_args())

    node = cyber.Node("rtk_player")

    Logger.config(
        log_file=os.path.join(APOLLO_ROOT, 'data/log/rtk_player.log'),
        use_stdout=True,
        log_level=logging.DEBUG)

    record_file = os.path.join(APOLLO_ROOT, 'data/log/garage.csv')

    player = RtkPlayer(record_file, node, args['speedmulti'],
                       args['complete'].lower(), args['replan'].lower())
    atexit.register(player.shutdown)

    node.create_reader('/apollo/canbus/chassis', chassis_pb2.Chassis,
                       player.chassis_callback)

    node.create_reader('/apollo/localization/pose',
                       localization_pb2.LocalizationEstimate,
                       player.localization_callback)

    node.create_reader('/apollo/control/pad', pad_msg_pb2.PadMessage,
                       player.padmsg_callback)

    while not cyber.is_shutdown():
        now = cyber_time.Time.now().to_sec()
        player.publish_planningmsg()
        sleep_time = 0.1 - (cyber_time.Time.now().to_sec() - now)
        if sleep_time > 0:
            time.sleep(sleep_time)


if __name__ == '__main__':
    cyber.init()
    main()
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Record GPS and IMU data
"""

import atexit
import logging
import math
import os
import sys
import time

from cyber.python.cyber_py3 import cyber
from gflags import FLAGS

from modules.tools.common.logger import Logger
import modules.tools.common.proto_utils as proto_utils
from modules.canbus.proto import chassis_pb2
from modules.common.configs.proto import vehicle_config_pb2
from modules.localization.proto import localization_pb2


class RtkRecord(object):
    """
    rtk recording class
    """

    def write(self, data):
        """Wrap file write function to flush data to disk"""
        self.file_handler.write(data)
        self.file_handler.flush()

    def __init__(self, record_file):
        self.firstvalid = False
        self.logger = Logger.get_logger("RtkRecord")
        self.record_file = record_file
        self.logger.info("Record file to: " + record_file)

        try:
            self.file_handler = open(record_file, 'w')
        except IOError:
            self.logger.error("Open file %s failed" % (record_file))
            self.file_handler.close()
            sys.exit(1)

        self.write("x,y,z,speed,acceleration,curvature,"
                   "curvature_change_rate,time,theta,gear,s,throttle,brake,steering\n")

        self.localization = localization_pb2.LocalizationEstimate()
        self.chassis = chassis_pb2.Chassis()
        self.chassis_received = False

        self.cars = 0.0
        self.startmoving = False

        self.terminating = False
        self.carcurvature = 0.0

        self.prev_carspeed = 0.0

        vehicle_config = vehicle_config_pb2.VehicleConfig()
        proto_utils.get_pb_from_text_file(
            "/apollo/modules/common/data/vehicle_param.pb.txt", vehicle_config)
        self.vehicle_param = vehicle_config.vehicle_param

    def chassis_callback(self, data):
        """
        New message received
        """
        if self.terminating is True:
            self.logger.info("terminating when receive chassis msg")
            return

        self.chassis.CopyFrom(data)
        #self.chassis = data
        if math.isnan(self.chassis.speed_mps):
            self.logger.warning("find nan speed_mps: %s" % str(self.chassis))
        if math.isnan(self.chassis.steering_percentage):
            self.logger.warning(
                "find nan steering_percentage: %s" % str(self.chassis))
        self.chassis_received = True

    def localization_callback(self, data):
        """
        New message received
        """
        if self.terminating is True:
            self.logger.info("terminating when receive localization msg")
            return

        if not self.chassis_received:
            self.logger.info(
                "chassis not received when localization is received")
            return

        self.localization.CopyFrom(data)
        #self.localization = data
        carx = self.localization.pose.position.x
        cary = self.localization.pose.position.y
        carz = self.localization.pose.position.z
        cartheta = self.localization.pose.heading
        if math.isnan(self.chassis.speed_mps):
            self.logger.warning("find nan speed_mps: %s" % str(self.chassis))
            return
        if math.isnan(self.chassis.steering_percentage):
            self.logger.warning(
                "find nan steering_percentage: %s" % str(self.chassis))
            return
        carspeed = self.chassis.speed_mps
        caracceleration = self.localization.pose.linear_acceleration_vrf.y

        speed_epsilon = 1e-9
        if abs(self.prev_carspeed) < speed_epsilon \
                and abs(carspeed) < speed_epsilon:
            caracceleration = 0.0

        carsteer = self.chassis.steering_percentage
        carmax_steer_angle = self.vehicle_param.max_steer_angle
        carsteer_ratio = self.vehicle_param.steer_ratio
        carwheel_base = self.vehicle_param.wheel_base
        curvature = math.tan(math.radians(carsteer / 100
                                          * math.degrees(carmax_steer_angle)) / carsteer_ratio) / carwheel_base
        if abs(carspeed) >= speed_epsilon:
            carcurvature_change_rate = (curvature - self.carcurvature) / (
                carspeed * 0.01)
        else:
            carcurvature_change_rate = 0.0
        self.carcurvature = curvature
        cartime = self.localization.header.timestamp_sec
        cargear = self.chassis.gear_location

        if abs(carspeed) >= speed_epsilon:
            if self.startmoving is False:
                self.logger.info(
                    "carspeed !=0 and startmoving is False, Start Recording")
            self.startmoving = True

        if self.startmoving:
            self.cars += carspeed * 0.01
            self.write(
                "%s, %s, %s, %s, %s, %s, %s, %.4f, %s, %s, %s, %s, %s, %s\n" %
                (carx, cary, carz, carspeed, caracceleration, self.carcurvature,
                 carcurvature_change_rate, cartime, cartheta, cargear,
                 self.cars, self.chassis.throttle_percentage,
                 self.chassis.brake_percentage,
                 self.chassis.steering_percentage))
            self.logger.debug(
                "started moving and write data at time %s" % cartime)
        else:
            self.logger.debug("not start moving, do not write data to file")

        self.prev_carspeed = carspeed

    def shutdown(self):
        """
        shutdown node
        """
        self.terminating = True
        self.logger.info("Shutting Down...")
        self.logger.info("File is written into %s" % self.record_file)
        self.file_handler.close()


def main(argv):
    """
    Main node
    """
    node = cyber.Node("rtk_recorder")
    argv = FLAGS(argv)

    log_dir = "/apollo/data/log"
    if len(argv) > 1:
        log_dir = argv[1]

    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    Logger.config(
        log_file=log_dir + "rtk_recorder.log",
        use_stdout=True,
        log_level=logging.DEBUG)
    print("runtime log is in %s%s" % (log_dir, "rtk_recorder.log"))

    record_file = log_dir + "/garage.csv"
    recorder = RtkRecord(record_file)
    atexit.register(recorder.shutdown)
    node.create_reader('/apollo/canbus/chassis',
                       chassis_pb2.Chassis,
                       recorder.chassis_callback)

    node.create_reader('/apollo/localization/pose',
                       localization_pb2.LocalizationEstimate,
                       recorder.localization_callback)

    while not cyber.is_shutdown():
        time.sleep(0.002)


if __name__ == '__main__':
    cyber.init()
    main(sys.argv)
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can replay a message pb file
"""
import os.path
import sys
import argparse
import glob
import time

from google.protobuf import text_format

from cyber.python.cyber_py3 import cyber

import modules.tools.common.proto_utils as proto_utils
from modules.tools.common.message_manager import PbMessageManager

g_message_manager = PbMessageManager()


def topic_publisher(topic, filename, period):
    """publisher"""
    cyber.init()
    node = cyber.Node("replay_file")
    meta_msg = None
    msg = None
    if not topic:
        print("Topic not specified, start to guess")
        meta_msg, msg = g_message_manager.parse_file(filename)
        topic = meta_msg.topic()
    else:
        meta_msg = g_message_manager.get_msg_meta_by_topic(topic)
        if not meta_msg:
            print("Failed to find meta info for topic: %s" % (topic))
            return False
        msg = meta_msg.parse_file(filename)
        if not msg:
            print("Failed to parse file[%s] with topic[%s]" % (filename,
                                                               topic))
            return False

    if not msg or not meta_msg:
        print("Unknown topic: %s" % topic)
        return False

    writer = node.create_writer(topic, meta_msg.msg_type)

    if period == 0:
        while not cyber.is_shutdown():
            input("Press any key to publish one message...")
            writer.write(msg)
            print("Topic[%s] message published" % topic)
    else:
        print("started to publish topic[%s] message with rate period %s" %
              (topic, period))
        while not cyber.is_shutdown():
            writer.write(msg)
            time.sleep(period)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="replay a planning result pb file")
    parser.add_argument(
        "filename", action="store", type=str, help="planning result files")
    parser.add_argument(
        "--topic", action="store", type=str, help="set the planning topic")
    parser.add_argument(
        "--period",
        action="store",
        type=float,
        default=0.1,
        help="set the topic publish time duration")
    args = parser.parse_args()
    period = 0.0  # use step by step mode
    if args.period:  # play with a given period, (1.0 / frequency)
        period = args.period
    to_replay = args.filename
    files = []
    if os.path.isdir(args.filename):
        files = glob.glob(args.filename + "/*")
        i = 0
        for f in files:
            print("%d  %s" % (i, f))
            i += 1
        str_input = input("Select message by number: ")
        try:
            selected_file = int(str_input)
            if selected_file < 0 or selected_file > len(files):
                print("%d is an invalid number" % selected_file)
        except:
            print("%s is not a number" % str_input)
        print("Will publish file[%d]: %s" % (selected_file,
                                             files[selected_file]))
        to_replay = files[selected_file]
    topic_publisher(args.topic, to_replay, period)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

""" Restore record file by replacing its video frames with image frames. """

import datetime
import errno
import glob
import os
import shutil
import time

from absl import app
from absl import flags
from absl import logging
import cv2

from cyber.python.cyber_py3.record import RecordReader, RecordWriter
from modules.drivers.proto.sensor_image_pb2 import CompressedImage


flags.DEFINE_string('from_record', None, 'The source record file that needs to be restored.')
flags.DEFINE_string('to_record', None, 'The restored record file.')

# The compressed channels that have videos we need to decode
IMAGE_FRONT_6MM_CHANNEL = '/apollo/sensor/camera/front_6mm/image/compressed'
IMAGE_FRONT_12MM_CHANNEL = '/apollo/sensor/camera/front_12mm/image/compressed'
IMAGE_REAR_6MM_CHANNEL = '/apollo/sensor/camera/rear_6mm/image/compressed'
IMAGE_LEFT_FISHEYE_CHANNEL = '/apollo/sensor/camera/left_fisheye/image/compressed'
IMAGE_RIGHT_FISHEYE_CHANNEL = '/apollo/sensor/camera/right_fisheye/image/compressed'

VIDEO_FRONT_6MM_CHANNEL = '/apollo/sensor/camera/front_6mm/video/compressed'
VIDEO_FRONT_12MM_CHANNEL = '/apollo/sensor/camera/front_12mm/video/compressed'
VIDEO_REAR_6MM_CHANNEL = '/apollo/sensor/camera/rear_6mm/video/compressed'
VIDEO_LEFT_FISHEYE_CHANNEL = '/apollo/sensor/camera/left_fisheye/video/compressed'
VIDEO_RIGHT_FISHEYE_CHANNEL = '/apollo/sensor/camera/right_fisheye/video/compressed'

VIDEO_CHANNELS = [
    IMAGE_FRONT_6MM_CHANNEL,
    IMAGE_FRONT_12MM_CHANNEL,
    IMAGE_REAR_6MM_CHANNEL,
    IMAGE_LEFT_FISHEYE_CHANNEL,
    IMAGE_RIGHT_FISHEYE_CHANNEL,
    VIDEO_FRONT_6MM_CHANNEL,
    VIDEO_FRONT_12MM_CHANNEL,
    VIDEO_REAR_6MM_CHANNEL,
    VIDEO_LEFT_FISHEYE_CHANNEL,
    VIDEO_RIGHT_FISHEYE_CHANNEL,
]

VIDEO_IMAGE_MAP = {
    IMAGE_FRONT_6MM_CHANNEL: IMAGE_FRONT_6MM_CHANNEL,
    IMAGE_FRONT_12MM_CHANNEL: IMAGE_FRONT_12MM_CHANNEL,
    IMAGE_REAR_6MM_CHANNEL: IMAGE_REAR_6MM_CHANNEL,
    IMAGE_LEFT_FISHEYE_CHANNEL: IMAGE_LEFT_FISHEYE_CHANNEL,
    IMAGE_RIGHT_FISHEYE_CHANNEL: IMAGE_RIGHT_FISHEYE_CHANNEL,
    VIDEO_FRONT_6MM_CHANNEL: IMAGE_FRONT_6MM_CHANNEL,
    VIDEO_FRONT_12MM_CHANNEL: IMAGE_FRONT_12MM_CHANNEL,
    VIDEO_REAR_6MM_CHANNEL: IMAGE_REAR_6MM_CHANNEL,
    VIDEO_LEFT_FISHEYE_CHANNEL: IMAGE_LEFT_FISHEYE_CHANNEL,
    VIDEO_RIGHT_FISHEYE_CHANNEL: IMAGE_RIGHT_FISHEYE_CHANNEL,
}


class VideoConverter(object):
    """Convert video into images."""

    def __init__(self, work_dir, topic):
        # Initial type of video frames that defined in apollo video drive proto
        # The initial frame has meta data information shared by the following tens of frames
        self.initial_frame_type = 1
        self.image_ids = []
        self.first_initial_found = False
        video_dir = os.path.join(work_dir, 'videos')
        self.video_file = os.path.join(video_dir, '{}.h265'.format(topic))
        self.image_dir = '{}_images'.format(self.video_file)
        makedirs(video_dir)
        makedirs(self.image_dir)
        self.frame_writer = open(self.video_file, 'wb+')

    def close_writer(self):
        """Close the video frames writer"""
        self.frame_writer.close()

    def write_frame(self, py_message):
        """Write video frames into binary format file"""
        if not self.first_initial_found:
            proto = image_message_to_proto(py_message)
            if proto.frame_type != self.initial_frame_type:
                return
            self.first_initial_found = True
        self.frame_writer.write(py_message.message)
        self.image_ids.append(get_message_id(py_message.timestamp, py_message.topic))

    def decode(self):
        """Decode video file into images"""
        video_decoder_exe = '/apollo/bazel-bin/modules/drivers/video/tools/decode_video/video2jpg'
        return_code = os.system('{} --input_video={} --output_dir={}'.format(
            video_decoder_exe, self.video_file, self.image_dir))
        if return_code != 0:
            logging.error('Failed to execute video2jpg for video {}'.format(self.video_file))
            return False
        generated_images = sorted(glob.glob('{}/*.jpg'.format(self.image_dir)))
        if len(generated_images) != len(self.image_ids):
            logging.error('Mismatch between original {} and generated frames {}'.format(
                len(self.image_ids), len(generated_images)))
            return False
        for idx in range(len(generated_images)):
            os.rename(generated_images[idx], os.path.join(self.image_dir, self.image_ids[idx]))
        return True

    def move_images(self, overall_image_dir):
        """Move self's images to overall image dir"""
        for image_file in os.listdir(self.image_dir):
            shutil.move(os.path.join(self.image_dir, image_file),
                        os.path.join(overall_image_dir, image_file))


def restore_record(input_record, output_record):
    """Entrance of processing."""
    # Define working dirs that store intermediate results in the middle of processing
    work_dir = 'restore_video_work_dir_{}'.format(
        datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d-%H-%M-%S'))

    # Decode videos
    converters = {}
    for topic in VIDEO_CHANNELS:
        converters[topic] = VideoConverter(work_dir, topic)

    reader = RecordReader(input_record)
    for message in reader.read_messages():
        if message.topic in VIDEO_CHANNELS:
            converters[message.topic].write_frame(message)

    image_dir = os.path.join(work_dir, 'images')
    makedirs(image_dir)
    for topic in VIDEO_CHANNELS:
        converters[topic].close_writer()
        converters[topic].decode()
        converters[topic].move_images(image_dir)

    # Restore target record file
    writer = RecordWriter(0, 0)
    writer.open(output_record)
    topic_descs = {}
    counter = 0
    reader = RecordReader(input_record)
    for message in reader.read_messages():
        message_content = message.message
        message_topic = message.topic
        if message.topic in VIDEO_CHANNELS:
            message_content = retrieve_image(image_dir, message)
            message_topic = VIDEO_IMAGE_MAP[message.topic]
            if not message_content:
                continue
        counter += 1
        if counter % 1000 == 0:
            logging.info('rewriting {} th message to record {}'.format(counter, output_record))
        writer.write_message(message_topic, message_content, message.timestamp)
        if message_topic not in topic_descs:
            topic_descs[message_topic] = reader.get_protodesc(message_topic)
            writer.write_channel(message_topic, message.data_type, topic_descs[message_topic])
    writer.close()

    logging.info('All Done, converted record: {}'.format(output_record))


def retrieve_image(image_dir, message):
    """Actually change the content of message from video bytes to image bytes"""
    message_id = get_message_id(message.timestamp, message.topic)
    message_path = os.path.join(image_dir, message_id)
    if not os.path.exists(message_path):
        logging.error('message {} not found in image dir'.format(message_id))
        return None
    img_bin = cv2.imread(message_path)
    # Check by using NoneType explicitly to avoid ambitiousness
    if img_bin is None:
        logging.error('failed to read original message: {}'.format(message_path))
        return None
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 95]
    result, encode_img = cv2.imencode('.jpg', img_bin, encode_param)
    if not result:
        logging.error('failed to encode message {}'.format(message_id))
        return None
    message_proto = image_message_to_proto(message)
    message_proto.format = '; jpeg compressed bgr8'
    message_proto.data = message_proto.data.replace(message_proto.data[:], bytearray(encode_img))
    return message_proto.SerializeToString()


def get_message_id(timestamp, topic):
    """Unify the way to get a unique identifier for the given message"""
    return '{}{}'.format(timestamp, topic.replace('/', '_'))


def image_message_to_proto(py_message):
    """Message to prototype"""
    message_proto = CompressedImage()
    message_proto.ParseFromString(py_message.message)
    return message_proto


def makedirs(dir_path):
    """Make directories recursively."""
    if os.path.exists(dir_path):
        return
    try:
        os.makedirs(dir_path)
    except OSError as error:
        if error.errno != errno.EEXIST:
            logging.error('Failed to makedir ' + dir_path)
            raise


def main(argv):
    """Main process."""
    if not flags.FLAGS.from_record or not os.path.exists(flags.FLAGS.from_record):
        logging.error('Please provide valid source record file.')
        return
    to_record = flags.FLAGS.to_record
    if not to_record:
        to_record = '{}_restored'.format(flags.FLAGS.from_record)
        logging.warn('The default restored record file is set as {}'.format(to_record))
    restore_record(flags.FLAGS.from_record, to_record)


if __name__ == '__main__':
    app.run(main)
#!/usr/bin/env python3

###############################################################################
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can publish audio event message
"""

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time

import argparse
import datetime
import shutil
import time
import os
import sys

from modules.tools.common.message_manager import PbMessageManager
from modules.tools.common import proto_utils

g_message_manager = PbMessageManager()

g_args = None

g_localization = None


def OnReceiveLocalization(localization_msg):
    global g_localization
    g_localization = localization_msg


def main(args):
    audio_event_meta_msg = g_message_manager.get_msg_meta_by_topic(
        args.audio_event_topic)
    if not audio_event_meta_msg:
        print('Unknown audio_event topic name: %s' % args.audio_event_topic)
        sys.exit(1)

    localization_meta_msg = g_message_manager.get_msg_meta_by_topic(
        args.localization_topic)
    if not localization_meta_msg:
        print('Unknown localization topic name: %s' % args.localization_topic)
        sys.exit(1)

    cyber.init()
    node = cyber.Node("audio_event_node")
    node.create_reader(localization_meta_msg.topic,
                       localization_meta_msg.msg_type, OnReceiveLocalization)

    writer = node.create_writer(audio_event_meta_msg.topic,
                                audio_event_meta_msg.msg_type)
    seq_num = 0
    while not cyber.is_shutdown():
        obstacle_id = input(
            "Type in obstacle ID and press Enter (current time: " +
            str(datetime.datetime.now()) + ")\n>")
        obstacle_id = obstacle_id.strip()
        # TODO(QiL) add obstacle id sanity check.
        current_time = cyber_time.Time.now().to_sec()
        moving_result = None
        audio_type = None
        siren_is_on = None
        audio_direction = None
        while not moving_result:
            moving_result = input("Type MovingResult:>")
            moving_result = moving_result.strip()
        while not audio_type:
            audio_type = input("Type AudioType:>")
            audio_type = audio_type.strip()
        while not siren_is_on:
            siren_is_on = input("Type SirenOnOffStatus:>")
            siren_is_on = siren_is_on.strip()
        while not audio_direction:
            audio_direction = input("Type AudioDirection:>")
            audio_direction = audio_direction.strip()
        event_msg = audio_event_meta_msg.msg_type()
        event_msg.header.timestamp_sec = current_time
        event_msg.header.module_name = 'audio_event'
        seq_num += 1
        event_msg.header.sequence_num = seq_num
        event_msg.header.version = 1
        event_msg.id = obstacle_id
        event_msg.moving_result = moving_result
        event_msg.audio_type = audio_type
        event_msg.siren_is_on = siren_is_on
        event_msg.audio_direction = audio_direction
        if g_localization:
            event_msg.location.CopyFrom(g_localization.pose)
        writer.write(event_msg)
        time_str = datetime.datetime.fromtimestamp(current_time).strftime(
            "%Y%m%d%H%M%S")
        filename = os.path.join(args.dir, "%s_audio_event.pb.txt" % time_str)
        proto_utils.write_pb_to_text_file(event_msg, filename)
        print('Logged to rosbag and written to file %s' % filename)
        time.sleep(0.1)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to write audio events when recording rosbag")
    parser.add_argument(
        "--audio_event_topic",
        action="store",
        default="/apollo/audio_event",
        help="""the audio event topic""")
    parser.add_argument(
        "--localization_topic",
        action="store",
        default="/apollo/localization/pose",
        help="""the drive event topic""")
    parser.add_argument(
        "--dir",
        action="store",
        default="data/bag",
        help="""The log export directory.""")
    g_args = parser.parse_args()
    main(g_args)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Usage:
    python body_sensation_evalution.py bag1 bag2 ...
"""

import argparse
import collections
import math
import sys
import time

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from modules.canbus.proto import chassis_pb2
from modules.canbus.proto.chassis_pb2 import Chassis
from modules.localization.proto import localization_pb2

BUMP_TIME_THRESHOLD = 3
ACCELERATE_TIME_THRESHOLD = 1
SPEED_UP_THRESHOLD_2 = 2
SPEED_UP_THRESHOLD_4 = 4
SPEED_DOWN_THRESHOLD_2 = -2
SPEED_DOWN_THRESHOLD_4 = -4

kChassisTopic = '/apollo/canbus/chassis'
kLocalizationTopic = '/apollo/localization/pose'


class BodySensationCalculator(object):
    """The class to dispose body sensation from rosbag"""

    def __init__(self):
        self.driving_mode = []
        self._timestamp = 0.0
        self._last_bump_time = 0.0
        self._last_speed_down_2_time = 0.0
        self._last_speed_down_4_time = 0.0
        self._last_speed_up_2_time = 0.0
        self._last_speed_up_4_time = 0.0
        self._last_turning_time = 0.0
        self._speed_down_2_flag = 0
        self._speed_down_4_flag = 0
        self._speed_up_2_flag = 0
        self._speed_up_4_flag = 0
        self._turning_flag = 0
        self.auto_counts = {}
        self.auto_counts["speed_down_2"] = 0
        self.auto_counts["speed_down_4"] = 0
        self.auto_counts["speed_up_2"] = 0
        self.auto_counts["speed_up_4"] = 0
        self.auto_counts["turning"] = 0
        self.auto_counts["bumps"] = 0
        self.manual_counts = {}
        self.manual_counts["speed_down_2"] = 0
        self.manual_counts["speed_down_4"] = 0
        self.manual_counts["speed_up_2"] = 0
        self.manual_counts["speed_up_4"] = 0
        self.manual_counts["turning"] = 0
        self.manual_counts["bumps"] = 0

    def get_driving_mode(self, bag_file):
        """get driving mode, which is stored in a dict"""
        mode = {}
        mode["status"] = 'UNKNOW'
        mode["start_time"] = 0.0
        mode["end_time"] = 0.0
        chassis = chassis_pb2.Chassis()
        reader = RecordReader(bag_file)

        for msg in reader.read_messages():
            if msg.topic == kChassisTopic:
                chassis.ParseFromString(msg.message)
                _t = msg.timestamp
                t = int(str(_t)) * pow(10, -9)
                cur_status = chassis.driving_mode
                if mode["status"] != cur_status:
                    if mode["status"] != 'UNKNOW':
                        self.driving_mode.append(mode)
                    mode["status"] = cur_status
                    mode["start_time"] = t
                mode["end_time"] = t
            self.driving_mode.append(mode)

    def _check_status(self, timestamp):
        """check driving mode according to timestamp"""
        for mode in self.driving_mode:
            if timestamp >= mode["start_time"] and timestamp <= mode["end_time"]:
                if mode["status"] == Chassis.COMPLETE_AUTO_DRIVE:
                    return True
                else:
                    return False
        return False

    def _bumps_rollback(self, bump_time):
        """rollback 1 second when passing bumps"""
        if bump_time - self._last_speed_down_2_time <= ACCELERATE_TIME_THRESHOLD:
            if self._check_status(self._last_speed_down_2_time):
                self.auto_counts["speed_down_2"] -= 1
            else:
                self.manual_counts["speed_down_2"] -= 1

        if bump_time - self._last_speed_up_2_time <= ACCELERATE_TIME_THRESHOLD:
            if self._check_status(self._last_speed_up_2_time):
                self.auto_counts["speed_up_2"] -= 1
            else:
                self.manual_counts["speed_up_2"] -= 1

        if bump_time - self._last_speed_down_4_time <= ACCELERATE_TIME_THRESHOLD:
            if self._check_status(self._last_speed_down_4_time):
                self.auto_counts["speed_down_4"] -= 1
            else:
                self.manual_counts["speed_down_4"] -= 1

        if bump_time - self._last_speed_up_4_time <= ACCELERATE_TIME_THRESHOLD:
            if self._check_status(self._last_speed_up_4_time):
                self.auto_counts["speed_up_4"] -= 1
            else:
                self.manual_counts["speed_up_4"] -= 1

        if bump_time - self._last_turning_time <= ACCELERATE_TIME_THRESHOLD:
            if self._check_status(self._last_turning_time):
                self.auto_counts["turning"] -= 1
            else:
                self.manual_counts["turning"] -= 1

    def calculate(self, bag_file):
        """calculate body sensation, it should be after get driving mode"""
        localization = localization_pb2.LocalizationEstimate()
        reader = RecordReader(bag_file)
        for msg in reader.read_messages():
            if msg.topic == kLocalizationTopic:
                localization.ParseFromString(msg.message)
                _t = msg.timestamp
                t = int(str(_t)) * pow(10, -9)
                self.timestamp = t
                diff_bump_time = t - self._last_bump_time
                if diff_bump_time <= BUMP_TIME_THRESHOLD:
                    continue
                acc_x = localization.pose.linear_acceleration.x
                acc_y = localization.pose.linear_acceleration.y
                acc_z = localization.pose.linear_acceleration.z

                if abs(acc_z) >= SPEED_UP_THRESHOLD_2 and diff_bump_time >= BUMP_TIME_THRESHOLD:
                    self._bumps_rollback(t)
                    self._last_bump_time = t

                    if self._check_status(t):
                        self.auto_counts["bumps"] += 1
                    else:
                        self.manual_counts["bumps"] += 1
                else:
                    if self._speed_down_2_flag:
                        if acc_y <= SPEED_DOWN_THRESHOLD_4:
                            self._speed_down_4_flag = 1
                            continue
                        if acc_y <= SPEED_DOWN_THRESHOLD_2:
                            continue
                        if self._speed_down_4_flag == 1 \
                                and t - self._last_speed_down_4_time >= ACCELERATE_TIME_THRESHOLD:
                            self._last_speed_down_4_time = t
                            if self._check_status(t):
                                self.auto_counts["speed_down_4"] += 1
                            else:
                                self.manual_counts["speed_down_4"] += 1
                        elif t - self._last_speed_down_2_time >= ACCELERATE_TIME_THRESHOLD:
                            self._last_speed_down_2_time = t
                            if self._check_status(t):
                                self.auto_counts["speed_down_2"] += 1
                            else:
                                self.manual_counts["speed_down_2"] += 1
                        self._speed_down_2_flag = 0
                        self._speed_down_4_flag = 0
                    elif acc_y <= SPEED_DOWN_THRESHOLD_2:
                        self._speed_down_2_flag = 1

                    if self._speed_up_2_flag:
                        if acc_y >= SPEED_UP_THRESHOLD_4:
                            self._speed_up_4_flag = 1
                            continue
                        if acc_y >= SPEED_UP_THRESHOLD_2:
                            continue
                        if self._speed_up_4_flag == 1 \
                                and t - self._last_speed_up_4_time >= ACCELERATE_TIME_THRESHOLD:
                            self._last_speed_up_4_time = t
                            if self._check_status(t):
                                self.auto_counts["speed_up_4"] += 1
                            else:
                                self.manual_counts["speed_up_4"] += 1
                        elif t - self._last_speed_up_2_time >= ACCELERATE_TIME_THRESHOLD:
                            self._last_speed_up_2_time = t
                            if self._check_status(t):
                                self.auto_counts["speed_up_2"] += 1
                            else:
                                self.manual_counts["speed_up_2"] += 1
                        self._speed_up_2_flag = 0
                        self._speed_up_4_flag = 0
                    elif acc_y >= SPEED_UP_THRESHOLD_2:
                        self._speed_up_2_flag = 1

                    if self._turning_flag:
                        if abs(acc_x) >= SPEED_UP_THRESHOLD_2:
                            continue
                        if t - self._last_turning_time >= ACCELERATE_TIME_THRESHOLD:
                            self._last_turning_time = t
                            if self._check_status(t):
                                self.auto_counts["turning"] += 1
                            else:
                                self.manual_counts["turning"] += 1
                        self._turning_flag = 0
                    elif abs(acc_x) >= SPEED_UP_THRESHOLD_2:
                        self._turning_flag = 1


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to evaluate the body sensation. \
        It should be used like 'python body_sensation_evalution.py bag1 bag2 ...' ")
    parser.add_argument(
        "in_rosbag", action="store", nargs='+', type=str, help="the input rosbag")
    args = parser.parse_args()
    bsc = BodySensationCalculator()
    for bag_file in args.in_rosbag:
        bsc.get_driving_mode(bag_file)
    for bag_file in args.in_rosbag:
        bsc.calculate(bag_file)
    counts = {}
    counts["auto"] = sorted(bsc.auto_counts.items())
    counts["manual"] = sorted(bsc.manual_counts.items())
    print(counts)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Collect some channel average size info.

Usage:
    ./channel_size_stats.py <record_path>
        <record_path>    Support * and ?.
Example:
    ./channel_size_stats.py a.record
"""

import argparse
import glob
import os
import sys

import glog

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from cyber.python.cyber_py3.record import RecordWriter
from modules.planning.proto import planning_pb2


class ChannelSizeStats(object):
    """Sample bags to contain PNC related topics only."""
    TOPICS = [
        '/apollo/canbus/chassis',
        '/apollo/control',
        '/apollo/perception/obstacles',
        '/apollo/perception/traffic_light',
        #        '/apollo/planning',
        '/apollo/prediction',
        '/apollo/routing_request',
        '/apollo/routing_response',
        '/apollo/localization/pose',
        '/apollo/sensor/camera/front_6mm/image/compressed',
        '/apollo/sensor/lidar128/compensator/PointCloud2'
    ]

    @classmethod
    def process_record(cls, input_record):
        channel_size_stats = {}
        freader = RecordReader(input_record)
        print('----- Begin to process record -----')
        for channelname, msg, datatype, timestamp in freader.read_messages():
            if channelname in ChannelSizeStats.TOPICS:
                if channelname in channel_size_stats:
                    channel_size_stats[channelname]['total'] += len(msg)
                    channel_size_stats[channelname]['num'] += 1
                else:
                    channel_size_stats[channelname] = {}
                    channel_size_stats[channelname]['total'] = len(msg)
                    channel_size_stats[channelname]['num'] = 1.0
            elif channelname == "/apollo/planning":
                adc_trajectory = planning_pb2.ADCTrajectory()
                adc_trajectory.ParseFromString(msg)
                name = "planning_no_debug"
                adc_trajectory.ClearField("debug")
                planning_str = adc_trajectory.SerializeToString()
                if name in channel_size_stats:
                    channel_size_stats[name]['total'] += len(planning_str)
                    channel_size_stats[name]['num'] += 1
                else:
                    channel_size_stats[name] = {}
                    channel_size_stats[name]['total'] = len(planning_str)
                    channel_size_stats[name]['num'] = 1.0

        for channelname in channel_size_stats.keys():
            print(channelname, " num:", channel_size_stats[channelname]['num'],
                  " avg size:", channel_size_stats[channelname]['total'] / channel_size_stats[channelname]['num'])
        print('----- Finish processing record -----')


if __name__ == '__main__':
    cyber.init()
    parser = argparse.ArgumentParser(
        description="Calculate channel average size. \
            Usage: 'python channel_size_stats.py input_record '")
    parser.add_argument('input', type=str, help="the input record")
    args = parser.parse_args()
    ChannelSizeStats.process_record(args.input)
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can publish drive event message
"""

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time

import argparse
import datetime
import shutil
import time
import os
import sys

from modules.tools.common.message_manager import PbMessageManager
from modules.tools.common import proto_utils

g_message_manager = PbMessageManager()

g_args = None

g_localization = None


def OnReceiveLocalization(localization_msg):
    global g_localization
    g_localization = localization_msg


def main(args):
    drive_event_meta_msg = g_message_manager.get_msg_meta_by_topic(
        args.drive_event_topic)
    if not drive_event_meta_msg:
        print('Unknown drive_event topic name: %s' % args.drive_event_topic)
        sys.exit(1)

    localization_meta_msg = g_message_manager.get_msg_meta_by_topic(
        args.localization_topic)
    if not localization_meta_msg:
        print('Unknown localization topic name: %s' % args.localization_topic)
        sys.exit(1)

    cyber.init()
    node = cyber.Node("derive_event_node")
    node.create_reader(localization_meta_msg.topic,
                       localization_meta_msg.msg_type, OnReceiveLocalization)

    writer = node.create_writer(drive_event_meta_msg.topic,
                                drive_event_meta_msg.msg_type)
    seq_num = 0
    while not cyber.is_shutdown():
        event_type = input(
            "Type in Event Type('d') and press Enter (current time: " +
            str(datetime.datetime.now()) + ")\n>")
        event_type = event_type.strip()
        if len(event_type) != 1 or event_type[0].lower() != 'd':
            continue
        current_time = cyber_time.Time.now().to_sec()
        event_str = None
        while not event_str:
            event_str = input("Type Event:>")
            event_str = event_str.strip()
        event_msg = drive_event_meta_msg.msg_type()
        event_msg.header.timestamp_sec = current_time
        event_msg.header.module_name = 'drive_event'
        seq_num += 1
        event_msg.header.sequence_num = seq_num
        event_msg.header.version = 1
        event_msg.event = event_str
        if g_localization:
            event_msg.location.CopyFrom(g_localization.pose)
        writer.write(event_msg)
        time_str = datetime.datetime.fromtimestamp(current_time).strftime(
            "%Y%m%d%H%M%S")
        filename = os.path.join(args.dir, "%s_drive_event.pb.txt" % time_str)
        proto_utils.write_pb_to_text_file(event_msg, filename)
        print('Logged to rosbag and written to file %s' % filename)
        time.sleep(0.1)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to write events when recording rosbag")
    parser.add_argument(
        "--drive_event_topic",
        action="store",
        default="/apollo/drive_event",
        help="""the drive event topic""")
    parser.add_argument(
        "--localization_topic",
        action="store",
        default="/apollo/localization/pose",
        help="""the drive event topic""")
    parser.add_argument(
        "--dir",
        action="store",
        default="data/bag",
        help="""The log export directory.""")
    g_args = parser.parse_args()
    main(g_args)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can extract raw gpsbin from rosbag directory into /tmp/gpsimu.bin.

dump_gpsbin.py rosbag_input_directory output_file

"""

import argparse
import glob
import os
import shutil

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from modules.drivers.gnss.proto import gnss_pb2


g_args = None
kRawDataTopic = '/apollo/sensor/gnss/raw_data'


def dump_bag(in_dir, out_file):
    """
    out_bag = in_bag
    """
    print('Begin')
    gnss = gnss_pb2.RawData()
    global g_args
    bag_files = glob.glob(in_dir + "/*.record.*")
    with open(out_file, 'w') as fp:
        for bag_file in sorted(bag_files):
            print('Processing bag_file: %s' % bag_file)
            reader = RecordReader(bag_file)
            for msg in reader.read_messages():
                if msg.topic == kRawDataTopic:
                    gnss.ParseFromString(msg.message)
                    f.write(str(gnss))


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to dump gpsimu raw data")
    parser.add_argument(
        "in_dir", action="store", type=str, help="the input bag directory")
    parser.add_argument(
        "out_file", action="store", type=str, help="the output file")

    g_args = parser.parse_args()

    dump_bag(g_args.in_dir, g_args.out_file)
    print("{} is generated".format(g_args.out_file))
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can dump a rosbag into separate text files that contains the pb messages
"""

import argparse
from datetime import datetime
import os
import shutil

from cyber.python.cyber_py3.record import RecordReader


g_args = None

g_delta_t = 0.5  # 1 second approximate time match region.


def write_to_file(file_path, topic_pb):
    """
    write pb message to file
    """
    with open(file_path, 'w') as fp:
        fp.write(str(topic_pb))


def dump_bag(in_bag, out_dir):
    """
    out_bag = in_bag + routing_bag
    """
    reader = RecordReader(in_bag)
    seq = 0
    global g_args
    topic_name_map = {
        "/apollo/localization/pose": ["localization", None],
        "/apollo/canbus/chassis": ["chassis", None],
        "/apollo/routing_response": ["routing", None],
        "/apollo/routing_resquest": ["routing_request", None],
        "/apollo/perception/obstacles": ["perception", None],
        "/apollo/prediction": ["prediction", None],
        "/apollo/planning": ["planning", None],
        "/apollo/control": ["control", None]
    }
    first_time = None
    record_num = 0
    for channel, message, _type, _timestamp in reader.read_messages():
        t = _timestamp
        msg = message
        record_num += 1
        if record_num % 1000 == 0:
            print('Processing record_num: %d' % record_num)
        if first_time is None:
            first_time = t
        if channel not in topic_name_map:
            continue
        dt1 = datetime.utcfromtimestamp(t/1000000000)
        dt2 = datetime.utcfromtimestamp(first_time/1000000000)
        relative_time = (dt1 - dt2).seconds - g_args.start_time
        print ("relative_time", relative_time)
        if ((g_args.time_duration > 0) and
                (relative_time < 0 or relative_time > g_args.time_duration)):
            continue
        if channel == '/apollo/planning':
            seq += 1
            topic_name_map[channel][1] = msg
            print('Generating seq: %d' % seq)
            for t, name_pb in topic_name_map.items():
                if name_pb[1] is None:
                    continue
                file_path = os.path.join(out_dir,
                                         str(seq) + "_" + name_pb[0] + ".pb.txt")
                write_to_file(file_path, name_pb[1])
        topic_name_map[channel][1] = msg


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to dump the protobuf messages according to the planning message"
        "Usage: python dump_planning.py bag_file save_directory")
    parser.add_argument(
        "in_rosbag", action="store", type=str, help="the input ros bag")
    parser.add_argument(
        "out_dir",
        action="store",
        help="the output directory for the dumped file")
    parser.add_argument(
        "--start_time",
        type=float,
        action="store",
        default=0.0,
        help="""The time range to extract in second""")
    parser.add_argument(
        "--time_duration",
        type=float,
        action="store",
        default=-1,
        help="""time duration to extract in second, negative to extract all""")

    g_args = parser.parse_args()

    if os.path.exists(g_args.out_dir):
        shutil.rmtree(g_args.out_dir)
    os.makedirs(g_args.out_dir)
    dump_bag(g_args.in_rosbag, g_args.out_dir)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can dump a cyber record into separate text files that contains
the pb messages
"""

import argparse
import os
import shutil
import sys
import time

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record
from modules.tools.common.message_manager import PbMessageManager


g_message_manager = PbMessageManager()


def write_to_file(file_path, topic_pb):
    """
    Write pb message to file
    """
    with open(file_path, 'w') as fp:
        fp.write(str(topic_pb))


def dump_record(in_record, out_dir, start_time, duration, filter_topic):
    freader = record.RecordReader()
    if not freader.open(in_record):
        print('Failed to open: %s' % in_record)
        return
    time.sleep(1)
    seq = 0
    while not freader.endoffile():
        read_msg_succ = freader.read_message()
        if not read_msg_succ:
            print('Read failed')
            return
        t_sec = freader.currentmessage_time()
        if start_time and t_sec < start_time:
            print('Not yet reached the start time')
            continue
        if start_time and t_sec >= start_time + duration:
            print('Done')
            break
        topic = freader.currentmessage_channelname()
        msg_type = freader.get_messagetype(topic)
        if topic == '/apollo/sensor/mobileye':
            continue
        if not filter_topic or topic == filter_topic:
            message_file = topic.replace("/", "_")
            file_path = os.path.join(out_dir,
                                     str(seq) + message_file + ".pb.txt")
            meta_msg = g_message_manager.get_msg_meta_by_topic(topic)
            if meta_msg is None:
                print('Unknown topic: %s' % topic)
                continue
            msg = meta_msg.msg_type()
            msg.ParseFromString(freader.current_rawmessage())
            write_to_file(file_path, msg)
        seq += 1
    freader.close()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to dump the protobuf messages in a cyber record into text files"
    )
    parser.add_argument(
        "in_record",
        action="store",
        type=str,
        help="the input cyber record")
    parser.add_argument(
        "--start_time",
        action="store",
        type=float,
        help="the input cyber record")
    parser.add_argument(
        "--duration",
        action="store",
        type=float,
        default=1.0,
        help="the input cyber record")
    parser.add_argument(
        "out_dir",
        action="store",
        help="the output directory for the dumped file")
    parser.add_argument(
        "--topic",
        action="store",
        help="""the topic that you want to dump. If this option is not provided,
        the tool will dump all the messages regardless of the message topic."""
    )
    args = parser.parse_args()
    if not os.path.exists(args.out_dir):
        print('%s does not exist' % args.out_dir)
        sys.exit(1)

    dump_record(args.in_record, args.out_dir, args.start_time, args.duration,
                args.topic)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
dump road test log.
Usage:
    ./dump_road_test_log.py bag1 bag2 ...
"""

import sys
import time

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from modules.common.proto import drive_event_pb2


kEventTopic = '/apollo/drive_event'


class EventDumper(object):
    """
    Dump event
    """

    def __init__(self):
        """
        Init
        """

    def calculate(self, bag_file):
        """
        Calculate mileage
        """
        try:
            drive_event = drive_event_pb2.DriveEvent()
            reader = RecordReader(bag_file)
        except Exception:
            print('Cannot open bag file %s' % bag_file)
        else:
            with open('/apollo/test.txt', 'a') as fp:
                for msg in reader.read_messages():
                    if msg.topic == kEventTopic:
                        drive_event.ParseFromString(msg.message)
                        msg_time = time.localtime(drive_event.header.timestamp_sec)
                        fp.write(time.strftime("%Y-%m-%d %H:%M:%S", msg_time))
                        fp.write(str(drive_event.type) + ':')
                        fp.write(drive_event.event.encode('utf-8') + '\n')


def main():
    if len(sys.argv) < 2:
        print('Usage: %s <bag_file1> <bag_file2> ...' % sys.argv[0])
        sys.exit(0)

    ed = EventDumper()
    for bag_file in sys.argv[1:]:
        ed.calculate(bag_file)


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can extract driving trajectory from a record
"""

import argparse
import os
import shutil
import sys
import time

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import record
from modules.tools.common.message_manager import PbMessageManager


g_message_manager = PbMessageManager()


def write_to_file(file_path, topic_pb):
    """
    write pb message to file
    """
    with open(file_path, 'w') as fp:
        fp.write(str(topic_pb))


def extract_record(in_record, output):
    freader = record.RecordReader(in_record)
    print("begin to extract from record {}".format(in_record))
    time.sleep(1)
    seq = 0
    localization_topic = '/apollo/localization/pose'
    meta_msg = g_message_manager.get_msg_meta_by_topic(localization_topic)
    localization_type = meta_msg.msg_type
    for channelname, msg_data, datatype, timestamp in freader.read_messages():
        topic = channelname
        if topic != localization_topic:
            continue
        msg = localization_type()
        msg.ParseFromString(msg_data)
        pose = msg.pose
        output.write("%s %s %s %s %s %s %s %s\n" %
                     (msg.measurement_time, pose.position.x, pose.position.y,
                      pose.position.z, pose.orientation.qx,
                      pose.orientation.qy, pose.orientation.qz,
                      pose.orientation.qw))
    print("Finished extracting from record {}".format(in_record))


def main(args):
    out = open(args.output, 'w') if args.output or sys.stdout
    for record_file in args.in_record:
        extract_record(record_file, out)
    out.close()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to dump the localization messages for map team"
                    "Usage: python extract_trajectory.py bag1 bag2 --output output.txt")
    parser.add_argument(
        "in_record",
        action="store",
        nargs='+',
        type=str,
        help="the input cyber record(s)")
    parser.add_argument(
        "--output",
        action="store",
        type=str,
        help="the output file, default is stdout")
    args = parser.parse_args()
    main(args)
#!/usr/bin/env python3

###############################################################################
# Copyright 2018 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Sample PNC topics. For each /path/to/a.record, will generate
/path/to/pnc_sample/a.record.

Usage:
    ./sample_pnc_topics.py <record_path>
        <record_path>    Support * and ?.
Example:
    ./sample_pnc_topics.py '/mnt/nfs/public_test/2018-04-??/*/mkz8/*/*.record'
"""

import argparse
import glob
import os
import sys

import glog

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from cyber.python.cyber_py3.record import RecordWriter


class SamplePNC(object):
    """Sample bags to contain PNC related topics only."""
    TOPICS = [
        '/apollo/sensor/conti_radar',
        '/apollo/sensor/delphi_esr',
        '/apollo/sensor/gnss/best_pose',
        '/apollo/sensor/gnss/corrected_imu',
        '/apollo/sensor/gnss/gnss_status',
        '/apollo/sensor/gnss/imu',
        '/apollo/sensor/gnss/ins_stat',
        '/apollo/sensor/gnss/odometry',
        '/apollo/sensor/gnss/rtk_eph',
        '/apollo/sensor/gnss/rtk_obs',
        '/apollo/sensor/mobileye',
        '/apollo/canbus/chassis',
        '/apollo/canbus/chassis_detail',
        '/apollo/control',
        '/apollo/control/pad',
        '/apollo/navigation',
        '/apollo/perception/obstacles',
        '/apollo/perception/traffic_light',
        '/apollo/planning',
        '/apollo/prediction',
        '/apollo/routing_request',
        '/apollo/routing_response',
        '/apollo/localization/pose',
        '/apollo/drive_event',
        '/tf',
        '/tf_static',
        '/apollo/monitor',
        '/apollo/monitor/system_status',
        '/apollo/monitor/static_info',
    ]

    @classmethod
    def process_record(cls, input_record, output_record):
        print("filtering: {} -> {}".format(input_record, output_record))
        output_dir = os.path.dirname(output_record)
        if output_dir != "" and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        freader = RecordReader(input_record)
        fwriter = RecordWriter()
        if not fwriter.open(output_record):
            print('writer open failed!')
            return
        print('----- Begin to process record -----')
        for channelname, msg, datatype, timestamp in freader.read_messages():
            if channelname in SamplePNC.TOPICS:
                desc = freader.get_protodesc(channelname)
                fwriter.write_channel(channelname, datatype, desc)
                fwriter.write_message(channelname, msg, timestamp)
        print('----- Finish processing record -----')


if __name__ == '__main__':
    cyber.init()
    parser = argparse.ArgumentParser(
        description="Filter pnc record. \
            Usage: 'python sample_pnc_topic.py input_record  output_record'")
    parser.add_argument('input', type=str, help="the input record")
    parser.add_argument('output', type=str, help="the output record")
    args = parser.parse_args()
    SamplePNC.process_record(args.input, args.output)
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Stat disengagements and auto/manual driving mileage.
Usage:
    ./stat_mileage.py bag1 bag2 ...
"""

import collections
import math
import sys

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from modules.canbus.proto import chassis_pb2
from modules.canbus.proto.chassis_pb2 import Chassis
from modules.localization.proto import localization_pb2


kChassisTopic = '/apollo/canbus/chassis'
kLocalizationTopic = '/apollo/localization/pose'


class MileageCalculator(object):
    """
    Calculate mileage
    """

    def __init__(self):
        """Init."""
        self.auto_mileage = 0.0
        self.manual_mileage = 0.0
        self.disengagements = 0

    def calculate(self, bag_file):
        """
        Calculate mileage
        """
        last_pos = None
        last_mode = 'Unknown'
        mileage = collections.defaultdict(lambda: 0.0)
        chassis = chassis_pb2.Chassis()
        localization = localization_pb2.LocalizationEstimate()
        reader = RecordReader(bag_file)
        for msg in reader.read_messages():
            if msg.topic == kChassisTopic:
                chassis.ParseFromString(msg.message)
                # Mode changed
                if last_mode != chassis.driving_mode:
                    if (last_mode == Chassis.COMPLETE_AUTO_DRIVE and
                            chassis.driving_mode == Chassis.EMERGENCY_MODE):
                        self.disengagements += 1
                    last_mode = chassis.driving_mode
                    # Reset start position.
                    last_pos = None
            elif msg.topic == kLocalizationTopic:
                localization.ParseFromString(msg.message)
                cur_pos = localization.pose.position
                if last_pos:
                    # Accumulate mileage, from xyz-distance to miles.
                    mileage[last_mode] += 0.000621371 * math.sqrt(
                        (cur_pos.x - last_pos.x) ** 2 +
                        (cur_pos.y - last_pos.y) ** 2 +
                        (cur_pos.z - last_pos.z) ** 2)
                last_pos = cur_pos
        self.auto_mileage += mileage[Chassis.COMPLETE_AUTO_DRIVE]
        self.manual_mileage += (mileage[Chassis.COMPLETE_MANUAL] +
                                mileage[Chassis.EMERGENCY_MODE])


def main():
    if len(sys.argv) < 2:
        print('Usage: %s [Bag_file1] [Bag_file2] ...' % sys.argv[0])
        sys.exit(0)

    mc = MileageCalculator()
    for bag_file in sys.argv[1:]:
        mc.calculate(bag_file)
    print('Disengagements: %d' % mc.disengagements)
    print('Auto mileage:   %.3f km / %.3f miles' %
          (mc.auto_mileage * 1.60934, mc.auto_mileage))
    print('Manual mileage: %.3f km / %.3f miles' %
          (mc.manual_mileage * 1.60934, mc.manual_mileage))


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Stat static info.
Usage:
    ./stat_static_info.py <record_file>
    ./stat_static_info.py <task_dir>  # <task_dir> contains a list of records.
"""

import os
import sys

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from modules.canbus.proto import chassis_pb2
from modules.dreamview.proto import hmi_status_pb2


kChassisInfoTopic = '/apollo/canbus/chassis'
kHMIInfoTopic = '/apollo/hmi/status'


class StaticInfoCalculator(object):
    """
    Stat static information
    """

    def __init__(self):
        self.vehicle_name = None
        self.vehicle_vin = None

    def process_file(self, record_file):
        """
        Extract information from record file.
        Return True if we are done collecting all information.
        """
        try:
            reader = RecordReader(record_file)
            print("Begin to process record file {}".format(record_file))
            for msg in reader.read_messages():
                print(msg.topic)
                if msg.topic == kChassisInfoTopic and self.vehicle_vin is None:
                    chassis = chassis_pb2.Chassis()
                    chassis.ParseFromString(msg.message)
                    if chassis.license.vin:
                        self.vehicle_vin = chassis.license.vin
                elif msg.topic == kHMIInfoTopic and self.vehicle_name is None:
                    hmistatus = hmi_status_pb2.HMIStatus()
                    hmistatus.ParseFromString(msg.message)
                    if hmistatus.current_map:
                        self.vehicle_name = hmistatus.current_map
                        print(self.vehicle_name)
                if self.done():
                    return True
        except:
            return False
        print("Finished processing record file {}".format(record_file))
        return self.done()

    def process_dir(self, record_dir):
        """
        Process a directory
        """
        files = []
        dirs = []
        for f in os.listdir(record_dir):
            f_path = os.path.join(record_dir, f)
            if os.path.isfile(f_path):
                files.append(f_path)
            elif os.path.isdir(f_path):
                dirs.append(f_path)
            # Ignore links.

        # Reverse sort the records or dirs, trying to get info from the latest.
        for record in sorted(files, reverse=True):
            if self.process_file(record):
                return True
        for subdir in sorted(dirs, reverse=True):
            if self.process_dir(subdir):
                return True
        return False

    def done(self):
        """
        Check if all info are collected
        """
        # Currently we only care about vehicle name.
        return bool(self.vehicle_name)


def main():
    """
    Process a path
    """
    if len(sys.argv) < 2:
        print("Usage: %s <record_file|task_dir>" % sys.argv[0])
        sys.exit(0)

    path = sys.argv[1]
    calc = StaticInfoCalculator()
    if os.path.isfile(path):
        calc.process_file(path)
    else:
        calc.process_dir(path)

    # Output result, which might be None
    print('vehicle_name: %s' % calc.vehicle_name)
    print('vehicle_vin: %s' % calc.vehicle_vin)


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can dump tf2 stats

usage:
   tf_stats -f record_file
"""

import argparse

from cyber.python.cyber_py3.record import RecordReader
from modules.transform.proto import transform_pb2


g_args = None


def tf_stats(in_bag):
    """
    """
    reader = RecordReader(in_bag)
    global g_args
    stats = {}

    for channel, message, _type, _timestamp in reader.read_messages():
        if channel != '/tf':
            continue
        tf_pb = transform_pb2.TransformStampeds()
        tf_pb.ParseFromString(message)
        for transform in tf_pb.transforms:
            key = transform.header.frame_id + "=>" + transform.child_frame_id
            if key in stats.keys():
                stats[key] += 1
            else:
                stats[key] = 1
    print('tf stats: {}'.format(stats))


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to print tf stats")
    parser.add_argument(
        "-f", action="store", type=str, help="the input data file")
    g_args = parser.parse_args()

    tf_stats(g_args.f)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This program can transcribe a protobuf message to file
"""

import argparse
import shutil
import os
import sys
import time

from cyber.python.cyber_py3 import cyber
from modules.tools.common.message_manager import PbMessageManager
import modules.tools.common.proto_utils as proto_utils


g_message_manager = PbMessageManager()
g_args = None


def transcribe(proto_msg):
    header = proto_msg.header
    seq = "%05d" % header.sequence_num
    name = header.module_name
    file_path = os.path.join(g_args.out_dir, seq + "_" + name + ".pb.txt")
    print('Write proto buffer message to file: %s' % file_path)
    proto_utils.write_pb_to_text_file(proto_msg, file_path)


def main(args):
    if not os.path.exists(args.out_dir):
        os.makedirs(args.out_dir)
    meta_msg = g_message_manager.get_msg_meta_by_topic(args.topic)
    if not meta_msg:
        print('Unknown topic name: %s' % args.topic)
        sys.exit(1)
    cyber.init()
    node = cyber.Node("transcribe_node")
    node.create_reader(args.topic, meta_msg.msg_type, transcribe)
    while not cyber.is_shutdown():
        time.sleep(0.005)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="A tool to transcribe received protobuf messages into text files")
    parser.add_argument(
        "topic", action="store", help="the topic that you want to transcribe.")
    parser.add_argument(
        "--out_dir",
        action="store",
        default='.',
        help="the output directory for the dumped file, the default value is current directory"
    )
    g_args = parser.parse_args()
    main(g_args)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import itertools
import sys

import matplotlib.pyplot as plt

import modules.tools.common.proto_utils as proto_utils
import modules.tools.routing.debug_topo as debug_topo
from modules.routing.proto.routing_pb2 import RoutingResponse
from modules.routing.proto.topo_graph_pb2 import Graph


color_iter = itertools.cycle(
    ['navy', 'c', 'cornflowerblue', 'gold', 'darkorange'])
g_central_curve_dict = {}
g_center_point_dict = {}


def get_center_of_passage_region(region):
    """Get center of passage region center curve"""
    center_points = [g_center_point_dict[seg.id] for seg in region.segment]
    return center_points[len(center_points) // 2]


def plot_region(region, color):
    "Plot passage region"
    for seg in region.segment:
        center_pt = debug_topo.plot_central_curve_with_s_range(
            g_central_curve_dict[seg.id], seg.start_s, seg.end_s, color=color)
        debug_topo.draw_id(center_pt, seg.id, 'r')
        g_center_point_dict[seg.id] = center_pt
        print('Plot lane id: %s, start s: %f, end s: %f' % (seg.id, seg.start_s,
                                                            seg.end_s))


def plot_lane_change(lane_change, passage_regions):
    """Plot lane change information"""
    st_idx = lane_change.start_passage_region_index
    ed_idx = lane_change.end_passage_region_index
    from_pt = get_center_of_passage_region(passage_regions[st_idx])
    to_pt = get_center_of_passage_region(passage_regions[ed_idx])
    plt.gca().annotate(
        "",
        xy=(to_pt[0], to_pt[1]),
        xytext=(from_pt[0], from_pt[1]),
        arrowprops=dict(
            facecolor='blue', edgecolor='none', alpha=0.7, shrink=0.05))


def plot_road(road):
    """Plot road"""
    for region in road.passage_region:
        plot_region(region, 'green')
    for lane_change in road.lane_change_info:
        plot_lane_change(lane_change, road.passage_region)


def plot_junction(junction):
    """Plot junction"""
    plot_region(junction.passage_region, 'red')


def plot_result(routing_result, central_curve_dict):
    """Plot routing result"""
    plt.close()
    plt.figure()
    for way in routing_result.route:
        if way.HasField("road_info"):
            plot_road(way.road_info)
        else:
            plot_junction(way.junction_info)

    plt.gca().set_aspect(1)
    plt.title('Passage region')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.legend()

    plt.draw()


def print_help():
    """Print help information.

    Print help information of usage.

    Args:

    """
    print('usage:')
    print('     python debug_topo.py file_path, then', end=' ')
    print_help_command()


def print_help_command():
    """Print command help information.

    Print help information of command.

    Args:

    """
    print('type in command: [q] [r]')
    print('         q               exit')
    print('         p               plot passage region')


if __name__ == '__main__':
    if len(sys.argv) != 3:
        print_help()
        sys.exit(0)
    print('Please wait for loading data...')

    topo_graph_file = sys.argv[1]
    graph = proto_utils.get_pb_from_bin_file(topo_graph_file, Graph())
    g_central_curve_dict = {nd.lane_id: nd.central_curve for nd in graph.node}

    plt.ion()
    while 1:
        print_help_command()
        print('cmd>', end=' ')
        instruction = raw_input()
        argv = instruction.strip(' ').split(' ')
        if len(argv) == 1:
            if argv[0] == 'q':
                sys.exit(0)
            elif argv[0] == 'p':
                routing_result_file = sys.argv[2]
                result = proto_utils.get_pb_from_bin_file(routing_result_file,
                                                          RoutingResponse())
                plot_result(result, g_central_curve_dict)
            else:
                print('[ERROR] wrong command')
            continue

        else:
            print('[ERROR] wrong arguments')
            continue
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import itertools
import os
import sys

import gflags
import matplotlib.pyplot as plt

import modules.tools.routing.debug_topo as debug_topo
import modules.routing.proto.topo_graph_pb2 as topo_graph_pb2
import modules.tools.routing.util

color_iter = itertools.cycle(
    ['navy', 'c', 'cornflowerblue', 'gold', 'darkorange'])


def read_route(route_file_name):
    """Read route result text file"""
    fin = open(route_file_name)
    route = []
    for line in fin:
        lane = {}
        items = line.strip().split(',')
        lane['id'] = items[0]
        lane['is virtual'] = int(items[1])
        lane['start s'] = float(items[2])
        lane['end s'] = float(items[3])
        route.append(lane)
    return route


def plot_route(lanes, central_curve_dict):
    """Plot route result"""
    plt.close()
    plt.figure()
    for lane in lanes:
        lane_id = lane['id']
        if lane['is virtual']:
            color = 'red'
        else:
            color = 'green'
        mid_pt = debug_topo.plot_central_curve_with_s_range(
            central_curve_dict[lane_id],
            lane['start s'],
            lane['end s'],
            color=color)
        debug_topo.draw_id(mid_pt, lane_id, 'y')
    plt.gca().set_aspect(1)
    plt.title('Routing result')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.legend()

    plt.draw()


def print_help_command():
    """Print command help information.

    Print help information of command.

    Args:

    """
    print('type in command: [q] [r]')
    print('         q               exit')
    print('         r               plot route result')
    print('         r_map           plot route result with map')


if __name__ == '__main__':
    map_dir = util.get_map_dir(sys.argv)
    graph = util.get_topodata(map_dir)
    base_map = util.get_mapdata(map_dir)
    route = util.get_routingdata()

    central_curves = {}
    for nd in graph.node:
        central_curves[nd.lane_id] = nd.central_curve

    plt.ion()
    while 1:
        print_help_command()
        print('cmd>', end=' ')
        instruction = raw_input()
        argv = instruction.strip(' ').split(' ')
        if len(argv) == 1:
            if argv[0] == 'q':
                sys.exit(0)
            elif argv[0] == 'r':
                plot_route(route, central_curves)
            elif argv[0] == 'r_map':
                plot_route(route, central_curves)
                util.draw_map(plt.gca(), base_map)
            else:
                print('[ERROR] wrong command')
            continue

        else:
            print('[ERROR] wrong arguments')
            continue
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import itertools
import math
import sys

import matplotlib.pyplot as plt

import modules.tools.common.proto_utils as proto_utils
import modules.routing.proto.topo_graph_pb2 as topo_graph_pb2
import modules.tools.routing.util as util


color_iter = itertools.cycle(
    ['navy', 'c', 'cornflowerblue', 'gold', 'darkorange'])


def calculate_s(px, py):
    """Calculate s array based on x and y arrays"""
    dis = 0.0
    ps = [dis]
    for i in range(len(px) - 1):
        gap = math.sqrt(pow(px[i + 1] - px[i], 2) + pow(py[i + 1] - py[i], 2))
        dis = dis + gap
        ps.append(dis)
    return ps


def draw_line(line, color):
    """draw line, return x array and y array"""
    px, py = proto_utils.flatten(line.point, ['x', 'y'])
    px, py = util.downsample_array(px), util.downsample_array(py)
    plt.gca().plot(px, py, color=color, lw=3, alpha=0.8)
    return px, py


def draw_arc(arc):
    """draw arc"""
    xy = (arc.center.x, arc.center.y)
    start = 0
    end = 0
    if arc.start_angle < arc.end_angle:
        start = arc.start_angle / math.pi * 180
        end = arc.end_angle / math.pi * 180
    else:
        end = arc.start_angle / math.pi * 180
        start = arc.end_angle / math.pi * 180

    pac = mpatches.Arc(
        xy, arc.radius * 2, arc.radius * 2, angle=0, theta1=start, theta2=end)

    plt.gca().add_patch(pac)


def draw_id(coordinate, id_string, color):
    """draw id"""
    x = coordinate[0]
    y = coordinate[1]
    plt.annotate(
        id_string,
        xy=(x, y),
        xytext=(30, 30),
        textcoords='offset points',
        bbox=dict(boxstyle='round,pad=0.5', fc=color, alpha=0.5),
        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'),
        horizontalalignment='right',
        verticalalignment='bottom')


def plot_central_curve_with_s_range(central_curve, start_s, end_s, color):
    """plot topology graph node with given start and end s, return middle point"""
    node_x = []
    node_y = []
    for curve in central_curve.segment:
        px, py = proto_utils.flatten(curve.line_segment.point, ['x', 'y'])
        node_x.extend(px)
        node_y.extend(py)
    start_plot_index = 0
    end_plot_index = len(node_x)
    node_s = calculate_s(node_x, node_y)
    for i in range(len(node_s)):
        if node_s[i] >= start_s:
            start_plot_index = i
            break
    for i in range(len(node_s) - 1, -1, -1):
        if node_s[i] <= end_s:
            end_plot_index = i + 1
            break
    plt.gca().plot(
        node_x[start_plot_index:end_plot_index],
        node_y[start_plot_index:end_plot_index],
        color=color,
        lw=3,
        alpha=0.8)
    mid_index = (start_plot_index + end_plot_index) // 2
    return [node_x[mid_index], node_y[mid_index]]


def plot_central_curve(central_curve, color):
    """plot topology graph node, return node middle point"""
    node_x = []
    node_y = []
    for curve in central_curve.segment:
        if curve.HasField('line_segment'):
            px, py = draw_line(curve.line_segment, color)
            node_x = node_x + px
            node_y = node_y + py
        # if curve.HasField('arc'):
        #    draw_arc(curve.arc)
    return [node_x[len(node_x) // 2], node_y[len(node_y) // 2]]


def plot_node(node, plot_id, color):
    """plot topology graph node"""
    print('length of %s: %f' % (node.lane_id, node.length))
    mid_pt = plot_central_curve(node.central_curve, color)
    if 'l' in plot_id:
        draw_id(mid_pt, node.lane_id, 'green')
    if 'r' in plot_id:
        draw_id(mid_pt, node.road_id, 'red')
    return mid_pt


def plot_edge(edge, midddle_point_map):
    """plot topology graph edge"""
    if edge.direction_type == topo_graph_pb2.Edge.FORWARD:
        return
    # if lane change is allowed, draw an arrow from lane with from_id to lane with to_id
    from_id = edge.from_lane_id
    from_pt = midddle_point_map[from_id]
    to_id = edge.to_lane_id
    to_pt = midddle_point_map[to_id]
    plt.gca().annotate(
        "",
        xy=(to_pt[0], to_pt[1]),
        xytext=(from_pt[0], from_pt[1]),
        arrowprops=dict(arrowstyle="->", connectionstyle="arc3"))


def plot_all(graph, plot_id=''):
    """plot topology graph"""
    plt.close()
    fig = plt.figure()
    fig.canvas.mpl_connect('button_press_event', util.onclick)
    lane_middle_point_map = {}
    for i, (nd, color) in enumerate(zip(graph.node, color_iter)):
        nd_mid_pt = plot_node(nd, plot_id, color)
        lane_middle_point_map[nd.lane_id] = nd_mid_pt
    for i, eg in enumerate(graph.edge):
        plot_edge(eg, lane_middle_point_map)
    plt.gca().set_aspect(1)
    plt.title('Routing topology graph')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.legend()

    plt.draw()


def plot_id(graph, lane_id):
    """plot topology graph"""
    plt.close()
    fig = plt.figure()
    fig.canvas.mpl_connect('button_press_event', util.onclick)
    lane_middle_point_map = {}
    plot_ids = [lane_id]
    for eg in graph.edge:
        if eg.from_lane_id == lane_id:
            plot_ids.append(eg.to_lane_id)
    for i, (nd, color) in enumerate(zip(graph.node, color_iter)):
        if nd.lane_id in plot_ids:
            nd_mid_pt = plot_node(nd, 'l', color)
            lane_middle_point_map[nd.lane_id] = nd_mid_pt
    for i, eg in enumerate(graph.edge):
        if eg.from_lane_id == lane_id:
            plot_edge(eg, lane_middle_point_map)
    plt.gca().set_aspect(1)
    plt.title('Routing topology graph')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.legend()

    plt.draw()


def print_help_command():
    """Print command help information.

    Print help information of command.

    Args:

    """
    print('type in command: [q] [a] [i lane_id]')
    print('         q               exit')
    print('         a               plot all topology')
    print('         a_id            plot all topology with lane id')
    print('         a_rid           plot all topology with road id')
    print('         i lane_id       plot lanes could be reached from lane with lane_id')
    print('         i_map lane_id   plot lanes could be reached from lane with lane_id, with map')


if __name__ == '__main__':
    map_dir = util.get_map_dir(sys.argv)
    graph = util.get_topodata(map_dir)
    base_map = util.get_mapdata(map_dir)
    print("district: %s" % graph.hdmap_district)
    print("version: %s" % graph.hdmap_version)

    plt.ion()
    while 1:
        print_help_command()
        print('cmd>', end=' ')
        instruction = raw_input()
        argv = instruction.strip(' ').split(' ')
        if len(argv) == 1:
            if argv[0] == 'q':
                sys.exit(0)
            elif argv[0] == 'a':
                plot_all(graph)
            elif argv[0] == 'a_id':
                plot_all(graph, 'l')
            elif argv[0] == 'a_rid':
                plot_all(graph, 'r')
            else:
                print('[ERROR] wrong command')
            continue

        if len(argv) == 2:
            if argv[0] == 'i':
                plot_id(graph, argv[1])
            elif argv[0] == 'i_map':
                plot_id(graph, argv[1])
                util.draw_map(plt.gca(), base_map)
            else:
                print('[ERROR] wrong command')
            continue

        else:
            print('[ERROR] wrong arguments')
            continue
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""Show road."""

import sys

import matplotlib.pyplot as plt

import modules.tools.common.proto_utils as proto_utils
import modules.tools.routing.util as util


g_color = [
    'navy', 'c', 'cornflowerblue', 'gold', 'darkorange', 'darkviolet',
    'aquamarine', 'firebrick', 'limegreen'
]


def draw_line(line_segment, color):
    """
    :param line_segment:
    :return: none
    """
    px, py = proto_utils.flatten(line_segment.point, ['x', 'y'])
    px, py = downsample_array(px), downsample_array(py)
    plt.gca().plot(px, py, lw=10, alpha=0.8, color=color)
    return px[len(px) // 2], py[len(py) // 2]


def draw_arc(arc):
    """
    :param arc: proto obj
    :return: none
    """
    xy = (arc.center.x, arc.center.y)
    start = 0
    end = 0
    if arc.start_angle < arc.end_angle:
        start = arc.start_angle / math.pi * 180
        end = arc.end_angle / math.pi * 180
    else:
        end = arc.start_angle / math.pi * 180
        start = arc.end_angle / math.pi * 180

    pac = mpatches.Arc(
        xy, arc.radius * 2, arc.radius * 2, angle=0, theta1=start, theta2=end)

    plt.gca().add_patch(pac)


def downsample_array(array):
    """down sample given array"""
    skip = 5
    result = array[::skip]
    result.append(array[-1])
    return result


def draw_boundary(line_segment):
    """
    :param line_segment:
    :return:
    """
    px, py = proto_utils.flatten(line_segment.point, ['x', 'y'])
    px, py = downsample_array(px), downsample_array(py)
    plt.gca().plot(px, py, 'k')


def draw_id(x, y, id_string):
    """Draw id_string on (x, y)"""
    plt.annotate(
        id_string,
        xy=(x, y),
        xytext=(40, -40),
        textcoords='offset points',
        ha='right',
        va='bottom',
        bbox=dict(boxstyle='round,pad=0.5', fc='green', alpha=0.5),
        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))


def get_road_index_of_lane(lane_id, road_lane_set):
    """Get road index of lane"""
    for i, lane_set in enumerate(road_lane_set):
        if lane_id in lane_set:
            return i
    return -1


def draw_map(drivemap):
    """ draw map from mapfile"""
    print('Map info:')
    print('\tVersion:\t', end=' ')
    print(drivemap.header.version)
    print('\tDate:\t', end=' ')
    print(drivemap.header.date)
    print('\tDistrict:\t', end=' ')
    print(drivemap.header.district)

    road_lane_set = []
    for road in drivemap.road:
        lanes = []
        for sec in road.section:
            lanes.extend(proto_utils.flatten(sec.lane_id, 'id'))
        road_lane_set.append(lanes)

    for lane in drivemap.lane:
        for curve in lane.central_curve.segment:
            if curve.HasField('line_segment'):
                road_idx = get_road_index_of_lane(lane.id.id, road_lane_set)
                if road_idx == -1:
                    print('Failed to get road index of lane')
                    sys.exit(-1)
                center_x, center_y = draw_line(curve.line_segment,
                                               g_color[road_idx % len(g_color)])
                draw_id(center_x, center_y, str(road_idx))
                # break
            # if curve.HasField('arc'):
            #    draw_arc(curve.arc)

        for curve in lane.left_boundary.curve.segment:
            if curve.HasField('line_segment'):
                draw_boundary(curve.line_segment)

        for curve in lane.right_boundary.curve.segment:
            if curve.HasField('line_segment'):
                draw_boundary(curve.line_segment)
                # break

    return drivemap


if __name__ == "__main__":
    print("Reading map data")
    map_dir = util.get_map_dir(sys.argv)
    base_map = util.get_mapdata(map_dir)
    print("Done reading map data")
    plt.subplots()
    draw_map(base_map)
    plt.axis('equal')
    plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import os
import sys

import gflags
import matplotlib.pyplot as plt

import modules.tools.common.proto_utils as proto_utils
import modules.map.proto.map_pb2 as map_pb2
import modules.routing.proto.topo_graph_pb2 as topo_graph_pb2
import modules.routing.proto.routing_pb2 as routing_pb2

FLAGS = gflags.FLAGS
gflags.DEFINE_string('map_dir', 'modules/map/data/demo', 'map directory')


def get_map_dir(argv):
    sys.argv.insert(1, '--undefok')
    flagfile = os.path.normpath(
        os.path.join(
            os.path.dirname(__file__), '../../common/data',
            'global_flagfile.txt'))
    sys.argv.insert(2, '--flagfile=' + flagfile)
    argv = FLAGS(sys.argv)
    mapdir = os.path.normpath(
        os.path.join(os.path.dirname(__file__), '../../../', FLAGS.map_dir))
    print("Map dir: %s " % FLAGS.map_dir)
    return mapdir


def get_mapdata(map_dir):
    print('Please wait for loading map data...')
    map_data_path = os.path.join(map_dir, 'base_map.bin')
    print('File: %s' % map_data_path)
    return proto_utils.get_pb_from_bin_file(map_data_path, map_pb2.Map())


def get_topodata(map_dir):
    print('Please wait for loading routing topo data...')
    topo_data_path = os.path.join(map_dir, 'routing_map.bin')
    print("File: %s" % topo_data_path)
    return proto_utils.get_pb_from_bin_file(topo_data_path, topo_graph_pb2.Graph())


def get_routingdata():
    print('Please wait for loading route response data...')
    log_dir = os.path.normpath(
        os.path.join(os.path.dirname(__file__), '../../../data/log'))
    route_data_path = os.path.join(log_dir, 'passage_region_debug.bin')
    print("File: %s" % route_data_path)
    return proto_utils.get_pb_from_text_file(route_data_path, routing_pb2.RoutingResponse())


def onclick(event):
    """Event function when mouse left button is clicked"""

    print('\nClick captured! x=%f\ty=%f' % (event.xdata, event.ydata))
    print('cmd>')


def downsample_array(array, step=5):
    """Down sample given array"""

    result = array[::step]
    result.append(array[-1])
    return result


def draw_boundary(ax, line_segment):
    """
    :param line_segment:
    :return:
    """

    px = [float(p.x) for p in line_segment.point]
    py = [float(p.y) for p in line_segment.point]

    px = downsample_array(px)
    py = downsample_array(py)
    ax.plot(px, py, 'k', lw=0.4)


def draw_map(ax, mapfile):
    """Draw map from mapfile"""

    for lane in mapfile.lane:
        for curve in lane.left_boundary.curve.segment:
            if curve.HasField('line_segment'):
                draw_boundary(ax, curve.line_segment)

        for curve in lane.right_boundary.curve.segment:
            if curve.HasField('line_segment'):
                draw_boundary(ax, curve.line_segment)
    plt.draw()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import os
import shutil

import yaml

from google.protobuf import text_format

from modules.dreamview.proto import preprocess_table_pb2
from modules.tools.common.proto_utils import get_pb_from_text_file

ROOT_DIR = '/apollo/modules/tools/sensor_calibration'

class ConfigYaml(object):
    """generate yaml configuration for next-step calibration service.
    automatically generate calibration configuration yaml file. help user to
    input the initial extrinsics values or path(lidar, camera), intrinsics path(camera),
    sensor name if needs changes.
    """

    def __init__(self, supported_calibrations=['lidar_to_gnss', 'camera_to_lidar']):
        self._task_name = 'unknown'
        self._supported_tasks = supported_calibrations
        self._source_sensor = ''
        self._table_info = preprocess_table_pb2.PreprocessTable()
        print('calibration service now support: {}'.format(self._supported_tasks))

    def load_sample_yaml_file(self, task_name, sample_file=None):
        if sample_file is None:
            sample_file = os.path.join(os.path.dirname(__file__),
                                       'config', task_name + '_sample_config.yaml')
        try:
            with open(sample_file, 'r') as f:
                data = yaml.safe_load(f)
        except IOError:
            raise ValueError(
                'cannot open the sample configure yaml file at {}'.format(sample_file))
        return data

    def _generate_lidar_to_gnss_calibration_yaml(self, in_data, lidar_folder_name, gnss_folder_name):
        in_data['sensor_files_directory'] = os.path.join(
            '.', lidar_folder_name, "")
        in_data['odometry_file'] = os.path.join(
            '.', gnss_folder_name, 'odometry')
        for lidar_config in self._table_info.lidar_config:
            if lidar_config.sensor_name == self._source_sensor:
                in_data['transform']['translation']['x'] = round(
                    lidar_config.translation.x, 4)
                in_data['transform']["translation"]["y"] = round(
                    lidar_config.translation.y, 4)
                in_data['transform']["translation"]["z"] = round(
                    lidar_config.translation.z, 4)
        return in_data

    def _generate_camera_init_param_yaml(self, root_path, in_data):
        init_param_folder = os.path.join(
            os.path.dirname(__file__), 'config/init_params')
        out_param_folder = os.path.join(root_path, 'init_params')
        if os.path.exists(out_param_folder):
            print('folder: %s exists' % out_param_folder)
        else:
            print('create folder: %s' % out_param_folder)
            os.makedirs(out_param_folder)
        camera_config = self._table_info.camera_config
        # copy sample intrinsic yaml file to correct location
        # wait for user input about intrinsics
        sample_intrinsic_yaml = os.path.join(
            init_param_folder, 'sample_intrinsics.yaml')
        intrinsic_data = self.load_sample_yaml_file(self._task_name,
                                                    sample_file=sample_intrinsic_yaml)
        for iter, data in enumerate(camera_config.D):
            intrinsic_data['D'][iter] = data
        for iter, data in enumerate(camera_config.K):
            intrinsic_data['K'][iter] = data
        # dump the intrinsic yaml data
        out_intrinsic_yaml = os.path.join(out_param_folder,
                                          in_data['source_sensor'] + '_intrinsics.yaml')
        try:
            with open(out_intrinsic_yaml, 'w') as f:
                yaml.safe_dump(intrinsic_data, f)
        except IOError:
            raise ValueError('cannot generate the task config yaml '
                             'file at {}'.format(out_intrinsic_yaml))


        # load extrinsics sample yaml, rename source sensor and destination sensor
        sample_extrinsic_yaml = os.path.join(
            init_param_folder, 'sample_extrinsics.yaml')
        extrinsic_data = self.load_sample_yaml_file(self._task_name,
                                                    sample_file=sample_extrinsic_yaml)
        # set up the source_sensor(camera name) to dest sensor(lidar name)
        extrinsic_data['header']['frame_id'] = in_data['destination_sensor']
        extrinsic_data['child_frame_id'] = in_data['source_sensor']
        extrinsic_data['transform']['translation']['x'] = round(
            camera_config.translation.x, 4)
        extrinsic_data['transform']["translation"]["y"] = round(
            camera_config.translation.y, 4)
        extrinsic_data['transform']["translation"]["z"] = round(
            camera_config.translation.z, 4)
        # dump the extrinsic yaml data
        out_extrinsic_yaml = os.path.join(out_param_folder, in_data['source_sensor']
                                          + '_' + in_data['destination_sensor'] + '_extrinsics.yaml')
        try:
            with open(out_extrinsic_yaml, 'w') as f:
                yaml.safe_dump(extrinsic_data, f)
        except IOError:
            raise ValueError('cannot generate the task config yaml '
                             'file at {}'.format(out_extrinsic_yaml))

    def _generate_camera_to_lidar_calibration_yaml(self, in_data):
        in_data['intrinsic'] = os.path.join('.', 'init_params',
                                            in_data['source_sensor'] + '_intrinsics.yaml')
        in_data['extrinsic'] = os.path.join('.', 'init_params', in_data['source_sensor']
                                            + '_' + in_data['destination_sensor'] + '_extrinsics.yaml')

        return in_data

    def get_task_name(self):
        if self._task_name == 'unknown':
            raise ValueError('have not set the task name, the valid task names'
                             'are: {}'.format(self._supported_tasks))
        return self._task_name

    def generate_task_config_yaml(self, task_name, source_sensor, dest_sensor,
                                  source_folder, dest_folder, out_config_file,
                                  in_config_file=None):
        self._task_name = task_name
        self._source_sensor = source_sensor
        out_data = self.load_sample_yaml_file(
            task_name=task_name, sample_file=in_config_file)
        out_data['source_sensor'] = source_sensor
        out_data['destination_sensor'] = dest_sensor
        if task_name not in self._supported_tasks:
            raise ValueError('does not support the calibration task: {}'.format(
                task_name))
        user_config = os.path.join(ROOT_DIR, 'config',
                                   task_name + '_user.config')
        if os.path.exists(user_config):
            try:
                get_pb_from_text_file(user_config, self._table_info)
            except text_format.ParseError:
                print(f'Error: Cannot parse {user_config} as text proto')

        if self._task_name == 'lidar_to_gnss':
            out_data = self._generate_lidar_to_gnss_calibration_yaml(
                out_data, source_folder, dest_folder)

        elif self._task_name == 'camera_to_lidar':
            if source_folder != dest_folder:
                raise ValueError(
                    'camera frame and lidar frame should be in same folder')
            out_root_path = os.path.dirname(out_config_file)
            self._generate_camera_init_param_yaml(out_root_path, out_data)
            out_data = self._generate_camera_to_lidar_calibration_yaml(
                out_data)

        print(out_data)
        try:
            with open(out_config_file, 'w') as f:
                yaml.safe_dump(out_data, f)
        except IOError:
            raise ValueError(
                'cannot generate the task config yaml file at {}'.format(out_config_file))
        return True
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
This is a bunch of classes to manage cyber record channel FileIO.
"""

import os
import sys
import struct

import numpy as np


class FileObject(object):
    """Wrapper for file object"""

    # Initializing file object
    def __init__(self, file_path, operation='write', file_type='binary'):
        if operation != 'write' and operation != 'read':
            raise ValueError("Unsupported file operation: %s" % operation)

        if file_type != 'binary' and file_type != 'txt':
            raise ValueError("Unsupported file type: %s" % file_type)

        operator = 'w' if operation == 'write' else 'r'
        operator += 'b' if file_type == 'binary' else ''

        try:
            self._file_object = open(file_path, operator)
        except IOError:
            raise ValueError("Cannot open file: {}".format(file_path))

    # Safely close file
    def __del__(self):
        self._file_object.close()

    def file_object(self):
        return self._file_object

    def save_to_file(self, data):
        raise NotImplementedError


class TimestampFileObject(FileObject):
    """class to handle sensor timestamp for each Apollo sensor channel"""

    def __init__(self, file_path, operation='write', file_type='txt'):
        super(TimestampFileObject, self).__init__(file_path,
                                                  operation, file_type)

    def save_to_file(self, data):
        if not isinstance(data, list) and not isinstance(data, np.ndarray):
            raise ValueError("timestamps must be in a list")

        for i, ts in enumerate(data):
            self._file_object.write("%05d %.6f\n" % (i + 1, ts))


class OdometryFileObject(FileObject):
    """class to handle gnss/odometry topic"""

    def load_file(self):
        struct_len = struct.calcsize('i')
        data_size = struct.Struct('i').unpack(self._file_object.read(struct.calcsize('i')))[0]
        s0 = struct.Struct('d')
        s1 = struct.Struct('I')
        s2 = struct.Struct('7d')
        data = np.zeros((data_size, 9), dtype='float64')
        # , int32, float64, float64, float64, float64, float64, float64, float64')
        for d in data:
            #d[0] = s0.unpack_from(self._file_object.read(s0.size))[0]
            d[0] = s0.unpack(self._file_object.read(s0.size))[0]
            d[1] = s1.unpack_from(self._file_object.read(s1.size))[0]
            d[2:] = np.array(s2.unpack_from(self._file_object.read(s2.size)))
        return data.tolist()

    def save_to_file(self, data):
        """
        odometry data: total 9 elements
        [
        double timestamp
        int32 postion_type
        double qw, qx, qy, qz
        double x, y, z
        ]
        """
        if not isinstance(data, list):
            raise ValueError("Odometry data must be in a list")
        data_size = len(data)
        self._file_object.write(struct.pack('I', data_size))
        # have to pack separate, to avoid struct padding, now 8+4+7*8 = 68 bytes
        # TODO (yuanfan / gchen-Apollo): follow protobuf across tools.

        s0 = struct.Struct('d')
        s1 = struct.Struct('I')
        s2 = struct.Struct('7d')
        for d in data:
            # print(d[0])
            self._file_object.write(s0.pack(d[0]))
            self._file_object.write(s1.pack(d[1]))
            pack_d = s2.pack(d[2], d[3], d[4], d[5], d[6], d[7], d[8])
            self._file_object.write(pack_d)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This is a tool to extract useful information from given record files. It does
self-check the validity of the uploaded data and able to inform developer's when
the data is not qualified, and reduce the size of uploaded data significantly.
"""
from datetime import datetime
import os
import shutil
import six
import sys
import time
import yaml

from absl import app
from absl import flags
from google.protobuf import text_format
import numpy as np

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3.record import RecordReader
from cyber.proto import record_pb2
from modules.dreamview.proto import preprocess_table_pb2
from modules.tools.common.proto_utils import get_pb_from_text_file
from modules.tools.sensor_calibration.configuration_yaml_generator import ConfigYaml
from modules.tools.sensor_calibration.extract_static_data import get_subfolder_list, select_static_image_pcd
from modules.tools.sensor_calibration.proto import extractor_config_pb2
from modules.tools.sensor_calibration.sanity_check import sanity_check
from modules.tools.sensor_calibration.sensor_msg_extractor import GpsParser, ImageParser, PointCloudParser, PoseParser, ContiRadarParser

SMALL_TOPICS = [
    '/apollo/canbus/chassis',
    '/apollo/canbus/chassis_detail',
    '/apollo/control',
    '/apollo/control/pad',
    '/apollo/drive_event',
    '/apollo/guardian',
    '/apollo/hmi/status',
    '/apollo/localization/pose',
    '/apollo/localization/msf_gnss',
    '/apollo/localization/msf_lidar',
    '/apollo/localization/msf_status',
    '/apollo/monitor',
    '/apollo/monitor/system_status',
    '/apollo/navigation',
    '/apollo/perception/obstacles',
    '/apollo/perception/traffic_light',
    '/apollo/planning',
    '/apollo/prediction',
    '/apollo/relative_map',
    '/apollo/routing_request',
    '/apollo/routing_response',
    '/apollo/routing_response_history',
    '/apollo/sensor/conti_radar',
    '/apollo/sensor/delphi_esr',
    '/apollo/sensor/gnss/best_pose',
    '/apollo/sensor/gnss/corrected_imu',
    '/apollo/sensor/gnss/gnss_status',
    '/apollo/sensor/gnss/imu',
    '/apollo/sensor/gnss/ins_stat',
    '/apollo/sensor/gnss/odometry',
    '/apollo/sensor/gnss/raw_data',
    '/apollo/sensor/gnss/rtk_eph',
    '/apollo/sensor/gnss/rtk_obs',
    '/apollo/sensor/gnss/heading',
    '/apollo/sensor/mobileye',
    '/tf',
    '/tf_static',
]

flags.DEFINE_string('config', '',
                    'protobuf text format configuration file abosolute path')
flags.DEFINE_string('root_dir', '/apollo/modules/tools/sensor_calibration',
                    'program root dir')

FLAGS = flags.FLAGS


class Extractor(object):
    def __init__(self):
        self.node = cyber.Node("sendor_calibration_preprocessor")
        self.writer = self.node.create_writer("/apollo/dreamview/progress",
                                              preprocess_table_pb2.Progress, 6)
        self.config = extractor_config_pb2.DataExtractionConfig()
        self.progress = preprocess_table_pb2.Progress()
        self.progress.percentage = 0.0
        self.progress.log_string = "Preprocessing in progress..."
        self.progress.status = preprocess_table_pb2.Status.UNKNOWN
        try:
            get_pb_from_text_file(FLAGS.config, self.config)
        except text_format.ParseError:
            print(f'Error: Cannot parse {FLAGS.config} as text proto')
        self.records = []
        for r in self.config.records.record_path:
            self.records.append(str(r))
        self.start_timestamp = -1
        self.end_timestamp = -1
        if self.config.io_config.start_timestamp == "FLOAT_MIN":
            self.start_timestamp = np.finfo(np.float32).min
        else:
            self.start_timestamp = np.float32(
                self.config.io_config.start_timestamp)

        if self.config.io_config.end_timestamp == "FLOAT_MAX":
            self.end_timestamp = np.finfo(np.float32).max
        else:
            self.end_timestamp = np.float32(
                self.config.io_config.end_timestamp)

    @staticmethod
    def process_dir(path, operation):
        """Create or remove directory."""
        try:
            if operation == 'create':
                if os.path.exists(path):
                    print(f'folder: {path} exists')
                else:
                    print(f'create folder: {path}')
                    os.makedirs(path)
            elif operation == 'remove':
                os.remove(path)
            else:
                print(
                    f'Error! Unsupported operation {operation} for directory.')
                return False
        except OSError as e:
            print(f'Failed to {operation} directory: {path}. '
                  f'Error: {six.text_type(e)}')
            return False

        return True

    @staticmethod
    def get_sensor_channel_list(record_file):
        """Get the channel list of sensors for calibration."""
        record_reader = RecordReader(record_file)
        return set(channel_name
                   for channel_name in record_reader.get_channellist()
                   if 'sensor' in channel_name
                   or '/localization/pose' in channel_name)

    @staticmethod
    def validate_channel_list(channels, dictionary):
        ret = True
        for channel in channels:
            if channel not in dictionary:
                print(f'ERROR: channel {channel} does not exist in '
                      'record sensor channels')
                ret = False
        return ret

    @staticmethod
    def in_range(v, s, e):
        return True if v >= s and v <= e else False

    @staticmethod
    def build_parser(channel, output_path):
        parser = None
        if channel.endswith("/image"):
            parser = ImageParser(output_path=output_path, instance_saving=True)
        elif channel.endswith("/PointCloud2"):
            parser = PointCloudParser(output_path=output_path,
                                      instance_saving=True)
        elif channel.endswith("/gnss/odometry"):
            parser = GpsParser(output_path=output_path, instance_saving=False)
        elif channel.endswith("/localization/pose"):
            parser = PoseParser(output_path=output_path, instance_saving=False)
        elif channel.startswith("/apollo/sensor/radar"):
            parser = ContiRadarParser(output_path=output_path,
                                      instance_saving=True)
        else:
            raise ValueError(f"Not Support this channel type: {channel}")
        return parser

    def print_and_publish(self,
                          str,
                          status=preprocess_table_pb2.Status.UNKNOWN):
        """status: 0 for success, 1 for fail, 2 for unknown"""
        print(str)
        self.progress.log_string = str
        self.progress.status = status
        self.writer.write(self.progress)
        time.sleep(0.5)

    def extract_data(self, record_files, output_path, channels,
                     extraction_rates):
        """
        Extract the desired channel messages if channel_list is specified.
        Otherwise extract all sensor calibration messages according to
        extraction rate, 10% by default.
        """
        # all records have identical sensor channels.
        sensor_channels = self.get_sensor_channel_list(record_files[0])

        if (len(channels) > 0
                and not self.validate_channel_list(channels, sensor_channels)):
            print('The input channel list is invalid.')
            return False

        # Extract all the sensor channels if channel_list is empty(no input arguments).
        print(sensor_channels)
        if len(channels) == 0:
            channels = sensor_channels

        # Declare logging variables
        process_channel_success_num = len(channels)
        process_channel_failure_num = 0
        process_msg_failure_num = 0

        channel_success = {}
        channel_occur_time = {}
        channel_output_path = {}
        # channel_messages = {}
        channel_parsers = {}
        channel_message_number = {}
        channel_processed_msg_num = {}

        for channel in channels:
            channel_success[channel] = True
            channel_occur_time[channel] = -1
            topic_name = channel.replace('/', '_')
            channel_output_path[channel] = os.path.join(
                output_path, topic_name)
            self.process_dir(channel_output_path[channel], operation='create')
            channel_parsers[channel] =\
                self.build_parser(channel, channel_output_path[channel])
            channel_message_number[channel] = 0
            for record_file in record_files:
                record_reader = RecordReader(record_file)
                channel_message_number[
                    channel] += record_reader.get_messagenumber(channel)
            channel_message_number[channel] = channel_message_number[
                channel] // extraction_rates[channel]

        channel_message_number_total = 0
        for num in channel_message_number.values():
            channel_message_number_total += num
        channel_processed_msg_num = 0

        # if channel in SMALL_TOPICS:
        # channel_messages[channel] = list()
        for record_file in record_files:
            record_reader = RecordReader(record_file)
            for msg in record_reader.read_messages():
                if msg.topic in channels:
                    # Only care about messages in certain time intervals
                    msg_timestamp_sec = msg.timestamp / 1e9
                    if not self.in_range(msg_timestamp_sec,
                                         self.start_timestamp,
                                         self.end_timestamp):
                        continue

                    channel_occur_time[msg.topic] += 1
                    # Extract the topic according to extraction_rate
                    if channel_occur_time[msg.topic] % extraction_rates[
                            msg.topic] != 0:
                        continue

                    ret = channel_parsers[msg.topic].parse_sensor_message(msg)
                    channel_processed_msg_num += 1
                    self.progress.percentage = channel_processed_msg_num / \
                        channel_message_number_total * 90.0
                    # Calculate parsing statistics
                    if not ret:
                        process_msg_failure_num += 1
                        if channel_success[msg.topic]:
                            channel_success[msg.topic] = False
                            process_channel_failure_num += 1
                            process_channel_success_num -= 1
                            log_string = (
                                'Failed to extract data from channel: '
                                f'{msg.topic} in record {record_file}')
                            print(log_string)
                            self.progress.log_string = log_string

                    self.writer.write(self.progress)

        # traverse the dict, if any channel topic stored as a list
        # then save the list as a summary file, mostly binary file
        for channel, parser in channel_parsers.items():
            self.save_combined_messages_info(parser, channel)

        # Logging statics about channel extraction
        self.print_and_publish(
            (f"Extracted sensor channel number {len(channels)} "
             f"from record files: {' '.join(record_files)}"))
        self.print_and_publish(
            (f'Successfully processed {process_channel_success_num} channels, '
             f'and {process_channel_failure_num} was failed.'))
        if process_msg_failure_num > 0:
            self.print_and_publish(
                f'Channel extraction failure number is {process_msg_failure_num}.',
                preprocess_table_pb2.Status.FAIL)

        return True

    @staticmethod
    def save_combined_messages_info(parser, channel):
        if not parser.save_messages_to_file():
            raise ValueError(
                f"cannot save combined messages into single file for : {channel}"
            )
        if not parser.save_timestamps_to_file():
            raise ValueError(f"cannot save tiemstamp info for {channel}")

    @staticmethod
    def generate_compressed_file(input_path,
                                 input_name,
                                 output_path,
                                 compressed_file='sensor_data'):
        """
        Compress data extraction directory as a single tar.gz archive
        """
        cwd_path = os.getcwd()
        os.chdir(input_path)
        shutil.make_archive(base_name=os.path.join(output_path,
                                                   compressed_file),
                            format='gztar',
                            root_dir=input_path,
                            base_dir=input_name)
        os.chdir(cwd_path)

    @staticmethod
    def generate_extraction_rate_dict(channels,
                                      large_topic_extraction_rate,
                                      small_topic_extraction_rate=1):
        """
        Default extraction rate for small topics is 1, which means no sampling
        """

        # Validate extration_rate, and set it as an integer.
        if large_topic_extraction_rate < 1.0 or small_topic_extraction_rate < 1.0:
            raise ValueError(
                "Extraction rate must be a number no less than 1.")

        large_topic_extraction_rate = np.floor(large_topic_extraction_rate)
        small_topic_extraction_rate = np.floor(small_topic_extraction_rate)

        rates = {}
        for channel in channels:
            if channel in SMALL_TOPICS:
                rates[channel] = small_topic_extraction_rate
            else:
                rates[channel] = large_topic_extraction_rate

        return rates

    @staticmethod
    def validate_record(record_file):
        """Validate the record file."""
        # Check the validity of a cyber record file according to header info.
        record_reader = RecordReader(record_file)
        header_msg = record_reader.get_headerstring()
        header = record_pb2.Header()
        header.ParseFromString(header_msg)
        print(f"header is {header}")

        if not header.is_complete:
            print(f'Record file: {record_file} is not completed.')
            return False
        if header.size == 0:
            print(f'Record file: {record_file}. size is 0.')
            return False
        if header.major_version != 1 and header.minor_version != 0:
            print(
                f'Record file: {record_file}. version [{header.major_version}: '
                f'{header.minor_version}] is wrong.')
            return False
        if header.begin_time >= header.end_time:
            print(
                f'Record file: {record_file}. begin time [{header.begin_time}] '
                f'is equal or larger than end time [{header.end_time}].')
            return False

        if header.message_number < 1 or header.channel_number < 1:
            print(
                f'Record file: {record_file}. [message:channel] number '
                f'[{header.message_number}:{header.channel_number}] is invalid.'
            )
            return False

        # There should be at least one sensor channel
        sensor_channels = Extractor.get_sensor_channel_list(record_file)
        if len(sensor_channels) < 1:
            print(f'Record file: {record_file}. cannot find sensor channels.')
            return False

        return True

    def validate_record_files(self, kword='.record.'):
        # load file list from directory if needs
        file_abs_paths = []
        if not isinstance(self.records, list):
            raise ValueError("Record files must be in a list")

        records = self.records
        if len(records) == 1 and os.path.isdir(records[0]):
            print(f'Load cyber records from: {records[0]}')
            for f in sorted(os.listdir(records[0])):
                if kword in f:
                    file_abs_path = os.path.join(records[0], f)
                    if Extractor.validate_record(file_abs_path):
                        file_abs_paths.append(file_abs_path)
                    else:
                        print(f'Invalid record file: {file_abs_path}')
        else:
            for f in records:
                if not os.path.isfile(f):
                    raise ValueError("Input cyber record does not exist "
                                     f"or not a regular file: {f}")

                if Extractor.validate_record(f):
                    file_abs_paths.append(f)
                else:
                    print(f'Invalid record file: {f}')

        if len(file_abs_paths) < 1:
            raise ValueError("All the input record files are invalid")

        # Validate all record files have the same sensor topics
        first_record_file = file_abs_paths[0]
        default_sensor_channels = Extractor.get_sensor_channel_list(
            first_record_file)
        for i, f in enumerate(file_abs_paths[1:]):
            sensor_channels = Extractor.get_sensor_channel_list(f)
            if sensor_channels != default_sensor_channels:
                print(
                    f'Default sensor channel list in {first_record_file} is: ')
                print(default_sensor_channels)
                print(f'but sensor channel list in {file_abs_paths[i]} is: ')
                print(sensor_channels)
                raise ValueError(
                    "The record files should contain the same channel list")

        return file_abs_paths

    def parse_channel_config(self):
        channel_list = set()
        extraction_rate_dict = dict()

        for channel in self.config.channels.channel:
            if channel.name in channel_list:
                raise ValueError(
                    f"Duplicated channel config for : {channel.name}")
            else:
                channel_list.add(channel.name)
                extraction_rate_dict[channel.name] = channel.extraction_rate
        return channel_list, extraction_rate_dict

    @staticmethod
    def get_substring(str, prefix, suffix):
        """return substring, eclusive prefix or suffix"""
        str_p = str.rfind(prefix) + len(prefix)
        end_p = str.rfind(suffix)
        return str[str_p:end_p]

    def reorganize_extracted_data(self,
                                  tmp_data_path,
                                  remove_input_data_cache=False):
        root_path = os.path.dirname(os.path.normpath(tmp_data_path))
        output_path = None

        config_yaml = ConfigYaml()
        task_name = self.config.io_config.task_name
        if task_name == 'lidar_to_gnss':
            subfolders = [
                x for x in get_subfolder_list(tmp_data_path)
                if '_apollo_sensor_' in x or '_localization_pose' in x
            ]
            odometry_subfolders = [
                x for x in subfolders if '_odometry' in x or '_pose' in x
            ]
            lidar_subfolders = [x for x in subfolders if '_PointCloud2' in x]
            print(lidar_subfolders)
            print(odometry_subfolders)
            if len(lidar_subfolders) == 0 or len(odometry_subfolders) != 1:
                raise ValueError(('one odometry and more than 0 lidar(s)'
                                  'sensor are needed for sensor calibration'))
            odometry_subfolder = odometry_subfolders[0]
            yaml_list = []
            gnss_name = 'novatel'
            multi_lidar_out_path = os.path.join(
                root_path, 'multi_lidar_to_gnss_calibration')
            output_path = multi_lidar_out_path

            for lidar in lidar_subfolders:
                # get the lidar name from folder name string
                lidar_name = Extractor.get_substring(str=lidar,
                                                     prefix='_apollo_sensor_',
                                                     suffix='_PointCloud2')

                # reorganize folder structure: each lidar has its raw data,
                # corresponding odometry and configuration yaml file

                if not Extractor.process_dir(multi_lidar_out_path, 'create'):
                    raise ValueError(
                        f'Failed to create directory: {multi_lidar_out_path}')
                lidar_in_path = os.path.join(tmp_data_path, lidar)
                lidar_out_path = os.path.join(multi_lidar_out_path, lidar)
                if not os.path.exists(lidar_out_path):
                    shutil.copytree(lidar_in_path, lidar_out_path)
                odometry_in_path = os.path.join(tmp_data_path,
                                                odometry_subfolder)
                odometry_out_path = os.path.join(multi_lidar_out_path,
                                                 odometry_subfolder)
                if not os.path.exists(odometry_out_path):
                    shutil.copytree(odometry_in_path, odometry_out_path)
                generated_config_yaml = os.path.join(
                    tmp_data_path, lidar_name + '_' + 'sample_config.yaml')
                config_yaml.generate_task_config_yaml(
                    task_name=task_name,
                    source_sensor=lidar_name,
                    dest_sensor=gnss_name,
                    source_folder=lidar,
                    dest_folder=odometry_subfolder,
                    out_config_file=generated_config_yaml)
                print(f'lidar {lidar_name} calibration data and configuration'
                      ' are generated.')
                yaml_list.append(generated_config_yaml)

            out_data = {
                'calibration_task': task_name,
                'destination_sensor': gnss_name,
                'odometry_file': odometry_subfolder + '/odometry'
            }
            sensor_files_directory_list = []
            source_sensor_list = []
            transform_list = []
            for i in range(len(yaml_list)):
                with open(yaml_list[i], 'r') as f:
                    data = yaml.safe_load(f)
                    sensor_files_directory_list.append(
                        data['sensor_files_directory'])
                    source_sensor_list.append(data['source_sensor'])
                    transform_list.append(data['transform'])
            out_data['sensor_files_directory'] = sensor_files_directory_list
            out_data['source_sensor'] = source_sensor_list
            out_data['transform'] = transform_list
            out_data['main_sensor'] = source_sensor_list[0]

            table = preprocess_table_pb2.PreprocessTable()
            user_config = os.path.join(FLAGS.root_dir, 'config',
                                       'lidar_to_gnss_user.config')
            if os.path.exists(user_config):
                try:
                    get_pb_from_text_file(user_config, table)
                except text_format.ParseError:
                    print(f'Error: Cannot parse {user_config} as text proto')

                if table.HasField("main_sensor"):
                    out_data['main_sensor'] = table.main_sensor

            multi_lidar_yaml = os.path.join(multi_lidar_out_path,
                                            'sample_config.yaml')
            with open(multi_lidar_yaml, 'w') as f:
                yaml.safe_dump(out_data, f)

        elif task_name == 'camera_to_lidar':
            # data selection.
            pair_data_folder_name = 'camera-lidar-pairs'
            cameras, lidar = select_static_image_pcd(
                path=tmp_data_path,
                min_distance=5,
                stop_times=4,
                wait_time=3,
                check_range=50,
                image_static_diff_threshold=0.005,
                output_folder_name=pair_data_folder_name,
                image_suffix='.jpg',
                pcd_suffix='.pcd')
            lidar_name = Extractor.get_substring(str=lidar,
                                                 prefix='_apollo_sensor_',
                                                 suffix='_PointCloud2')
            for camera in cameras:
                camera_name = Extractor.get_substring(str=camera,
                                                      prefix='_apollo_sensor_',
                                                      suffix='_image')
                out_path = os.path.join(
                    root_path,
                    camera_name + '_to_' + lidar_name + '_calibration')
                output_path = out_path
                if not Extractor.process_dir(out_path, 'create'):
                    raise ValueError(f'Failed to create directory: {out_path}')
                # reorganize folder structure: each camera has its images,
                # corresponding lidar pointclouds, camera initial extrinsics,
                # intrinsics, and configuration yaml file

                in_pair_data_path = os.path.join(tmp_data_path, camera,
                                                 pair_data_folder_name)
                out_pair_data_path = os.path.join(out_path,
                                                  pair_data_folder_name)
                shutil.copytree(in_pair_data_path, out_pair_data_path)
                generated_config_yaml = os.path.join(out_path,
                                                     'sample_config.yaml')
                config_yaml.generate_task_config_yaml(
                    task_name=task_name,
                    source_sensor=camera_name,
                    dest_sensor=lidar_name,
                    source_folder=None,
                    dest_folder=None,
                    out_config_file=generated_config_yaml)
        elif task_name == 'radar_to_gnss':
            print('not ready. stay tuned')
        else:
            raise ValueError(
                f'Unsupported data extraction task for {task_name}')

        if remove_input_data_cache:
            print(f'removing the cache at {tmp_data_path}')
            os.system(f'rm -rf {tmp_data_path}')
        return output_path

    def sanity_check_path(self, path):
        """Sanity check wrapper"""
        result, log_str = sanity_check(path)
        if result is True:
            self.progress.percentage = 100.0
            self.progress.status = preprocess_table_pb2.Status.SUCCESS
        else:
            self.progress.status = preprocess_table_pb2.Status.FAIL
        self.progress.log_string = log_str
        self.writer.write(self.progress)
        time.sleep(0.5)

    def create_tmp_directory(self):
        """Create directory to save the extracted data use time now() as folder name"""
        output_relative_path = self.config.io_config.task_name + datetime.now(
        ).strftime("-%Y-%m-%d-%H-%M") + '/tmp/'

        output_abs_path = os.path.join(self.config.io_config.output_path,
                                       output_relative_path)
        ret = self.process_dir(output_abs_path, 'create')
        if not ret:
            raise ValueError(
                f'Failed to create extrated data directory: {output_abs_path}')
        return output_abs_path


def main(argv):
    """Main function"""

    cyber.init("data_extractor")
    extractor = Extractor()

    valid_record_list = extractor.validate_record_files(kword='.record.')

    channels, extraction_rates = extractor.parse_channel_config()
    print(f'parsing the following channels: {channels}')

    output_tmp_path = extractor.create_tmp_directory()
    extractor.extract_data(valid_record_list, output_tmp_path, channels,
                           extraction_rates)

    output_abs_path = extractor.reorganize_extracted_data(
        tmp_data_path=output_tmp_path, remove_input_data_cache=True)

    print('Data extraction is completed successfully!')
    extractor.sanity_check_path(output_abs_path)
    cyber.shutdown()
    sys.exit(0)


if __name__ == '__main__':
    # root_path = '/apollo/data/extracted_data/MKZ5-2019-05-15/lidar_to_gnss-2019-11-25-11-02/tmp'
    # task_name = 'lidar_to_gnss'
    # root_path = '/apollo/data/extracted_data/udevl002-2019-06-14/camera_to_lidar-2019-11-26-19-49/tmp'
    # task_name = 'camera_to_lidar'
    # reorganize_extracted_data(tmp_data_path=root_path, task_name=task_name)
    app.run(main)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
This is a tool to etract useful information from already extracted sensor data,
mainly for camera lidar calibration.
"""

from datetime import datetime
from shutil import copyfile
import argparse
import cv2
import os
import six
import sys

from google.protobuf import text_format
import numpy as np

from cyber.python.cyber_py3.record import RecordReader
from cyber.proto import record_pb2
from modules.tools.sensor_calibration.configuration_yaml_generator import ConfigYaml
from modules.tools.sensor_calibration.data_file_object import TimestampFileObject, OdometryFileObject
from modules.tools.sensor_calibration.proto import extractor_config_pb2


CYBER_PATH = os.environ['CYBER_PATH']
CYBER_RECORD_HEADER_LENGTH = 2048

Z_FILL_LEN = 4
Z_DEFAULT_LEN = 5


def mkdir_p(path):
    if not os.path.isdir(path):
        os.makedirs(path)
    else:
        print('folder {} exists'.format(path))


def get_subfolder_list(d):
    """list the 1st-level directories under the root directory
    ignore hidden folders"""
    return [f for f in os.listdir(d) if not f.startswith('.') and
            os.path.isdir(os.path.join(d, f))]


def sort_files_by_timestamp(in_path, out_path,
                            timestamp_filename,
                            extension='.png'):
    """sort files by timestamp"""
    ts_file = os.path.join(in_path, timestamp_filename)
    out_ts_file = os.path.join(out_path, timestamp_filename)
    ts_map = np.loadtxt(ts_file)
    sorted_ids = np.argsort(ts_map[:, 1])
    ts_map = ts_map[sorted_ids]
    # sorted_ts = np.vstack((np.arange(sorted_ids), ts_map[:,1])).T
    # np.savetxt(out_ts_file, ts_map, sorted_ts)
    ts_obj = TimestampFileObject(file_path=out_ts_file)
    ts_obj.save_to_file(ts_map[:, 1])

    if extension == '.png' or extension == '.pcd':
        for i, idx in enumerate(ts_map[:, 0]):
            in_file_name = os.path.join(in_path, ("%06d" % (idx + 1)) + extension)
            out_file_name = os.path.join(out_path, ("%06d" % (i + 1)) + extension)
            copyfile(in_file_name, out_file_name)

    elif extension == 'odometry':
        tmp_file = os.path.join(in_path, 'odometry')
        in_odm = OdometryFileObject(file_path=tmp_file,
                                    operation='read',
                                    file_type='binary')
        data = in_odm.load_file()
        sorted_data = []
        for idx in ts_map[:, 0]:
            d = data[idx]
            sorted_data.append(d)

        tmp_file = os.path.join(out_path, 'odometry')
        out_odm = OdometryFileObject(file_path=tmp_file,
                                     operation='write',
                                     file_type='binary')
        out_odm.save_to_file(sorted_data)


def find_nearest(array, value):
    idx = np.searchsorted(array, value, side="left")
    if idx > 0 and (idx == len(array) or
                    math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):
        return idx-1
    else:
        return idx


def find_synchronized_timestamp_index(query_ts, source_ts, max_threshold=1.0):
    # for each element in query, find the nearest element in source,
    # if the distance < max_threshold
    ts1 = query_ts
    ts2 = source_ts
    if len(ts1) == 0 or len(ts2) == 0:
        return {}

    nearest_index_map = {}
    start = 0
    for i in range(len(ts1)):
        if start >= len(ts2):
            break

        min_ts_diff = max_threshold
        min_j = -1
        for j in range(start, len(ts2)):
            ts_diff = ts2[j] - ts1[i]
            if abs(ts_diff) < min_ts_diff:
                min_j = j
                min_ts_diff = abs(ts_diff)

            if ts_diff >= 0:
                # the rest ts2 > ts1, no need to loop ts2 anymore
                break

        if min_j > 0:  # find valid nearest index in ts2
            start = min_j  # reset start for case i++
            nearest_index_map[i] = min_j
    # for i, j in nearest_index_map.items():
    #     print([i, j, query_ts[i], source_ts[j]])
    return nearest_index_map


def get_difference_score_between_images(path, file_indexes,
                                        suffix=".png", thumbnail_size=32):
    image_sum = np.zeros(len(file_indexes), dtype=np.float32)
    image_diff = np.zeros(len(file_indexes), dtype=np.float32)
    image_thumbnails = []
    for c, idx in enumerate(file_indexes):
        image_file = os.path.join(path, str(int(idx)).zfill(Z_DEFAULT_LEN) + suffix)
        image = cv2.imread(image_file)
        image_thumbnails.append(cv2.resize(image,
                                           (thumbnail_size, thumbnail_size), interpolation=cv2.INTER_AREA))
        image_sum[c] = np.sum(image_thumbnails[-1])

    image_diff[0] = np.finfo(float).max
    for c in range(len(file_indexes)-1, 0, -1):
        image_diff[c] = np.sum(cv2.absdiff(image_thumbnails[c], image_thumbnails[c-1]))
        image_diff[c] = image_diff[c] / image_sum[c]

    # print("image_diff is: ")
    # for i in range(len(image_diff)):
    #     print([i, image_diff[i], image_sum[i]])
    return image_diff


def get_distance_by_odometry(data, i, j):
    #  calculate x-y plane distance
    return np.linalg.norm(data[i, -3:-1] - data[j, -3:-1])


def check_static_by_odometry(data, index, check_range=40,
                             movable_threshold=0.01):
    start_idx = np.maximum(index - check_range, 0)
    end_idx = np.minimum(index + check_range, data.shape[0]-1)
    #  skip if start and end index are too nearby.
    if end_idx - start_idx < 2 * check_range:
        return False
    #  calculate x-y plane distance
    distance = get_distance_by_odometry(data, start_idx, end_idx)
    # print("distance is %d %d %f" % (start_idx, end_idx,distance))
    return distance < movable_threshold


def select_static_image_pcd(path, min_distance=5, stop_times=5,
                            wait_time=3, check_range=50,
                            image_static_diff_threshold=0.005,
                            output_folder_name='camera-lidar-pairs',
                            image_suffix='.jpg', pcd_suffix='.pcd'):
    """
    select pairs of images and pcds, odometry information may
    come from /apollolocalization/pose as well
    """
    subfolders = [x for x in get_subfolder_list(
        path) if '_apollo_sensor_' in x or '_localization_pose' in x]
    lidar_subfolder = [x for x in subfolders if '_PointCloud2' in x]
    odometry_subfolder = [x for x in subfolders if'_odometry' in x or '_localization_pose' in x]
    camera_subfolders = [x for x in subfolders if'_image' in x]
    if len(lidar_subfolder) is not 1 or \
            len(odometry_subfolder) is not 1:
        raise ValueError('only one main lidar and one Odometry'
                         'sensor is needed for sensor calibration')

    lidar_subfolder = lidar_subfolder[0]
    odometry_subfolder = odometry_subfolder[0]
    #  load timestamp dictionary
    timestamp_dict = {}
    for f in subfolders:
        f_abs_path = os.path.join(path, f)
        ts_file = os.path.join(f_abs_path, 'timestamps')
        ts_map = np.loadtxt(ts_file)
        timestamp_dict[f] = ts_map
    #  load odometry binary file
    odometry_file = os.path.join(path, odometry_subfolder, 'odometry')
    in_odm = OdometryFileObject(file_path=odometry_file,
                                operation='read',
                                file_type='binary')
    odometry_data = np.array(in_odm.load_file())
    for camera in camera_subfolders:
        print("working on sensor message: {}".format(camera))
        camera_gps_nearest_pairs = \
            find_synchronized_timestamp_index(
                timestamp_dict[camera][:, 1],
                timestamp_dict[odometry_subfolder][:, 1],
                max_threshold=0.2)

        camera_lidar_nearest_pairs = \
            find_synchronized_timestamp_index(
                timestamp_dict[camera][:, 1],
                timestamp_dict[lidar_subfolder][:, 1],
                max_threshold=0.5)

        # clean camera-lidar paris not exist in both dictionary
        del_ids = []
        for key in camera_lidar_nearest_pairs:
            if key not in camera_gps_nearest_pairs:
                del_ids.append(key)
        for key in del_ids:
            del camera_lidar_nearest_pairs[key]

        camera_folder_path = os.path.join(path, camera)
        print('foder: {}'.format(camera_folder_path))
        camera_diff = get_difference_score_between_images(
            camera_folder_path, timestamp_dict[camera][:, 0], suffix=image_suffix)
        valid_image_indexes = [x for x, v in enumerate(camera_diff)
                               if v <= image_static_diff_threshold]
        valid_images = (timestamp_dict[camera][valid_image_indexes, 0]).astype(int)
        # generate valid camera frame
        candidate_idx = []
        last_idx = -1
        last_odometry_idx = -1
        for i in valid_images:
            if i in camera_lidar_nearest_pairs:
                odometry_idx = camera_gps_nearest_pairs[i]
                #  not static considering odometry motion.
                if not check_static_by_odometry(odometry_data,
                                                odometry_idx, check_range=check_range):
                    continue

                if last_idx is -1:
                    last_idx = i
                    last_odometry_idx = odometry_idx
                    candidate_idx.append(i)
                    continue
                time_interval = timestamp_dict[camera][i, 1] - timestamp_dict[camera][last_idx, 1]
                odomerty_interval = \
                    get_distance_by_odometry(odometry_data, odometry_idx, last_odometry_idx)
                # timestamp interval > wait_time and odometry_interval > min_distance`
                if time_interval < wait_time or \
                        odomerty_interval < min_distance:
                    continue

                candidate_idx.append(i)
                last_idx = i
                last_odometry_idx = odometry_idx
                # print(odometry_data[odometry_idx])
                # print(odometry_data[last_odometry_idx])
                # print([i, odomerty_interval])
        #  check candidate number and select best stop according to camera_diff score
        print("all valid static image index: ", candidate_idx)
        if len(candidate_idx) < stop_times:
            raise ValueError('not enough stops detected,'
                             'thus no sufficient data for camera-lidar calibration')
        elif len(candidate_idx) > stop_times:
            tmp_diff = camera_diff[candidate_idx]

            tmp_idx = np.argsort(tmp_diff)[:stop_times]
            candidate_idx = [candidate_idx[x] for x in tmp_idx]
            candidate_idx.sort()
        #  save files
        image_idx = candidate_idx
        print("selected best static image index: ", image_idx)
        lidar_idx = [camera_lidar_nearest_pairs[x] for x in image_idx]
        output_path = os.path.join(camera_folder_path, output_folder_name)
        mkdir_p(output_path)
        for count, i in enumerate(image_idx):
            #  save images
            in_file = os.path.join(camera_folder_path, str(
                int(i)).zfill(Z_DEFAULT_LEN) + image_suffix)
            out_file = os.path.join(output_path, str(
                int(count)).zfill(Z_FILL_LEN) + '_00' + image_suffix)
            copyfile(in_file, out_file)
            j = camera_lidar_nearest_pairs[i]
            #  save pcd
            in_file = os.path.join(path, lidar_subfolder, str(
                int(j)).zfill(Z_DEFAULT_LEN) + pcd_suffix)
            out_file = os.path.join(output_path, str(
                int(count)).zfill(Z_FILL_LEN) + '_00' + pcd_suffix)
            copyfile(in_file, out_file)
            print("generate image-lidar-pair:[%d, %d]" % (i, j))
    return camera_subfolders, lidar_subfolder


def main2():
    for str in ['_apollo_sensor_lidar16_front_center_PointCloud2',
                '_apollo_sensor_lidar16_rear_left_PointCloud2',
                '_apollo_sensor_lidar16_rear_right_PointCloud2',
                '_apollo_sensor_lidar128_PointCloud2']:
         # _apollo_sensor_lidar128_PointCloud2'
        in_path = '/apollo/data/Lidar_GNSS_Calibration-2019-07-12-15-25/' + str
        out_path = os.path.join(in_path, 'new')
        mkdir_p(out_path)
        timestamp_filename = 'timestamps.txt'
        extension = '.pcd'
        sort_files_by_timestamp(in_path, out_path, timestamp_filename, extension=extension)

    in_path = '/apollo/data/Lidar_GNSS_Calibration-2019-07-12-15-25/_apollo_sensor_gnss_odometry'
    out_path = os.path.join(in_path, 'new')
    mkdir_p(out_path)
    timestamp_filename = 'timestamps.txt'
    extension = 'odometry'
    sort_files_by_timestamp(in_path, out_path, timestamp_filename, extension=extension)


def main():
    if CYBER_PATH is None:
        print('Error: environment variable CYBER_PATH was not found, '
              'set environment first.')
        sys.exit(1)

    os.chdir(CYBER_PATH)

    parser = argparse.ArgumentParser(
        description='A tool to extract useful data information for camera-to-lidar calibration.')
    parser.add_argument("-i", "--workspace_path", action="store", default="", required=True,
                        dest='workspace',
                        help="Specify the worksapce where storing extracted sensor messages")
    args = parser.parse_args()

    select_static_image_pcd(path=args.workspace, min_distance=5, stop_times=5,
                            wait_time=3, check_range=50,
                            image_static_diff_threshold=0.005)


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import atexit
import logging
import os
import sys
import time

#from common.logger import Logger
from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time

from modules.drivers.gnss.proto import ins_pb2


class InsStat(object):
    def __init__(self,node):
        self.insstat_pub = node.create_writer('/apollo/sensor/gnss/ins_stat', ins_pb2.InsStat)
        self.sequence_num = 0
        self.terminating = False

    def publish_statmsg(self):
        insstat = ins_pb2.InsStat()
        now = cyber_time.Time.now().to_sec()
        insstat.header.timestamp_sec = now
        insstat.header.module_name = "ins_stat"
        insstat.header.sequence_num = self.sequence_num
        self.sequence_num = self.sequence_num + 1
        insstat.ins_status = 3
        insstat.pos_type = 56
        #self.logger.info("%s"%insstat)
        self.insstat_pub.write(insstat)

    def shutdown(self):
        """
        shutdown rosnode
        """
        self.terminating = True
        #self.logger.info("Shutting Down...")
        time.sleep(0.2)

def main():
    """
    Main rosnode
    """
    node=cyber.Node('ins_stat_publisher')
    ins_stat = InsStat(node)
    while not cyber.is_shutdown():
        now = cyber_time.Time.now().to_sec()
        ins_stat.publish_statmsg()
        sleep_time = 0.5 - (cyber_time.Time.now().to_sec() - now)
        if sleep_time > 0:
            time.sleep(sleep_time)

if __name__ == '__main__':
    cyber.init()
    main()
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import argparse
import atexit
import logging
import os
import sys
import time

#from common.logger import Logger
from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time

from modules.localization.proto import localization_pb2
from modules.localization.proto import gps_pb2

class OdomPublisher(object):
    def __init__(self, node):
        self.localization = localization_pb2.LocalizationEstimate()
        self.gps_odom_pub = node.create_writer('/apollo/sensor/gnss/odometry', gps_pb2.Gps) 
        self.sequence_num = 0
        self.terminating = False
        self.position_x = 0
        self.position_y = 0
        self.position_z = 0
        self.orientation_x = 0
        self.orientation_y = 0
        self.orientation_z = 0
        self.orientation_w = 0
        self.linear_velocity_x = 0 
        self.linear_velocity_y = 0
        self.linear_velocity_z = 0

    def localization_callback(self, data):
        """
        New message received
        """
        self.localization.CopyFrom(data)
        self.position_x = self.localization.pose.position.x
        self.position_y = self.localization.pose.position.y
        self.position_z = self.localization.pose.position.z
        self.orientation_x = self.localization.pose.orientation.qx
        self.orientation_y = self.localization.pose.orientation.qy
        self.orientation_z = self.localization.pose.orientation.qz
        self.orientation_w = self.localization.pose.orientation.qw
        self.linear_velocity_x = self.localization.pose.linear_velocity.x
        self.linear_velocity_y = self.localization.pose.linear_velocity.y
        self.linear_velocity_z = self.localization.pose.linear_velocity.z

    def publish_odom(self):
        odom = gps_pb2.Gps()
        now = cyber_time.Time.now().to_sec()
        odom.header.timestamp_sec = now
        odom.header.module_name = "odometry"
        odom.header.sequence_num = self.sequence_num
        self.sequence_num = self.sequence_num + 1

        odom.localization.position.x = self.position_x
        odom.localization.position.y = self.position_y
        odom.localization.position.z = self.position_z
        odom.localization.orientation.qx = self.orientation_x
        odom.localization.orientation.qy = self.orientation_y
        odom.localization.orientation.qz = self.orientation_z
        odom.localization.orientation.qw = self.orientation_w
        odom.localization.linear_velocity.x = self.linear_velocity_x
        odom.localization.linear_velocity.y = self.linear_velocity_y
        odom.localization.linear_velocity.z = self.linear_velocity_z
        #self.logger.info("%s"%odom)
        self.gps_odom_pub.write(odom)

    def shutdown(self):
        """
        shutdown rosnode
        """
        self.terminating = True
        #self.logger.info("Shutting Down...")
        time.sleep(0.2)

def main():
    """
    Main rosnode
    """
    node = cyber.Node('odom_publisher')
    odom = OdomPublisher(node)
    node.create_reader('/apollo/localization/pose', localization_pb2.LocalizationEstimate, odom.localization_callback)
    while not cyber.is_shutdown():
        now = cyber_time.Time.now().to_sec()
        odom.publish_odom()
        sleep_time = 0.01 - (cyber_time.Time.now().to_sec() - now)
        if sleep_time > 0:
            time.sleep(sleep_time)

if __name__ == '__main__':
    cyber.init()
    main()
    cyber.shutdown()
#!/usr/bin/env python

###############################################################################
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This is a tool to sanity check the output files of extract_data.py
"""

import os
import yaml

from absl import app
from absl import flags
from absl import logging

import modules.tools.common.file_utils as file_utils

flags.DEFINE_string('input_folder', '', 'The folder stores extracted messages')


def missing_config_file(path):
    sample_config_files = []
    for (dirpath, _, filenames) in os.walk(path):
        for filename in filenames:
            if filename == 'sample_config.yaml':
                end_file = os.path.join(dirpath, filename)
                sample_config_files.append(end_file)
    if (len(sample_config_files) == 0):
        return True, []
    return False, sample_config_files


def missing_calibration_task(sample_config_files):
    for sample_config_file in sample_config_files:
        print(sample_config_file)
        with open(sample_config_file, 'r') as f:
            data = yaml.safe_load(f)
        if not ('calibration_task' in data):
            return True
    return False


def file_type_exist(file_dir, file_type):
    files = os.listdir(file_dir)

    for k in range(len(files)):
        files[k] = os.path.splitext(files[k])[1]
    if file_type in files:
        return True
    return False


def list_to_str(data):
    if isinstance(data, list):
        return data[0]
    else:
        return data


def missing_lidar_gnss_file(lidar_gnss_config):
    with open(lidar_gnss_config, 'r') as f:
        data = yaml.safe_load(f)
    yaml_dir = os.path.dirname(lidar_gnss_config)
    odometry_dir = os.path.join(yaml_dir, data['odometry_file'])
    point_cloud_dir = os.path.join(yaml_dir,
                                   list_to_str(data['sensor_files_directory']))
    logging.info(
        f"odometry_dir:{odometry_dir} , point_cloud_dir: {point_cloud_dir}")
    if not os.access(odometry_dir, os.F_OK):
        logging.info('odometry file does not exist')
        return True
    if not file_type_exist(point_cloud_dir, '.pcd'):
        logging.info('pcd file does not exist')
        return True
    return False


def missing_camera_lidar_file(camera_lidar_configs):
    with open(camera_lidar_configs, 'r') as f:
        data = yaml.safe_load(f)
    yaml_dir = os.path.dirname(camera_lidar_configs)
    camera_lidar_pairs_dir = os.path.join(yaml_dir, data['data_path'])
    extrinsics_yaml_dir = os.path.join(yaml_dir, data['extrinsic'])
    intrinsics_yaml_dir = os.path.join(yaml_dir, data['intrinsic'])
    jpg_flag = file_type_exist(camera_lidar_pairs_dir, '.jpg')
    pcd_flag = file_type_exist(camera_lidar_pairs_dir, '.pcd')
    if not (jpg_flag and pcd_flag):
        logging.info('camera_lidar_pairs data error')
        return True
    if not os.access(extrinsics_yaml_dir, os.F_OK):
        logging.info('extrinsics_yaml file does not exist')
        return True
    if not os.access(intrinsics_yaml_dir, os.F_OK):
        logging.info('intrinsics_yaml file does not exist')
        return True
    return False


def missing_calibration_data_file(sample_config_files):
    lidar_file_flag = False
    camera_file_flag = False
    for sample_config_file in sample_config_files:
        with open(sample_config_file, 'r') as f:
            data = yaml.safe_load(f)
            if data['calibration_task'] == 'lidar_to_gnss':
                if (missing_lidar_gnss_file(sample_config_file)):
                    lidar_file_flag = True
            if data['calibration_task'] == 'camera_to_lidar':
                if (missing_camera_lidar_file(sample_config_file)):
                    camera_file_flag = True
    return lidar_file_flag, camera_file_flag


def is_oversize_file(path):
    dir_size = file_utils.getInputDirDataSize(path)
    if dir_size == 0:
        logging.error('The input dir is empty!')
        return True
    if dir_size >= 5 * 1024 * 1024 * 1024:
        logging.error('The record file is oversize!')
        return True
    return False


def sanity_check(input_folder):
    err_msg = None
    lidar_gnss_flag = False
    camera_lidar_flag = False
    if is_oversize_file(input_folder):
        err_msg = "The input file is oversize(1G)!"

    config_flag, config_files = missing_config_file(input_folder)
    if config_flag:
        err_msg = "Missing sample_config.yaml!"
    if missing_calibration_task(config_files):
        err_msg = "The sample_config.yaml file miss calibration_task config!"
    lidar_gnss_flag, camera_lidar_flag = missing_calibration_data_file(
        config_files)
    if lidar_gnss_flag and not camera_lidar_flag:
        err_msg = "Missing Lidar_gnss files!"
    elif not lidar_gnss_flag and camera_lidar_flag:
        err_msg = "Missing camera_lidar files!"
    elif lidar_gnss_flag and camera_lidar_flag:
        err_msg = "Missing lidar_gnss and camera_lidar files!"
    else:
        info_msg = f"{input_folder} Passed sanity check."
        logging.info(info_msg)
        return True, info_msg
    logging.error(err_msg)
    return False, err_msg


def main(argv):
    sanity_check(input_folder=flags.FLAGS.input_folder)


if __name__ == "__main__":
    app.run(main)
#!/usr/bin/env python3

###############################################################################
# Copyright 2019 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

"""
This is a bunch of classes to manage cyber record channel extractor.
"""

import os
import struct
import sys

import cv2
import numpy as np

from pypcd import pypcd

from modules.tools.sensor_calibration.data_file_object import TimestampFileObject, OdometryFileObject
from modules.drivers.proto import conti_radar_pb2
from modules.drivers.proto import sensor_image_pb2
from modules.drivers.proto import pointcloud_pb2
from modules.localization.proto import gps_pb2
from modules.localization.proto import localization_pb2


class SensorMessageParser(object):
    """Wrapper for cyber channel message extractor"""

    # Initializing extractor
    def __init__(self, output_path, instance_saving=True):
        """
        instance_saving:
        True for large channel message, e.g., Camera/lidar/Radar;
        False for small channel message, e.g., GNSS topics
        """
        self._msg_parser = None
        self._timestamps = []
        self._proto_parser = None
        self._init_parser()
        self._parsed_data = None
        self._output_path = output_path
        self._timestamp_file = os.path.join(self._output_path, "timestamps")
        self._instance_saving = instance_saving

    # initializing msg and proto parser
    def _init_parser(self):
        raise NotImplementedError

    def parse_sensor_message(self, msg):
        raise NotImplementedError

    def save_messages_to_file(self):
        return True

    def get_msg_count(self):
        return len(self._timestamps)

    def get_timestamps(self):
        return self._timestamps

    def save_timestamps_to_file(self):
        timestamp_file_obj = TimestampFileObject(self._timestamp_file,
                                                 operation='write',
                                                 file_type='txt')
        timestamp_file_obj.save_to_file(self._timestamps)
        return True


class GpsParser(SensorMessageParser):
    """
    class to parse GNSS odometry channel.
    saving this small topic as a whole.
    """

    def __init__(self, output_path, instance_saving=False):
        super(GpsParser, self).__init__(output_path, instance_saving)
        if not self._instance_saving:
            self._parsed_data = []
            self._odomotry_output_file = os.path.join(self._output_path, "odometry")

    def _init_parser(self):
        self._msg_parser = gps_pb2.Gps()

    def parse_sensor_message(self, msg):
        """ parse Gps information from GNSS odometry channel"""
        gps = self._msg_parser
        gps.ParseFromString(msg.message)

        # all double, except point_type is int32
        ts = gps.header.timestamp_sec
        self._timestamps.append(ts)

        point_type = 56
        qw = gps.localization.orientation.qw
        qx = gps.localization.orientation.qx
        qy = gps.localization.orientation.qy
        qz = gps.localization.orientation.qz
        x = gps.localization.position.x
        y = gps.localization.position.y
        z = gps.localization.position.z
        # save 9 values as a tuple, for eaisier struct packing during storage
        if self._instance_saving:
            raise ValueError("Gps odometry should be saved in a file")
        else:
            self._parsed_data.append((ts, point_type, qw, qx, qy, qz, x, y, z))

        return True

    def save_messages_to_file(self):
        """save list of parsed Odometry messages to file"""
        odometry_file_obj = OdometryFileObject(file_path=self._odomotry_output_file,
                                               operation='write',
                                               file_type='binary')
        odometry_file_obj.save_to_file(self._parsed_data)
        return True


class PoseParser(GpsParser):
    """
    inherit similar data saver and data structure from GpsParser
    save the ego-localization information same as odometry
    """

    def _init_parser(self):
        self._msg_parser = localization_pb2.LocalizationEstimate()

    def parse_sensor_message(self, msg):
        """ parse localization information from localization estimate channel"""
        loc_est = self._msg_parser
        loc_est.ParseFromString(msg.message)

        # all double, except point_type is int32
        ts = loc_est.header.timestamp_sec
        self._timestamps.append(ts)

        point_type = 56
        qw = loc_est.pose.orientation.qw
        qx = loc_est.pose.orientation.qx
        qy = loc_est.pose.orientation.qy
        qz = loc_est.pose.orientation.qz
        x = loc_est.pose.position.x
        y = loc_est.pose.position.y
        z = loc_est.pose.position.z
        # save 9 values as a tuple, for eaisier struct packing during storage
        if self._instance_saving:
            raise ValueError("localization--pseudo odometry-- should be saved in a file")
        else:
            self._parsed_data.append((ts, point_type, qw, qx, qy, qz, x, y, z))

        return True


class PointCloudParser(SensorMessageParser):
    """
    class to parse apollo/$(lidar)/PointCloud2 channels.
    saving separately each parsed msg
    """

    def __init__(self, output_path, instance_saving=True, suffix='.pcd'):
        super(PointCloudParser, self).__init__(output_path, instance_saving)
        self._suffix = suffix

    def convert_xyzit_pb_to_array(self, xyz_i_t, data_type):
        arr = np.zeros(len(xyz_i_t), dtype=data_type)
        for i, point in enumerate(xyz_i_t):
            # change timestamp to timestamp_sec
            arr[i] = (point.x, point.y, point.z,
                      point.intensity, point.timestamp/1e9)
        return arr

    def make_xyzit_point_cloud(self, xyz_i_t):
        """
        Make a pointcloud object from PointXYZIT message, as Pointcloud.proto.
        message PointXYZIT {
          optional float x = 1 [default = nan];
          optional float y = 2 [default = nan];
          optional float z = 3 [default = nan];
          optional uint32 intensity = 4 [default = 0];
          optional uint64 timestamp = 5 [default = 0];
        }
        """

        md = {'version': .7,
              'fields': ['x', 'y', 'z', 'intensity', 'timestamp'],
              'count': [1, 1, 1, 1, 1],
              'width': len(xyz_i_t),
              'height': 1,
              'viewpoint': [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
              'points': len(xyz_i_t),
              'type': ['F', 'F', 'F', 'U', 'F'],
              'size': [4, 4, 4, 4, 8],
              'data': 'binary_compressed'}

        typenames = []
        for t, s in zip(md['type'], md['size']):
            np_type = pypcd.pcd_type_to_numpy_type[(t, s)]
            typenames.append(np_type)

        np_dtype = np.dtype(list(zip(md['fields'], typenames)))
        pc_data = self.convert_xyzit_pb_to_array(xyz_i_t, data_type=np_dtype)
        pc = pypcd.PointCloud(md, pc_data)
        return pc

    def save_pointcloud_meta_to_file(self, pc_meta, pcd_file):
        pypcd.save_point_cloud_bin_compressed(pc_meta, pcd_file)

    def _init_parser(self):
        self._msg_parser = pointcloud_pb2.PointCloud()

    def parse_sensor_message(self, msg):
        """
        Transform protobuf PointXYZIT to standard PCL bin_compressed_file(*.pcd).
        """
        pointcloud = self._msg_parser
        pointcloud.ParseFromString(msg.message)

        self._timestamps.append(pointcloud.measurement_time)
        # self._timestamps.append(pointcloud.header.timestamp_sec)

        self._parsed_data = self.make_xyzit_point_cloud(pointcloud.point)

        if self._instance_saving:
            file_name = "%05d" % self.get_msg_count() + self._suffix
            output_file = os.path.join(self._output_path, file_name)
            self.save_pointcloud_meta_to_file(pc_meta=self._parsed_data, pcd_file=output_file)
        else:
            raise ValueError("not implement multiple message concatenation for PointCloud2 topic")
        # TODO(gchen-Apollo): add saint check
        return True


class ImageParser(SensorMessageParser):
    """
    class to parse apollo/$(camera)/image channels.
    saving separately each parsed msg
    """

    def __init__(self, output_path, instance_saving=True, suffix='.jpg'):
        super(ImageParser, self).__init__(output_path, instance_saving)
        self._suffix = suffix

    def _init_parser(self):
        self._msg_parser = sensor_image_pb2.Image()

    def parse_sensor_message(self, msg):

        image = self._msg_parser
        image.ParseFromString(msg.message)

        self._timestamps.append(image.header.timestamp_sec)
        # Save image according to cyber format, defined in sensor camera proto.
        # height = 4, image height, that is, number of rows.
        # width = 5,  image width, that is, number of columns.
        # encoding = 6, as string, type is 'rgb8', 'bgr8' or 'gray'.
        # step = 7, full row length in bytes.
        # data = 8, actual matrix data in bytes, size is (step * rows).
        # type = CV_8UC1 if image step is equal to width as gray, CV_8UC3
        # if step * 3 is equal to width.
        if image.encoding == 'rgb8' or image.encoding == 'bgr8':
            if image.step != image.width * 3:
                print('Image.step %d does not equal to Image.width %d * 3 for color image.'
                      % (image.step, image.width))
                return False
        elif image.encoding == 'gray' or image.encoding == 'y':
            if image.step != image.width:
                print('Image.step %d does not equal to Image.width %d or gray image.'
                      % (image.step, image.width))
                return False
        else:
            print('Unsupported image encoding type: %s.' % image.encoding)
            return False

        channel_num = image.step // image.width
        self._parsed_data = np.fromstring(image.data, dtype=np.uint8).reshape(
            (image.height, image.width, channel_num))

        if self._instance_saving:
            file_name = "%05d" % self.get_msg_count() + self._suffix
            output_file = os.path.join(self._output_path, file_name)
            self.save_image_mat_to_file(image_file=output_file)
        else:
            raise ValueError("not implement multiple message concatenation for Image topic")

        return True

    def save_image_mat_to_file(self, image_file):
        # Save image in BGR oder
        image_mat = self._parsed_data
        if self._msg_parser.encoding == 'rgb8':
            cv2.imwrite(image_file, cv2.cvtColor(image_mat, cv2.COLOR_RGB2BGR))
        else:
            cv2.imwrite(image_file, image_mat)


class ContiRadarParser(SensorMessageParser):
    """
    class to parse apollo/sensor/radar/$(position) channels.
    saving separately each parsed msg
    """

    def __init__(self, output_path, instance_saving=True, suffix='.pcd'):
        super(ContiRadarParser, self).__init__(output_path, instance_saving)
        self._suffix = suffix

    def convert_contiobs_pb_to_array(self, obs, data_type):
        arr = np.zeros(len(obs), dtype=data_type)
        for i, ob in enumerate(obs):
            # change timestamp to timestamp_sec
            # z value is 0
            # now using x, y, z, and t. later more information will be added
            arr[i] = (ob.longitude_dist, ob.lateral_dist, 0, ob.header.timestamp_sec)
        return arr

    def make_contidata_point_cloud(self, contiobs):
        """
        Make a pointcloud object from contiradar message, as conti_radar.proto.
        message ContiRadarObs {
          //                x axis  ^
          //                        | longitude_dist
          //                        |
          //                        |
          //                        |
          //          lateral_dist  |
          //          y axis        |
          //        <----------------
          //        ooooooooooooo   //radar front surface

          optional apollo.common.Header header = 1;
          // longitude distance to the radar; (+) = forward; unit = m
          optional double longitude_dist = 4;
          // lateral distance to the radar; (+) = left; unit = m
          optional double lateral_dist = 5;
          .......
        }
        """

        md = {'version': .7,
              'fields': ['x', 'y', 'z', 'timestamp'],
              'count': [1, 1, 1, 1],
              'width': len(contiobs),
              'height': 1,
              'viewpoint': [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
              'points': len(contiobs),
              'type': ['F', 'F', 'F', 'F'],
              'size': [4, 4, 4, 8],
              'data': 'binary'}

        typenames = []
        for t, s in zip(md['type'], md['size']):
            np_type = pypcd.pcd_type_to_numpy_type[(t, s)]
            typenames.append(np_type)

        np_dtype = np.dtype(list(zip(md['fields'], typenames)))
        pc_data = self.convert_contiobs_pb_to_array(contiobs, data_type=np_dtype)
        pc = pypcd.PointCloud(md, pc_data)
        return pc

    def save_pointcloud_meta_to_file(self, pc_meta, pcd_file):
        pypcd.save_point_cloud_bin(pc_meta, pcd_file)

    def _init_parser(self):
        self._msg_parser = conti_radar_pb2.ContiRadar()

    def parse_sensor_message(self, msg):
        """
        Transform protobuf radar message to standard PCL bin_file(*.pcd).
        """
        radar_data = self._msg_parser
        radar_data.ParseFromString(msg.message)

        self._timestamps.append(radar_data.header.timestamp_sec)
        # self._timestamps.append(pointcloud.header.timestamp_sec)

        self._parsed_data = self.make_contidata_point_cloud(radar_data.contiobs)

        if self._instance_saving:
            file_name = "%05d" % self.get_msg_count() + self._suffix
            output_file = os.path.join(self._output_path, file_name)
            self.save_pointcloud_meta_to_file(pc_meta=self._parsed_data, pcd_file=output_file)
        else:
            raise ValueError("not implement multiple message concatenation for COontiRadar topic")
        # TODO(gchen-Apollo): add saint check
        return True
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
Data Collector
"""

import os
import signal
import sys
import time

from cyber.python.cyber_py3 import cyber
from cyber.python.cyber_py3 import cyber_time
from modules.canbus.proto import chassis_pb2
from modules.control.proto import control_cmd_pb2
from modules.localization.proto import localization_pb2
from modules.tools.vehicle_calibration.plot_data import Plotter


class DataCollector(object):
    """
    DataCollector Class
    """

    def __init__(self, node):
        self.sequence_num = 0
        self.control_pub = node.create_writer('/apollo/control',
                                              control_cmd_pb2.ControlCommand)
        time.sleep(0.3)
        self.controlcmd = control_cmd_pb2.ControlCommand()

        self.canmsg_received = False
        self.localization_received = False

        self.case = 'a'
        self.in_session = False

        self.outfile = ""

    def run(self, cmd):
        signal.signal(signal.SIGINT, self.signal_handler)

        self.in_session = True
        self.cmd = list(map(float, cmd))
        out = ''
        if self.cmd[0] > 0:
            out += 't'
        else:
            out += 'b'
        out = out + str(int(self.cmd[0]))
        if self.cmd[2] > 0:
            out += 't'
        else:
            out += 'b'
        out += str(int(self.cmd[2])) + 'r'
        i = 0
        self.outfile = out + str(i) + '_recorded.csv'
        while os.path.exists(self.outfile):
            i += 1
            self.outfile = out + str(i) + '_recorded.csv'
        self.file = open(self.outfile, 'w')
        self.file.write(
            "time,io,ctlmode,ctlbrake,ctlthrottle,ctlgear_location," +
            "vehicle_speed,engine_rpm,driving_mode,throttle_percentage," +
            "brake_percentage,gear_location,imu\n"
        )

        print('Send Reset Command.')
        self.controlcmd.header.module_name = "control"
        self.controlcmd.header.sequence_num = self.sequence_num
        self.sequence_num = self.sequence_num + 1
        self.controlcmd.header.timestamp_sec = cyber_time.Time.now().to_sec()
        self.controlcmd.pad_msg.action = 2
        self.control_pub.write(self.controlcmd)

        time.sleep(0.2)
        # Set Default Message
        print('Send Default Command.')
        self.controlcmd.pad_msg.action = 1
        self.controlcmd.throttle = 0
        self.controlcmd.brake = 0
        self.controlcmd.steering_rate = 100
        self.controlcmd.steering_target = 0
        self.controlcmd.gear_location = chassis_pb2.Chassis.GEAR_DRIVE

        self.canmsg_received = False
        self.case = 'a'

        while self.in_session:
            now = cyber_time.Time.now().to_sec()
            self.publish_control()
            sleep_time = 0.01 - (cyber_time.Time.now().to_sec() - now)
            if sleep_time > 0:
                time.sleep(sleep_time)

    def signal_handler(self, signal, frame):
        self.in_session = False

    def callback_localization(self, data):
        """
        New Localization
        """
        self.acceleration = data.pose.linear_acceleration_vrf.y
        self.localization_received = True

    def callback_canbus(self, data):
        """
        New CANBUS
        """
        if not self.localization_received:
            print('No Localization Message Yet')
            return
        timenow = data.header.timestamp_sec
        self.vehicle_speed = data.speed_mps
        self.engine_rpm = data.engine_rpm
        self.throttle_percentage = data.throttle_percentage
        self.brake_percentage = data.brake_percentage
        self.gear_location = data.gear_location
        self.driving_mode = data.driving_mode

        self.canmsg_received = True
        if self.in_session:
            self.write_file(timenow, 0)

    def publish_control(self):
        """
        New Control Command
        """
        if not self.canmsg_received:
            print('No CAN Message Yet')
            return

        self.controlcmd.header.sequence_num = self.sequence_num
        self.sequence_num += 1

        if self.case == 'a':
            if self.cmd[0] > 0:
                self.controlcmd.throttle = self.cmd[0]
                self.controlcmd.brake = 0
            else:
                self.controlcmd.throttle = 0
                self.controlcmd.brake = -self.cmd[0]
            if self.vehicle_speed >= self.cmd[1]:
                self.case = 'd'
        elif self.case == 'd':
            if self.cmd[2] > 0:
                self.controlcmd.throttle = self.cmd[0]
                self.controlcmd.brake = 0
            else:
                self.controlcmd.throttle = 0
                self.controlcmd.brake = -self.cmd[2]
            if self.vehicle_speed == 0:
                self.in_session = False

        self.controlcmd.header.timestamp_sec = cyber_time.Time.now().to_sec()
        self.control_pub.write(self.controlcmd)
        self.write_file(self.controlcmd.header.timestamp_sec, 1)
        if self.in_session == False:
            self.file.close()

    def write_file(self, time, io):
        """
        Write Message to File
        """
        self.file.write(
            "%.4f,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\n" %
            (time, io, 1, self.controlcmd.brake, self.controlcmd.throttle,
             self.controlcmd.gear_location, self.vehicle_speed, self.engine_rpm,
             self.driving_mode, self.throttle_percentage, self.brake_percentage,
             self.gear_location, self.acceleration))


def main():
    """
    Main function
    """
    node = cyber.Node("data_collector")

    data_collector = DataCollector(node)
    plotter = Plotter()
    node.create_reader('/apollo/localization/pose',
                       localization_pb2.LocalizationEstimate,
                       data_collector.callback_localization)
    node.create_reader('/apollo/canbus/chassis', chassis_pb2.Chassis,
                       data_collector.callback_canbus)

    print('Enter q to quit.')
    print('Enter p to plot result from last run.')
    print('Enter x to remove result from last run.')
    print('Enter x y z, where x is acceleration command, ' +
          'y is speed limit, z is decceleration command.')
    print('Positive number for throttle and negative number for brake.')

    while True:
        cmd = input("Enter commands: ").split()
        if len(cmd) == 0:
            print('Quiting.')
            break
        elif len(cmd) == 1:
            if cmd[0] == "q":
                break
            elif cmd[0] == "p":
                print('Plotting result.')
                if os.path.exists(data_collector.outfile):
                    plotter.process_data(data_collector.outfile)
                    plotter.plot_result()
                else:
                    print('File does not exist: %s' % data_collector.outfile)
            elif cmd[0] == "x":
                print('Removing last result.')
                if os.path.exists(data_collector.outfile):
                    os.remove(data_collector.outfile)
                else:
                    print('File does not exist: %s' % date_collector.outfile)
        elif len(cmd) == 3:
            data_collector.run(cmd)


if __name__ == '__main__':
    cyber.init()
    main()
    cyber.shutdown()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This module provide function to plot the speed control info from log csv file
"""

import sys

import matplotlib.pyplot as plt
import numpy as np
import tkinter.filedialog

from modules.tools.vehicle_calibration.process import get_start_index
from modules.tools.vehicle_calibration.process import preprocess
from modules.tools.vehicle_calibration.process import process


class Plotter(object):
    """
    Plot the speed info
    """

    def __init__(self):
        """
        Init the speed info
        """
        np.set_printoptions(precision=3)
        self.file = open('temp_result.csv', 'a')

    def process_data(self, filename):
        """
        Load the file and preprocess th data
        """
        self.data = preprocess(filename)

        self.tablecmd, self.tablespeed, self.tableacc, self.speedsection, self.accsection, self.timesection = process(
            self.data)

    def plot_result(self):
        """
        Plot the desired data
        """
        fig, axarr = plt.subplots(2, 1, sharex=True)
        plt.tight_layout()
        fig.subplots_adjust(hspace=0)

        axarr[0].plot(
            self.data['time'], self.data['ctlbrake'], label='Brake CMD')
        axarr[0].plot(
            self.data['time'],
            self.data['brake_percentage'],
            label='Brake Output')
        axarr[0].plot(
            self.data['time'], self.data['ctlthrottle'], label='Throttle CMD')
        axarr[0].plot(
            self.data['time'],
            self.data['throttle_percentage'],
            label='Throttle Output')
        axarr[0].plot(
            self.data['time'],
            self.data['engine_rpm'] / 100,
            label='Engine RPM')
        axarr[0].legend(fontsize='medium')
        axarr[0].grid(True)
        axarr[0].set_title('Command')

        axarr[1].plot(
            self.data['time'],
            self.data['vehicle_speed'],
            label='Vehicle Speed')

        for i in range(len(self.timesection)):
            axarr[1].plot(
                self.timesection[i],
                self.speedsection[i],
                label='Speed Segment')
            axarr[1].plot(
                self.timesection[i], self.accsection[i], label='IMU Segment')

        axarr[1].legend(fontsize='medium')
        axarr[1].grid(True)
        axarr[1].set_title('Speed')

        mng = plt.get_current_fig_manager()
        mng.full_screen_toggle()

        # plt.tight_layout(pad=0.20)
        fig.canvas.mpl_connect('key_press_event', self.press)
        plt.show()

    def press(self, event):
        """
        Keyboard events during plotting
        """
        if event.key == 'q' or event.key == 'Q':
            self.file.close()
            plt.close()

        if event.key == 'w' or event.key == 'W':
            for i in range(len(self.tablecmd)):
                for j in range(len(self.tablespeed[i])):
                    self.file.write("%s, %s, %s\n" %
                                    (self.tablecmd[i], self.tablespeed[i][j],
                                     self.tableacc[i][j]))
            print("Finished writing results")


def main():
    """
    demo
    """
    if len(sys.argv) == 2:
        # Get the latest file
        file_path = sys.argv[1]
    else:
        file_path = tkinter.filedialog.askopenfilename(
            initialdir="/home/caros/.ros",
            filetypes=(("csv files", ".csv"), ("all files", "*.*")))
    print('File path: %s' % file_path)
    plotter = Plotter()
    plotter.process_data(file_path)
    print('Finished reading the file.')
    plotter.plot_result()


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
import sys

import matplotlib.pyplot as plt
import numpy as np
from matplotlib import cm as cmx
from matplotlib import colors as mcolors

markers = [
    "o", "v", "^", "<", ">", "1", "2", "3", "4", "8", "s", "p", "*", "+", "x",
    "d", "|", "_"
]

if len(sys.argv) < 2:
    print('Usage: %s result.csv' % sys.argv[0])
    sys.exit(0)

fn = sys.argv[1]

speed_table = {}
with open(fn, 'r') as f:
    for line in f:
        items = line.split(',')
        cmd = round(float(items[0]))
        speed = float(items[1])
        acc = round(float(items[2]), 2)
        if speed in speed_table:
            cmd_table = speed_table[speed]
            if cmd in cmd_table:
                cmd_table[cmd].append(acc)
            else:
                cmd_table[cmd] = [acc]
        else:
            cmd_table = {}
            cmd_table[cmd] = [acc]
            speed_table[speed] = cmd_table

for speed in speed_table:
    cmd_dict = speed_table[speed]
    speed_list = []
    acc_list = []
    for cmd in cmd_dict:
        for acc in cmd_dict[cmd]:
            speed_list.append(speed)
            acc_list.append(acc)
    plt.plot(speed_list, acc_list, 'b.')
plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import math
import sys

import matplotlib.pyplot as plt
import numpy as np
from matplotlib import cm as cmx
from matplotlib import colors as mcolors

markers = [
    "o", "v", "^", "<", ">", "1", "2", "3", "4", "8", "s", "p", "*", "+", "x",
    "d", "|", "_"
]

if len(sys.argv) < 2:
    print("Usage: python plot_results.py result.csv")
    sys.exit(0)

with open(sys.argv[1], 'r') as f:
    cmd_table = {}

    for line in f:
        items = line.split(',')
        cmd = round(float(items[0]))
        speed = float(items[1])
        acc = float(items[2])
        if cmd in cmd_table:
            speed_table = cmd_table[cmd]
            if speed in speed_table:
                speed_table[speed].append(acc)
            else:
                speed_table[speed] = [acc]
        else:
            speed_table = {}
            speed_table[speed] = [acc]
            cmd_table[cmd] = speed_table

NCURVES = len(cmd_table)
np.random.seed(101)
curves = [np.random.random(20) for i in range(NCURVES)]
values = list(range(NCURVES))
jet = cm = plt.get_cmap('brg')
cNorm = mcolors.Normalize(vmin=0, vmax=values[-1])
scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)

cnt = 0
cmds = list(cmd_table.keys())
cmds.sort()

fig, ax = plt.subplots()
for cmd in cmds:
    print('ctrl cmd = %s' % cmd)
    speed_table = cmd_table[cmd]
    X = []
    Y = []
    speeds = list(speed_table.keys())
    speeds.sort()
    for speed in speeds:
        X.append(speed)
        Y.append(np.mean(speed_table[speed]))
    colorVal = scalarMap.to_rgba(values[cnt])
    ax.plot(
        X,
        Y,
        c=colorVal,
        linestyle=':',
        marker=markers[cnt % len(markers)],
        label="cmd=" + str(cmd))
    cnt += 1

ax.legend(loc='upper center', shadow=True, bbox_to_anchor=(0.5, 1.1), ncol=5)

plt.ylabel("acc")
plt.xlabel("speed")
plt.grid()
plt.show()
#!/usr/bin/env python3

###############################################################################
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This module provides the preprocessing function of vehicle calibration data
"""
import os
import re
import shutil
import time

from absl import app
from absl import flags
from absl import logging
from datetime import datetime

from cyber.python.cyber_py3 import cyber
from modules.dreamview.proto import preprocess_table_pb2
from modules.tools.vehicle_calibration.sanity_check import sanity_check

flags.DEFINE_string('vehicle_type', '', 'The vehicle type to be calibrated')
flags.DEFINE_string('data_path', '/apollo/output', 'Default output data path')
flags.DEFINE_string('calibration_data_path',
                    '/apollo/modules/calibration/data',
                    'Default vehicle configuration file directory')
flags.DEFINE_string('config_file_name', 'vehicle_param.pb.txt',
                    'Default vehicle configuration file name')
flags.DEFINE_string('record_root_path', '/apollo/data/bag',
                    'Default record root path')
flags.DEFINE_integer(
    'record_num', 1, 'The number of record folders '
    'required for this calibration task')

FLAGS = flags.FLAGS


def main(argv):
    cyber.init("Preprocessor")
    preprocessor = Preprocessor()
    task_dir = preprocessor.create_tree()
    preprocessor.sanity_check_path(task_dir)
    cyber.shutdown()


class Preprocessor(object):
    def __init__(self):
        self.record_num = FLAGS.record_num
        self.vehicle_type = self.folder_case(FLAGS.vehicle_type)
        self.config_file = self.get_config_path()
        self.node = cyber.Node("vehicle_calibration_preprocessor")
        self.writer = self.node.create_writer("/apollo/dreamview/progress",
                                              preprocess_table_pb2.Progress,
                                              10)
        self.progress = preprocess_table_pb2.Progress()
        self.progress.percentage = 0.0
        self.progress.log_string = "Press the button to start preprocessing"

    @staticmethod
    def folder_case(str):
        """Convert a string from title case to folder case"""
        return "_".join(str.lower().split(" "))

    def create_if_not_exists(self, path):
        """Create dir if path does not exists"""
        try:
            if not os.path.exists(path):
                os.makedirs(path)
                self.log_and_publish(f'Sucessfully created {path}')
        except OSError:
            self.log_and_publish(f'Failed to create: {path}', 'error')

        return path

    def get_config_path(self):
        """Get the configuration file of the specified vehicle type"""
        return os.path.join(FLAGS.calibration_data_path, self.vehicle_type,
                            FLAGS.config_file_name)

    def get_records_info(self):
        """Get records required for calibration"""
        res = []
        for dir in os.listdir(FLAGS.record_root_path):
            match = re.match(r'(^\d{4}-\d{2}-\d{2})-(\d{2}-\d{2}-\d{2}_s$)',
                             dir)
            if match is not None:
                record_info = {}
                record_info['rel_path'] = match.group()
                record_info['abs_path'] = os.path.join(FLAGS.record_root_path,
                                                       match.group())
                record_info['prefix'] = match.group(1)
                res.append(record_info)
        if len(res) < self.record_num:
            self.log_and_publish(
                f'The number of records in {FLAGS.record_root_path} '
                f'is less than {self.record_num}', 'error')

        res = sorted(res, key=lambda record: record['rel_path'],
                     reverse=True)[:self.record_num]
        return res

    def log_and_publish(self,
                        str,
                        logging_level="info",
                        status=preprocess_table_pb2.Status.UNKNOWN):
        """Publish the str by cyber writer"""
        if logging_level == 'info':
            logging.info(str)
        elif logging_level == 'warn':
            logging.warn(str)
        elif logging_level == 'error':
            logging.error(str)
        elif logging_level == 'fatal':
            logging.fatal(str)
        else:
            logging.info(str)

        self.progress.log_string = str
        self.progress.status = status
        self.writer.write(self.progress)
        time.sleep(0.5)

    def create_tree(self):
        """Create file tree according to a specific order"""
        task_dir = self.create_if_not_exists(
            os.path.join(FLAGS.data_path,
                         'task' + datetime.now().strftime("-%Y-%m-%d-%H-%M")))
        vehicle_dir = self.create_if_not_exists(
            os.path.join(task_dir, self.vehicle_type))
        records_dir = self.create_if_not_exists(
            os.path.join(vehicle_dir, "Records"))
        shutil.copy(self.config_file, vehicle_dir)
        records_info = self.get_records_info()
        finished_records = 0
        self.progress.log_string = 'Start preprocessing...'

        for iter in records_info:
            sub_dir = self.create_if_not_exists(
                os.path.join(records_dir, iter['prefix']))
            shutil.copytree(iter['abs_path'],
                            os.path.join(sub_dir, iter['rel_path']))
            finished_records += 1
            self.progress.percentage = (
                finished_records / self.record_num) * 80.0
            self.writer.write(self.progress)

        self.log_and_publish(
            f'The file tree has been successfully created at {task_dir}.')
        return task_dir

    def sanity_check_path(self, path):
        """Sanity check wrapper"""
        result, log_str = sanity_check(path)
        if result is True:
            self.progress.percentage = 100.0
            self.progress.status = preprocess_table_pb2.Status.SUCCESS
        else:
            self.progress.status = preprocess_table_pb2.Status.FAIL
        self.progress.log_string = log_str
        self.writer.write(self.progress)
        time.sleep(0.5)


if __name__ == "__main__":
    app.run(main)
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This module provide function to plot the speed control info from log csv file
"""

import math
import warnings

import numpy as np
import scipy.signal as signal


warnings.simplefilter('ignore', np.RankWarning)

SPEED_INTERVAL = 0.2
SPEED_DELAY = 130  # Speed report delay relative to IMU information


def preprocess(filename):
    data = np.genfromtxt(filename, delimiter=',', names=True)
    data = data[np.where(data['io'] == 0)[0]]
    data = data[np.argsort(data['time'])]
    data['time'] = data['time'] - data['time'][get_start_index(data)]

    b, a = signal.butter(6, 0.05, 'low')
    data['imu'] = signal.filtfilt(b, a, data['imu'])

    data['imu'] = np.append(data['imu'][-SPEED_DELAY // 10:],
                            data['imu'][0:-SPEED_DELAY // 10])
    return data


def get_start_index(data):
    if np.all(data['vehicle_speed'] == 0):
        return 0

    start_ind = np.where(data['brake_percentage'] == 40)

    if len(start_ind[0] > 0):
        ind = start_ind[0][0]
        while ind < len(data):
            if data['brake_percentage'][ind] == 40:
                ind += 1
            else:
                break
        return ind
    else:
        ind = 0
        while ind < len(data):
            if abs(data['vehicle_speed'][ind]) < 0.01:
                ind += 1
            else:
                break
        return ind


def process(data):
    """
    process data
    """
    np.set_printoptions(precision=3)

    if np.all(data['vehicle_speed'] == 0):
        print("All Speed = 0")
        return [], [], [], [], [], []

    start_index = get_start_index(data)

    # print "Start index: ", start_index
    data = data[start_index:]
    data['time'] = data['time'] - data['time'][0]

    transition = np.where(
        np.logical_or(
            np.diff(data['ctlbrake']) != 0, np.diff(data['ctlthrottle']) != 0))[
                0]
    transition = np.insert(np.append(transition, len(data) - 1), 0, 0)
    # print "Transition indexes: ", transition

    speedsegments = []
    timesegments = []
    accsegments = []
    tablespeed = []
    tableacc = []
    tablecmd = []

    for i in range(len(transition) - 1):
        # print "process transition index:", data['time'][transition[i]], ":", data['time'][transition[i + 1]]
        speedsection = data['vehicle_speed'][transition[i]:transition[i +
                                                                      1] + 1]
        timesection = data['time'][transition[i]:transition[i + 1] + 1]
        brake = data['ctlbrake'][transition[i] + 1]
        throttle = data['ctlthrottle'][transition[i] + 1]
        imusection = data['imu'][transition[i]:transition[i + 1] + 1]
        if brake == 0 and throttle == 0:
            continue
        # print "Brake CMD: ", brake, " Throttle CMD: ", throttle
        firstindex = 0

        while speedsection[firstindex] == 0:
            firstindex += 1
        firstindex = max(firstindex - 2, 0)
        speedsection = speedsection[firstindex:]
        timesection = timesection[firstindex:]
        imusection = imusection[firstindex:]

        if speedsection[0] < speedsection[-1]:
            is_increase = True
            lastindex = np.argmax(speedsection)
        else:
            is_increase = False
            lastindex = np.argmin(speedsection)

        speedsection = speedsection[0:lastindex + 1]
        timesection = timesection[0:lastindex + 1]
        imusection = imusection[0:lastindex + 1]

        speedmin = np.min(speedsection)
        speedmax = np.max(speedsection)
        speedrange = np.arange(
            max(0, round(speedmin / SPEED_INTERVAL) * SPEED_INTERVAL),
            min(speedmax, 10.01), SPEED_INTERVAL)
        # print "Speed min, max", speedmin, speedmax, is_increase, firstindex, lastindex, speedsection[-1]
        accvalue = []
        for value in speedrange:
            val_ind = 0
            if is_increase:
                while val_ind < len(
                        speedsection) - 1 and value > speedsection[val_ind]:
                    val_ind += 1
            else:
                while val_ind < len(
                        speedsection) - 1 and value < speedsection[val_ind]:
                    val_ind += 1
            if val_ind == 0:
                imu_value = imusection[val_ind]
            else:
                slope = (imusection[val_ind] - imusection[val_ind - 1]) / (
                    speedsection[val_ind] - speedsection[val_ind - 1])
                imu_value = imusection[val_ind - 1] + slope * (
                    value - speedsection[val_ind - 1])
            accvalue.append(imu_value)

        if brake == 0:
            cmd = throttle
        else:
            cmd = -brake
        # print "Overall CMD: ", cmd
        # print "Time: ", timesection
        # print "Speed: ", speedrange
        # print "Acc: ", accvalue
        # print cmd
        tablecmd.append(cmd)
        tablespeed.append(speedrange)
        tableacc.append(accvalue)

        speedsegments.append(speedsection)
        accsegments.append(imusection)
        timesegments.append(timesection)

    return tablecmd, tablespeed, tableacc, speedsegments, accsegments, timesegments
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This module provide function to plot the speed control info from log csv file
"""

import math
import sys

import numpy as np
import tkinter.filedialog

from modules.tools.vehicle_calibration.process import get_start_index
from modules.tools.vehicle_calibration.process import preprocess
from modules.tools.vehicle_calibration.process import process


class Plotter(object):
    """
    plot the speed info
    """

    def __init__(self, filename):
        """
        init the speed info
        """

        np.set_printoptions(precision=3)
        self.file = open('result.csv', 'a')
        self.file_one = open(filename + ".result", 'w')

    def process_data(self, filename):
        """
        load the file and preprocess th data
        """

        self.data = preprocess(filename)

        self.tablecmd, self.tablespeed, self.tableacc, self.speedsection, self.accsection, self.timesection = process(
            self.data)

    def save_data(self):
        """
        save_data
        """
        for i in range(len(self.tablecmd)):
            for j in range(len(self.tablespeed[i])):
                self.file.write("%s, %s, %s\n" %
                                (self.tablecmd[i], self.tablespeed[i][j],
                                 self.tableacc[i][j]))
                self.file_one.write("%s, %s, %s\n" %
                                    (self.tablecmd[i], self.tablespeed[i][j],
                                     self.tableacc[i][j]))


def main():
    """
    demo
    """
    if len(sys.argv) == 2:
        # get the latest file
        file_path = sys.argv[1]
    else:
        file_path = tkinter.filedialog.askopenfilename(
            initialdir="/home/caros/.ros",
            filetypes=(("csv files", ".csv"), ("all files", "*.*")))
    plotter = Plotter(file_path)
    plotter.process_data(file_path)
    plotter.save_data()
    print('save result to:', file_path + ".result")


if __name__ == '__main__':
    main()
#!/usr/bin/env python3

###############################################################################
# Copyright 2017 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

import sys

import numpy as np

import modules.tools.common.proto_utils as proto_utils
from modules.control.proto import calibration_table_pb2
from modules.control.proto.control_conf_pb2 import ControlConf


def load_calibration_raw_data(fn):
    speed_table = {}
    with open(fn, 'r') as f:
        for line in f:
            items = line.split(',')
            cmd = round(float(items[0]))
            speed = float(items[1])
            acc = round(float(items[2]), 2)
            if speed in speed_table:
                cmd_table = speed_table[speed]
                if cmd in cmd_table:
                    cmd_table[cmd].append(acc)
                else:
                    cmd_table[cmd] = [acc]
            else:
                cmd_table = {}
                cmd_table[cmd] = [acc]
                speed_table[speed] = cmd_table

    for speed in speed_table:
        cmd_table = speed_table[speed]
        for cmd in cmd_table:
            cmd_table[cmd] = round(np.mean(cmd_table[cmd]), 2)
    # After this the acc_list converted to an average float number.

    speed_table2 = {}
    for speed in speed_table:
        cmd_table = speed_table[speed]
        acc_table = {}
        for cmd in cmd_table:
            acc = cmd_table[cmd]
            if acc in acc_table:
                acc_table[acc].append(cmd)
            else:
                acc_table[acc] = [cmd]
        speed_table2[speed] = acc_table

    return speed_table2


def load_calibration_raw_data_old(fn):
    speed_table = {}
    with open(fn, 'r') as f:
        for line in f:
            items = line.split(',')
            cmd = round(float(items[0]))
            speed = float(items[1])
            acc = round(float(items[2]), 2)
            if speed in speed_table:
                acc_table = speed_table[speed]
                if acc in acc_table:
                    acc_table[acc].append(cmd)
                else:
                    acc_table[acc] = [cmd]
            else:
                acc_table = {}
                acc_table[acc] = [cmd]
                speed_table[speed] = acc_table

    return speed_table


def get_calibration_table_pb(speed_table):
    calibration_table_pb = calibration_table_pb2.ControlCalibrationTable()
    speeds = list(speed_table.keys())
    speeds.sort()
    for speed in speeds:
        acc_table = speed_table[speed]
        accs = list(acc_table.keys())
        accs.sort()
        for acc in accs:
            cmds = acc_table[acc]
            cmd = np.mean(cmds)
            item = calibration_table_pb.calibration.add()
            item.speed = speed
            item.acceleration = acc
            item.command = cmd
    return calibration_table_pb


if __name__ == '__main__':
    if len(sys.argv) != 3:
        print("Usage: %s old_control_conf.pb.txt result.csv" % sys.argv[0])
        sys.exit(0)

    ctl_conf_pb = proto_utils.get_pb_from_text_file(sys.argv[1], ControlConf())
    speed_table_dict = load_calibration_raw_data(sys.argv[2])
    calibration_table_pb = get_calibration_table_pb(speed_table_dict)
    ctl_conf_pb.lon_controller_conf.calibration_table.CopyFrom(
        calibration_table_pb)

    with open('control_conf.pb.txt', 'w') as f:
        f.write(str(ctl_conf_pb))
#!/usr/bin/env python3

###############################################################################
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################
"""
This is a tool to sanity check the vechicle calibration files
"""
import fnmatch
import math
import os
import google.protobuf.text_format as text_format
from absl import logging

from cyber.python.cyber_py3.record import RecordReader
import modules.common.configs.proto.vehicle_config_pb2 as vehicle_config_pb2
import modules.tools.common.proto_utils as proto_utils
import modules.tools.common.file_utils as file_utils

# could be a list
ConfFile = 'vehicle_param.pb.txt'
CHASSIS_CHANNEL = '/apollo/canbus/chassis'
LOCALIZATION_CHANNEL = '/apollo/localization/pose'
CHANNELS = {CHASSIS_CHANNEL, LOCALIZATION_CHANNEL}


def is_record_file(path):
    """Naive check if a path is a record."""
    return path.endswith('.record') or fnmatch.fnmatch(path, '*.record.?????')


def get_vehicle(path):
    return [
        subdir for subdir in os.listdir(path)
        if os.path.isdir(os.path.join(path, subdir))
    ]


def missing_input_path(path):
    input_size = file_utils.getInputDirDataSize(path)
    if input_size == 0:
        return True
    return False


def list_records(path):
    logging.info("in list_records:%s" % path)
    records = []
    for (dirpath, _, filenames) in os.walk(path):
        logging.info('filenames: %s' % filenames)
        logging.info('dirpath %s' % dirpath)
        for filename in filenames:
            end_file = os.path.join(dirpath, filename)
            logging.info("end_files: %s" % end_file)
            if is_record_file(end_file):
                records.append(end_file)
    return records


def missing_file(path):
    vehicles = get_vehicle(path)
    logging.info(f'vehicles {vehicles}')
    result = []
    for vehicle in vehicles:
        # config file
        conf = os.path.join(path, vehicle, ConfFile)
        logging.info(f'vehicles conf {conf}')
        if not os.path.exists(conf):
            logging.error(f'Missing configuration file in {vehicle}')
            result.append(ConfFile)
        # record file
        logging.info("list of records:" %
                     list_records(os.path.join(path, vehicle)))
        if len(list_records(os.path.join(path, vehicle))) == 0:
            logging.error(f'No record files in {vehicle}')
            result.append('record')
        if len(result):
            return True, result
    return False, []


def parse_error(path):
    vehicles = get_vehicle(path)
    pb_value = vehicle_config_pb2.VehicleConfig()
    for vehicle in vehicles:
        conf = os.path.join(path, vehicle, ConfFile)
        try:
            proto_utils.get_pb_from_text_file(conf, pb_value)
            return False
        except text_format.ParseError:
            logging.error(
                f'Error: Cannot parse {conf} as binary or text proto')
            return True


def check_vehicle_id(conf):
    # print(conf.HasField('vehicle_id.other_unique_id'))
    vehicle_id = conf.vehicle_param.vehicle_id
    if vehicle_id.vin or vehicle_id.plate or vehicle_id.other_unique_id:
        return True
    logging.error('Error: No vehicle ID')
    return False


def missing_field(path):
    vehicles = get_vehicle(path)
    logging.info(f'vehicles in missing field: {vehicles}')
    result = []
    for vehicle in vehicles:
        conf_file = os.path.join(path, vehicle, ConfFile)
        logging.info(f'conf_file: {conf_file}')
        # reset for each vehicle to avoid overwrited
        pb_value = vehicle_config_pb2.VehicleConfig()
        conf = proto_utils.get_pb_from_text_file(conf_file, pb_value)
        logging.info(f'vehicles conf {conf}')
        if not check_vehicle_id(conf):
            result.append("vehicle_id")
        # required field
        fields = [
            conf.vehicle_param.brake_deadzone,
            conf.vehicle_param.throttle_deadzone,
            conf.vehicle_param.max_acceleration,
            conf.vehicle_param.max_deceleration
        ]
        # for value in conf.vehicle_param:
        # has field is always true since a default value is given
        for field in fields:
            if math.isnan(field):
                result.append(field)
        if len(result):
            return True, result
    return False, result


def missing_message_data(path, channels=CHANNELS):
    result = []
    for record in list_records(path):
        logging.info(f'reading records {record}')
        reader = RecordReader(record)
        for channel in channels:
            logging.info(f'has {reader.get_messagenumber(channel)} messages')
            if reader.get_messagenumber(channel) == 0:
                result.append(record)
    if len(result):
        return True, result
    return False, []


def sanity_check(input_folder):
    err_msg = None
    path_flag = missing_input_path(input_folder)
    field_flag, field_result = missing_field(input_folder)
    channel_flag, channel_result = missing_message_data(input_folder)
    file_flag, file_result = missing_file(input_folder)
    if path_flag:
        err_msg = f'Input path {input_folder} folder structure is wrong'
    if file_flag:
        err_msg = f'One or more files are missing in {input_folder}'
    elif parse_error(input_folder):
        err_msg = f'Config file cannot be parsed in {input_folder}'
    elif field_flag:
        err_msg = f'One or more fields are missing in {input_folder}'
    elif channel_flag:
        err_msg = (
            'Messages are missing in records channels apollo/chassis or '
            f'apollo/localization/pose, records are {channel_result}')
    else:
        info_msg = f'{input_folder} Passed sanity check.'
        logging.info(info_msg)
        return True, info_msg
    logging.error(err_msg)
    return False, err_msg
